{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pennylane as qml\n",
    "import torch\n",
    "from pennylane import numpy as np\n",
    "from pennylane.optimize import NesterovMomentumOptimizer\n",
    "from pennylane.operation import Tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "def data_load_and_process():\n",
    "    iris = load_iris()\n",
    "    X = iris.data\n",
    "    X = X / 4 * np.pi\n",
    "    Y = iris.target\n",
    "    return X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_qubits = 4\n",
    "num_classes = 3\n",
    "dev = qml.device(\"default.qubit\", wires = num_qubits)\n",
    "\n",
    "\n",
    "from pennylane.templates import AngleEmbedding\n",
    "from pennylane.templates.layers import StronglyEntanglingLayers\n",
    "\n",
    "@qml.qnode(dev)\n",
    "def circuit(weights, x):\n",
    "    AngleEmbedding(x, wires = range(num_qubits))\n",
    "    StronglyEntanglingLayers(weights, wires = range(num_qubits))\n",
    "    return qml.expval(qml.PauliZ(1)), qml.expval(qml.PauliZ(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def variational_classifier(params, x):\n",
    "    weights = params[0]\n",
    "    bias1 = params[1]\n",
    "    bias2 = params[2]\n",
    "    M1, M2 = circuit(weights, x)\n",
    "    M1_bias, M2_bias = M1 + bias1, M2 + bias2\n",
    "    prediction = 2 * M1_bias + M2_bias\n",
    "    return prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cost_fn(params, X, labels):\n",
    "    num_labels = len(labels)\n",
    "    loss = 0\n",
    "    predictions = [variational_classifier(params, x) for x in X]\n",
    "    for l,p in zip(labels, predictions):\n",
    "        loss += l * np.log(np.abs(p))\n",
    "    return -loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(labels, predictions):\n",
    "    acc = 0\n",
    "    for l,p in zip(labels, hard_predictions):\n",
    "        if np.abs(l - p) < 1e-2:\n",
    "            acc = acc + 1\n",
    "    acc = acc / len(labels)\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 20\n",
    "num_layers = 4\n",
    "steps = 100\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def training(num_layers, steps):\n",
    "    \n",
    "    weights = 0.01 * np.random.randn(num_layers, num_qubits, 3)\n",
    "    bias1 = 0.0\n",
    "    bias2 = 0.0\n",
    "    params = [weights, bias1, bias2]\n",
    "    \n",
    "    opt = qml.NesterovMomentumOptimizer(0.1)\n",
    "    \n",
    "    for i in range(steps):\n",
    "        batch_index = np.random.choice(len(X), size = batch_size)\n",
    "        \n",
    "        X_batch = X[batch_index]\n",
    "        Y_batch = Y[batch_index]\n",
    "        params, cost_new = opt.step_and_cost(lambda p: cost_fn(params, X_batch, Y_batch), params)  \n",
    "        \n",
    "        if i % 10 == 0:\n",
    "            print(\"iteration: \", i, \" cost: \", cost_new)\n",
    "        \n",
    "    return params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration:  0  cost:  81.01507371481308\n",
      "iteration:  10  cost:  55.381757792360176\n",
      "iteration:  20  cost:  45.21236157553546\n",
      "iteration:  30  cost:  87.39123981513406\n",
      "iteration:  40  cost:  55.88971467031096\n",
      "iteration:  50  cost:  85.08859236916295\n",
      "iteration:  60  cost:  73.21073436475585\n",
      "iteration:  70  cost:  74.69776836443545\n",
      "iteration:  80  cost:  58.323353966015745\n",
      "iteration:  90  cost:  43.50795816998282\n"
     ]
    }
   ],
   "source": [
    "X, Y = data_load_and_process()\n",
    "params = training(num_layers, steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tensor(-0.37710499, requires_grad=True), tensor(-0.1809945, requires_grad=True), tensor(-0.31522379, requires_grad=True), tensor(-0.19417406, requires_grad=True), tensor(-0.40219837, requires_grad=True), tensor(-0.22026651, requires_grad=True), tensor(-0.34297876, requires_grad=True), tensor(-0.29275031, requires_grad=True), tensor(-0.13144686, requires_grad=True), tensor(-0.19499271, requires_grad=True), tensor(-0.35525609, requires_grad=True), tensor(-0.23673058, requires_grad=True), tensor(-0.18314893, requires_grad=True), tensor(-0.26558135, requires_grad=True), tensor(-0.58041443, requires_grad=True), tensor(-0.33080225, requires_grad=True), tensor(-0.49295578, requires_grad=True), tensor(-0.37121118, requires_grad=True), tensor(-0.22060177, requires_grad=True), tensor(-0.36186294, requires_grad=True), tensor(-0.17818872, requires_grad=True), tensor(-0.34225684, requires_grad=True), tensor(-0.62765005, requires_grad=True), tensor(-0.14998748, requires_grad=True), tensor(-0.06005223, requires_grad=True), tensor(-0.12290173, requires_grad=True), tensor(-0.22753747, requires_grad=True), tensor(-0.31772345, requires_grad=True), tensor(-0.34687231, requires_grad=True), tensor(-0.18637693, requires_grad=True), tensor(-0.15620561, requires_grad=True), tensor(-0.28113899, requires_grad=True), tensor(-0.37963574, requires_grad=True), tensor(-0.43872699, requires_grad=True), tensor(-0.19315248, requires_grad=True), tensor(-0.35326747, requires_grad=True), tensor(-0.43333649, requires_grad=True), tensor(-0.40614754, requires_grad=True), tensor(-0.21101694, requires_grad=True), tensor(-0.29255891, requires_grad=True), tensor(-0.42745742, requires_grad=True), tensor(0.27527183, requires_grad=True), tensor(-0.31663093, requires_grad=True), tensor(-0.23148779, requires_grad=True), tensor(-0.07257442, requires_grad=True), tensor(-0.17853206, requires_grad=True), tensor(-0.29682291, requires_grad=True), tensor(-0.2742638, requires_grad=True), tensor(-0.35532559, requires_grad=True), tensor(-0.31241699, requires_grad=True), tensor(0.23157136, requires_grad=True), tensor(0.20723368, requires_grad=True), tensor(0.14347126, requires_grad=True), tensor(-0.29825779, requires_grad=True), tensor(0.04538671, requires_grad=True), tensor(0.06880573, requires_grad=True), tensor(0.17639754, requires_grad=True), tensor(-0.24185932, requires_grad=True), tensor(0.12601929, requires_grad=True), tensor(0.00520432, requires_grad=True), tensor(-0.66757379, requires_grad=True), tensor(0.1412841, requires_grad=True), tensor(-0.50747415, requires_grad=True), tensor(0.1015968, requires_grad=True), tensor(0.13335263, requires_grad=True), tensor(0.2133827, requires_grad=True), tensor(0.13280993, requires_grad=True), tensor(0.01325863, requires_grad=True), tensor(-0.2625554, requires_grad=True), tensor(-0.17116172, requires_grad=True), tensor(0.06791107, requires_grad=True), tensor(0.07402873, requires_grad=True), tensor(-0.08307469, requires_grad=True), tensor(0.07297494, requires_grad=True), tensor(0.13647407, requires_grad=True), tensor(0.16577279, requires_grad=True), tensor(0.05305192, requires_grad=True), tensor(0.05919891, requires_grad=True), tensor(0.09031611, requires_grad=True), tensor(-0.07774743, requires_grad=True), tensor(-0.26407897, requires_grad=True), tensor(-0.28140241, requires_grad=True), tensor(0.00790505, requires_grad=True), tensor(-0.00296445, requires_grad=True), tensor(0.13364558, requires_grad=True), tensor(0.21407817, requires_grad=True), tensor(0.15969711, requires_grad=True), tensor(-0.28449785, requires_grad=True), tensor(0.20097969, requires_grad=True), tensor(-0.14134881, requires_grad=True), tensor(-0.06863844, requires_grad=True), tensor(0.15382406, requires_grad=True), tensor(-0.07341329, requires_grad=True), tensor(-0.33428134, requires_grad=True), tensor(0.00562181, requires_grad=True), tensor(0.22550332, requires_grad=True), tensor(0.13818628, requires_grad=True), tensor(0.13585977, requires_grad=True), tensor(-0.11868005, requires_grad=True), tensor(0.07420905, requires_grad=True), tensor(0.0001556, requires_grad=True), tensor(-0.00954395, requires_grad=True), tensor(-0.00319709, requires_grad=True), tensor(0.00964275, requires_grad=True), tensor(-0.0121915, requires_grad=True), tensor(0.01695437, requires_grad=True), tensor(-0.06280321, requires_grad=True), tensor(-0.00871167, requires_grad=True), tensor(-0.00819829, requires_grad=True), tensor(0.02745542, requires_grad=True), tensor(-0.00756573, requires_grad=True), tensor(-0.00723772, requires_grad=True), tensor(-0.01705623, requires_grad=True), tensor(-0.01377581, requires_grad=True), tensor(-0.04640044, requires_grad=True), tensor(-0.08160031, requires_grad=True), tensor(0.01951255, requires_grad=True), tensor(0.08015475, requires_grad=True), tensor(-0.01106791, requires_grad=True), tensor(-0.20106876, requires_grad=True), tensor(-0.03582635, requires_grad=True), tensor(-0.01270181, requires_grad=True), tensor(0.00219393, requires_grad=True), tensor(-0.00830302, requires_grad=True), tensor(-0.01503663, requires_grad=True), tensor(0.00017198, requires_grad=True), tensor(0.0081881, requires_grad=True), tensor(0.03764925, requires_grad=True), tensor(-0.00926117, requires_grad=True), tensor(0.01882702, requires_grad=True), tensor(-0.00029732, requires_grad=True), tensor(0.0001476, requires_grad=True), tensor(-0.0134952, requires_grad=True), tensor(0.03259985, requires_grad=True), tensor(-0.01872376, requires_grad=True), tensor(0.00787506, requires_grad=True), tensor(-0.07749212, requires_grad=True), tensor(0.0261781, requires_grad=True), tensor(0.03999053, requires_grad=True), tensor(-0.02329457, requires_grad=True), tensor(-0.05332356, requires_grad=True), tensor(-0.08582514, requires_grad=True), tensor(-0.00954395, requires_grad=True), tensor(-0.01200102, requires_grad=True), tensor(-0.06514146, requires_grad=True), tensor(-0.06442849, requires_grad=True), tensor(-0.02675789, requires_grad=True), tensor(-0.00823367, requires_grad=True), tensor(-0.08716447, requires_grad=True), tensor(0.03217546, requires_grad=True)]\n"
     ]
    }
   ],
   "source": [
    "predictions = [variational_classifier(params, x) for x in X]\n",
    "print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2]\n"
     ]
    }
   ],
   "source": [
    "print(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
