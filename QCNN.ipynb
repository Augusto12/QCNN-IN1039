{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quantum Convolutional Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is an implementation of 8 Qubit QCNN circuit testing various ansatze."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pennylane as qml\n",
    "from pennylane import numpy as np\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# QCNN Circuit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here are various unitary ansatze to test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unitraies for Convolutional Layers \n",
    "def U_TTN(params, wires): # 2 params\n",
    "    qml.RY(params[0], wires = wires[0])\n",
    "    qml.RY(params[1], wires = wires[1])\n",
    "    qml.CNOT(wires = [wires[0], wires[1]])\n",
    "\n",
    "def U_5(params, wires): # 10 params\n",
    "    qml.RX(params[0], wires = wires[0])\n",
    "    qml.RX(params[1], wires = wires[1])\n",
    "    qml.RZ(params[2], wires = wires[0])\n",
    "    qml.RZ(params[3], wires = wires[1])\n",
    "    qml.CRZ(params[4], wires = [wires[1], wires[0]])\n",
    "    qml.CRZ(params[5], wires = [wires[0], wires[1]])\n",
    "    qml.RX(params[6], wires = wires[0])\n",
    "    qml.RX(params[7], wires = wires[1])\n",
    "    qml.RZ(params[8], wires = wires[0])\n",
    "    qml.RZ(params[9], wires = wires[1])\n",
    "    \n",
    "def U_6(params, wires): # 10 params\n",
    "    qml.RX(params[0], wires = wires[0])\n",
    "    qml.RX(params[1], wires = wires[1])\n",
    "    qml.RZ(params[2], wires = wires[0])\n",
    "    qml.RZ(params[3], wires = wires[1])\n",
    "    qml.CRX(params[4], wires = [wires[1], wires[0]])\n",
    "    qml.CRX(params[5], wires = [wires[0], wires[1]])\n",
    "    qml.RX(params[6], wires = wires[0])\n",
    "    qml.RX(params[7], wires = wires[1])\n",
    "    qml.RZ(params[8], wires = wires[0])\n",
    "    qml.RZ(params[9], wires = wires[1])\n",
    "\n",
    "def U_9(params, wires): # 2 params\n",
    "    qml.Hadamard(wires = wires[0])\n",
    "    qml.Hadamard(wires = wires[1])\n",
    "    qml.CZ(wires = [wires[0],wires[1]])\n",
    "    qml.RX(params[0], wires = wires[0])\n",
    "    qml.RX(params[1], wires = wires[1])\n",
    "\n",
    "def U_13(params, wires): # 6 params\n",
    "    qml.RY(params[0], wires = wires[0])\n",
    "    qml.RY(params[1], wires = wires[1])\n",
    "    qml.CRZ(params[2], wires = [wires[1], wires[0]])\n",
    "    qml.RY(params[3], wires = wires[0])\n",
    "    qml.RY(params[4], wires = wires[1])\n",
    "    qml.CRZ(params[5], wires = [wires[0], wires[1]])\n",
    "\n",
    "def U_14(params, wires): # 6 params\n",
    "    qml.RY(params[0], wires = wires[0])\n",
    "    qml.RY(params[1], wires = wires[1])\n",
    "    qml.CRX(params[2], wires = [wires[1], wires[0]])\n",
    "    qml.RY(params[3], wires = wires[0])\n",
    "    qml.RY(params[4], wires = wires[1])\n",
    "    qml.CRX(params[5], wires = [wires[0], wires[1]])\n",
    "\n",
    "def U_15(params, wires): # 4 params\n",
    "    qml.RY(params[0], wires = wires[0])\n",
    "    qml.RY(params[1], wires = wires[1])\n",
    "    qml.CNOT(wires = [wires[1], wires[0]])\n",
    "    qml.RY(params[2], wires = wires[0])\n",
    "    qml.RY(params[3], wires = wires[1])\n",
    "    qml.CNOT(wires = [wires[0], wires[1]])\n",
    "\n",
    "# Unitraies for Pooling and Fully Connected Layers\n",
    "def V_0(theta, wires):\n",
    "    qml.CRZ(theta, wires = [wires[0], wires[1]])\n",
    "\n",
    "def V_1(theta, wires):\n",
    "    qml.CRX(theta, wires = [wires[0], wires[1]])\n",
    "\n",
    "def F(theta, wires):\n",
    "    qml.CRZ(theta, wires = [wires[0], wires[1]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define general layers that will be used in the circuits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convolution Layer1\n",
    "def conv_layer1(U, params):\n",
    "    U(params, wires = [0,7])\n",
    "    for i in range (0,8,2):\n",
    "        U(params, wires = [i, i+1])\n",
    "    for i in range (1,7,2):\n",
    "        U(params, wires = [i, i+1])\n",
    "    \n",
    "def conv_layer2(U, params):\n",
    "    U(params, wires = [0,2])\n",
    "    U(params, wires = [4,6])\n",
    "    U(params, wires = [2,4])\n",
    "    U(params, wires = [0,6])\n",
    "    \n",
    "def pooling_layer1(V_0, V_1, params):\n",
    "    for i in range(0,8,2):\n",
    "        V_0(params[0], wires = [i+1, i])\n",
    "    for i in range(0,8,2):\n",
    "        qml.PauliX(wires = i+1)\n",
    "    for i in range(0,8,2):\n",
    "        V_1(params[1], wires = [i+1, i])\n",
    "        \n",
    "\n",
    "def pooling_layer2(V_0, V_1, params): # 2params\n",
    "    V_0(params[0], wires = [2,0])\n",
    "    V_0(params[0], wires = [6,4])\n",
    "    \n",
    "    qml.PauliX(wires = 2)\n",
    "    qml.PauliX(wires = 6)\n",
    "    \n",
    "    V_1(params[1], wires = [2,0])\n",
    "    V_1(params[1], wires = [6,4])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we define various possible embedding methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pennylane.templates.embeddings import AmplitudeEmbedding, AngleEmbedding\n",
    "\n",
    "def data_embedding(X, embedding_type = 'Amplitude'):\n",
    "    if embedding_type == 'Amplitude':\n",
    "        AmplitudeEmbedding(X, wires = range(8), normalize = True)\n",
    "    elif embedding_type == 'Angle':\n",
    "        AngleEmbedding(X, wires = range(8), rotation = 'Y')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define QCNN circuit with given Unitary Ansatz and embedding method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev = qml.device('default.qubit', wires = 8)\n",
    "\n",
    "@qml.qnode(dev)\n",
    "def QCNN(X, params, U, U_params, embedding_type = 'Amplitude'):\n",
    "\n",
    "    param1 = params[0:U_params]\n",
    "    param2 = params[U_params:U_params + 2]\n",
    "    param3 = params[U_params + 2: 2*U_params + 2]\n",
    "    param4 = params[2*U_params + 2: 2*U_params + 4]\n",
    "    param5 = params[2*U_params + 4]\n",
    "    \n",
    "    # Data Embedding\n",
    "    data_embedding(X, embedding_type = embedding_type)\n",
    "    \n",
    "    #Quantum Convolutional Neural Network\n",
    "    if U == 'U_TTN':\n",
    "        conv_layer1(U_TTN, param1)\n",
    "        pooling_layer1(V_0, V_1, param2)\n",
    "        conv_layer2(U_TTN, param3)\n",
    "        pooling_layer2(V_0, V_1, param4)\n",
    "        F(param5, wires = [0,4])\n",
    "        \n",
    "    elif U == 'U_5':\n",
    "        conv_layer1(U_5, param1)\n",
    "        pooling_layer1(V_0, V_1, param2)\n",
    "        conv_layer2(U_5, param3)\n",
    "        pooling_layer2(V_0, V_1, param4)\n",
    "        F(param5, wires = [0,4])\n",
    "        \n",
    "    elif U == 'U_6':\n",
    "        conv_layer1(U_6, param1)\n",
    "        pooling_layer1(V_0, V_1, param2)\n",
    "        conv_layer2(U_6, param3)\n",
    "        pooling_layer2(V_0, V_1, param4)\n",
    "        F(param5, wires = [0,4])\n",
    "        \n",
    "    elif U == 'U_9':\n",
    "        conv_layer1(U_9, param1)\n",
    "        pooling_layer1(V_0, V_1, param2)\n",
    "        conv_layer2(U_9, param3)\n",
    "        pooling_layer2(V_0, V_1, param4)\n",
    "        F(param5, wires = [0,4])\n",
    "        \n",
    "    elif U == 'U_13':\n",
    "        conv_layer1(U_13, param1)\n",
    "        pooling_layer1(V_0, V_1, param2)\n",
    "        conv_layer2(U_13, param3)\n",
    "        pooling_layer2(V_0, V_1, param4)\n",
    "        F(param5, wires = [0,4])\n",
    "        \n",
    "    elif U == 'U_14':\n",
    "        conv_layer1(U_14, param1)\n",
    "        pooling_layer1(V_0, V_1, param2)\n",
    "        conv_layer2(U_14, param3)\n",
    "        pooling_layer2(V_0, V_1, param4)\n",
    "        F(param5, wires = [0,4])\n",
    "        \n",
    "    elif U == 'U_15':\n",
    "        conv_layer1(U_15, param1)\n",
    "        pooling_layer1(V_0, V_1, param2)\n",
    "        conv_layer2(U_15, param3)\n",
    "        pooling_layer2(V_0, V_1, param4)\n",
    "        F(param5, wires = [0,4])\n",
    "        \n",
    "    return qml.expval(qml.PauliZ(4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Quantum Circuits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def square_loss(labels, predictions):\n",
    "    loss = 0\n",
    "    for l, p in zip(labels, predictions):\n",
    "        loss = loss + (l - p) ** 2\n",
    "\n",
    "    loss = loss / len(labels)\n",
    "    return loss\n",
    "\n",
    "def cost(params, X, Y, U, U_params, embedding_type):\n",
    "    predictions = [QCNN(x, params, U, U_params, embedding_type) for x in X]\n",
    "    return square_loss(Y, predictions)\n",
    "\n",
    "def accuracy_test(predictions, labels):\n",
    "    acc = 0\n",
    "    for l,p in zip(labels, predictions):\n",
    "        if np.abs(l - p) < 1:\n",
    "            acc = acc + 1\n",
    "    return acc / len(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def circuit_training(X_train, Y_train, U, U_params, embedding_type):\n",
    "    total_params = U_params * 2 + 2 * 2 + 1\n",
    "    params = np.random.randn(total_params)\n",
    "    steps = 100\n",
    "    learning_rate = 0.1\n",
    "    batch_size =25\n",
    "    opt = qml.NesterovMomentumOptimizer(learning_rate)\n",
    "    \n",
    "    for it in range(steps):\n",
    "        batch_index = np.random.randint(0, len(X_train), (batch_size,))\n",
    "        X_batch = [X_train[i] for i in batch_index]\n",
    "        Y_batch = [Y_train[i] for i in batch_index]\n",
    "        params, cost_new = opt.step_and_cost(lambda v: cost(v, X_batch, Y_batch, U, U_params, embedding_type), params)\n",
    "        if it % 10 == 0:\n",
    "            print(\"iteration: \", it, \" cost: \", cost_new)\n",
    "    return params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MNIST Data loading and processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from sklearn import decomposition\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, BatchNormalization, Activation\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras import layers, losses\n",
    "\n",
    "def data_load_and_process(classes = [0,1], feature_reduction = 'resize256'):\n",
    "    \n",
    "    (x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
    "    x_train, x_test = x_train[..., np.newaxis]/255.0, x_test[..., np.newaxis]/255.0 #normalize the data\n",
    "    \n",
    "    x_train_filter_01 = np.where((y_train == classes[0]) | (y_train == classes[1]))\n",
    "    x_test_filter_01 = np.where((y_test == classes[0]) | (y_test == classes[1]))\n",
    "    \n",
    "    x_train_01, x_test_01 = x_train[x_train_filter_01], x_test[x_test_filter_01]\n",
    "    y_train_01, y_test_01 = y_train[x_train_filter_01], y_test[x_test_filter_01]\n",
    "    \n",
    "    y_train_01 = [1 if y ==classes[0] else -1 for y in y_train_01]\n",
    "    y_test_01 = [1 if y ==classes[1] else -1 for y in y_test_01]\n",
    "    \n",
    "    if feature_reduction == 'resize256':   \n",
    "        x_train_01 = tf.image.resize(x_train_01[:], (256, 1)).numpy()\n",
    "        x_test_01 = tf.image.resize(x_test_01[:], (256, 1)).numpy()\n",
    "        x_train_01, x_test_01 = tf.squeeze(x_train_01), tf.squeeze(x_test_01) \n",
    "        return x_train_01, x_test_01, y_train_01, y_test_01\n",
    "    \n",
    "    elif feature_reduction == 'pca8':\n",
    "        x_train_01 = tf.image.resize(x_train_01[:], (784, 1)).numpy()\n",
    "        x_test_01 = tf.image.resize(x_test_01[:], (784, 1)).numpy()\n",
    "        x_train_01, x_test_01 = tf.squeeze(x_train_01), tf.squeeze(x_test_01)\n",
    "        \n",
    "        pca = PCA(8)\n",
    "        x_train_01 = pca.fit_transform(x_train_01)\n",
    "        x_test_01 = pca.transform(x_test_01) \n",
    "        return x_train_01, x_test_01, y_train_01, y_test_01\n",
    "\n",
    "    elif feature_reduction == 'autoencoder8':\n",
    "        latent_dim = 8 \n",
    "        class Autoencoder(Model):\n",
    "            def __init__(self, latent_dim):\n",
    "                super(Autoencoder, self).__init__()\n",
    "                self.latent_dim = latent_dim   \n",
    "                self.encoder = tf.keras.Sequential([\n",
    "                layers.Flatten(),\n",
    "                  layers.Dense(latent_dim, activation='relu'),\n",
    "                ])\n",
    "                self.decoder = tf.keras.Sequential([\n",
    "                layers.Dense(784, activation='sigmoid'),\n",
    "                layers.Reshape((28, 28))\n",
    "                ])\n",
    "            def call(self, x):\n",
    "                encoded = self.encoder(x)\n",
    "                decoded = self.decoder(encoded)\n",
    "                return decoded\n",
    "\n",
    "        autoencoder = Autoencoder(latent_dim)\n",
    "        \n",
    "        autoencoder.compile(optimizer='adam', loss=losses.MeanSquaredError())\n",
    "        autoencoder.fit(x_train_01, x_train_01,\n",
    "                epochs=10,\n",
    "                shuffle=True,\n",
    "                validation_data=(x_test_01, x_test_01))\n",
    "        \n",
    "        x_train_01, x_test_01 = autoencoder.encoder(x_train_01).numpy(), autoencoder.encoder(x_test_01).numpy()\n",
    "        return x_train_01, x_test_01, y_train_01, y_test_01\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use PCA and Autoencoder to reduce it into 8 features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "Unitaries = ['U_TTN', 'U_5', 'U_6', 'U_9', 'U_13', 'U_14', 'U_15']\n",
    "U_num_params = [2, 10, 10, 4, 6, 6, 4]\n",
    "Encodings = ['resize256', 'pca8', 'autoencoder8']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 12665 samples, validate on 2115 samples\n",
      "Epoch 1/10\n",
      "12665/12665 [==============================] - 1s 62us/sample - loss: 0.0640 - val_loss: 0.0346\n",
      "Epoch 2/10\n",
      "12665/12665 [==============================] - 1s 41us/sample - loss: 0.0300 - val_loss: 0.0272\n",
      "Epoch 3/10\n",
      "12665/12665 [==============================] - 1s 40us/sample - loss: 0.0260 - val_loss: 0.0242\n",
      "Epoch 4/10\n",
      "12665/12665 [==============================] - 1s 41us/sample - loss: 0.0232 - val_loss: 0.0220\n",
      "Epoch 5/10\n",
      "12665/12665 [==============================] - 1s 40us/sample - loss: 0.0217 - val_loss: 0.0209\n",
      "Epoch 6/10\n",
      "12665/12665 [==============================] - 1s 40us/sample - loss: 0.0209 - val_loss: 0.0203\n",
      "Epoch 7/10\n",
      "12665/12665 [==============================] - 1s 48us/sample - loss: 0.0203 - val_loss: 0.0197\n",
      "Epoch 8/10\n",
      "12665/12665 [==============================] - 1s 46us/sample - loss: 0.0198 - val_loss: 0.0193\n",
      "Epoch 9/10\n",
      "12665/12665 [==============================] - 1s 41us/sample - loss: 0.0194 - val_loss: 0.0189\n",
      "Epoch 10/10\n",
      "12665/12665 [==============================] - 1s 42us/sample - loss: 0.0190 - val_loss: 0.0185\n",
      "WARNING:tensorflow:Layer flatten_1 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer flatten_1 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "x_train_resize256, x_test_resize256, y_train_resize256, y_test_resize256 = data_load_and_process(classes = [0,1], feature_reduction = 'resize256')\n",
    "x_train_pca8, x_test_pca8, y_train_pca8, y_test_pca8 = data_load_and_process(classes = [0,1], feature_reduction = 'pca8')\n",
    "x_train_autoencoder8, x_test_autoencoder8, y_train_autoencoder8, y_test_autoencoder8 = data_load_and_process(classes = [0,1], feature_reduction = 'autoencoder8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Loss History for U_TTN resize256\n",
      "iteration:  0  cost:  1.0942672649744019\n",
      "iteration:  10  cost:  0.8531428899961425\n",
      "iteration:  20  cost:  0.7873782303591627\n",
      "iteration:  30  cost:  0.7461528416652592\n",
      "iteration:  40  cost:  0.6980639428506551\n",
      "iteration:  50  cost:  0.6975354376885243\n",
      "iteration:  60  cost:  0.727635809626079\n",
      "iteration:  70  cost:  0.7030198372359991\n",
      "iteration:  80  cost:  0.6423794458980574\n",
      "iteration:  90  cost:  0.6891742354525557\n",
      "Accuracy for U_TTN resize256 :0.15555555555555556\n",
      "\n",
      "\n",
      "Loss History for U_TTN pca8\n",
      "iteration:  0  cost:  0.9746653475415564\n",
      "iteration:  10  cost:  1.046105677817918\n",
      "iteration:  20  cost:  1.027484537498441\n",
      "iteration:  30  cost:  1.0159608709191443\n",
      "iteration:  40  cost:  0.9638455832074588\n",
      "iteration:  50  cost:  0.9188259550799254\n",
      "iteration:  60  cost:  0.9871963402266046\n",
      "iteration:  70  cost:  0.969281733018343\n",
      "iteration:  80  cost:  0.9271242124286451\n",
      "iteration:  90  cost:  0.964488033443634\n",
      "Accuracy for U_TTN pca8 :0.40709219858156026\n",
      "\n",
      "\n",
      "Loss History for U_TTN autoencoder8\n",
      "iteration:  0  cost:  1.0333896272174767\n",
      "iteration:  10  cost:  0.9371454210073138\n",
      "iteration:  20  cost:  1.0411714889930292\n",
      "iteration:  30  cost:  0.9205330219832516\n",
      "iteration:  40  cost:  1.038583378327743\n",
      "iteration:  50  cost:  0.8974471264729448\n",
      "iteration:  60  cost:  1.0225661503533139\n",
      "iteration:  70  cost:  0.9758950678567503\n",
      "iteration:  80  cost:  0.9962493718953422\n",
      "iteration:  90  cost:  1.070717249621615\n",
      "Accuracy for U_TTN autoencoder8 :0.4846335697399527\n",
      "\n",
      "\n",
      "Loss History for U_5 resize256\n",
      "iteration:  0  cost:  0.87351505269578\n",
      "iteration:  10  cost:  0.5086276980626098\n",
      "iteration:  20  cost:  0.5336552752020078\n",
      "iteration:  30  cost:  0.6265680373093211\n",
      "iteration:  40  cost:  0.39123053305015776\n",
      "iteration:  50  cost:  0.3617534027399499\n",
      "iteration:  60  cost:  0.4520628904413816\n",
      "iteration:  70  cost:  0.4289866573449116\n",
      "iteration:  80  cost:  0.4263885853606397\n",
      "iteration:  90  cost:  0.6091032186063638\n",
      "Accuracy for U_5 resize256 :0.08321513002364066\n",
      "\n",
      "\n",
      "Loss History for U_5 pca8\n",
      "iteration:  0  cost:  1.086995327225504\n",
      "iteration:  10  cost:  0.9957087053816683\n",
      "iteration:  20  cost:  0.8905610426703201\n",
      "iteration:  30  cost:  0.8178625074647665\n",
      "iteration:  40  cost:  0.8388955672803269\n",
      "iteration:  50  cost:  0.7824875153086327\n",
      "iteration:  60  cost:  0.848595002541412\n",
      "iteration:  70  cost:  0.8738266635033323\n",
      "iteration:  80  cost:  0.7668660357718491\n",
      "iteration:  90  cost:  0.7344209512169639\n",
      "Accuracy for U_5 pca8 :0.275177304964539\n",
      "\n",
      "\n",
      "Loss History for U_5 autoencoder8\n",
      "iteration:  0  cost:  1.4370089712534466\n",
      "iteration:  10  cost:  1.1509024922218354\n",
      "iteration:  20  cost:  0.9839476541977272\n",
      "iteration:  30  cost:  1.0101562826702455\n",
      "iteration:  40  cost:  0.9871278832003191\n",
      "iteration:  50  cost:  0.9934737298766142\n",
      "iteration:  60  cost:  0.9905938823306444\n",
      "iteration:  70  cost:  1.1042544814748663\n",
      "iteration:  80  cost:  0.9868825596170825\n",
      "iteration:  90  cost:  0.8902416631678114\n",
      "Accuracy for U_5 autoencoder8 :0.41134751773049644\n",
      "\n",
      "\n",
      "Loss History for U_6 resize256\n",
      "iteration:  0  cost:  0.9810889349554338\n",
      "iteration:  10  cost:  0.6374093125695941\n",
      "iteration:  20  cost:  0.506929729700601\n",
      "iteration:  30  cost:  0.48153084302727345\n",
      "iteration:  40  cost:  0.4084490580053982\n",
      "iteration:  50  cost:  0.43225872574131374\n",
      "iteration:  60  cost:  0.39386094170390734\n",
      "iteration:  70  cost:  0.32153190120504754\n",
      "iteration:  80  cost:  0.35553173928942283\n",
      "iteration:  90  cost:  0.36540999818050746\n",
      "Accuracy for U_6 resize256 :0.02033096926713948\n",
      "\n",
      "\n",
      "Loss History for U_6 pca8\n",
      "iteration:  0  cost:  1.6793824806075002\n",
      "iteration:  10  cost:  0.8569055113819621\n",
      "iteration:  20  cost:  0.8766463942673494\n",
      "iteration:  30  cost:  0.7997547719270852\n",
      "iteration:  40  cost:  0.8097830736509991\n",
      "iteration:  50  cost:  0.804840068755498\n",
      "iteration:  60  cost:  0.769253970924291\n",
      "iteration:  70  cost:  0.883566819121199\n",
      "iteration:  80  cost:  0.9171198745955286\n",
      "iteration:  90  cost:  0.803306012254827\n",
      "Accuracy for U_6 pca8 :0.33522458628841606\n",
      "\n",
      "\n",
      "Loss History for U_6 autoencoder8\n",
      "iteration:  0  cost:  1.0229867439484588\n",
      "iteration:  10  cost:  0.9450356977423253\n",
      "iteration:  20  cost:  0.9694716001939429\n",
      "iteration:  30  cost:  0.9683643712648474\n",
      "iteration:  40  cost:  0.955651321725718\n",
      "iteration:  50  cost:  0.9166840980206729\n",
      "iteration:  60  cost:  0.7540944748563523\n",
      "iteration:  70  cost:  0.9807892823560068\n",
      "iteration:  80  cost:  0.8223720213596282\n",
      "iteration:  90  cost:  0.7989917688611213\n",
      "Accuracy for U_6 autoencoder8 :0.32056737588652484\n",
      "\n",
      "\n",
      "Loss History for U_9 resize256\n",
      "iteration:  0  cost:  0.9915583384578042\n",
      "iteration:  10  cost:  0.875336812858183\n",
      "iteration:  20  cost:  0.8453721535805068\n",
      "iteration:  30  cost:  0.8197168951913726\n",
      "iteration:  40  cost:  0.7472034624889274\n",
      "iteration:  50  cost:  0.8401341793902816\n",
      "iteration:  60  cost:  0.8147714891821127\n",
      "iteration:  70  cost:  0.7929108888917145\n",
      "iteration:  80  cost:  0.7779404371518922\n",
      "iteration:  90  cost:  0.7906905881100315\n",
      "Accuracy for U_9 resize256 :0.14184397163120568\n",
      "\n",
      "\n",
      "Loss History for U_9 pca8\n",
      "iteration:  0  cost:  0.9966155737106215\n",
      "iteration:  10  cost:  1.0145423161091855\n",
      "iteration:  20  cost:  0.9891800822072692\n",
      "iteration:  30  cost:  0.9966820755904974\n",
      "iteration:  40  cost:  0.9987808359418249\n",
      "iteration:  50  cost:  0.8939046018092957\n",
      "iteration:  60  cost:  0.9742617581783122\n",
      "iteration:  70  cost:  0.9549084812488989\n",
      "iteration:  80  cost:  0.9792039853146498\n",
      "iteration:  90  cost:  0.9259197363438726\n",
      "Accuracy for U_9 pca8 :0.44349881796690305\n",
      "\n",
      "\n",
      "Loss History for U_9 autoencoder8\n",
      "iteration:  0  cost:  1.0054641787894483\n",
      "iteration:  10  cost:  0.9722554992038189\n",
      "iteration:  20  cost:  1.0312671513224259\n",
      "iteration:  30  cost:  1.0115618399201716\n",
      "iteration:  40  cost:  0.9970870674330985\n",
      "iteration:  50  cost:  0.9791430458643055\n",
      "iteration:  60  cost:  0.990696791502431\n",
      "iteration:  70  cost:  0.9842564345542131\n",
      "iteration:  80  cost:  0.9961267988657333\n",
      "iteration:  90  cost:  1.0139227245269726\n",
      "Accuracy for U_9 autoencoder8 :0.47375886524822697\n",
      "\n",
      "\n",
      "Loss History for U_13 resize256\n",
      "iteration:  0  cost:  1.6812050501024567\n",
      "iteration:  10  cost:  0.9507772635517664\n",
      "iteration:  20  cost:  1.0024416765115272\n",
      "iteration:  30  cost:  0.8291487352627578\n",
      "iteration:  40  cost:  0.6666169541194296\n",
      "iteration:  50  cost:  0.622181294733284\n",
      "iteration:  60  cost:  0.6208590287197416\n",
      "iteration:  70  cost:  0.5681678628112528\n",
      "iteration:  80  cost:  0.6274519956117092\n",
      "iteration:  90  cost:  0.5578468836772688\n",
      "Accuracy for U_13 resize256 :0.07281323877068557\n",
      "\n",
      "\n",
      "Loss History for U_13 pca8\n",
      "iteration:  0  cost:  1.5135197249845058\n",
      "iteration:  10  cost:  1.3623725404998535\n",
      "iteration:  20  cost:  0.808842083643809\n",
      "iteration:  30  cost:  0.88373106151199\n",
      "iteration:  40  cost:  0.6879368285227995\n",
      "iteration:  50  cost:  0.8343700104059496\n",
      "iteration:  60  cost:  0.8560114351886032\n",
      "iteration:  70  cost:  0.8511699210910513\n",
      "iteration:  80  cost:  0.7870548146805046\n",
      "iteration:  90  cost:  0.7853365314710782\n",
      "Accuracy for U_13 pca8 :0.31631205673758866\n",
      "\n",
      "\n",
      "Loss History for U_13 autoencoder8\n",
      "iteration:  0  cost:  1.1507974830667518\n",
      "iteration:  10  cost:  1.0135979367066517\n",
      "iteration:  20  cost:  1.1745609260136565\n",
      "iteration:  30  cost:  1.1924941225672472\n",
      "iteration:  40  cost:  0.9922545371384425\n",
      "iteration:  50  cost:  0.8792776045729198\n",
      "iteration:  60  cost:  0.8973605283703898\n",
      "iteration:  70  cost:  0.8697741397844426\n",
      "iteration:  80  cost:  0.8879005686946115\n",
      "iteration:  90  cost:  0.8809892213170728\n",
      "Accuracy for U_13 autoencoder8 :0.3900709219858156\n",
      "\n",
      "\n",
      "Loss History for U_14 resize256\n",
      "iteration:  0  cost:  1.015464338617644\n",
      "iteration:  10  cost:  0.8789585021752445\n",
      "iteration:  20  cost:  0.7912954393325127\n",
      "iteration:  30  cost:  0.8791611925767667\n",
      "iteration:  40  cost:  0.7194262296166761\n",
      "iteration:  50  cost:  0.7276082970237876\n",
      "iteration:  60  cost:  0.64175197527615\n",
      "iteration:  70  cost:  0.6006958774834671\n",
      "iteration:  80  cost:  0.5260534849961116\n",
      "iteration:  90  cost:  0.5214830934002245\n",
      "Accuracy for U_14 resize256 :0.03735224586288416\n",
      "\n",
      "\n",
      "Loss History for U_14 pca8\n",
      "iteration:  0  cost:  1.3870175790370889\n",
      "iteration:  10  cost:  0.9863361314801224\n",
      "iteration:  20  cost:  0.8848820368261996\n",
      "iteration:  30  cost:  1.0507009880152045\n",
      "iteration:  40  cost:  0.9570859701075602\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration:  50  cost:  0.8941169959995452\n",
      "iteration:  60  cost:  0.9131950857114964\n",
      "iteration:  70  cost:  0.6347706463054172\n",
      "iteration:  80  cost:  1.0025654080905404\n",
      "iteration:  90  cost:  0.7496178193503394\n",
      "Accuracy for U_14 pca8 :0.32907801418439714\n",
      "\n",
      "\n",
      "Loss History for U_14 autoencoder8\n",
      "iteration:  0  cost:  1.5964540766920303\n",
      "iteration:  10  cost:  1.1958022408925195\n",
      "iteration:  20  cost:  1.137576306851333\n",
      "iteration:  30  cost:  1.103143024504743\n",
      "iteration:  40  cost:  0.9044117193541353\n",
      "iteration:  50  cost:  0.9403079976271786\n",
      "iteration:  60  cost:  0.9385615930162322\n",
      "iteration:  70  cost:  0.8417815234948374\n",
      "iteration:  80  cost:  0.7891746881478877\n",
      "iteration:  90  cost:  0.982912851848127\n",
      "Accuracy for U_14 autoencoder8 :0.3177304964539007\n",
      "\n",
      "\n",
      "Loss History for U_15 resize256\n",
      "iteration:  0  cost:  0.6214040636756165\n",
      "iteration:  10  cost:  0.6165501428963386\n",
      "iteration:  20  cost:  0.544737023102904\n",
      "iteration:  30  cost:  0.41421216408930767\n",
      "iteration:  40  cost:  0.4417434550104557\n",
      "iteration:  50  cost:  0.3585625335824274\n",
      "iteration:  60  cost:  0.38791935717891557\n",
      "iteration:  70  cost:  0.4028986497711938\n",
      "iteration:  80  cost:  0.41013021039164405\n",
      "iteration:  90  cost:  0.29847225005584915\n",
      "Accuracy for U_15 resize256 :0.010874704491725768\n",
      "\n",
      "\n",
      "Loss History for U_15 pca8\n",
      "iteration:  0  cost:  0.9978027265071716\n",
      "iteration:  10  cost:  0.9312047317785536\n",
      "iteration:  20  cost:  0.9786538894644541\n",
      "iteration:  30  cost:  0.8556459816848809\n",
      "iteration:  40  cost:  0.748560700542767\n",
      "iteration:  50  cost:  0.5565130637878732\n",
      "iteration:  60  cost:  0.9742406763956011\n",
      "iteration:  70  cost:  1.0075733759322891\n",
      "iteration:  80  cost:  0.9675045391955175\n",
      "iteration:  90  cost:  0.7896253706627722\n",
      "Accuracy for U_15 pca8 :0.3366430260047281\n",
      "\n",
      "\n",
      "Loss History for U_15 autoencoder8\n",
      "iteration:  0  cost:  1.035193490899881\n",
      "iteration:  10  cost:  0.9325259931323078\n",
      "iteration:  20  cost:  0.8599740608061042\n",
      "iteration:  30  cost:  0.6921740414981926\n",
      "iteration:  40  cost:  0.8799000899857312\n",
      "iteration:  50  cost:  0.8216964483996501\n",
      "iteration:  60  cost:  0.9828817539565401\n",
      "iteration:  70  cost:  0.9574798510958786\n",
      "iteration:  80  cost:  0.8214955241945404\n",
      "iteration:  90  cost:  0.6365812187646473\n",
      "Accuracy for U_15 autoencoder8 :0.3219858156028369\n"
     ]
    }
   ],
   "source": [
    "I = len(Unitaries)\n",
    "J = len(Encodings)\n",
    "All_predictions = []\n",
    "\n",
    "for i in range(I):\n",
    "    for j in range(J):\n",
    "        U = Unitaries[i]\n",
    "        U_params = U_num_params[i]\n",
    "        Encoding = Encodings[j]\n",
    "        if Encoding == 'resize256':\n",
    "            Embedding = 'Amplitude'\n",
    "            X_train, X_test, Y_train, Y_test = x_train_resize256, x_test_resize256, y_train_resize256, y_test_resize256\n",
    "        elif Encoding == 'pca8':\n",
    "            Embedding = 'Angle'\n",
    "            X_train, X_test, Y_train, Y_test = x_train_pca8, x_test_pca8, y_train_pca8, y_test_pca8\n",
    "        elif Encoding == 'autoencoder8':\n",
    "            Embedding = 'Angle'\n",
    "            X_train, X_test, Y_train, Y_test = x_train_autoencoder8, x_test_autoencoder8, y_train_autoencoder8, y_test_autoencoder8\n",
    "        \n",
    "        print(\"\\n\")\n",
    "        print(\"Loss History for \" + U + \" \" + Encoding)\n",
    "        trained_params = circuit_training(X_train, Y_train, U, U_params, Embedding)\n",
    "\n",
    "        predictions = [QCNN(x, trained_params, U, U_params, Embedding) for x in X_test]\n",
    "        All_predictions.append(predictions)\n",
    "        accuracy = accuracy_test(predictions, Y_test)\n",
    "        print(\"Accuracy for \" + U + \" \" + Encoding + \" :\" + str(accuracy))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
