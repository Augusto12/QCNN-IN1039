{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quantum Convolutional Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is an implementation of 8 Qubit QCNN circuit (Quantum Convolutional Neural Networks by Iris Cong et al, 2019) and Tree Tensor Network circuit (Hierarchical Quantum Classifier by Ed Grant et al, 2018) with the comparisons among various ansatze."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leeseok/.local/lib/python3.7/site-packages/pandas/compat/__init__.py:97: UserWarning: Could not import the lzma module. Your installed Python is incomplete. Attempting to use lzma compression will result in a RuntimeError.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "import pennylane as qml\n",
    "from pennylane import numpy as np\n",
    "import statistics as st\n",
    "import random\n",
    "import os\n",
    "np.random.seed(0)\n",
    "\n",
    "import sklearn.datasets\n",
    "import tensorflow as tf\n",
    "#import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# QCNN Circuit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here are various unitary ansatze to test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unitraies for Convolutional Layers \n",
    "def U_TTN(params, wires): # 2 params\n",
    "    qml.RY(params[0], wires = wires[0])\n",
    "    qml.RY(params[1], wires = wires[1])\n",
    "    qml.CNOT(wires = [wires[0], wires[1]])\n",
    "\n",
    "def U_5(params, wires): # 10 params\n",
    "    qml.RX(params[0], wires = wires[0])\n",
    "    qml.RX(params[1], wires = wires[1])\n",
    "    qml.RZ(params[2], wires = wires[0])\n",
    "    qml.RZ(params[3], wires = wires[1])\n",
    "    qml.CRZ(params[4], wires = [wires[1], wires[0]])\n",
    "    qml.CRZ(params[5], wires = [wires[0], wires[1]])\n",
    "    qml.RX(params[6], wires = wires[0])\n",
    "    qml.RX(params[7], wires = wires[1])\n",
    "    qml.RZ(params[8], wires = wires[0])\n",
    "    qml.RZ(params[9], wires = wires[1])\n",
    "    \n",
    "def U_6(params, wires): # 10 params\n",
    "    qml.RX(params[0], wires = wires[0])\n",
    "    qml.RX(params[1], wires = wires[1])\n",
    "    qml.RZ(params[2], wires = wires[0])\n",
    "    qml.RZ(params[3], wires = wires[1])\n",
    "    qml.CRX(params[4], wires = [wires[1], wires[0]])\n",
    "    qml.CRX(params[5], wires = [wires[0], wires[1]])\n",
    "    qml.RX(params[6], wires = wires[0])\n",
    "    qml.RX(params[7], wires = wires[1])\n",
    "    qml.RZ(params[8], wires = wires[0])\n",
    "    qml.RZ(params[9], wires = wires[1])\n",
    "\n",
    "def U_9(params, wires): # 2 params\n",
    "    qml.Hadamard(wires = wires[0])\n",
    "    qml.Hadamard(wires = wires[1])\n",
    "    qml.CZ(wires = [wires[0],wires[1]])\n",
    "    qml.RX(params[0], wires = wires[0])\n",
    "    qml.RX(params[1], wires = wires[1])\n",
    "\n",
    "def U_13(params, wires): # 6 params\n",
    "    qml.RY(params[0], wires = wires[0])\n",
    "    qml.RY(params[1], wires = wires[1])\n",
    "    qml.CRZ(params[2], wires = [wires[1], wires[0]])\n",
    "    qml.RY(params[3], wires = wires[0])\n",
    "    qml.RY(params[4], wires = wires[1])\n",
    "    qml.CRZ(params[5], wires = [wires[0], wires[1]])\n",
    "\n",
    "def U_14(params, wires): # 6 params\n",
    "    qml.RY(params[0], wires = wires[0])\n",
    "    qml.RY(params[1], wires = wires[1])\n",
    "    qml.CRX(params[2], wires = [wires[1], wires[0]])\n",
    "    qml.RY(params[3], wires = wires[0])\n",
    "    qml.RY(params[4], wires = wires[1])\n",
    "    qml.CRX(params[5], wires = [wires[0], wires[1]])\n",
    "\n",
    "def U_15(params, wires): # 4 params\n",
    "    qml.RY(params[0], wires = wires[0])\n",
    "    qml.RY(params[1], wires = wires[1])\n",
    "    qml.CNOT(wires = [wires[1], wires[0]])\n",
    "    qml.RY(params[2], wires = wires[0])\n",
    "    qml.RY(params[3], wires = wires[1])\n",
    "    qml.CNOT(wires = [wires[0], wires[1]])\n",
    "\n",
    "def U_SO4(params, wires): # 6 params\n",
    "    qml.RY(params[0], wires = wires[0])\n",
    "    qml.RY(params[1], wires = wires[1])\n",
    "    qml.CNOT(wires = [wires[0], wires[1]])\n",
    "    qml.RY(params[2], wires = wires[0])\n",
    "    qml.RY(params[3], wires = wires[1])\n",
    "    qml.CNOT(wires = [wires[0], wires[1]])\n",
    "    qml.RY(params[4], wires = wires[0])\n",
    "    qml.RY(params[5], wires = wires[1])\n",
    "\n",
    "# Unitraies for Pooling and Fully Connected Layers\n",
    "def V_0(theta, wires):\n",
    "    qml.CRZ(theta, wires = [wires[0], wires[1]])\n",
    "\n",
    "def V_1(theta, wires):\n",
    "    qml.CRX(theta, wires = [wires[0], wires[1]])\n",
    "\n",
    "def F(theta, wires):\n",
    "    qml.CRZ(theta, wires = [wires[0], wires[1]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is general circuit structures used in Quantum Convolutional Neural Network (QCNN) circuits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convolution Layer1\n",
    "def conv_layer1(U, params):\n",
    "    U(params, wires = [0,7])\n",
    "    for i in range (0,8,2):\n",
    "        U(params, wires = [i, i+1])\n",
    "    for i in range (1,7,2):\n",
    "        U(params, wires = [i, i+1])\n",
    "    \n",
    "def conv_layer2(U, params):\n",
    "    U(params, wires = [0,2])\n",
    "    U(params, wires = [4,6])\n",
    "    U(params, wires = [2,4])\n",
    "    U(params, wires = [0,6])\n",
    "    \n",
    "def pooling_layer1(V_0, V_1, params):\n",
    "    for i in range(0,8,2):\n",
    "        V_0(params[0], wires = [i+1, i])\n",
    "    for i in range(0,8,2):\n",
    "        qml.PauliX(wires = i+1)\n",
    "    for i in range(0,8,2):\n",
    "        V_1(params[1], wires = [i+1, i])\n",
    "        \n",
    "\n",
    "def pooling_layer2(V_0, V_1, params): # 2params\n",
    "    V_0(params[0], wires = [2,0])\n",
    "    V_0(params[0], wires = [6,4])\n",
    "    \n",
    "    qml.PauliX(wires = 2)\n",
    "    qml.PauliX(wires = 6)\n",
    "    \n",
    "    V_1(params[1], wires = [2,0])\n",
    "    V_1(params[1], wires = [6,4])\n",
    "    \n",
    "def pooling_layer3(V_0, V_1, params):\n",
    "    V_0(params[0], wires = [0,4])\n",
    "    qml.PauliX(wires = 0)\n",
    "    V_1(params[1], wires = [0,4])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we define various possible embedding methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pennylane.templates.embeddings import AmplitudeEmbedding, AngleEmbedding\n",
    "\n",
    "def data_embedding(X, embedding_type = 'Amplitude'):\n",
    "    if embedding_type == 'Amplitude':\n",
    "        AmplitudeEmbedding(X, wires = range(8), normalize = True)\n",
    "    elif embedding_type == 'Angle':\n",
    "        AngleEmbedding(X, wires = range(8), rotation = 'Y')\n",
    "    elif embedding_type == \"Compact\":\n",
    "        AngleEmbedding(X[:8], wires = range(8), rotation = 'X')\n",
    "        AngleEmbedding(X[8:], wires = range(8), rotation = 'Y')\n",
    "        #AngleEmbedding(X[16:], wires = range(8), rotation = 'Z')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define QCNN circuit with given Unitary Ansatz and embedding method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev = qml.device('default.qubit', wires = 8)\n",
    "\n",
    "@qml.qnode(dev)\n",
    "def QCNN(X, params, U, U_params, embedding_type = 'Amplitude'):\n",
    "\n",
    "    param1 = params[0:U_params]\n",
    "    param2 = params[U_params:U_params + 2]\n",
    "    param3 = params[U_params + 2: 2*U_params + 2]\n",
    "    param4 = params[2*U_params + 2: 2*U_params + 4]\n",
    "    param5 = params[2*U_params + 4: 3*U_params + 4]\n",
    "    param6 = params[3*U_params+4:]\n",
    "    \n",
    "    # Data Embedding\n",
    "    data_embedding(X, embedding_type = embedding_type)\n",
    "    \n",
    "    #Quantum Convolutional Neural Network\n",
    "    if U == 'U_TTN':\n",
    "        conv_layer1(U_TTN, param1)\n",
    "        pooling_layer1(V_0, V_1, param2)\n",
    "        conv_layer2(U_TTN, param3)\n",
    "        pooling_layer2(V_0, V_1, param4)\n",
    "        U_TTN(param5, wires = [0,4])\n",
    "        pooling_layer3(V_0, V_1, param6)\n",
    "        \n",
    "    elif U == 'U_5':\n",
    "        conv_layer1(U_5, param1)\n",
    "        pooling_layer1(V_0, V_1, param2)\n",
    "        conv_layer2(U_5, param3)\n",
    "        pooling_layer2(V_0, V_1, param4)\n",
    "        U_5(param5, wires = [0,4])\n",
    "        pooling_layer3(V_0, V_1, param6)\n",
    "        \n",
    "    elif U == 'U_6':\n",
    "        conv_layer1(U_6, param1)\n",
    "        pooling_layer1(V_0, V_1, param2)\n",
    "        conv_layer2(U_6, param3)\n",
    "        pooling_layer2(V_0, V_1, param4)\n",
    "        U_6(param5, wires = [0,4])\n",
    "        pooling_layer3(V_0, V_1, param6)\n",
    "        \n",
    "    elif U == 'U_9':\n",
    "        conv_layer1(U_9, param1)\n",
    "        pooling_layer1(V_0, V_1, param2)\n",
    "        conv_layer2(U_9, param3)\n",
    "        pooling_layer2(V_0, V_1, param4)\n",
    "        U_9(param5, wires = [0,4])\n",
    "        pooling_layer3(V_0, V_1, param6)\n",
    "        \n",
    "    elif U == 'U_13':\n",
    "        conv_layer1(U_13, param1)\n",
    "        pooling_layer1(V_0, V_1, param2)\n",
    "        conv_layer2(U_13, param3)\n",
    "        pooling_layer2(V_0, V_1, param4)\n",
    "        U_13(param5, wires = [0,4])\n",
    "        pooling_layer3(V_0, V_1, param6)\n",
    "        \n",
    "    elif U == 'U_14':\n",
    "        conv_layer1(U_14, param1)\n",
    "        pooling_layer1(V_0, V_1, param2)\n",
    "        conv_layer2(U_14, param3)\n",
    "        pooling_layer2(V_0, V_1, param4)\n",
    "        U_14(param5, wires = [0,4])\n",
    "        pooling_layer3(V_0, V_1, param6)\n",
    "        \n",
    "    elif U == 'U_15':\n",
    "        conv_layer1(U_15, param1)\n",
    "        pooling_layer1(V_0, V_1, param2)\n",
    "        conv_layer2(U_15, param3)\n",
    "        pooling_layer2(V_0, V_1, param4)\n",
    "        U_15(param5, wires = [0,4])\n",
    "        pooling_layer3(V_0, V_1, param6) \n",
    "        \n",
    "    elif U == 'U_SO4':\n",
    "        conv_layer1(U_SO4, param1)\n",
    "        pooling_layer1(V_0, V_1, param2)\n",
    "        conv_layer2(U_SO4, param3)\n",
    "        pooling_layer2(V_0, V_1, param4)\n",
    "        U_SO4(param5, wires = [0,4])\n",
    "        pooling_layer3(V_0, V_1, param6)    \n",
    "        \n",
    "    return qml.expval(qml.PauliZ(4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is Hierarchical Quantum Classifier structure with different Ansatze"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_TTN = qml.device('default.qubit', wires = 8)\n",
    "\n",
    "@qml.qnode(dev_TTN)\n",
    "def Hierarchical_classifier(X, params, U, U_params, embedding_type = 'Amplitude'):\n",
    "    \n",
    "    param1 = params[0 * U_params:1 * U_params]\n",
    "    param2 = params[1 * U_params:2 * U_params]\n",
    "    param3 = params[2 * U_params:3 * U_params]\n",
    "    param4 = params[3 * U_params:4 * U_params]\n",
    "    param5 = params[4 * U_params:5 * U_params]\n",
    "    param6 = params[5 * U_params:6 * U_params]\n",
    "    param7 = params[6 * U_params:7 * U_params]\n",
    "    \n",
    "    data_embedding(X, embedding_type = embedding_type)\n",
    "    ['U_TTN', 'U_5', 'U_6', 'U_13', 'U_14', 'U_15', 'U_SO4'] \n",
    "    if U == 'U_TTN':\n",
    "        # layer 1\n",
    "        U_TTN(param1, wires = [0,1])\n",
    "        U_TTN(param2, wires = [2,3])\n",
    "        U_TTN(param3, wires = [4,5])\n",
    "        U_TTN(param4, wires = [6,7])\n",
    "        # layer 2\n",
    "        U_TTN(param5, wires = [1,3])\n",
    "        U_TTN(param6, wires = [5,7])\n",
    "        # layer 3\n",
    "        U_TTN(param7, wires = [3,7])\n",
    "    elif U == 'U_5':\n",
    "        # layer 1\n",
    "        U_5(param1, wires = [0,1])\n",
    "        U_5(param2, wires = [2,3])\n",
    "        U_5(param3, wires = [4,5])\n",
    "        U_5(param4, wires = [6,7])\n",
    "        # layer 2\n",
    "        U_5(param5, wires = [1,3])\n",
    "        U_5(param6, wires = [5,7])\n",
    "        # layer 3\n",
    "        U_5(param7, wires = [3,7])\n",
    "    elif U == 'U_6':\n",
    "        # layer 1\n",
    "        U_6(param1, wires = [0,1])\n",
    "        U_6(param2, wires = [2,3])\n",
    "        U_6(param3, wires = [4,5])\n",
    "        U_6(param4, wires = [6,7])\n",
    "        # layer 2\n",
    "        U_6(param5, wires = [1,3])\n",
    "        U_6(param6, wires = [5,7])\n",
    "        # layer 3\n",
    "        U_6(param7, wires = [3,7])\n",
    "    elif U == 'U_13':\n",
    "        # layer 1\n",
    "        U_13(param1, wires = [0,1])\n",
    "        U_13(param2, wires = [2,3])\n",
    "        U_13(param3, wires = [4,5])\n",
    "        U_13(param4, wires = [6,7])\n",
    "        # layer 2\n",
    "        U_13(param5, wires = [1,3])\n",
    "        U_13(param6, wires = [5,7])\n",
    "        # layer 3\n",
    "        U_13(param7, wires = [3,7])\n",
    "    elif U == 'U_14':\n",
    "        # layer 1\n",
    "        U_14(param1, wires = [0,1])\n",
    "        U_14(param2, wires = [2,3])\n",
    "        U_14(param3, wires = [4,5])\n",
    "        U_14(param4, wires = [6,7])\n",
    "        # layer 2\n",
    "        U_14(param5, wires = [1,3])\n",
    "        U_14(param6, wires = [5,7])\n",
    "        # layer 3\n",
    "        U_14(param7, wires = [3,7])\n",
    "    elif U == 'U_15':\n",
    "        # layer 1\n",
    "        U_15(param1, wires = [0,1])\n",
    "        U_15(param2, wires = [2,3])\n",
    "        U_15(param3, wires = [4,5])\n",
    "        U_15(param4, wires = [6,7])\n",
    "        # layer 2\n",
    "        U_15(param5, wires = [1,3])\n",
    "        U_15(param6, wires = [5,7])\n",
    "        # layer 3\n",
    "        U_15(param7, wires = [3,7])\n",
    "    elif U == 'U_SO4':\n",
    "        # layer 1\n",
    "        U_SO4(param1, wires = [0,1])\n",
    "        U_SO4(param2, wires = [2,3])\n",
    "        U_SO4(param3, wires = [4,5])\n",
    "        U_SO4(param4, wires = [6,7])\n",
    "        # layer 2\n",
    "        U_SO4(param5, wires = [1,3])\n",
    "        U_SO4(param6, wires = [5,7])\n",
    "        # layer 3\n",
    "        U_SO4(param7, wires = [3,7])\n",
    "    \n",
    "\n",
    "    return qml.expval(qml.PauliZ(7))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Quantum Circuits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def square_loss(labels, predictions):\n",
    "    loss = 0\n",
    "    for l, p in zip(labels, predictions):\n",
    "        loss = loss + (l - p) ** 2\n",
    "\n",
    "    loss = loss / len(labels)\n",
    "    return loss\n",
    "\n",
    "def cost(params, X, Y, U, U_params, embedding_type, circuit):\n",
    "    if circuit == 'QCNN':\n",
    "        predictions = [QCNN(x, params, U, U_params, embedding_type) for x in X]\n",
    "    elif circuit == 'Hierarchical':\n",
    "        predictions = [Hierarchical_classifier(x, params, U, U_params, embedding_type) for x in X]\n",
    "    \n",
    "    return square_loss(Y, predictions)\n",
    "\n",
    "def accuracy_test_binary(predictions, labels):\n",
    "    acc = 0\n",
    "    for l,p in zip(labels, predictions):\n",
    "        if np.abs(l - p) < 1:\n",
    "            acc = acc + 1\n",
    "    return acc / len(labels)\n",
    "\n",
    "def accuracy_test_one_class(predictions, labels):\n",
    "    acc = 0\n",
    "    for l,p in zip(labels, predictions):\n",
    "        if np.abs(l - p) < 0.5:\n",
    "            acc = acc + 1\n",
    "    return acc / len(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def circuit_training(X_train, Y_train, X_val, Y_val, U, U_params, embedding_type, circuit):\n",
    "    if circuit == 'QCNN':\n",
    "        total_params = U_params * 3 + 2 * 3\n",
    "    elif circuit == 'Hierarchical':\n",
    "        total_params = U_params * 7\n",
    "        \n",
    "    params = np.random.randn(total_params)\n",
    "    steps = 400\n",
    "    learning_rate = 0.01\n",
    "    batch_size = 25\n",
    "    opt = qml.NesterovMomentumOptimizer(learning_rate)\n",
    "    validation=[]\n",
    "    \n",
    "    for it in range(steps):\n",
    "        batch_index = np.random.randint(0, len(X_train), (batch_size,))\n",
    "        X_batch = [X_train[i] for i in batch_index]\n",
    "        Y_batch = [Y_train[i] for i in batch_index]\n",
    "        params, cost_new = opt.step_and_cost(lambda v: cost(v, X_batch, Y_batch, U, U_params, embedding_type, circuit), params)\n",
    "        \n",
    "        if it % 10 == 0:\n",
    "            predictions = [QCNN(x, params, U, U_params, embedding_type) for x in X_val]\n",
    "            validation.append(accuracy_test_binary(predictions, Y_val))\n",
    "            print(validation)\n",
    "            \n",
    "            if len(validation) > 3:\n",
    "                if (validation[it//10] < validation[it//10 - 3]) & (validation[it//10] < validation[it//10 - 2]) & (validation[it//10] < validation[it//10 - 1]):\n",
    "                    break\n",
    "                    \n",
    "        print(\"iteration: \", it, \" cost: \", cost_new)\n",
    "        \n",
    "        \n",
    "    return params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MNIST Data loading and processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use PCA and Autoencoder to reduce it into 8 features. We test both one-class classification (labeling 0 and 1) and binary classification (labeling -1 and 1)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from sklearn import decomposition\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, BatchNormalization, Activation\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras import layers, losses\n",
    "\n",
    "def data_load_and_process(classes = [0,1], feature_reduction = 'resize256', binary = True):\n",
    "    \n",
    "    (x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
    "    x_train, x_test = x_train[..., np.newaxis]/255.0, x_test[..., np.newaxis]/255.0 #normalize the data\n",
    "    \n",
    "    x_train_filter_01 = np.where((y_train == classes[0]) | (y_train == classes[1]))\n",
    "    x_test_filter_01 = np.where((y_test == classes[0]) | (y_test == classes[1]))\n",
    "    \n",
    "    x_train_01, x_test_01 = x_train[x_train_filter_01], x_test[x_test_filter_01]\n",
    "    y_train_01, y_test_01 = y_train[x_train_filter_01], y_test[x_test_filter_01]\n",
    "    \n",
    "    if binary == False:\n",
    "        y_train_01 = [1 if y ==classes[0] else 0 for y in y_train_01]\n",
    "        y_test_01 = [1 if y ==classes[0] else 0 for y in y_test_01]\n",
    "    elif binary == True:\n",
    "        y_train_01 = [1 if y ==classes[0] else -1 for y in y_train_01]\n",
    "        y_test_01 = [1 if y ==classes[0] else -1 for y in y_test_01]\n",
    "        \n",
    "    \n",
    "    if feature_reduction == 'resize256':   \n",
    "        x_train_01 = tf.image.resize(x_train_01[:], (256, 1)).numpy()\n",
    "        x_test_01 = tf.image.resize(x_test_01[:], (256, 1)).numpy()\n",
    "        x_train_01, x_test_01 = tf.squeeze(x_train_01), tf.squeeze(x_test_01) \n",
    "        return x_train_01, x_test_01, y_train_01, y_test_01\n",
    "    \n",
    "    elif feature_reduction == 'pca8':\n",
    "        x_train_01 = tf.image.resize(x_train_01[:], (784, 1)).numpy()\n",
    "        x_test_01 = tf.image.resize(x_test_01[:], (784, 1)).numpy()\n",
    "        x_train_01, x_test_01 = tf.squeeze(x_train_01), tf.squeeze(x_test_01)\n",
    "        \n",
    "        pca = PCA(8)\n",
    "        x_train_01 = pca.fit_transform(x_train_01)\n",
    "        x_test_01 = pca.transform(x_test_01)\n",
    "        \n",
    "        #Rescale for angle embedding\n",
    "        x_train_01, x_test_01 = (x_train_01 + 10) * (np.pi / 20), (x_test_01 + 10) * (np.pi / 20)\n",
    "        \n",
    "        return x_train_01, x_test_01, y_train_01, y_test_01\n",
    "    \n",
    "    elif feature_reduction == 'pca16':\n",
    "        x_train_01 = tf.image.resize(x_train_01[:], (784, 1)).numpy()\n",
    "        x_test_01 = tf.image.resize(x_test_01[:], (784, 1)).numpy()\n",
    "        x_train_01, x_test_01 = tf.squeeze(x_train_01), tf.squeeze(x_test_01)\n",
    "        \n",
    "        pca = PCA(16)\n",
    "        x_train_01 = pca.fit_transform(x_train_01)\n",
    "        x_test_01 = pca.transform(x_test_01)\n",
    "        \n",
    "        #Rescale for angle embedding\n",
    "        x_train_01, x_test_01 = (x_train_01 + 10) * (np.pi / 20), (x_test_01 + 10) * (np.pi / 20)\n",
    "        \n",
    "        return x_train_01, x_test_01, y_train_01, y_test_01\n",
    "\n",
    "    elif feature_reduction == 'autoencoder8':\n",
    "        latent_dim = 8 \n",
    "        class Autoencoder(Model):\n",
    "            def __init__(self, latent_dim):\n",
    "                super(Autoencoder, self).__init__()\n",
    "                self.latent_dim = latent_dim   \n",
    "                self.encoder = tf.keras.Sequential([\n",
    "                layers.Flatten(),\n",
    "                  layers.Dense(latent_dim, activation='relu'),\n",
    "                ])\n",
    "                self.decoder = tf.keras.Sequential([\n",
    "                layers.Dense(784, activation='sigmoid'),\n",
    "                layers.Reshape((28, 28))\n",
    "                ])\n",
    "            def call(self, x):\n",
    "                encoded = self.encoder(x)\n",
    "                decoded = self.decoder(encoded)\n",
    "                return decoded\n",
    "        \n",
    "        autoencoder = Autoencoder(latent_dim)\n",
    "        \n",
    "        autoencoder.compile(optimizer='adam', loss=losses.MeanSquaredError())\n",
    "        autoencoder.fit(x_train_01, x_train_01,\n",
    "                epochs=10,\n",
    "                shuffle=True,\n",
    "                validation_data=(x_test_01, x_test_01))\n",
    "        \n",
    "        x_train_01, x_test_01 = autoencoder.encoder(x_train_01).numpy(), autoencoder.encoder(x_test_01).numpy()\n",
    "        #Rescale for Angle Embedding\n",
    "        x_train_01, x_test_01 = x_train_01 * (np.pi / 50), x_test_01 * (np.pi / 50)\n",
    "        \n",
    "        return x_train_01, x_test_01, y_train_01, y_test_01\n",
    "    \n",
    "    elif feature_reduction == 'autoencoder16':\n",
    "        latent_dim = 16 \n",
    "        class Autoencoder(Model):\n",
    "            def __init__(self, latent_dim):\n",
    "                super(Autoencoder, self).__init__()\n",
    "                self.latent_dim = latent_dim   \n",
    "                self.encoder = tf.keras.Sequential([\n",
    "                layers.Flatten(),\n",
    "                  layers.Dense(latent_dim, activation='relu'),\n",
    "                ])\n",
    "                self.decoder = tf.keras.Sequential([\n",
    "                layers.Dense(784, activation='sigmoid'),\n",
    "                layers.Reshape((28, 28))\n",
    "                ])\n",
    "            def call(self, x):\n",
    "                encoded = self.encoder(x)\n",
    "                decoded = self.decoder(encoded)\n",
    "                return decoded\n",
    "        \n",
    "        autoencoder = Autoencoder(latent_dim)\n",
    "        \n",
    "        autoencoder.compile(optimizer='adam', loss=losses.MeanSquaredError())\n",
    "        autoencoder.fit(x_train_01, x_train_01,\n",
    "                epochs=10,\n",
    "                shuffle=True,\n",
    "                validation_data=(x_test_01, x_test_01))\n",
    "        \n",
    "        x_train_01, x_test_01 = autoencoder.encoder(x_train_01).numpy(), autoencoder.encoder(x_test_01).numpy()\n",
    "        #Rescale for Angle Embedding\n",
    "        x_train_01, x_test_01 = x_train_01 * (np.pi / 50), x_test_01 * (np.pi / 50)\n",
    "        \n",
    "        return x_train_01, x_test_01, y_train_01, y_test_01"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Benchmarking function trains and performs accuracy tests for all the given unitary ansatze, feature reduction methods, and circuit structures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Benchmarking(Unitaries, U_num_params, Encodings, circuit, binary = True):\n",
    "    I = len(Unitaries)\n",
    "    J = len(Encodings)\n",
    "    All_predictions = []\n",
    "\n",
    "    accuracy_list = []\n",
    "    \n",
    "    for step in range(5):\n",
    "        print(str(step) + \"th step : \")\n",
    "        for i in range(I):\n",
    "            for j in range(J):\n",
    "                U = Unitaries[i]\n",
    "                U_params = U_num_params[i]\n",
    "                Encoding = Encodings[j]\n",
    "                if Encoding == 'resize256':\n",
    "                    Embedding = 'Amplitude'\n",
    "                    X_train, X_test, Y_train, Y_test = data_load_and_process(classes = classes, feature_reduction = 'resize256', binary = binary)\n",
    "                elif Encoding == 'pca8':\n",
    "                    Embedding = 'Angle'\n",
    "                    X_train, X_test, Y_train, Y_test = data_load_and_process(classes = classes, feature_reduction = 'pca8', binary = binary)\n",
    "                elif Encoding == 'pca16':\n",
    "                    Embedding = 'Compact'\n",
    "                    X_train, X_test, Y_train, Y_test = data_load_and_process(classes = classes, feature_reduction = 'pca16', binary = binary)\n",
    "                elif Encoding == 'autoencoder8':\n",
    "                    Embedding = 'Angle'\n",
    "                    X_train, X_test, Y_train, Y_test = data_load_and_process(classes = classes, feature_reduction = 'autoencoder8', binary = binary)\n",
    "                elif Encoding == 'autoencoder16':\n",
    "                    Embedding = 'Compact'\n",
    "                    X_train, X_test, Y_train, Y_test = data_load_and_process(classes = classes, feature_reduction = 'autoencoder16', binary = binary)\n",
    "\n",
    "                    \n",
    "                #Make validation data by randomly extracting 1000 data from X_train, Y_train\n",
    "                randomlist = random.sample(range(0, len(X_train)), 500)\n",
    "                X_val = [X_train[r] for r in randomlist]\n",
    "                Y_val = [Y_train[r] for r in randomlist]\n",
    "                \n",
    "                X_train = [i for j, i in enumerate(X_train) if j not in randomlist]\n",
    "                Y_train = [i for j, i in enumerate(Y_train) if j not in randomlist]\n",
    "                \n",
    "                print(\"\\n\")\n",
    "                print(\"Loss History for \" + circuit + \" circuits, \"+ U + \" \" + Encoding)\n",
    "                trained_params = circuit_training(X_train, Y_train, X_val, Y_val, U, U_params, Embedding, circuit)\n",
    "\n",
    "                if circuit == 'QCNN':\n",
    "                    predictions = [QCNN(x, trained_params, U, U_params, Embedding) for x in X_test]\n",
    "                elif circuit == 'Hierarchical':\n",
    "                    predictions = [Hierarchical_classifier(x, trained_params, U, U_params, Embedding) for x in X_test]\n",
    "\n",
    "\n",
    "                if binary == True:\n",
    "                    accuracy = accuracy_test_binary(predictions, Y_test)\n",
    "                elif binary == False:\n",
    "                    accuracy = accuracy_test_one_class(predictions, Y_test)\n",
    "                \n",
    "                accuracy_list.append(accuracy) #store results\n",
    "\n",
    "                print(\"Accuracy for \" + U + \" \" + Encoding + \" :\" + str(accuracy))\n",
    "                \n",
    "    print(accuracy_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Results for QCNN circuit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.1 Binary Classification with 1, -1 labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "Unitaries = ['U_TTN', 'U_5', 'U_6', 'U_9', 'U_13', 'U_14', 'U_15', 'U_SO4'] \n",
    "U_num_params = [2, 10, 10, 2, 6, 6, 4, 6]\n",
    "Encodings = ['resize256', 'pca8', 'pca16', 'autoencoder8', 'autoencoder16']\n",
    "classes = [0,1]\n",
    "circuit = 'QCNN'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0th step : \n",
      "\n",
      "\n",
      "Loss History for QCNN circuits, U_TTN resize256\n",
      "[0.544]\n",
      "iteration:  0  cost:  0.9268568666490181\n",
      "iteration:  1  cost:  0.9165087067919642\n",
      "iteration:  2  cost:  0.9494373721693371\n",
      "iteration:  3  cost:  0.7562196642191972\n",
      "iteration:  4  cost:  1.025579576773208\n",
      "iteration:  5  cost:  0.9116733315899882\n",
      "iteration:  6  cost:  0.8179514982703104\n",
      "iteration:  7  cost:  0.8544212710272064\n",
      "iteration:  8  cost:  0.8623752109877917\n",
      "iteration:  9  cost:  0.8783832183364231\n",
      "[0.544, 0.55]\n",
      "iteration:  10  cost:  0.827265819036497\n",
      "iteration:  11  cost:  0.7727733129974065\n",
      "iteration:  12  cost:  0.9058695684596588\n",
      "iteration:  13  cost:  0.8218012022050912\n",
      "iteration:  14  cost:  0.9286926551412488\n",
      "iteration:  15  cost:  0.7983076739185678\n",
      "iteration:  16  cost:  0.8108123033484909\n",
      "iteration:  17  cost:  0.9143155894221171\n",
      "iteration:  18  cost:  0.9381777074037468\n",
      "iteration:  19  cost:  0.9093346618185997\n",
      "[0.544, 0.55, 0.552]\n",
      "iteration:  20  cost:  0.9226175449813039\n",
      "iteration:  21  cost:  0.7781432152980183\n",
      "iteration:  22  cost:  0.8825958506553273\n",
      "iteration:  23  cost:  0.8522867665577597\n",
      "iteration:  24  cost:  0.8759988182478183\n",
      "iteration:  25  cost:  0.9151911166300557\n",
      "iteration:  26  cost:  0.9344520986358589\n",
      "iteration:  27  cost:  0.8360911177831417\n",
      "iteration:  28  cost:  0.9457135130994493\n",
      "iteration:  29  cost:  0.9048435210611785\n",
      "[0.544, 0.55, 0.552, 0.602]\n",
      "iteration:  30  cost:  0.7182675626332773\n",
      "iteration:  31  cost:  0.8102672904666391\n",
      "iteration:  32  cost:  0.7974197644931219\n",
      "iteration:  33  cost:  0.7736063694319892\n",
      "iteration:  34  cost:  0.8102343876842895\n",
      "iteration:  35  cost:  0.7341715179334818\n",
      "iteration:  36  cost:  0.9431896211106057\n",
      "iteration:  37  cost:  0.7450918097460274\n",
      "iteration:  38  cost:  0.7679286834067421\n",
      "iteration:  39  cost:  0.8060788833944601\n",
      "[0.544, 0.55, 0.552, 0.602, 0.63]\n",
      "iteration:  40  cost:  0.727742953137201\n",
      "iteration:  41  cost:  0.8484222553700188\n",
      "iteration:  42  cost:  0.769932796927332\n",
      "iteration:  43  cost:  0.7260281226108478\n",
      "iteration:  44  cost:  0.856176288017258\n",
      "iteration:  45  cost:  0.7660121349376406\n",
      "iteration:  46  cost:  0.7424038736333763\n",
      "iteration:  47  cost:  0.706773834842391\n",
      "iteration:  48  cost:  0.7408546498177115\n",
      "iteration:  49  cost:  0.7891896001316802\n",
      "[0.544, 0.55, 0.552, 0.602, 0.63, 0.656]\n",
      "iteration:  50  cost:  0.7680665727535296\n",
      "iteration:  51  cost:  0.772968834842346\n",
      "iteration:  52  cost:  0.8556967430924494\n",
      "iteration:  53  cost:  0.8205127755406487\n",
      "iteration:  54  cost:  0.6222215683444228\n",
      "iteration:  55  cost:  0.691738808896526\n",
      "iteration:  56  cost:  0.8211183008631938\n",
      "iteration:  57  cost:  0.7931212693428327\n",
      "iteration:  58  cost:  0.7803994715131783\n",
      "iteration:  59  cost:  0.7058608858649322\n",
      "[0.544, 0.55, 0.552, 0.602, 0.63, 0.656, 0.698]\n",
      "iteration:  60  cost:  0.7696841024592116\n",
      "iteration:  61  cost:  0.7099968237515693\n",
      "iteration:  62  cost:  0.8115811569759317\n",
      "iteration:  63  cost:  0.6996357454935854\n",
      "iteration:  64  cost:  0.7576713676172661\n",
      "iteration:  65  cost:  0.7488866886581051\n",
      "iteration:  66  cost:  0.713369024162004\n",
      "iteration:  67  cost:  0.7511267931791284\n",
      "iteration:  68  cost:  0.6548399344250819\n",
      "iteration:  69  cost:  0.6737119270011509\n",
      "[0.544, 0.55, 0.552, 0.602, 0.63, 0.656, 0.698, 0.726]\n",
      "iteration:  70  cost:  0.6787252006289267\n",
      "iteration:  71  cost:  0.7521919773246136\n",
      "iteration:  72  cost:  0.7934836123626507\n",
      "iteration:  73  cost:  0.6916914232297444\n",
      "iteration:  74  cost:  0.8258298769564522\n",
      "iteration:  75  cost:  0.7037340871089626\n",
      "iteration:  76  cost:  0.7012272834239492\n",
      "iteration:  77  cost:  0.7261249821233108\n",
      "iteration:  78  cost:  0.6847198889234886\n",
      "iteration:  79  cost:  0.817358528027716\n",
      "[0.544, 0.55, 0.552, 0.602, 0.63, 0.656, 0.698, 0.726, 0.788]\n",
      "iteration:  80  cost:  0.7639946070277316\n",
      "iteration:  81  cost:  0.759249646164614\n",
      "iteration:  82  cost:  0.6696422030454668\n",
      "iteration:  83  cost:  0.7191101249161325\n",
      "iteration:  84  cost:  0.7376155911809289\n",
      "iteration:  85  cost:  0.7754812453049139\n",
      "iteration:  86  cost:  0.7367795390242811\n",
      "iteration:  87  cost:  0.6700341295031064\n",
      "iteration:  88  cost:  0.5883698722902015\n",
      "iteration:  89  cost:  0.7048259448698616\n",
      "[0.544, 0.55, 0.552, 0.602, 0.63, 0.656, 0.698, 0.726, 0.788, 0.876]\n",
      "iteration:  90  cost:  0.5697344013921299\n",
      "iteration:  91  cost:  0.7249627078396138\n",
      "iteration:  92  cost:  0.648823854987418\n",
      "iteration:  93  cost:  0.6602729547070494\n",
      "iteration:  94  cost:  0.6830859984121667\n",
      "iteration:  95  cost:  0.6277537751976421\n",
      "iteration:  96  cost:  0.6849187730058555\n",
      "iteration:  97  cost:  0.6465150457706277\n",
      "iteration:  98  cost:  0.7090637423771669\n",
      "iteration:  99  cost:  0.6676903948118096\n",
      "[0.544, 0.55, 0.552, 0.602, 0.63, 0.656, 0.698, 0.726, 0.788, 0.876, 0.908]\n",
      "iteration:  100  cost:  0.6529860319526726\n",
      "iteration:  101  cost:  0.6960725778112985\n",
      "iteration:  102  cost:  0.6636465330834875\n",
      "iteration:  103  cost:  0.6428559994356751\n",
      "iteration:  104  cost:  0.6117450535790688\n",
      "iteration:  105  cost:  0.5942429086815567\n",
      "iteration:  106  cost:  0.6350084289042538\n",
      "iteration:  107  cost:  0.5861388592893617\n",
      "iteration:  108  cost:  0.6595260296372086\n",
      "iteration:  109  cost:  0.6272149758947412\n",
      "[0.544, 0.55, 0.552, 0.602, 0.63, 0.656, 0.698, 0.726, 0.788, 0.876, 0.908, 0.926]\n",
      "iteration:  110  cost:  0.6114299930309302\n",
      "iteration:  111  cost:  0.6289250179903944\n",
      "iteration:  112  cost:  0.6426323581869504\n",
      "iteration:  113  cost:  0.6511886033153463\n",
      "iteration:  114  cost:  0.6777545176693982\n",
      "iteration:  115  cost:  0.6957034632472917\n",
      "iteration:  116  cost:  0.6774181966720532\n",
      "iteration:  117  cost:  0.6218591008093723\n",
      "iteration:  118  cost:  0.6839477260551675\n",
      "iteration:  119  cost:  0.7052776006452999\n",
      "[0.544, 0.55, 0.552, 0.602, 0.63, 0.656, 0.698, 0.726, 0.788, 0.876, 0.908, 0.926, 0.946]\n",
      "iteration:  120  cost:  0.6544986329741082\n",
      "iteration:  121  cost:  0.6721492080850666\n",
      "iteration:  122  cost:  0.5813409706499569\n",
      "iteration:  123  cost:  0.6220934488235937\n",
      "iteration:  124  cost:  0.5409429366950824\n",
      "iteration:  125  cost:  0.6260252083296808\n",
      "iteration:  126  cost:  0.6336130483212397\n",
      "iteration:  127  cost:  0.5907021343011052\n",
      "iteration:  128  cost:  0.6707515418666192\n",
      "iteration:  129  cost:  0.6438059586869794\n",
      "[0.544, 0.55, 0.552, 0.602, 0.63, 0.656, 0.698, 0.726, 0.788, 0.876, 0.908, 0.926, 0.946, 0.956]\n",
      "iteration:  130  cost:  0.6706970882968255\n",
      "iteration:  131  cost:  0.6210793031535836\n",
      "iteration:  132  cost:  0.6073716729504021\n",
      "iteration:  133  cost:  0.5964609095629249\n",
      "iteration:  134  cost:  0.6309759624859167\n",
      "iteration:  135  cost:  0.5719913784441598\n",
      "iteration:  136  cost:  0.5940013271080684\n",
      "iteration:  137  cost:  0.6241632897252763\n",
      "iteration:  138  cost:  0.6364290932652313\n",
      "iteration:  139  cost:  0.6322549614443124\n",
      "[0.544, 0.55, 0.552, 0.602, 0.63, 0.656, 0.698, 0.726, 0.788, 0.876, 0.908, 0.926, 0.946, 0.956, 0.958]\n",
      "iteration:  140  cost:  0.6269288540732804\n",
      "iteration:  141  cost:  0.6009264815142571\n",
      "iteration:  142  cost:  0.5619143963920781\n",
      "iteration:  143  cost:  0.6224787839941035\n",
      "iteration:  144  cost:  0.5564975034625399\n",
      "iteration:  145  cost:  0.6398250724033128\n",
      "iteration:  146  cost:  0.6012354238847645\n",
      "iteration:  147  cost:  0.5980656093033536\n",
      "iteration:  148  cost:  0.6662833476108153\n",
      "iteration:  149  cost:  0.5036480671241548\n",
      "[0.544, 0.55, 0.552, 0.602, 0.63, 0.656, 0.698, 0.726, 0.788, 0.876, 0.908, 0.926, 0.946, 0.956, 0.958, 0.96]\n",
      "iteration:  150  cost:  0.5697445694962705\n",
      "iteration:  151  cost:  0.6832866235182319\n",
      "iteration:  152  cost:  0.5654957785708503\n",
      "iteration:  153  cost:  0.5925655985815758\n",
      "iteration:  154  cost:  0.5933804590633704\n",
      "iteration:  155  cost:  0.5882073194488491\n",
      "iteration:  156  cost:  0.5618951035363082\n",
      "iteration:  157  cost:  0.6328778087330258\n",
      "iteration:  158  cost:  0.5611578203592738\n",
      "iteration:  159  cost:  0.534429043785354\n",
      "[0.544, 0.55, 0.552, 0.602, 0.63, 0.656, 0.698, 0.726, 0.788, 0.876, 0.908, 0.926, 0.946, 0.956, 0.958, 0.96, 0.964]\n",
      "iteration:  160  cost:  0.6283728351177337\n",
      "iteration:  161  cost:  0.5862839351369779\n",
      "iteration:  162  cost:  0.6027818600037573\n",
      "iteration:  163  cost:  0.6155340094052563\n",
      "iteration:  164  cost:  0.5380783294115429\n",
      "iteration:  165  cost:  0.6263223145603991\n",
      "iteration:  166  cost:  0.5372054237136821\n",
      "iteration:  167  cost:  0.6718578677796876\n",
      "iteration:  168  cost:  0.5963714957347527\n",
      "iteration:  169  cost:  0.544440527343419\n",
      "[0.544, 0.55, 0.552, 0.602, 0.63, 0.656, 0.698, 0.726, 0.788, 0.876, 0.908, 0.926, 0.946, 0.956, 0.958, 0.96, 0.964, 0.964]\n",
      "iteration:  170  cost:  0.6224816536969484\n",
      "iteration:  171  cost:  0.609741926449767\n",
      "iteration:  172  cost:  0.5365192184718319\n",
      "iteration:  173  cost:  0.6700009806743288\n",
      "iteration:  174  cost:  0.6465857809607661\n",
      "iteration:  175  cost:  0.6357311230868248\n",
      "iteration:  176  cost:  0.5673688748054698\n",
      "iteration:  177  cost:  0.5036694312773983\n",
      "iteration:  178  cost:  0.601949755536906\n",
      "iteration:  179  cost:  0.4531207070000288\n",
      "[0.544, 0.55, 0.552, 0.602, 0.63, 0.656, 0.698, 0.726, 0.788, 0.876, 0.908, 0.926, 0.946, 0.956, 0.958, 0.96, 0.964, 0.964, 0.964]\n",
      "iteration:  180  cost:  0.6110075388443825\n",
      "iteration:  181  cost:  0.5044237370047759\n",
      "iteration:  182  cost:  0.543101380798255\n",
      "iteration:  183  cost:  0.5829983792941985\n",
      "iteration:  184  cost:  0.6398144398802512\n",
      "iteration:  185  cost:  0.5096224641591143\n",
      "iteration:  186  cost:  0.5646657997267979\n",
      "iteration:  187  cost:  0.5651150079775588\n",
      "iteration:  188  cost:  0.7457032199831342\n",
      "iteration:  189  cost:  0.42808579132204955\n",
      "[0.544, 0.55, 0.552, 0.602, 0.63, 0.656, 0.698, 0.726, 0.788, 0.876, 0.908, 0.926, 0.946, 0.956, 0.958, 0.96, 0.964, 0.964, 0.964, 0.956]\n",
      "Accuracy for U_TTN resize256 :0.9522458628841608\n",
      "\n",
      "\n",
      "Loss History for QCNN circuits, U_TTN pca8\n",
      "[0.668]\n",
      "iteration:  0  cost:  0.9656707949650021\n",
      "iteration:  1  cost:  0.935342133548381\n",
      "iteration:  2  cost:  0.9557392627047815\n",
      "iteration:  3  cost:  0.9129583109251058\n",
      "iteration:  4  cost:  0.8929344514369413\n",
      "iteration:  5  cost:  0.8896198939553215\n",
      "iteration:  6  cost:  0.8914486147817827\n",
      "iteration:  7  cost:  0.7955081515799454\n",
      "iteration:  8  cost:  0.7751620404744781\n",
      "iteration:  9  cost:  0.8032676785497006\n",
      "[0.668, 0.892]\n",
      "iteration:  10  cost:  0.7672237567040148\n",
      "iteration:  11  cost:  0.6864760716837783\n",
      "iteration:  12  cost:  0.698269637720621\n",
      "iteration:  13  cost:  0.7398362228634511\n",
      "iteration:  14  cost:  0.7169280468907501\n",
      "iteration:  15  cost:  0.6825612804014528\n",
      "iteration:  16  cost:  0.6852234008749902\n",
      "iteration:  17  cost:  0.6414078583232183\n",
      "iteration:  18  cost:  0.6160890863638221\n",
      "iteration:  19  cost:  0.6333871251144021\n",
      "[0.668, 0.892, 0.89]\n",
      "iteration:  20  cost:  0.7166944476954992\n",
      "iteration:  21  cost:  0.5845027005489268\n",
      "iteration:  22  cost:  0.5270065629804281\n",
      "iteration:  23  cost:  0.5915276428600601\n",
      "iteration:  24  cost:  0.5749705941015206\n",
      "iteration:  25  cost:  0.601563062522855\n",
      "iteration:  26  cost:  0.6384616326074931\n",
      "iteration:  27  cost:  0.4999558296177341\n",
      "iteration:  28  cost:  0.4873581499694623\n",
      "iteration:  29  cost:  0.43572770455227205\n",
      "[0.668, 0.892, 0.89, 0.894]\n",
      "iteration:  30  cost:  0.5865419578408374\n",
      "iteration:  31  cost:  0.36657300306432705\n",
      "iteration:  32  cost:  0.3974668179552158\n",
      "iteration:  33  cost:  0.4571098946978848\n",
      "iteration:  34  cost:  0.39907294199113663\n",
      "iteration:  35  cost:  0.40969572116529757\n",
      "iteration:  36  cost:  0.4980985815675065\n",
      "iteration:  37  cost:  0.43178519117605163\n",
      "iteration:  38  cost:  0.4106460658372611\n",
      "iteration:  39  cost:  0.39038474863691625\n",
      "[0.668, 0.892, 0.89, 0.894, 0.936]\n",
      "iteration:  40  cost:  0.3338005164695563\n",
      "iteration:  41  cost:  0.34517828389490995\n",
      "iteration:  42  cost:  0.4113419477979064\n",
      "iteration:  43  cost:  0.38215932246546197\n",
      "iteration:  44  cost:  0.38864506977296315\n",
      "iteration:  45  cost:  0.44881804790116897\n",
      "iteration:  46  cost:  0.3950522142905381\n",
      "iteration:  47  cost:  0.39047490257050055\n",
      "iteration:  48  cost:  0.36657045735969523\n",
      "iteration:  49  cost:  0.4314314449485616\n",
      "[0.668, 0.892, 0.89, 0.894, 0.936, 0.95]\n",
      "iteration:  50  cost:  0.4780751204966993\n",
      "iteration:  51  cost:  0.4070339942018299\n",
      "iteration:  52  cost:  0.3771724207288098\n",
      "iteration:  53  cost:  0.4304891930757794\n",
      "iteration:  54  cost:  0.3086767760199335\n",
      "iteration:  55  cost:  0.28635226722655077\n",
      "iteration:  56  cost:  0.3643991421608036\n",
      "iteration:  57  cost:  0.442576190262615\n",
      "iteration:  58  cost:  0.2653045497004154\n",
      "iteration:  59  cost:  0.3818385314858702\n",
      "[0.668, 0.892, 0.89, 0.894, 0.936, 0.95, 0.942]\n",
      "iteration:  60  cost:  0.26647658532550755\n",
      "iteration:  61  cost:  0.30948406156750047\n",
      "iteration:  62  cost:  0.4420467012247572\n",
      "iteration:  63  cost:  0.3072126481521932\n",
      "iteration:  64  cost:  0.2354740232059996\n",
      "iteration:  65  cost:  0.30430270365153694\n",
      "iteration:  66  cost:  0.2520845233080934\n",
      "iteration:  67  cost:  0.39029537389710256\n",
      "iteration:  68  cost:  0.29508669747075605\n",
      "iteration:  69  cost:  0.4233564534583612\n",
      "[0.668, 0.892, 0.89, 0.894, 0.936, 0.95, 0.942, 0.952]\n",
      "iteration:  70  cost:  0.22979810014993862\n",
      "iteration:  71  cost:  0.2543071324969633\n",
      "iteration:  72  cost:  0.31247858653481414\n",
      "iteration:  73  cost:  0.3427319094334886\n",
      "iteration:  74  cost:  0.3779257705390361\n",
      "iteration:  75  cost:  0.3019882219378126\n",
      "iteration:  76  cost:  0.29964489847071524\n",
      "iteration:  77  cost:  0.3752699024590472\n",
      "iteration:  78  cost:  0.35426388986619484\n",
      "iteration:  79  cost:  0.2659800226087539\n",
      "[0.668, 0.892, 0.89, 0.894, 0.936, 0.95, 0.942, 0.952, 0.95]\n",
      "iteration:  80  cost:  0.22976347819248263\n",
      "iteration:  81  cost:  0.30969885083850773\n",
      "iteration:  82  cost:  0.300681198837734\n",
      "iteration:  83  cost:  0.3135542584365363\n",
      "iteration:  84  cost:  0.41486609522057116\n",
      "iteration:  85  cost:  0.2711145281158953\n",
      "iteration:  86  cost:  0.20669141108183364\n",
      "iteration:  87  cost:  0.28797821698832843\n",
      "iteration:  88  cost:  0.23222095874185672\n",
      "iteration:  89  cost:  0.3285251005653841\n",
      "[0.668, 0.892, 0.89, 0.894, 0.936, 0.95, 0.942, 0.952, 0.95, 0.952]\n",
      "iteration:  90  cost:  0.3049302403770431\n",
      "iteration:  91  cost:  0.2123602967231642\n",
      "iteration:  92  cost:  0.3171752852328176\n",
      "iteration:  93  cost:  0.4940763184374446\n",
      "iteration:  94  cost:  0.4251686601936009\n",
      "iteration:  95  cost:  0.2128273934158448\n",
      "iteration:  96  cost:  0.3459408988792429\n",
      "iteration:  97  cost:  0.35807758003580104\n",
      "iteration:  98  cost:  0.3250969785569842\n",
      "iteration:  99  cost:  0.3373057389214852\n",
      "[0.668, 0.892, 0.89, 0.894, 0.936, 0.95, 0.942, 0.952, 0.95, 0.952, 0.95]\n",
      "iteration:  100  cost:  0.25443885936261035\n",
      "iteration:  101  cost:  0.21293308620955556\n",
      "iteration:  102  cost:  0.3356966655575315\n",
      "iteration:  103  cost:  0.24953208737800384\n",
      "iteration:  104  cost:  0.40439326582189206\n",
      "iteration:  105  cost:  0.3301637987689118\n",
      "iteration:  106  cost:  0.31553080199423267\n",
      "iteration:  107  cost:  0.41898987692871825\n",
      "iteration:  108  cost:  0.34883130028553666\n",
      "iteration:  109  cost:  0.30195414865625037\n",
      "[0.668, 0.892, 0.89, 0.894, 0.936, 0.95, 0.942, 0.952, 0.95, 0.952, 0.95, 0.938]\n",
      "Accuracy for U_TTN pca8 :0.9621749408983451\n",
      "\n",
      "\n",
      "Loss History for QCNN circuits, U_TTN pca16\n",
      "[0.726]\n",
      "iteration:  0  cost:  0.9515333333808322\n",
      "iteration:  1  cost:  0.8829963253082924\n",
      "iteration:  2  cost:  0.9312109079675003\n",
      "iteration:  3  cost:  0.9591023593855535\n",
      "iteration:  4  cost:  0.9306036517872671\n",
      "iteration:  5  cost:  0.9410104743583346\n",
      "iteration:  6  cost:  0.9158204791033825\n",
      "iteration:  7  cost:  0.9640354766193405\n",
      "iteration:  8  cost:  0.8785705196911893\n",
      "iteration:  9  cost:  0.8665869792687105\n",
      "[0.726, 0.83]\n",
      "iteration:  10  cost:  0.8838979912137778\n",
      "iteration:  11  cost:  0.890714025378755\n",
      "iteration:  12  cost:  0.8906643685769509\n",
      "iteration:  13  cost:  0.8735953683982985\n",
      "iteration:  14  cost:  0.8548188434475597\n",
      "iteration:  15  cost:  0.8207575480803722\n",
      "iteration:  16  cost:  0.835302007287267\n",
      "iteration:  17  cost:  0.8128828304555659\n",
      "iteration:  18  cost:  0.8452155488129998\n",
      "iteration:  19  cost:  0.8502254618976403\n",
      "[0.726, 0.83, 0.904]\n",
      "iteration:  20  cost:  0.8025581064746238\n",
      "iteration:  21  cost:  0.7760995646705807\n",
      "iteration:  22  cost:  0.786957199016943\n",
      "iteration:  23  cost:  0.7385015260995956\n",
      "iteration:  24  cost:  0.7881150116562976\n",
      "iteration:  25  cost:  0.8302184446097935\n",
      "iteration:  26  cost:  0.7498104423391098\n",
      "iteration:  27  cost:  0.7321902713350907\n",
      "iteration:  28  cost:  0.7782601964140571\n",
      "iteration:  29  cost:  0.8030914032711378\n",
      "[0.726, 0.83, 0.904, 0.934]\n",
      "iteration:  30  cost:  0.7757916231777386\n",
      "iteration:  31  cost:  0.6772072206860703\n",
      "iteration:  32  cost:  0.7055166522716192\n",
      "iteration:  33  cost:  0.7197416084057613\n",
      "iteration:  34  cost:  0.7270500813478707\n",
      "iteration:  35  cost:  0.7303942120591961\n",
      "iteration:  36  cost:  0.7809807234985884\n",
      "iteration:  37  cost:  0.6463930304571198\n",
      "iteration:  38  cost:  0.7231572670650052\n",
      "iteration:  39  cost:  0.6765798866144085\n",
      "[0.726, 0.83, 0.904, 0.934, 0.942]\n",
      "iteration:  40  cost:  0.6790744534946248\n",
      "iteration:  41  cost:  0.6455456436272408\n",
      "iteration:  42  cost:  0.6969378991852315\n",
      "iteration:  43  cost:  0.6417693764212593\n",
      "iteration:  44  cost:  0.7003661859322279\n",
      "iteration:  45  cost:  0.7276037681952947\n",
      "iteration:  46  cost:  0.6358400118347594\n",
      "iteration:  47  cost:  0.6558495443583946\n",
      "iteration:  48  cost:  0.6233318634602679\n",
      "iteration:  49  cost:  0.6721298706091803\n",
      "[0.726, 0.83, 0.904, 0.934, 0.942, 0.942]\n",
      "iteration:  50  cost:  0.6399283844632255\n",
      "iteration:  51  cost:  0.6972032739358655\n",
      "iteration:  52  cost:  0.6551476399444798\n",
      "iteration:  53  cost:  0.6771924524376776\n",
      "iteration:  54  cost:  0.5910224437260915\n",
      "iteration:  55  cost:  0.6595246768614118\n",
      "iteration:  56  cost:  0.631155259805676\n",
      "iteration:  57  cost:  0.610042579523958\n",
      "iteration:  58  cost:  0.6050688435485923\n",
      "iteration:  59  cost:  0.6568148719097013\n",
      "[0.726, 0.83, 0.904, 0.934, 0.942, 0.942, 0.942]\n",
      "iteration:  60  cost:  0.6429492593259647\n",
      "iteration:  61  cost:  0.6461103568128569\n",
      "iteration:  62  cost:  0.6325060748165687\n",
      "iteration:  63  cost:  0.5805377480230377\n",
      "iteration:  64  cost:  0.6065153640532812\n",
      "iteration:  65  cost:  0.6197440777776928\n",
      "iteration:  66  cost:  0.5953577641736083\n",
      "iteration:  67  cost:  0.6432032886570619\n",
      "iteration:  68  cost:  0.6332012840297053\n",
      "iteration:  69  cost:  0.6316450648812972\n",
      "[0.726, 0.83, 0.904, 0.934, 0.942, 0.942, 0.942, 0.942]\n",
      "iteration:  70  cost:  0.5918381777376817\n",
      "iteration:  71  cost:  0.60241609357411\n",
      "iteration:  72  cost:  0.5574304607014522\n",
      "iteration:  73  cost:  0.6672209928199537\n",
      "iteration:  74  cost:  0.5479994139989859\n",
      "iteration:  75  cost:  0.595907878065887\n",
      "iteration:  76  cost:  0.5540449032464074\n",
      "iteration:  77  cost:  0.6293339391554381\n",
      "iteration:  78  cost:  0.6143927352599334\n",
      "iteration:  79  cost:  0.5802371638502631\n",
      "[0.726, 0.83, 0.904, 0.934, 0.942, 0.942, 0.942, 0.942, 0.948]\n",
      "iteration:  80  cost:  0.6558818791180603\n",
      "iteration:  81  cost:  0.6353505339941982\n",
      "iteration:  82  cost:  0.5718884703595726\n",
      "iteration:  83  cost:  0.5905915104922626\n",
      "iteration:  84  cost:  0.6556762338666262\n",
      "iteration:  85  cost:  0.6010362394655777\n",
      "iteration:  86  cost:  0.5516471463054929\n",
      "iteration:  87  cost:  0.5221498939948621\n",
      "iteration:  88  cost:  0.6081598610173298\n",
      "iteration:  89  cost:  0.5320248725347141\n",
      "[0.726, 0.83, 0.904, 0.934, 0.942, 0.942, 0.942, 0.942, 0.948, 0.95]\n",
      "iteration:  90  cost:  0.6417403726261038\n",
      "iteration:  91  cost:  0.5881334632226085\n",
      "iteration:  92  cost:  0.5854913363786586\n",
      "iteration:  93  cost:  0.5730823959820316\n",
      "iteration:  94  cost:  0.5661289403975243\n",
      "iteration:  95  cost:  0.5669263596526382\n",
      "iteration:  96  cost:  0.5272674658656562\n",
      "iteration:  97  cost:  0.6342600574307425\n",
      "iteration:  98  cost:  0.5202070166230552\n",
      "iteration:  99  cost:  0.5082202825036805\n",
      "[0.726, 0.83, 0.904, 0.934, 0.942, 0.942, 0.942, 0.942, 0.948, 0.95, 0.954]\n",
      "iteration:  100  cost:  0.6616332943414005\n",
      "iteration:  101  cost:  0.5270237924998855\n",
      "iteration:  102  cost:  0.552065026713767\n",
      "iteration:  103  cost:  0.575364766925676\n",
      "iteration:  104  cost:  0.4842314259638072\n",
      "iteration:  105  cost:  0.5312966347627225\n",
      "iteration:  106  cost:  0.5929415859736794\n",
      "iteration:  107  cost:  0.5559603733132655\n",
      "iteration:  108  cost:  0.5146498838743719\n",
      "iteration:  109  cost:  0.549212396182122\n",
      "[0.726, 0.83, 0.904, 0.934, 0.942, 0.942, 0.942, 0.942, 0.948, 0.95, 0.954, 0.958]\n",
      "iteration:  110  cost:  0.5470753937060301\n",
      "iteration:  111  cost:  0.5461914512503888\n",
      "iteration:  112  cost:  0.5277932254089672\n",
      "iteration:  113  cost:  0.5515382121979331\n",
      "iteration:  114  cost:  0.680636102690512\n",
      "iteration:  115  cost:  0.47534784272214076\n",
      "iteration:  116  cost:  0.6058175122600713\n",
      "iteration:  117  cost:  0.5298220207801452\n",
      "iteration:  118  cost:  0.5925795725772477\n",
      "iteration:  119  cost:  0.5398691773251602\n",
      "[0.726, 0.83, 0.904, 0.934, 0.942, 0.942, 0.942, 0.942, 0.948, 0.95, 0.954, 0.958, 0.956]\n",
      "iteration:  120  cost:  0.48181984541066636\n",
      "iteration:  121  cost:  0.5458945161100592\n",
      "iteration:  122  cost:  0.5648005271770584\n",
      "iteration:  123  cost:  0.5791364356772792\n",
      "iteration:  124  cost:  0.5689049094007264\n",
      "iteration:  125  cost:  0.548900496447655\n",
      "iteration:  126  cost:  0.5370625317023691\n",
      "iteration:  127  cost:  0.5658510819205875\n",
      "iteration:  128  cost:  0.5243057001306157\n",
      "iteration:  129  cost:  0.5353159945431377\n",
      "[0.726, 0.83, 0.904, 0.934, 0.942, 0.942, 0.942, 0.942, 0.948, 0.95, 0.954, 0.958, 0.956, 0.962]\n",
      "iteration:  130  cost:  0.5628554824530283\n",
      "iteration:  131  cost:  0.514019237517586\n",
      "iteration:  132  cost:  0.5160871763664986\n",
      "iteration:  133  cost:  0.5376106280588899\n",
      "iteration:  134  cost:  0.5092953145848623\n",
      "iteration:  135  cost:  0.6223248376447814\n",
      "iteration:  136  cost:  0.5338408275936058\n",
      "iteration:  137  cost:  0.49699376340912815\n",
      "iteration:  138  cost:  0.53134020297531\n",
      "iteration:  139  cost:  0.5666655609736562\n",
      "[0.726, 0.83, 0.904, 0.934, 0.942, 0.942, 0.942, 0.942, 0.948, 0.95, 0.954, 0.958, 0.956, 0.962, 0.962]\n",
      "iteration:  140  cost:  0.4643664416014179\n",
      "iteration:  141  cost:  0.5237910827993725\n",
      "iteration:  142  cost:  0.5128802160496755\n",
      "iteration:  143  cost:  0.5966899734986338\n",
      "iteration:  144  cost:  0.4981777436415233\n",
      "iteration:  145  cost:  0.48871490229836295\n",
      "iteration:  146  cost:  0.49469107989986333\n",
      "iteration:  147  cost:  0.48961816802073593\n",
      "iteration:  148  cost:  0.5447787832079785\n",
      "iteration:  149  cost:  0.4542622273129531\n",
      "[0.726, 0.83, 0.904, 0.934, 0.942, 0.942, 0.942, 0.942, 0.948, 0.95, 0.954, 0.958, 0.956, 0.962, 0.962, 0.958]\n",
      "iteration:  150  cost:  0.5490946760966385\n",
      "iteration:  151  cost:  0.5403022672495988\n",
      "iteration:  152  cost:  0.511719763342617\n",
      "iteration:  153  cost:  0.49476490872671997\n",
      "iteration:  154  cost:  0.5139548105497684\n",
      "iteration:  155  cost:  0.4631480180528845\n",
      "iteration:  156  cost:  0.6005212732060389\n",
      "iteration:  157  cost:  0.5952631346516128\n",
      "iteration:  158  cost:  0.5418389934003308\n",
      "iteration:  159  cost:  0.5548352692096797\n",
      "[0.726, 0.83, 0.904, 0.934, 0.942, 0.942, 0.942, 0.942, 0.948, 0.95, 0.954, 0.958, 0.956, 0.962, 0.962, 0.958, 0.958]\n",
      "iteration:  160  cost:  0.5665599153396476\n",
      "iteration:  161  cost:  0.5822364414449439\n",
      "iteration:  162  cost:  0.4820890111502396\n",
      "iteration:  163  cost:  0.45281735493788217\n",
      "iteration:  164  cost:  0.5152742615142648\n",
      "iteration:  165  cost:  0.5568703299486186\n",
      "iteration:  166  cost:  0.49732616028531385\n",
      "iteration:  167  cost:  0.5318736270587909\n",
      "iteration:  168  cost:  0.5097849103896753\n",
      "iteration:  169  cost:  0.5163045728724945\n",
      "[0.726, 0.83, 0.904, 0.934, 0.942, 0.942, 0.942, 0.942, 0.948, 0.95, 0.954, 0.958, 0.956, 0.962, 0.962, 0.958, 0.958, 0.956]\n",
      "Accuracy for U_TTN pca16 :0.9626477541371158\n",
      "Epoch 1/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.1072 - val_loss: 0.0353\n",
      "Epoch 2/10\n",
      "396/396 [==============================] - 0s 750us/step - loss: 0.0321 - val_loss: 0.0266\n",
      "Epoch 3/10\n",
      "396/396 [==============================] - 0s 757us/step - loss: 0.0261 - val_loss: 0.0238\n",
      "Epoch 4/10\n",
      "396/396 [==============================] - 0s 764us/step - loss: 0.0236 - val_loss: 0.0221\n",
      "Epoch 5/10\n",
      "396/396 [==============================] - 0s 762us/step - loss: 0.0222 - val_loss: 0.0208\n",
      "Epoch 6/10\n",
      "396/396 [==============================] - 0s 784us/step - loss: 0.0207 - val_loss: 0.0197\n",
      "Epoch 7/10\n",
      "396/396 [==============================] - 0s 770us/step - loss: 0.0198 - val_loss: 0.0190\n",
      "Epoch 8/10\n",
      "396/396 [==============================] - 0s 764us/step - loss: 0.0191 - val_loss: 0.0183\n",
      "Epoch 9/10\n",
      "396/396 [==============================] - 0s 784us/step - loss: 0.0189 - val_loss: 0.0179\n",
      "Epoch 10/10\n",
      "396/396 [==============================] - 0s 775us/step - loss: 0.0181 - val_loss: 0.0175\n",
      "\n",
      "\n",
      "Loss History for QCNN circuits, U_TTN autoencoder8\n",
      "[0.308]\n",
      "iteration:  0  cost:  1.0619608913836653\n",
      "iteration:  1  cost:  1.045359201308623\n",
      "iteration:  2  cost:  1.0420920147365873\n",
      "iteration:  3  cost:  1.0656785847560521\n",
      "iteration:  4  cost:  1.0441571935061136\n",
      "iteration:  5  cost:  1.0431553481994953\n",
      "iteration:  6  cost:  1.091064959031292\n",
      "iteration:  7  cost:  1.046354411499054\n",
      "iteration:  8  cost:  1.0634438865851152\n",
      "iteration:  9  cost:  1.0726740816694584\n",
      "[0.308, 0.364]\n",
      "iteration:  10  cost:  1.0080168953767905\n",
      "iteration:  11  cost:  1.0438653825416662\n",
      "iteration:  12  cost:  1.023964007610455\n",
      "iteration:  13  cost:  0.9904745273733466\n",
      "iteration:  14  cost:  1.0173154717893182\n",
      "iteration:  15  cost:  1.07921495374191\n",
      "iteration:  16  cost:  1.0408529077335649\n",
      "iteration:  17  cost:  1.0210024038531338\n",
      "iteration:  18  cost:  1.0308350026919888\n",
      "iteration:  19  cost:  0.9969031557640262\n",
      "[0.308, 0.364, 0.524]\n",
      "iteration:  20  cost:  0.9722838402195412\n",
      "iteration:  21  cost:  0.9884667640011364\n",
      "iteration:  22  cost:  0.9704615995275513\n",
      "iteration:  23  cost:  1.0052766509990831\n",
      "iteration:  24  cost:  0.9630374597200447\n",
      "iteration:  25  cost:  0.9657029304920512\n",
      "iteration:  26  cost:  0.9545448141456672\n",
      "iteration:  27  cost:  1.0033549491086458\n",
      "iteration:  28  cost:  0.9396908089517592\n",
      "iteration:  29  cost:  0.9493115006746264\n",
      "[0.308, 0.364, 0.524, 0.716]\n",
      "iteration:  30  cost:  0.9442827954580628\n",
      "iteration:  31  cost:  0.8885529388064063\n",
      "iteration:  32  cost:  0.8864644992440287\n",
      "iteration:  33  cost:  0.8849263958626633\n",
      "iteration:  34  cost:  0.9253550331417726\n",
      "iteration:  35  cost:  0.9147522507044108\n",
      "iteration:  36  cost:  0.9186286810065066\n",
      "iteration:  37  cost:  0.8796373346126455\n",
      "iteration:  38  cost:  0.8455457938913125\n",
      "iteration:  39  cost:  0.8418878273269557\n",
      "[0.308, 0.364, 0.524, 0.716, 0.798]\n",
      "iteration:  40  cost:  0.7993284104597055\n",
      "iteration:  41  cost:  0.836547803460692\n",
      "iteration:  42  cost:  0.9208670278580655\n",
      "iteration:  43  cost:  0.7822771657936396\n",
      "iteration:  44  cost:  0.892739991423771\n",
      "iteration:  45  cost:  0.8626702229072396\n",
      "iteration:  46  cost:  0.8427352784705985\n",
      "iteration:  47  cost:  0.9034369092145792\n",
      "iteration:  48  cost:  0.8534495685826474\n",
      "iteration:  49  cost:  0.9035448180267608\n",
      "[0.308, 0.364, 0.524, 0.716, 0.798, 0.822]\n",
      "iteration:  50  cost:  0.7851996768460071\n",
      "iteration:  51  cost:  0.8125084467097219\n",
      "iteration:  52  cost:  0.8302615626183332\n",
      "iteration:  53  cost:  0.8951602208797612\n",
      "iteration:  54  cost:  0.8293402470912676\n",
      "iteration:  55  cost:  0.839563416359138\n",
      "iteration:  56  cost:  0.7719219561878589\n",
      "iteration:  57  cost:  0.8076812524496099\n",
      "iteration:  58  cost:  0.7705116549182978\n",
      "iteration:  59  cost:  0.820450747787682\n",
      "[0.308, 0.364, 0.524, 0.716, 0.798, 0.822, 0.856]\n",
      "iteration:  60  cost:  0.8193853286516513\n",
      "iteration:  61  cost:  0.8078056849524508\n",
      "iteration:  62  cost:  0.7707105036690236\n",
      "iteration:  63  cost:  0.7747607964578755\n",
      "iteration:  64  cost:  0.9124595988940488\n",
      "iteration:  65  cost:  0.8005458437773618\n",
      "iteration:  66  cost:  0.7800326117094245\n",
      "iteration:  67  cost:  0.8095260082269021\n",
      "iteration:  68  cost:  0.8087568513252558\n",
      "iteration:  69  cost:  0.8017085363309809\n",
      "[0.308, 0.364, 0.524, 0.716, 0.798, 0.822, 0.856, 0.872]\n",
      "iteration:  70  cost:  0.7822720835947158\n",
      "iteration:  71  cost:  0.7387439776815095\n",
      "iteration:  72  cost:  0.7841363954491343\n",
      "iteration:  73  cost:  0.7688158939502944\n",
      "iteration:  74  cost:  0.7338237718859252\n",
      "iteration:  75  cost:  0.746231698854327\n",
      "iteration:  76  cost:  0.7819649973136371\n",
      "iteration:  77  cost:  0.7306920345332506\n",
      "iteration:  78  cost:  0.6853586633568568\n",
      "iteration:  79  cost:  0.7153788105455302\n",
      "[0.308, 0.364, 0.524, 0.716, 0.798, 0.822, 0.856, 0.872, 0.886]\n",
      "iteration:  80  cost:  0.6746509426999227\n",
      "iteration:  81  cost:  0.8230024655898549\n",
      "iteration:  82  cost:  0.7275194373628439\n",
      "iteration:  83  cost:  0.6828699020376817\n",
      "iteration:  84  cost:  0.7347544584670073\n",
      "iteration:  85  cost:  0.749878767057663\n",
      "iteration:  86  cost:  0.6781869540852731\n",
      "iteration:  87  cost:  0.7345456416102379\n",
      "iteration:  88  cost:  0.7661199184480918\n",
      "iteration:  89  cost:  0.7794695725581906\n",
      "[0.308, 0.364, 0.524, 0.716, 0.798, 0.822, 0.856, 0.872, 0.886, 0.906]\n",
      "iteration:  90  cost:  0.6754504421585804\n",
      "iteration:  91  cost:  0.7043415407269343\n",
      "iteration:  92  cost:  0.7035195823335394\n",
      "iteration:  93  cost:  0.6922070716267583\n",
      "iteration:  94  cost:  0.6579334342510813\n",
      "iteration:  95  cost:  0.7395144202855657\n",
      "iteration:  96  cost:  0.6593727076553452\n",
      "iteration:  97  cost:  0.67179309709543\n",
      "iteration:  98  cost:  0.7801990883747608\n",
      "iteration:  99  cost:  0.7137603294177874\n",
      "[0.308, 0.364, 0.524, 0.716, 0.798, 0.822, 0.856, 0.872, 0.886, 0.906, 0.922]\n",
      "iteration:  100  cost:  0.6888607646915976\n",
      "iteration:  101  cost:  0.7536232424366804\n",
      "iteration:  102  cost:  0.7479139994288161\n",
      "iteration:  103  cost:  0.681450743090577\n",
      "iteration:  104  cost:  0.7570682866938762\n",
      "iteration:  105  cost:  0.651043058877775\n",
      "iteration:  106  cost:  0.6724439664269733\n",
      "iteration:  107  cost:  0.6366739673193701\n",
      "iteration:  108  cost:  0.7009949579037571\n",
      "iteration:  109  cost:  0.6703737887491955\n",
      "[0.308, 0.364, 0.524, 0.716, 0.798, 0.822, 0.856, 0.872, 0.886, 0.906, 0.922, 0.932]\n",
      "iteration:  110  cost:  0.715202919203039\n",
      "iteration:  111  cost:  0.6055323750359094\n",
      "iteration:  112  cost:  0.6264089858368913\n",
      "iteration:  113  cost:  0.6381106077572318\n",
      "iteration:  114  cost:  0.6289518120518458\n",
      "iteration:  115  cost:  0.7028112911871562\n",
      "iteration:  116  cost:  0.6497080147371499\n",
      "iteration:  117  cost:  0.7189749323014867\n",
      "iteration:  118  cost:  0.7144858264896308\n",
      "iteration:  119  cost:  0.6427755393037189\n",
      "[0.308, 0.364, 0.524, 0.716, 0.798, 0.822, 0.856, 0.872, 0.886, 0.906, 0.922, 0.932, 0.936]\n",
      "iteration:  120  cost:  0.6451325735595879\n",
      "iteration:  121  cost:  0.6583704350146153\n",
      "iteration:  122  cost:  0.6005698847104632\n",
      "iteration:  123  cost:  0.6055845483516814\n",
      "iteration:  124  cost:  0.687092942252371\n",
      "iteration:  125  cost:  0.6358233639002073\n",
      "iteration:  126  cost:  0.6687520480303238\n",
      "iteration:  127  cost:  0.6608063559737574\n",
      "iteration:  128  cost:  0.6438134788978732\n",
      "iteration:  129  cost:  0.7307638038048527\n",
      "[0.308, 0.364, 0.524, 0.716, 0.798, 0.822, 0.856, 0.872, 0.886, 0.906, 0.922, 0.932, 0.936, 0.938]\n",
      "iteration:  130  cost:  0.7138724948803444\n",
      "iteration:  131  cost:  0.6956715741245607\n",
      "iteration:  132  cost:  0.639451337384768\n",
      "iteration:  133  cost:  0.628938630938796\n",
      "iteration:  134  cost:  0.6470456064532669\n",
      "iteration:  135  cost:  0.5442859881449665\n",
      "iteration:  136  cost:  0.5950101143174368\n",
      "iteration:  137  cost:  0.6456611114206432\n",
      "iteration:  138  cost:  0.7008713910811921\n",
      "iteration:  139  cost:  0.6869897157941217\n",
      "[0.308, 0.364, 0.524, 0.716, 0.798, 0.822, 0.856, 0.872, 0.886, 0.906, 0.922, 0.932, 0.936, 0.938, 0.936]\n",
      "iteration:  140  cost:  0.5740922524736011\n",
      "iteration:  141  cost:  0.5928896115564701\n",
      "iteration:  142  cost:  0.6409515189255213\n",
      "iteration:  143  cost:  0.6595576374485441\n",
      "iteration:  144  cost:  0.5641259901281652\n",
      "iteration:  145  cost:  0.6190291145447511\n",
      "iteration:  146  cost:  0.6120572933262342\n",
      "iteration:  147  cost:  0.6141586090496817\n",
      "iteration:  148  cost:  0.6828471498683534\n",
      "iteration:  149  cost:  0.6258651462647619\n",
      "[0.308, 0.364, 0.524, 0.716, 0.798, 0.822, 0.856, 0.872, 0.886, 0.906, 0.922, 0.932, 0.936, 0.938, 0.936, 0.932]\n",
      "Accuracy for U_TTN autoencoder8 :0.950354609929078\n",
      "Epoch 1/10\n",
      "396/396 [==============================] - 1s 1ms/step - loss: 0.0937 - val_loss: 0.0281\n",
      "Epoch 2/10\n",
      "396/396 [==============================] - 0s 781us/step - loss: 0.0269 - val_loss: 0.0226\n",
      "Epoch 3/10\n",
      "396/396 [==============================] - 0s 932us/step - loss: 0.0217 - val_loss: 0.0186\n",
      "Epoch 4/10\n",
      "396/396 [==============================] - 0s 794us/step - loss: 0.0183 - val_loss: 0.0157\n",
      "Epoch 5/10\n",
      "396/396 [==============================] - 0s 807us/step - loss: 0.0154 - val_loss: 0.0139\n",
      "Epoch 6/10\n",
      "396/396 [==============================] - 0s 798us/step - loss: 0.0139 - val_loss: 0.0128\n",
      "Epoch 7/10\n",
      "396/396 [==============================] - 0s 838us/step - loss: 0.0128 - val_loss: 0.0120\n",
      "Epoch 8/10\n",
      "396/396 [==============================] - 0s 813us/step - loss: 0.0121 - val_loss: 0.0114\n",
      "Epoch 9/10\n",
      "396/396 [==============================] - 0s 807us/step - loss: 0.0115 - val_loss: 0.0110\n",
      "Epoch 10/10\n",
      "396/396 [==============================] - 0s 945us/step - loss: 0.0112 - val_loss: 0.0107\n",
      "\n",
      "\n",
      "Loss History for QCNN circuits, U_TTN autoencoder16\n",
      "[0.328]\n",
      "iteration:  0  cost:  1.0982374857473212\n",
      "iteration:  1  cost:  1.0570242009421633\n",
      "iteration:  2  cost:  1.0133600988794174\n",
      "iteration:  3  cost:  1.034657320620242\n",
      "iteration:  4  cost:  0.987277892225499\n",
      "iteration:  5  cost:  0.9651237298258932\n",
      "iteration:  6  cost:  1.0010431006853693\n",
      "iteration:  7  cost:  0.9145105437938156\n",
      "iteration:  8  cost:  0.9402758354257051\n",
      "iteration:  9  cost:  0.8695361740119268\n",
      "[0.328, 0.66]\n",
      "iteration:  10  cost:  0.8550114988202339\n",
      "iteration:  11  cost:  0.8444724852608517\n",
      "iteration:  12  cost:  0.8843158441719642\n",
      "iteration:  13  cost:  0.7343299467718173\n",
      "iteration:  14  cost:  0.7910711119220802\n",
      "iteration:  15  cost:  0.7918968318411477\n",
      "iteration:  16  cost:  0.716567892013182\n",
      "iteration:  17  cost:  0.7192801522545494\n",
      "iteration:  18  cost:  0.7492600123042287\n",
      "iteration:  19  cost:  0.8863454109421253\n",
      "[0.328, 0.66, 0.752]\n",
      "iteration:  20  cost:  0.7880018051378873\n",
      "iteration:  21  cost:  0.6976224302621066\n",
      "iteration:  22  cost:  0.7216967865351339\n",
      "iteration:  23  cost:  0.7089304129643117\n",
      "iteration:  24  cost:  0.7086984445709459\n",
      "iteration:  25  cost:  0.7417411021545535\n",
      "iteration:  26  cost:  0.758628631986948\n",
      "iteration:  27  cost:  0.8567971494750455\n",
      "iteration:  28  cost:  0.7430184875527486\n",
      "iteration:  29  cost:  0.7615167980479244\n",
      "[0.328, 0.66, 0.752, 0.75]\n",
      "iteration:  30  cost:  0.6354110772006383\n",
      "iteration:  31  cost:  0.7526429723041081\n",
      "iteration:  32  cost:  0.6079079958571575\n",
      "iteration:  33  cost:  0.7917777542558345\n",
      "iteration:  34  cost:  0.6712841201479077\n",
      "iteration:  35  cost:  0.6596082536845818\n",
      "iteration:  36  cost:  0.6999308468802242\n",
      "iteration:  37  cost:  0.6545626761948394\n",
      "iteration:  38  cost:  0.8043105140694788\n",
      "iteration:  39  cost:  0.741341926857281\n",
      "[0.328, 0.66, 0.752, 0.75, 0.756]\n",
      "iteration:  40  cost:  0.9548095035505881\n",
      "iteration:  41  cost:  0.5356926496750603\n",
      "iteration:  42  cost:  0.5026798366268852\n",
      "iteration:  43  cost:  0.8005460065865296\n",
      "iteration:  44  cost:  0.6068160021884317\n",
      "iteration:  45  cost:  0.6618200896706667\n",
      "iteration:  46  cost:  0.6855101476943757\n",
      "iteration:  47  cost:  0.6878853476885483\n",
      "iteration:  48  cost:  0.8244182778320571\n",
      "iteration:  49  cost:  0.7595724387107264\n",
      "[0.328, 0.66, 0.752, 0.75, 0.756, 0.758]\n",
      "iteration:  50  cost:  0.7922424248653508\n",
      "iteration:  51  cost:  0.631501368584152\n",
      "iteration:  52  cost:  0.7159732929760717\n",
      "iteration:  53  cost:  0.7391058586128502\n",
      "iteration:  54  cost:  0.6246461582224991\n",
      "iteration:  55  cost:  0.7874045923128031\n",
      "iteration:  56  cost:  0.7062023967863823\n",
      "iteration:  57  cost:  0.7369084636666381\n",
      "iteration:  58  cost:  0.7237826705017841\n",
      "iteration:  59  cost:  0.6970846736295485\n",
      "[0.328, 0.66, 0.752, 0.75, 0.756, 0.758, 0.768]\n",
      "iteration:  60  cost:  0.516058555378822\n",
      "iteration:  61  cost:  0.805128981637997\n",
      "iteration:  62  cost:  0.6253213122710877\n",
      "iteration:  63  cost:  0.786888682249756\n",
      "iteration:  64  cost:  0.737453082445511\n",
      "iteration:  65  cost:  0.7035903888837963\n",
      "iteration:  66  cost:  0.621458094559858\n",
      "iteration:  67  cost:  0.6203536860284373\n",
      "iteration:  68  cost:  0.6749133180643905\n",
      "iteration:  69  cost:  0.7359016213450243\n",
      "[0.328, 0.66, 0.752, 0.75, 0.756, 0.758, 0.768, 0.784]\n",
      "iteration:  70  cost:  0.6869200792165586\n",
      "iteration:  71  cost:  0.6378536358627235\n",
      "iteration:  72  cost:  0.6794718295820222\n",
      "iteration:  73  cost:  0.6736448364222865\n",
      "iteration:  74  cost:  0.6939456893282003\n",
      "iteration:  75  cost:  0.564729273448107\n",
      "iteration:  76  cost:  0.7286902847090336\n",
      "iteration:  77  cost:  0.5830339049016606\n",
      "iteration:  78  cost:  0.7341515814554498\n",
      "iteration:  79  cost:  0.6537184320787304\n",
      "[0.328, 0.66, 0.752, 0.75, 0.756, 0.758, 0.768, 0.784, 0.782]\n",
      "iteration:  80  cost:  0.7516371377036779\n",
      "iteration:  81  cost:  0.6634253754150023\n",
      "iteration:  82  cost:  0.684771645152532\n",
      "iteration:  83  cost:  0.6621478183284166\n",
      "iteration:  84  cost:  0.7822666554496662\n",
      "iteration:  85  cost:  0.8272090057364736\n",
      "iteration:  86  cost:  0.7682480907690474\n",
      "iteration:  87  cost:  0.6064848401608808\n",
      "iteration:  88  cost:  0.8203680485482744\n",
      "iteration:  89  cost:  0.6988644779226315\n",
      "[0.328, 0.66, 0.752, 0.75, 0.756, 0.758, 0.768, 0.784, 0.782, 0.798]\n",
      "iteration:  90  cost:  0.7364685685648006\n",
      "iteration:  91  cost:  0.8012359787986364\n",
      "iteration:  92  cost:  0.7312709979038816\n",
      "iteration:  93  cost:  0.5709593905490358\n",
      "iteration:  94  cost:  0.7084174270199134\n",
      "iteration:  95  cost:  0.6346509249047778\n",
      "iteration:  96  cost:  0.6898169642233175\n",
      "iteration:  97  cost:  0.6739024703649875\n",
      "iteration:  98  cost:  0.5862094057654673\n",
      "iteration:  99  cost:  0.6491273496330494\n",
      "[0.328, 0.66, 0.752, 0.75, 0.756, 0.758, 0.768, 0.784, 0.782, 0.798, 0.814]\n",
      "iteration:  100  cost:  0.6930944013534794\n",
      "iteration:  101  cost:  0.7255798788343993\n",
      "iteration:  102  cost:  0.7158080033122736\n",
      "iteration:  103  cost:  0.6552009147894324\n",
      "iteration:  104  cost:  0.6229605906762745\n",
      "iteration:  105  cost:  0.633011791152963\n",
      "iteration:  106  cost:  0.6681764294413101\n",
      "iteration:  107  cost:  0.609581062182328\n",
      "iteration:  108  cost:  0.6490873368487388\n",
      "iteration:  109  cost:  0.5657718700450688\n",
      "[0.328, 0.66, 0.752, 0.75, 0.756, 0.758, 0.768, 0.784, 0.782, 0.798, 0.814, 0.81]\n",
      "iteration:  110  cost:  0.5596869432564339\n",
      "iteration:  111  cost:  0.6426003353112918\n",
      "iteration:  112  cost:  0.6729044998990688\n",
      "iteration:  113  cost:  0.6784985940527788\n",
      "iteration:  114  cost:  0.6289773779325561\n",
      "iteration:  115  cost:  0.6422106113128201\n",
      "iteration:  116  cost:  0.7826420615927545\n",
      "iteration:  117  cost:  0.6856708778519802\n",
      "iteration:  118  cost:  0.7236097117157221\n",
      "iteration:  119  cost:  0.6067535939353706\n",
      "[0.328, 0.66, 0.752, 0.75, 0.756, 0.758, 0.768, 0.784, 0.782, 0.798, 0.814, 0.81, 0.808]\n",
      "iteration:  120  cost:  0.731686216064063\n",
      "iteration:  121  cost:  0.6758378442147119\n",
      "iteration:  122  cost:  0.6006947553309137\n",
      "iteration:  123  cost:  0.6185349421566864\n",
      "iteration:  124  cost:  0.5625122730397867\n",
      "iteration:  125  cost:  0.5055081086057818\n",
      "iteration:  126  cost:  0.6646110355691277\n",
      "iteration:  127  cost:  0.7110651027078646\n",
      "iteration:  128  cost:  0.6251462499055767\n",
      "iteration:  129  cost:  0.6745274941646181\n",
      "[0.328, 0.66, 0.752, 0.75, 0.756, 0.758, 0.768, 0.784, 0.782, 0.798, 0.814, 0.81, 0.808, 0.806]\n",
      "Accuracy for U_TTN autoencoder16 :0.816548463356974\n",
      "\n",
      "\n",
      "Loss History for QCNN circuits, U_5 resize256\n",
      "[0.524]\n",
      "iteration:  0  cost:  0.8436374050918067\n",
      "iteration:  1  cost:  0.6958312827313139\n",
      "iteration:  2  cost:  0.719573441247462\n",
      "iteration:  3  cost:  0.8225855809251448\n",
      "iteration:  4  cost:  0.9222790337781585\n",
      "iteration:  5  cost:  0.8218385909738122\n",
      "iteration:  6  cost:  0.982890969286022\n",
      "iteration:  7  cost:  0.8872741038518567\n",
      "iteration:  8  cost:  0.8668084171196859\n",
      "iteration:  9  cost:  0.8570415556822367\n",
      "[0.524, 0.644]\n",
      "iteration:  10  cost:  0.8488998183459066\n",
      "iteration:  11  cost:  0.9040966807903049\n",
      "iteration:  12  cost:  0.7745370104318288\n",
      "iteration:  13  cost:  0.7539628788032802\n",
      "iteration:  14  cost:  0.7655063306058598\n",
      "iteration:  15  cost:  0.7498368906199633\n",
      "iteration:  16  cost:  0.7424027629354448\n",
      "iteration:  17  cost:  0.6797294473236322\n",
      "iteration:  18  cost:  0.8009342677583378\n",
      "iteration:  19  cost:  0.8073296042190776\n",
      "[0.524, 0.644, 0.852]\n",
      "iteration:  20  cost:  0.7619436469791891\n",
      "iteration:  21  cost:  0.7086596786113737\n",
      "iteration:  22  cost:  0.7360936132356017\n",
      "iteration:  23  cost:  0.7580227572130437\n",
      "iteration:  24  cost:  0.8310917063093666\n",
      "iteration:  25  cost:  0.7575095303235119\n",
      "iteration:  26  cost:  0.6822740174178358\n",
      "iteration:  27  cost:  0.6313907362839603\n",
      "iteration:  28  cost:  0.686298036117122\n",
      "iteration:  29  cost:  0.7049656849601037\n",
      "[0.524, 0.644, 0.852, 0.828]\n",
      "iteration:  30  cost:  0.6167094720606439\n",
      "iteration:  31  cost:  0.7839952099259473\n",
      "iteration:  32  cost:  0.7208849506813619\n",
      "iteration:  33  cost:  0.6721760503944183\n",
      "iteration:  34  cost:  0.7061583717874216\n",
      "iteration:  35  cost:  0.7753808437679571\n",
      "iteration:  36  cost:  0.6282053737918306\n",
      "iteration:  37  cost:  0.680996503567799\n",
      "iteration:  38  cost:  0.7150899893705916\n",
      "iteration:  39  cost:  0.6880026522275622\n",
      "[0.524, 0.644, 0.852, 0.828, 0.828]\n",
      "iteration:  40  cost:  0.6218590805473968\n",
      "iteration:  41  cost:  0.6898302316516025\n",
      "iteration:  42  cost:  0.681191840012265\n",
      "iteration:  43  cost:  0.6345682498460036\n",
      "iteration:  44  cost:  0.6914661089086312\n",
      "iteration:  45  cost:  0.6099918769344702\n",
      "iteration:  46  cost:  0.5858573511325554\n",
      "iteration:  47  cost:  0.6529050125475304\n",
      "iteration:  48  cost:  0.6296888664976186\n",
      "iteration:  49  cost:  0.617436797542374\n",
      "[0.524, 0.644, 0.852, 0.828, 0.828, 0.87]\n",
      "iteration:  50  cost:  0.6524735622427239\n",
      "iteration:  51  cost:  0.6601029623651281\n",
      "iteration:  52  cost:  0.627896452553078\n",
      "iteration:  53  cost:  0.7099494293752798\n",
      "iteration:  54  cost:  0.5603059791690141\n",
      "iteration:  55  cost:  0.7299725027510654\n",
      "iteration:  56  cost:  0.5990909875419501\n",
      "iteration:  57  cost:  0.6190641441031397\n",
      "iteration:  58  cost:  0.5443123861722111\n",
      "iteration:  59  cost:  0.542586412725548\n",
      "[0.524, 0.644, 0.852, 0.828, 0.828, 0.87, 0.88]\n",
      "iteration:  60  cost:  0.5853836475635453\n",
      "iteration:  61  cost:  0.547411493830146\n",
      "iteration:  62  cost:  0.6474326801804985\n",
      "iteration:  63  cost:  0.45545558933163327\n",
      "iteration:  64  cost:  0.5109666625824156\n",
      "iteration:  65  cost:  0.5022492183894741\n",
      "iteration:  66  cost:  0.5739893787212502\n",
      "iteration:  67  cost:  0.6699010939833012\n",
      "iteration:  68  cost:  0.5107306243725993\n",
      "iteration:  69  cost:  0.6182806529538624\n",
      "[0.524, 0.644, 0.852, 0.828, 0.828, 0.87, 0.88, 0.88]\n",
      "iteration:  70  cost:  0.4974674436310535\n",
      "iteration:  71  cost:  0.4917224667127862\n",
      "iteration:  72  cost:  0.5428258833389283\n",
      "iteration:  73  cost:  0.5096587681569096\n",
      "iteration:  74  cost:  0.5023016812611227\n",
      "iteration:  75  cost:  0.5676537184380727\n",
      "iteration:  76  cost:  0.5287991790143406\n",
      "iteration:  77  cost:  0.5627336750503389\n",
      "iteration:  78  cost:  0.5434761489830884\n",
      "iteration:  79  cost:  0.6169826584435577\n",
      "[0.524, 0.644, 0.852, 0.828, 0.828, 0.87, 0.88, 0.88, 0.886]\n",
      "iteration:  80  cost:  0.5007484719470426\n",
      "iteration:  81  cost:  0.5540861665866462\n",
      "iteration:  82  cost:  0.5370785747435691\n",
      "iteration:  83  cost:  0.3961222793484827\n",
      "iteration:  84  cost:  0.584409747221084\n",
      "iteration:  85  cost:  0.5015926987262724\n",
      "iteration:  86  cost:  0.46585130989989876\n",
      "iteration:  87  cost:  0.48418187599244994\n",
      "iteration:  88  cost:  0.5333024549710432\n",
      "iteration:  89  cost:  0.5301436300348311\n",
      "[0.524, 0.644, 0.852, 0.828, 0.828, 0.87, 0.88, 0.88, 0.886, 0.904]\n",
      "iteration:  90  cost:  0.4744764577137437\n",
      "iteration:  91  cost:  0.49997063037990147\n",
      "iteration:  92  cost:  0.550469963475219\n",
      "iteration:  93  cost:  0.4597708170690227\n",
      "iteration:  94  cost:  0.5798895342848734\n",
      "iteration:  95  cost:  0.4718603775303447\n",
      "iteration:  96  cost:  0.6551419601225471\n",
      "iteration:  97  cost:  0.6024255604399006\n",
      "iteration:  98  cost:  0.4029724368239724\n",
      "iteration:  99  cost:  0.4660757275287631\n",
      "[0.524, 0.644, 0.852, 0.828, 0.828, 0.87, 0.88, 0.88, 0.886, 0.904, 0.902]\n",
      "iteration:  100  cost:  0.5223628622651898\n",
      "iteration:  101  cost:  0.4922085086080747\n",
      "iteration:  102  cost:  0.5252052334164783\n",
      "iteration:  103  cost:  0.5646988466554332\n",
      "iteration:  104  cost:  0.49432728877844356\n",
      "iteration:  105  cost:  0.45389346466103553\n",
      "iteration:  106  cost:  0.48997397883549426\n",
      "iteration:  107  cost:  0.45891934489765673\n",
      "iteration:  108  cost:  0.4367145575154085\n",
      "iteration:  109  cost:  0.4729207545816565\n",
      "[0.524, 0.644, 0.852, 0.828, 0.828, 0.87, 0.88, 0.88, 0.886, 0.904, 0.902, 0.902]\n",
      "iteration:  110  cost:  0.4938914492611446\n",
      "iteration:  111  cost:  0.49469454658066403\n",
      "iteration:  112  cost:  0.5023159376397761\n",
      "iteration:  113  cost:  0.556216064788043\n",
      "iteration:  114  cost:  0.5426602926008275\n",
      "iteration:  115  cost:  0.4928834988945535\n",
      "iteration:  116  cost:  0.47166799937220333\n",
      "iteration:  117  cost:  0.41230068954663857\n",
      "iteration:  118  cost:  0.5299100729068627\n",
      "iteration:  119  cost:  0.4874191043489269\n",
      "[0.524, 0.644, 0.852, 0.828, 0.828, 0.87, 0.88, 0.88, 0.886, 0.904, 0.902, 0.902, 0.906]\n",
      "iteration:  120  cost:  0.4896679749472726\n",
      "iteration:  121  cost:  0.4657677653400812\n",
      "iteration:  122  cost:  0.45182308598426635\n",
      "iteration:  123  cost:  0.47995987533948564\n",
      "iteration:  124  cost:  0.387667511289854\n",
      "iteration:  125  cost:  0.4651507111932036\n",
      "iteration:  126  cost:  0.49380063254434503\n",
      "iteration:  127  cost:  0.5131519248792791\n",
      "iteration:  128  cost:  0.42840689451391434\n",
      "iteration:  129  cost:  0.5632942890574489\n",
      "[0.524, 0.644, 0.852, 0.828, 0.828, 0.87, 0.88, 0.88, 0.886, 0.904, 0.902, 0.902, 0.906, 0.902]\n",
      "iteration:  130  cost:  0.5166312709561327\n",
      "iteration:  131  cost:  0.37685002666006356\n",
      "iteration:  132  cost:  0.48209085328945006\n",
      "iteration:  133  cost:  0.5306478654970751\n",
      "iteration:  134  cost:  0.46714331978601037\n",
      "iteration:  135  cost:  0.5291688343338214\n",
      "iteration:  136  cost:  0.44950337337228885\n",
      "iteration:  137  cost:  0.41820797848720154\n",
      "iteration:  138  cost:  0.47310873502461476\n",
      "iteration:  139  cost:  0.44322693101182753\n",
      "[0.524, 0.644, 0.852, 0.828, 0.828, 0.87, 0.88, 0.88, 0.886, 0.904, 0.902, 0.902, 0.906, 0.902, 0.908]\n",
      "iteration:  140  cost:  0.3545356031301472\n",
      "iteration:  141  cost:  0.6034853561341034\n",
      "iteration:  142  cost:  0.5320318938699043\n",
      "iteration:  143  cost:  0.5389441130186067\n",
      "iteration:  144  cost:  0.4575034450545782\n",
      "iteration:  145  cost:  0.47766444414410075\n",
      "iteration:  146  cost:  0.4178883459377451\n",
      "iteration:  147  cost:  0.5623847165995876\n",
      "iteration:  148  cost:  0.4475238372458344\n",
      "iteration:  149  cost:  0.43824445698834097\n",
      "[0.524, 0.644, 0.852, 0.828, 0.828, 0.87, 0.88, 0.88, 0.886, 0.904, 0.902, 0.902, 0.906, 0.902, 0.908, 0.904]\n",
      "iteration:  150  cost:  0.47346453845401854\n",
      "iteration:  151  cost:  0.49741279986743187\n",
      "iteration:  152  cost:  0.5125854524631817\n",
      "iteration:  153  cost:  0.4686222350816015\n",
      "iteration:  154  cost:  0.5931077017310312\n",
      "iteration:  155  cost:  0.5392371728263922\n",
      "iteration:  156  cost:  0.49844836377390855\n",
      "iteration:  157  cost:  0.31761790515587435\n",
      "iteration:  158  cost:  0.4329804464525938\n",
      "iteration:  159  cost:  0.6878009191818839\n",
      "[0.524, 0.644, 0.852, 0.828, 0.828, 0.87, 0.88, 0.88, 0.886, 0.904, 0.902, 0.902, 0.906, 0.902, 0.908, 0.904, 0.912]\n",
      "iteration:  160  cost:  0.37054289545350677\n",
      "iteration:  161  cost:  0.4314558022530159\n",
      "iteration:  162  cost:  0.4407685668377934\n",
      "iteration:  163  cost:  0.4962137105894331\n",
      "iteration:  164  cost:  0.467122436054251\n",
      "iteration:  165  cost:  0.5860569814780466\n",
      "iteration:  166  cost:  0.3898233450298423\n",
      "iteration:  167  cost:  0.3825835408058641\n",
      "iteration:  168  cost:  0.500995042909834\n",
      "iteration:  169  cost:  0.458681744619784\n",
      "[0.524, 0.644, 0.852, 0.828, 0.828, 0.87, 0.88, 0.88, 0.886, 0.904, 0.902, 0.902, 0.906, 0.902, 0.908, 0.904, 0.912, 0.906]\n",
      "iteration:  170  cost:  0.4968465623421651\n",
      "iteration:  171  cost:  0.43154338589887326\n",
      "iteration:  172  cost:  0.5898950188354974\n",
      "iteration:  173  cost:  0.4999313908362398\n",
      "iteration:  174  cost:  0.5047253778460096\n",
      "iteration:  175  cost:  0.5373786254046411\n",
      "iteration:  176  cost:  0.3635013199881312\n",
      "iteration:  177  cost:  0.48652577132582864\n",
      "iteration:  178  cost:  0.48592777498496\n",
      "iteration:  179  cost:  0.6487728493508251\n",
      "[0.524, 0.644, 0.852, 0.828, 0.828, 0.87, 0.88, 0.88, 0.886, 0.904, 0.902, 0.902, 0.906, 0.902, 0.908, 0.904, 0.912, 0.906, 0.904]\n",
      "iteration:  180  cost:  0.49463582545799467\n",
      "iteration:  181  cost:  0.5385613069205402\n",
      "iteration:  182  cost:  0.5218081901884049\n",
      "iteration:  183  cost:  0.40855222195099217\n",
      "iteration:  184  cost:  0.42523271690695646\n",
      "iteration:  185  cost:  0.44664011330488984\n",
      "iteration:  186  cost:  0.4743087014199212\n",
      "iteration:  187  cost:  0.49904327057710446\n",
      "iteration:  188  cost:  0.521055878012169\n",
      "iteration:  189  cost:  0.37000637919492946\n",
      "[0.524, 0.644, 0.852, 0.828, 0.828, 0.87, 0.88, 0.88, 0.886, 0.904, 0.902, 0.902, 0.906, 0.902, 0.908, 0.904, 0.912, 0.906, 0.904, 0.91]\n",
      "iteration:  190  cost:  0.3855432010812686\n",
      "iteration:  191  cost:  0.4101756068531558\n",
      "iteration:  192  cost:  0.5419082536722862\n",
      "iteration:  193  cost:  0.5528027934535157\n",
      "iteration:  194  cost:  0.49777208404430373\n",
      "iteration:  195  cost:  0.4263605546201676\n",
      "iteration:  196  cost:  0.48115867384309263\n",
      "iteration:  197  cost:  0.47489349383630824\n",
      "iteration:  198  cost:  0.4965627441538236\n",
      "iteration:  199  cost:  0.5058064262071605\n",
      "[0.524, 0.644, 0.852, 0.828, 0.828, 0.87, 0.88, 0.88, 0.886, 0.904, 0.902, 0.902, 0.906, 0.902, 0.908, 0.904, 0.912, 0.906, 0.904, 0.91, 0.91]\n",
      "iteration:  200  cost:  0.3921444551746107\n",
      "iteration:  201  cost:  0.3820009383129975\n",
      "iteration:  202  cost:  0.5279653751587504\n",
      "iteration:  203  cost:  0.5216681778121955\n",
      "iteration:  204  cost:  0.48876752303464643\n",
      "iteration:  205  cost:  0.6935678829980325\n",
      "iteration:  206  cost:  0.5245493927513873\n",
      "iteration:  207  cost:  0.651248290711771\n",
      "iteration:  208  cost:  0.42793428786670445\n",
      "iteration:  209  cost:  0.45352273189731496\n",
      "[0.524, 0.644, 0.852, 0.828, 0.828, 0.87, 0.88, 0.88, 0.886, 0.904, 0.902, 0.902, 0.906, 0.902, 0.908, 0.904, 0.912, 0.906, 0.904, 0.91, 0.91, 0.924]\n",
      "iteration:  210  cost:  0.5320899125907759\n",
      "iteration:  211  cost:  0.41046293470269973\n",
      "iteration:  212  cost:  0.5072287115999502\n",
      "iteration:  213  cost:  0.4678001928838755\n",
      "iteration:  214  cost:  0.5044797824629981\n",
      "iteration:  215  cost:  0.39833813197002477\n",
      "iteration:  216  cost:  0.4846297785874403\n",
      "iteration:  217  cost:  0.4912236918209979\n",
      "iteration:  218  cost:  0.4342990326779001\n",
      "iteration:  219  cost:  0.5790951102029797\n",
      "[0.524, 0.644, 0.852, 0.828, 0.828, 0.87, 0.88, 0.88, 0.886, 0.904, 0.902, 0.902, 0.906, 0.902, 0.908, 0.904, 0.912, 0.906, 0.904, 0.91, 0.91, 0.924, 0.916]\n",
      "iteration:  220  cost:  0.43308694545725146\n",
      "iteration:  221  cost:  0.6240632767348039\n",
      "iteration:  222  cost:  0.4845182025324259\n",
      "iteration:  223  cost:  0.4840051077100027\n",
      "iteration:  224  cost:  0.4862856669487801\n",
      "iteration:  225  cost:  0.4343807737546028\n",
      "iteration:  226  cost:  0.4195267955587056\n",
      "iteration:  227  cost:  0.4247083990753206\n",
      "iteration:  228  cost:  0.4442100852053988\n",
      "iteration:  229  cost:  0.3709969174773481\n",
      "[0.524, 0.644, 0.852, 0.828, 0.828, 0.87, 0.88, 0.88, 0.886, 0.904, 0.902, 0.902, 0.906, 0.902, 0.908, 0.904, 0.912, 0.906, 0.904, 0.91, 0.91, 0.924, 0.916, 0.92]\n",
      "iteration:  230  cost:  0.45353295348444006\n",
      "iteration:  231  cost:  0.4555591502526971\n",
      "iteration:  232  cost:  0.4563406654982519\n",
      "iteration:  233  cost:  0.5540126303289816\n",
      "iteration:  234  cost:  0.44320597991781263\n",
      "iteration:  235  cost:  0.5087410399808154\n",
      "iteration:  236  cost:  0.5340130053635772\n",
      "iteration:  237  cost:  0.42070666151375524\n",
      "iteration:  238  cost:  0.520413501705355\n",
      "iteration:  239  cost:  0.5087901018336238\n",
      "[0.524, 0.644, 0.852, 0.828, 0.828, 0.87, 0.88, 0.88, 0.886, 0.904, 0.902, 0.902, 0.906, 0.902, 0.908, 0.904, 0.912, 0.906, 0.904, 0.91, 0.91, 0.924, 0.916, 0.92, 0.916]\n",
      "iteration:  240  cost:  0.4838271983653973\n",
      "iteration:  241  cost:  0.45538024829435414\n",
      "iteration:  242  cost:  0.4203866345668551\n",
      "iteration:  243  cost:  0.44459741165549793\n",
      "iteration:  244  cost:  0.4031573928320276\n",
      "iteration:  245  cost:  0.31688034927706393\n",
      "iteration:  246  cost:  0.5863139681163174\n",
      "iteration:  247  cost:  0.5228862366207309\n",
      "iteration:  248  cost:  0.5252313925107316\n",
      "iteration:  249  cost:  0.4158267146827113\n",
      "[0.524, 0.644, 0.852, 0.828, 0.828, 0.87, 0.88, 0.88, 0.886, 0.904, 0.902, 0.902, 0.906, 0.902, 0.908, 0.904, 0.912, 0.906, 0.904, 0.91, 0.91, 0.924, 0.916, 0.92, 0.916, 0.92]\n",
      "iteration:  250  cost:  0.5237351971311067\n",
      "iteration:  251  cost:  0.4621966225637224\n",
      "iteration:  252  cost:  0.49554531057606094\n",
      "iteration:  253  cost:  0.47784401563829293\n",
      "iteration:  254  cost:  0.5357219550710852\n",
      "iteration:  255  cost:  0.3540983280390613\n",
      "iteration:  256  cost:  0.5384352649104782\n",
      "iteration:  257  cost:  0.5448398828490723\n",
      "iteration:  258  cost:  0.47454480339179805\n",
      "iteration:  259  cost:  0.493960427125436\n",
      "[0.524, 0.644, 0.852, 0.828, 0.828, 0.87, 0.88, 0.88, 0.886, 0.904, 0.902, 0.902, 0.906, 0.902, 0.908, 0.904, 0.912, 0.906, 0.904, 0.91, 0.91, 0.924, 0.916, 0.92, 0.916, 0.92, 0.932]\n",
      "iteration:  260  cost:  0.4448238630699693\n",
      "iteration:  261  cost:  0.5066595045991016\n",
      "iteration:  262  cost:  0.5917587472239514\n",
      "iteration:  263  cost:  0.47470588072148134\n",
      "iteration:  264  cost:  0.3870305191171442\n",
      "iteration:  265  cost:  0.4642893248924304\n",
      "iteration:  266  cost:  0.3806085808480809\n",
      "iteration:  267  cost:  0.47721987067912125\n",
      "iteration:  268  cost:  0.43434772571435476\n",
      "iteration:  269  cost:  0.4144478368721043\n",
      "[0.524, 0.644, 0.852, 0.828, 0.828, 0.87, 0.88, 0.88, 0.886, 0.904, 0.902, 0.902, 0.906, 0.902, 0.908, 0.904, 0.912, 0.906, 0.904, 0.91, 0.91, 0.924, 0.916, 0.92, 0.916, 0.92, 0.932, 0.924]\n",
      "iteration:  270  cost:  0.4670901733443886\n",
      "iteration:  271  cost:  0.5375921183881772\n",
      "iteration:  272  cost:  0.4235294303414273\n",
      "iteration:  273  cost:  0.47417383108839745\n",
      "iteration:  274  cost:  0.5287949948372025\n",
      "iteration:  275  cost:  0.4602131309350771\n",
      "iteration:  276  cost:  0.47139055580461736\n",
      "iteration:  277  cost:  0.44205607711109357\n",
      "iteration:  278  cost:  0.4775865868652253\n",
      "iteration:  279  cost:  0.4321417760239251\n",
      "[0.524, 0.644, 0.852, 0.828, 0.828, 0.87, 0.88, 0.88, 0.886, 0.904, 0.902, 0.902, 0.906, 0.902, 0.908, 0.904, 0.912, 0.906, 0.904, 0.91, 0.91, 0.924, 0.916, 0.92, 0.916, 0.92, 0.932, 0.924, 0.926]\n",
      "iteration:  280  cost:  0.532182775405827\n",
      "iteration:  281  cost:  0.540695576084208\n",
      "iteration:  282  cost:  0.4704425251163296\n",
      "iteration:  283  cost:  0.3881478085887182\n",
      "iteration:  284  cost:  0.39734313299720186\n",
      "iteration:  285  cost:  0.44259102841231085\n",
      "iteration:  286  cost:  0.3556190602926533\n",
      "iteration:  287  cost:  0.5418221126581407\n",
      "iteration:  288  cost:  0.46062715554983596\n",
      "iteration:  289  cost:  0.4189720657922395\n",
      "[0.524, 0.644, 0.852, 0.828, 0.828, 0.87, 0.88, 0.88, 0.886, 0.904, 0.902, 0.902, 0.906, 0.902, 0.908, 0.904, 0.912, 0.906, 0.904, 0.91, 0.91, 0.924, 0.916, 0.92, 0.916, 0.92, 0.932, 0.924, 0.926, 0.918]\n",
      "Accuracy for U_5 resize256 :0.9243498817966903\n",
      "\n",
      "\n",
      "Loss History for QCNN circuits, U_5 pca8\n",
      "[0.594]\n",
      "iteration:  0  cost:  0.9262782031447233\n",
      "iteration:  1  cost:  1.03699570372636\n",
      "iteration:  2  cost:  0.945959717153501\n",
      "iteration:  3  cost:  0.9398181822301441\n",
      "iteration:  4  cost:  0.8665000880261648\n",
      "iteration:  5  cost:  0.9295634209775727\n",
      "iteration:  6  cost:  1.0125552198256298\n",
      "iteration:  7  cost:  0.7814324174668714\n",
      "iteration:  8  cost:  1.0145235535431758\n",
      "iteration:  9  cost:  1.0000543582602293\n",
      "[0.594, 0.622]\n",
      "iteration:  10  cost:  0.9068218053114986\n",
      "iteration:  11  cost:  1.044031546432645\n",
      "iteration:  12  cost:  0.9072503062114673\n",
      "iteration:  13  cost:  0.8435916995098492\n",
      "iteration:  14  cost:  0.8810100664605754\n",
      "iteration:  15  cost:  0.822841102144391\n",
      "iteration:  16  cost:  0.8500211666837569\n",
      "iteration:  17  cost:  0.7349938502804769\n",
      "iteration:  18  cost:  0.7737893821932428\n",
      "iteration:  19  cost:  0.9260619534305525\n",
      "[0.594, 0.622, 0.678]\n",
      "iteration:  20  cost:  0.8292151001259846\n",
      "iteration:  21  cost:  0.831875933774277\n",
      "iteration:  22  cost:  0.7837138112332223\n",
      "iteration:  23  cost:  0.8472326461313878\n",
      "iteration:  24  cost:  0.690643462848593\n",
      "iteration:  25  cost:  0.7035003828122351\n",
      "iteration:  26  cost:  0.8984069298558387\n",
      "iteration:  27  cost:  0.8523090452887839\n",
      "iteration:  28  cost:  0.781044279975698\n",
      "iteration:  29  cost:  0.72574168788091\n",
      "[0.594, 0.622, 0.678, 0.876]\n",
      "iteration:  30  cost:  0.6379359687650233\n",
      "iteration:  31  cost:  0.7034153125989058\n",
      "iteration:  32  cost:  0.7902808585453092\n",
      "iteration:  33  cost:  0.6840979972801854\n",
      "iteration:  34  cost:  0.6771580381186196\n",
      "iteration:  35  cost:  0.7438614883627257\n",
      "iteration:  36  cost:  0.6893057723133309\n",
      "iteration:  37  cost:  0.579408462906799\n",
      "iteration:  38  cost:  0.5622102692822173\n",
      "iteration:  39  cost:  0.6431927721253885\n",
      "[0.594, 0.622, 0.678, 0.876, 0.942]\n",
      "iteration:  40  cost:  0.5990035288536728\n",
      "iteration:  41  cost:  0.5850867343480358\n",
      "iteration:  42  cost:  0.4983801281991452\n",
      "iteration:  43  cost:  0.526176121073935\n",
      "iteration:  44  cost:  0.427163316576423\n",
      "iteration:  45  cost:  0.5277376376595616\n",
      "iteration:  46  cost:  0.5117721360027022\n",
      "iteration:  47  cost:  0.43200187745130686\n",
      "iteration:  48  cost:  0.5210195611868579\n",
      "iteration:  49  cost:  0.560972165194919\n",
      "[0.594, 0.622, 0.678, 0.876, 0.942, 0.962]\n",
      "iteration:  50  cost:  0.5028547088927464\n",
      "iteration:  51  cost:  0.3922110078371025\n",
      "iteration:  52  cost:  0.4440999733252965\n",
      "iteration:  53  cost:  0.34013330552028714\n",
      "iteration:  54  cost:  0.29907133340329367\n",
      "iteration:  55  cost:  0.3354460680009195\n",
      "iteration:  56  cost:  0.3144279170769758\n",
      "iteration:  57  cost:  0.33484568760618516\n",
      "iteration:  58  cost:  0.4197399126953376\n",
      "iteration:  59  cost:  0.32885390697902106\n",
      "[0.594, 0.622, 0.678, 0.876, 0.942, 0.962, 0.964]\n",
      "iteration:  60  cost:  0.37949707613412614\n",
      "iteration:  61  cost:  0.3110105206505293\n",
      "iteration:  62  cost:  0.3099675211510795\n",
      "iteration:  63  cost:  0.23086362338020078\n",
      "iteration:  64  cost:  0.3631777995324327\n",
      "iteration:  65  cost:  0.3349444762715555\n",
      "iteration:  66  cost:  0.23315163934163047\n",
      "iteration:  67  cost:  0.2280628165375031\n",
      "iteration:  68  cost:  0.302307058712219\n",
      "iteration:  69  cost:  0.23720593982948301\n",
      "[0.594, 0.622, 0.678, 0.876, 0.942, 0.962, 0.964, 0.964]\n",
      "iteration:  70  cost:  0.3242701432366619\n",
      "iteration:  71  cost:  0.19261305186588387\n",
      "iteration:  72  cost:  0.2539548852196274\n",
      "iteration:  73  cost:  0.17257623974676645\n",
      "iteration:  74  cost:  0.17661539656784903\n",
      "iteration:  75  cost:  0.1829005388202\n",
      "iteration:  76  cost:  0.29546459810299347\n",
      "iteration:  77  cost:  0.17910623703865497\n",
      "iteration:  78  cost:  0.1996387522187144\n",
      "iteration:  79  cost:  0.18642594712499216\n",
      "[0.594, 0.622, 0.678, 0.876, 0.942, 0.962, 0.964, 0.964, 0.966]\n",
      "iteration:  80  cost:  0.29990863223734787\n",
      "iteration:  81  cost:  0.19980805345553093\n",
      "iteration:  82  cost:  0.18686634907066746\n",
      "iteration:  83  cost:  0.20776196237500333\n",
      "iteration:  84  cost:  0.3239278015132983\n",
      "iteration:  85  cost:  0.18936528123491947\n",
      "iteration:  86  cost:  0.1854288658741899\n",
      "iteration:  87  cost:  0.18436653464748898\n",
      "iteration:  88  cost:  0.23247032996382663\n",
      "iteration:  89  cost:  0.2092820761780745\n",
      "[0.594, 0.622, 0.678, 0.876, 0.942, 0.962, 0.964, 0.964, 0.966, 0.97]\n",
      "iteration:  90  cost:  0.1193358859742421\n",
      "iteration:  91  cost:  0.20870835520914124\n",
      "iteration:  92  cost:  0.16901955805586819\n",
      "iteration:  93  cost:  0.13877523272443498\n",
      "iteration:  94  cost:  0.13946436232376364\n",
      "iteration:  95  cost:  0.19315928661246182\n",
      "iteration:  96  cost:  0.09583962034623704\n",
      "iteration:  97  cost:  0.21200981337290814\n",
      "iteration:  98  cost:  0.12351781088892105\n",
      "iteration:  99  cost:  0.25751550546401364\n",
      "[0.594, 0.622, 0.678, 0.876, 0.942, 0.962, 0.964, 0.964, 0.966, 0.97, 0.97]\n",
      "iteration:  100  cost:  0.2104825158364228\n",
      "iteration:  101  cost:  0.12051708595588034\n",
      "iteration:  102  cost:  0.22539311088907027\n",
      "iteration:  103  cost:  0.12307678050023267\n",
      "iteration:  104  cost:  0.2610785222597069\n",
      "iteration:  105  cost:  0.1422515995090355\n",
      "iteration:  106  cost:  0.3066518590382624\n",
      "iteration:  107  cost:  0.30657474106787336\n",
      "iteration:  108  cost:  0.15361909362278625\n",
      "iteration:  109  cost:  0.13458155173970301\n",
      "[0.594, 0.622, 0.678, 0.876, 0.942, 0.962, 0.964, 0.964, 0.966, 0.97, 0.97, 0.974]\n",
      "iteration:  110  cost:  0.2558473864406103\n",
      "iteration:  111  cost:  0.13479110906383884\n",
      "iteration:  112  cost:  0.14344869770340696\n",
      "iteration:  113  cost:  0.19448448917550734\n",
      "iteration:  114  cost:  0.21859710360084886\n",
      "iteration:  115  cost:  0.14783768568154923\n",
      "iteration:  116  cost:  0.19801718843209618\n",
      "iteration:  117  cost:  0.19942293698191957\n",
      "iteration:  118  cost:  0.15365883540535294\n",
      "iteration:  119  cost:  0.1712367161477501\n",
      "[0.594, 0.622, 0.678, 0.876, 0.942, 0.962, 0.964, 0.964, 0.966, 0.97, 0.97, 0.974, 0.97]\n",
      "iteration:  120  cost:  0.11252529097545513\n",
      "iteration:  121  cost:  0.11058660886809596\n",
      "iteration:  122  cost:  0.16595250824817384\n",
      "iteration:  123  cost:  0.19152474827428423\n",
      "iteration:  124  cost:  0.1589772773826301\n",
      "iteration:  125  cost:  0.23922585565199067\n",
      "iteration:  126  cost:  0.0728718676737543\n",
      "iteration:  127  cost:  0.22192289722573785\n",
      "iteration:  128  cost:  0.12178190871274738\n",
      "iteration:  129  cost:  0.20395573755113613\n",
      "[0.594, 0.622, 0.678, 0.876, 0.942, 0.962, 0.964, 0.964, 0.966, 0.97, 0.97, 0.974, 0.97, 0.974]\n",
      "iteration:  130  cost:  0.15296195247964006\n",
      "iteration:  131  cost:  0.127117829620686\n",
      "iteration:  132  cost:  0.08526658969756634\n",
      "iteration:  133  cost:  0.1694817027303857\n",
      "iteration:  134  cost:  0.21867956463829766\n",
      "iteration:  135  cost:  0.2621971090506971\n",
      "iteration:  136  cost:  0.09224025998022993\n",
      "iteration:  137  cost:  0.1353420107626577\n",
      "iteration:  138  cost:  0.19413306375427347\n",
      "iteration:  139  cost:  0.11955229514021347\n",
      "[0.594, 0.622, 0.678, 0.876, 0.942, 0.962, 0.964, 0.964, 0.966, 0.97, 0.97, 0.974, 0.97, 0.974, 0.974]\n",
      "iteration:  140  cost:  0.14582685545694848\n",
      "iteration:  141  cost:  0.20884929837761368\n",
      "iteration:  142  cost:  0.1678033887733448\n",
      "iteration:  143  cost:  0.15744723235116717\n",
      "iteration:  144  cost:  0.09817119272208359\n",
      "iteration:  145  cost:  0.14040237254464072\n",
      "iteration:  146  cost:  0.13667774325888965\n",
      "iteration:  147  cost:  0.23653067613719908\n",
      "iteration:  148  cost:  0.09849511516747174\n",
      "iteration:  149  cost:  0.08397745371366329\n",
      "[0.594, 0.622, 0.678, 0.876, 0.942, 0.962, 0.964, 0.964, 0.966, 0.97, 0.97, 0.974, 0.97, 0.974, 0.974, 0.974]\n",
      "iteration:  150  cost:  0.07714484752424523\n",
      "iteration:  151  cost:  0.17078999072035012\n",
      "iteration:  152  cost:  0.24848700843381966\n",
      "iteration:  153  cost:  0.12094454992126359\n",
      "iteration:  154  cost:  0.1795178944551016\n",
      "iteration:  155  cost:  0.11870130941573519\n",
      "iteration:  156  cost:  0.1936365715434406\n",
      "iteration:  157  cost:  0.14541670380303662\n",
      "iteration:  158  cost:  0.1143059676112779\n",
      "iteration:  159  cost:  0.11798790160152979\n",
      "[0.594, 0.622, 0.678, 0.876, 0.942, 0.962, 0.964, 0.964, 0.966, 0.97, 0.97, 0.974, 0.97, 0.974, 0.974, 0.974, 0.974]\n",
      "iteration:  160  cost:  0.1377593569771812\n",
      "iteration:  161  cost:  0.14304565570269373\n",
      "iteration:  162  cost:  0.10207921088046992\n",
      "iteration:  163  cost:  0.11383677930354134\n",
      "iteration:  164  cost:  0.0759338727467459\n",
      "iteration:  165  cost:  0.2601963139845327\n",
      "iteration:  166  cost:  0.12723584486663483\n",
      "iteration:  167  cost:  0.1745707691981881\n",
      "iteration:  168  cost:  0.1147893259700957\n",
      "iteration:  169  cost:  0.12733825897385312\n",
      "[0.594, 0.622, 0.678, 0.876, 0.942, 0.962, 0.964, 0.964, 0.966, 0.97, 0.97, 0.974, 0.97, 0.974, 0.974, 0.974, 0.974, 0.968]\n",
      "Accuracy for U_5 pca8 :0.9886524822695035\n",
      "\n",
      "\n",
      "Loss History for QCNN circuits, U_5 pca16\n",
      "[0.478]\n",
      "iteration:  0  cost:  1.0983485415754546\n",
      "iteration:  1  cost:  1.0703261667439508\n",
      "iteration:  2  cost:  1.036187912373549\n",
      "iteration:  3  cost:  0.9540679093833624\n",
      "iteration:  4  cost:  0.9215508643855744\n",
      "iteration:  5  cost:  0.9308831474548614\n",
      "iteration:  6  cost:  0.9632417715866832\n",
      "iteration:  7  cost:  0.9316960947199108\n",
      "iteration:  8  cost:  0.910367840315351\n",
      "iteration:  9  cost:  0.9937338733150658\n",
      "[0.478, 0.546]\n",
      "iteration:  10  cost:  0.7810706668713197\n",
      "iteration:  11  cost:  1.0066093261641462\n",
      "iteration:  12  cost:  0.8015211160731052\n",
      "iteration:  13  cost:  1.0714512397387899\n",
      "iteration:  14  cost:  0.8466675467183734\n",
      "iteration:  15  cost:  0.8051445361605276\n",
      "iteration:  16  cost:  0.8757805043046192\n",
      "iteration:  17  cost:  0.8463232947170076\n",
      "iteration:  18  cost:  0.9194394406972534\n",
      "iteration:  19  cost:  0.8512213935659346\n",
      "[0.478, 0.546, 0.83]\n",
      "iteration:  20  cost:  0.7872258134665573\n",
      "iteration:  21  cost:  0.7918836948768658\n",
      "iteration:  22  cost:  0.7006358680296025\n",
      "iteration:  23  cost:  0.6150618524352052\n",
      "iteration:  24  cost:  0.6097769455388329\n",
      "iteration:  25  cost:  0.5733906456281264\n",
      "iteration:  26  cost:  0.5381138892472169\n",
      "iteration:  27  cost:  0.6169015930244555\n",
      "iteration:  28  cost:  0.6675268159938096\n",
      "iteration:  29  cost:  0.5017607693144169\n",
      "[0.478, 0.546, 0.83, 0.85]\n",
      "iteration:  30  cost:  0.49419222984240063\n",
      "iteration:  31  cost:  0.6899538181135647\n",
      "iteration:  32  cost:  0.529084165952236\n",
      "iteration:  33  cost:  0.5832694480101153\n",
      "iteration:  34  cost:  0.3218242995577683\n",
      "iteration:  35  cost:  0.5017808653061575\n",
      "iteration:  36  cost:  0.4613464108892322\n",
      "iteration:  37  cost:  0.28047524076785885\n",
      "iteration:  38  cost:  0.34131630060694124\n",
      "iteration:  39  cost:  0.33233450839622264\n",
      "[0.478, 0.546, 0.83, 0.85, 0.95]\n",
      "iteration:  40  cost:  0.305990016300801\n",
      "iteration:  41  cost:  0.3324686322512607\n",
      "iteration:  42  cost:  0.3935786376385172\n",
      "iteration:  43  cost:  0.24722605254116187\n",
      "iteration:  44  cost:  0.3006015873219015\n",
      "iteration:  45  cost:  0.27095980581361867\n",
      "iteration:  46  cost:  0.28899671831122403\n",
      "iteration:  47  cost:  0.3404225046857181\n",
      "iteration:  48  cost:  0.17079000759368465\n",
      "iteration:  49  cost:  0.2733979960229369\n",
      "[0.478, 0.546, 0.83, 0.85, 0.95, 0.96]\n",
      "iteration:  50  cost:  0.2969017214241394\n",
      "iteration:  51  cost:  0.28832710978959364\n",
      "iteration:  52  cost:  0.2916339517330888\n",
      "iteration:  53  cost:  0.1637440476253163\n",
      "iteration:  54  cost:  0.19889172864448873\n",
      "iteration:  55  cost:  0.2604237697774482\n",
      "iteration:  56  cost:  0.1745910494644346\n",
      "iteration:  57  cost:  0.21042616295209576\n",
      "iteration:  58  cost:  0.1835050506730636\n",
      "iteration:  59  cost:  0.23665167347880542\n",
      "[0.478, 0.546, 0.83, 0.85, 0.95, 0.96, 0.96]\n",
      "iteration:  60  cost:  0.12912834989123576\n",
      "iteration:  61  cost:  0.32155781612642587\n",
      "iteration:  62  cost:  0.12862777768995848\n",
      "iteration:  63  cost:  0.08710255948040835\n",
      "iteration:  64  cost:  0.13804174117019768\n",
      "iteration:  65  cost:  0.18416880464609012\n",
      "iteration:  66  cost:  0.2169071447666342\n",
      "iteration:  67  cost:  0.34404233389811234\n",
      "iteration:  68  cost:  0.21670096170403563\n",
      "iteration:  69  cost:  0.10926883202450278\n",
      "[0.478, 0.546, 0.83, 0.85, 0.95, 0.96, 0.96, 0.96]\n",
      "iteration:  70  cost:  0.1596525012215296\n",
      "iteration:  71  cost:  0.15397651626472542\n",
      "iteration:  72  cost:  0.07745370067125579\n",
      "iteration:  73  cost:  0.28298586329285497\n",
      "iteration:  74  cost:  0.38683866828809976\n",
      "iteration:  75  cost:  0.20990900710265778\n",
      "iteration:  76  cost:  0.18498468394672954\n",
      "iteration:  77  cost:  0.13503056906739244\n",
      "iteration:  78  cost:  0.0866754915494949\n",
      "iteration:  79  cost:  0.06837636581940956\n",
      "[0.478, 0.546, 0.83, 0.85, 0.95, 0.96, 0.96, 0.96, 0.958]\n",
      "Accuracy for U_5 pca16 :0.9706855791962175\n",
      "Epoch 1/10\n",
      "396/396 [==============================] - 1s 962us/step - loss: 0.1091 - val_loss: 0.0363\n",
      "Epoch 2/10\n",
      "396/396 [==============================] - 0s 745us/step - loss: 0.0331 - val_loss: 0.0265\n",
      "Epoch 3/10\n",
      "396/396 [==============================] - 0s 763us/step - loss: 0.0261 - val_loss: 0.0236\n",
      "Epoch 4/10\n",
      "396/396 [==============================] - 0s 770us/step - loss: 0.0229 - val_loss: 0.0215\n",
      "Epoch 5/10\n",
      "396/396 [==============================] - 0s 921us/step - loss: 0.0214 - val_loss: 0.0200\n",
      "Epoch 6/10\n",
      "396/396 [==============================] - 0s 752us/step - loss: 0.0200 - val_loss: 0.0192\n",
      "Epoch 7/10\n",
      "396/396 [==============================] - 0s 760us/step - loss: 0.0197 - val_loss: 0.0187\n",
      "Epoch 8/10\n",
      "396/396 [==============================] - 0s 791us/step - loss: 0.0191 - val_loss: 0.0183\n",
      "Epoch 9/10\n",
      "396/396 [==============================] - 0s 767us/step - loss: 0.0186 - val_loss: 0.0181\n",
      "Epoch 10/10\n",
      "396/396 [==============================] - 0s 778us/step - loss: 0.0183 - val_loss: 0.0178\n",
      "\n",
      "\n",
      "Loss History for QCNN circuits, U_5 autoencoder8\n",
      "[0.678]\n",
      "iteration:  0  cost:  0.9445936752738823\n",
      "iteration:  1  cost:  0.7433124112962264\n",
      "iteration:  2  cost:  0.9496814947601677\n",
      "iteration:  3  cost:  0.8995564332789868\n",
      "iteration:  4  cost:  0.7679127433188578\n",
      "iteration:  5  cost:  0.8460637066676375\n",
      "iteration:  6  cost:  0.7637007118796297\n",
      "iteration:  7  cost:  0.7808388237526439\n",
      "iteration:  8  cost:  0.6236567518612468\n",
      "iteration:  9  cost:  0.7979563007788134\n",
      "[0.678, 0.774]\n",
      "iteration:  10  cost:  0.7230847805938536\n",
      "iteration:  11  cost:  0.7129217576758334\n",
      "iteration:  12  cost:  0.752902300663575\n",
      "iteration:  13  cost:  0.7126449334205062\n",
      "iteration:  14  cost:  0.8037930954651512\n",
      "iteration:  15  cost:  0.8158837835020901\n",
      "iteration:  16  cost:  0.7876954859168431\n",
      "iteration:  17  cost:  0.880741283209209\n",
      "iteration:  18  cost:  0.7360643137166231\n",
      "iteration:  19  cost:  0.6315351055544984\n",
      "[0.678, 0.774, 0.816]\n",
      "iteration:  20  cost:  0.6713885858403991\n",
      "iteration:  21  cost:  0.683316354975844\n",
      "iteration:  22  cost:  0.7248263425630458\n",
      "iteration:  23  cost:  0.6554027827855521\n",
      "iteration:  24  cost:  0.5891907739601654\n",
      "iteration:  25  cost:  0.7517754929341564\n",
      "iteration:  26  cost:  0.6904413044150656\n",
      "iteration:  27  cost:  0.5444392820828823\n",
      "iteration:  28  cost:  0.5841043929548445\n",
      "iteration:  29  cost:  0.6977155411026912\n",
      "[0.678, 0.774, 0.816, 0.836]\n",
      "iteration:  30  cost:  0.590366672106575\n",
      "iteration:  31  cost:  0.7901433151948636\n",
      "iteration:  32  cost:  0.6783820326394117\n",
      "iteration:  33  cost:  0.6787855799206562\n",
      "iteration:  34  cost:  0.7414621043780181\n",
      "iteration:  35  cost:  0.654176633712636\n",
      "iteration:  36  cost:  0.6412077001608827\n",
      "iteration:  37  cost:  0.5552478074818089\n",
      "iteration:  38  cost:  0.5401504796989769\n",
      "iteration:  39  cost:  0.5715492540446564\n",
      "[0.678, 0.774, 0.816, 0.836, 0.894]\n",
      "iteration:  40  cost:  0.5676974040813697\n",
      "iteration:  41  cost:  0.6025048267532293\n",
      "iteration:  42  cost:  0.6801679209126412\n",
      "iteration:  43  cost:  0.6852244997016272\n",
      "iteration:  44  cost:  0.5505169460040907\n",
      "iteration:  45  cost:  0.629129275753999\n",
      "iteration:  46  cost:  0.5931465380237786\n",
      "iteration:  47  cost:  0.5440585527826706\n",
      "iteration:  48  cost:  0.6234193816400811\n",
      "iteration:  49  cost:  0.6126073277607379\n",
      "[0.678, 0.774, 0.816, 0.836, 0.894, 0.89]\n",
      "iteration:  50  cost:  0.7098354020123275\n",
      "iteration:  51  cost:  0.5211000145110102\n",
      "iteration:  52  cost:  0.601888005101081\n",
      "iteration:  53  cost:  0.5024862489560764\n",
      "iteration:  54  cost:  0.6605550125004075\n",
      "iteration:  55  cost:  0.5856002017027607\n",
      "iteration:  56  cost:  0.5990116672709002\n",
      "iteration:  57  cost:  0.5573688452824285\n",
      "iteration:  58  cost:  0.6124883401079299\n",
      "iteration:  59  cost:  0.5734492316694476\n",
      "[0.678, 0.774, 0.816, 0.836, 0.894, 0.89, 0.91]\n",
      "iteration:  60  cost:  0.5755877099029159\n",
      "iteration:  61  cost:  0.5601713661122425\n",
      "iteration:  62  cost:  0.5617872528760466\n",
      "iteration:  63  cost:  0.4977539327161569\n",
      "iteration:  64  cost:  0.6083856895648858\n",
      "iteration:  65  cost:  0.495083646513636\n",
      "iteration:  66  cost:  0.47412534507197923\n",
      "iteration:  67  cost:  0.5921588181215454\n",
      "iteration:  68  cost:  0.6185535489147181\n",
      "iteration:  69  cost:  0.6254488368430694\n",
      "[0.678, 0.774, 0.816, 0.836, 0.894, 0.89, 0.91, 0.932]\n",
      "iteration:  70  cost:  0.6017251447155405\n",
      "iteration:  71  cost:  0.628487494151555\n",
      "iteration:  72  cost:  0.5379016651744205\n",
      "iteration:  73  cost:  0.5906949623928981\n",
      "iteration:  74  cost:  0.5788688348095498\n",
      "iteration:  75  cost:  0.4863550738243334\n",
      "iteration:  76  cost:  0.4209352425143558\n",
      "iteration:  77  cost:  0.513700563341385\n",
      "iteration:  78  cost:  0.5801066378121129\n",
      "iteration:  79  cost:  0.47284957164188485\n",
      "[0.678, 0.774, 0.816, 0.836, 0.894, 0.89, 0.91, 0.932, 0.908]\n",
      "iteration:  80  cost:  0.6158825705935632\n",
      "iteration:  81  cost:  0.5269470793905129\n",
      "iteration:  82  cost:  0.512068091199281\n",
      "iteration:  83  cost:  0.5358561266308008\n",
      "iteration:  84  cost:  0.6121902643018206\n",
      "iteration:  85  cost:  0.4852392673284885\n",
      "iteration:  86  cost:  0.4601565876136356\n",
      "iteration:  87  cost:  0.4956113699478514\n",
      "iteration:  88  cost:  0.5748469363654893\n",
      "iteration:  89  cost:  0.5685031425787959\n",
      "[0.678, 0.774, 0.816, 0.836, 0.894, 0.89, 0.91, 0.932, 0.908, 0.892]\n",
      "Accuracy for U_5 autoencoder8 :0.9125295508274232\n",
      "Epoch 1/10\n",
      "396/396 [==============================] - 1s 999us/step - loss: 0.0948 - val_loss: 0.0284\n",
      "Epoch 2/10\n",
      "396/396 [==============================] - 0s 794us/step - loss: 0.0270 - val_loss: 0.0224\n",
      "Epoch 3/10\n",
      "396/396 [==============================] - 0s 804us/step - loss: 0.0215 - val_loss: 0.0182\n",
      "Epoch 4/10\n",
      "396/396 [==============================] - 0s 957us/step - loss: 0.0178 - val_loss: 0.0152\n",
      "Epoch 5/10\n",
      "396/396 [==============================] - 0s 785us/step - loss: 0.0151 - val_loss: 0.0136\n",
      "Epoch 6/10\n",
      "396/396 [==============================] - 0s 781us/step - loss: 0.0137 - val_loss: 0.0127\n",
      "Epoch 7/10\n",
      "396/396 [==============================] - 0s 811us/step - loss: 0.0126 - val_loss: 0.0121\n",
      "Epoch 8/10\n",
      "396/396 [==============================] - 0s 789us/step - loss: 0.0122 - val_loss: 0.0116\n",
      "Epoch 9/10\n",
      "396/396 [==============================] - 0s 821us/step - loss: 0.0116 - val_loss: 0.0112\n",
      "Epoch 10/10\n",
      "396/396 [==============================] - 0s 815us/step - loss: 0.0112 - val_loss: 0.0110\n",
      "\n",
      "\n",
      "Loss History for QCNN circuits, U_5 autoencoder16\n",
      "[0.544]\n",
      "iteration:  0  cost:  0.8821223998640138\n",
      "iteration:  1  cost:  1.0045176271124638\n",
      "iteration:  2  cost:  0.816783867160792\n",
      "iteration:  3  cost:  0.7874973329512883\n",
      "iteration:  4  cost:  0.7133421625201366\n",
      "iteration:  5  cost:  0.6436283113650516\n",
      "iteration:  6  cost:  0.7236014049115618\n",
      "iteration:  7  cost:  0.6452050337245222\n",
      "iteration:  8  cost:  0.6492007758165481\n",
      "iteration:  9  cost:  0.6341400110477327\n",
      "[0.544, 0.818]\n",
      "iteration:  10  cost:  0.6707175747379678\n",
      "iteration:  11  cost:  0.8718147597393492\n",
      "iteration:  12  cost:  0.797611908171194\n",
      "iteration:  13  cost:  0.8099344269079765\n",
      "iteration:  14  cost:  0.6416502909138272\n",
      "iteration:  15  cost:  0.6422531163099743\n",
      "iteration:  16  cost:  0.7084882226521136\n",
      "iteration:  17  cost:  0.7326062658356918\n",
      "iteration:  18  cost:  0.6306274825058545\n",
      "iteration:  19  cost:  0.5965901720214108\n",
      "[0.544, 0.818, 0.87]\n",
      "iteration:  20  cost:  0.5781280637362343\n",
      "iteration:  21  cost:  0.6198763998294265\n",
      "iteration:  22  cost:  0.6063850710316064\n",
      "iteration:  23  cost:  0.6282240176496131\n",
      "iteration:  24  cost:  0.6434530330004398\n",
      "iteration:  25  cost:  0.604049260721104\n",
      "iteration:  26  cost:  0.6051264176721977\n",
      "iteration:  27  cost:  0.5024891689779154\n",
      "iteration:  28  cost:  0.620988242669507\n",
      "iteration:  29  cost:  0.5305715889194085\n",
      "[0.544, 0.818, 0.87, 0.886]\n",
      "iteration:  30  cost:  0.47886098853421905\n",
      "iteration:  31  cost:  0.48927683671581645\n",
      "iteration:  32  cost:  0.5885230857083126\n",
      "iteration:  33  cost:  0.5579389233444332\n",
      "iteration:  34  cost:  0.5128125499619525\n",
      "iteration:  35  cost:  0.5362576153138636\n",
      "iteration:  36  cost:  0.5595071303058416\n",
      "iteration:  37  cost:  0.603843254679365\n",
      "iteration:  38  cost:  0.5135881552756625\n",
      "iteration:  39  cost:  0.5856773936577961\n",
      "[0.544, 0.818, 0.87, 0.886, 0.942]\n",
      "iteration:  40  cost:  0.555265536928458\n",
      "iteration:  41  cost:  0.4647015063173566\n",
      "iteration:  42  cost:  0.5840100021536796\n",
      "iteration:  43  cost:  0.510518804754436\n",
      "iteration:  44  cost:  0.40307295566395956\n",
      "iteration:  45  cost:  0.5256762164347392\n",
      "iteration:  46  cost:  0.570362349155741\n",
      "iteration:  47  cost:  0.5727750198170622\n",
      "iteration:  48  cost:  0.5325562885260097\n",
      "iteration:  49  cost:  0.40425726490383623\n",
      "[0.544, 0.818, 0.87, 0.886, 0.942, 0.946]\n",
      "iteration:  50  cost:  0.4956179083429382\n",
      "iteration:  51  cost:  0.4326675600393773\n",
      "iteration:  52  cost:  0.458312070557376\n",
      "iteration:  53  cost:  0.4729449816628566\n",
      "iteration:  54  cost:  0.4815970566428429\n",
      "iteration:  55  cost:  0.49084493971871934\n",
      "iteration:  56  cost:  0.4794473783826397\n",
      "iteration:  57  cost:  0.5519080080822435\n",
      "iteration:  58  cost:  0.4766127815336749\n",
      "iteration:  59  cost:  0.48551607957030946\n",
      "[0.544, 0.818, 0.87, 0.886, 0.942, 0.946, 0.922]\n",
      "iteration:  60  cost:  0.49626310171057997\n",
      "iteration:  61  cost:  0.35964580493410325\n",
      "iteration:  62  cost:  0.3819231241921368\n",
      "iteration:  63  cost:  0.38877989013759434\n",
      "iteration:  64  cost:  0.43428399256033\n",
      "iteration:  65  cost:  0.4430320292815185\n",
      "iteration:  66  cost:  0.44385747158373673\n",
      "iteration:  67  cost:  0.5080246885158212\n",
      "iteration:  68  cost:  0.3078731737804904\n",
      "iteration:  69  cost:  0.4454737644806026\n",
      "[0.544, 0.818, 0.87, 0.886, 0.942, 0.946, 0.922, 0.92]\n",
      "Accuracy for U_5 autoencoder16 :0.9167848699763593\n",
      "\n",
      "\n",
      "Loss History for QCNN circuits, U_6 resize256\n",
      "[0.5]\n",
      "iteration:  0  cost:  0.9725125110306297\n",
      "iteration:  1  cost:  0.9633900904726622\n",
      "iteration:  2  cost:  0.9784834352835733\n",
      "iteration:  3  cost:  0.936198378314587\n",
      "iteration:  4  cost:  0.9480263632685434\n",
      "iteration:  5  cost:  0.9200089001479341\n",
      "iteration:  6  cost:  0.9685038766424028\n",
      "iteration:  7  cost:  0.9642775042658224\n",
      "iteration:  8  cost:  0.9292563765257082\n",
      "iteration:  9  cost:  0.9412278505116677\n",
      "[0.5, 0.806]\n",
      "iteration:  10  cost:  0.8901266719232956\n",
      "iteration:  11  cost:  0.9029755115012494\n",
      "iteration:  12  cost:  0.8874883417098748\n",
      "iteration:  13  cost:  0.9347727854432449\n",
      "iteration:  14  cost:  0.8563702215627237\n",
      "iteration:  15  cost:  0.9310421102369191\n",
      "iteration:  16  cost:  0.8917775153498337\n",
      "iteration:  17  cost:  0.7923820351357285\n",
      "iteration:  18  cost:  0.8774055339489365\n",
      "iteration:  19  cost:  0.8556641542496195\n",
      "[0.5, 0.806, 0.774]\n",
      "iteration:  20  cost:  0.8497470015544094\n",
      "iteration:  21  cost:  0.8538718187645408\n",
      "iteration:  22  cost:  0.8163877228205962\n",
      "iteration:  23  cost:  0.8380467163959463\n",
      "iteration:  24  cost:  0.748460518297035\n",
      "iteration:  25  cost:  0.755936108032905\n",
      "iteration:  26  cost:  0.7481024868114899\n",
      "iteration:  27  cost:  0.814209942840704\n",
      "iteration:  28  cost:  0.8229092057265756\n",
      "iteration:  29  cost:  0.8979172252576734\n",
      "[0.5, 0.806, 0.774, 0.778]\n",
      "iteration:  30  cost:  0.7239275676373295\n",
      "iteration:  31  cost:  0.7857226015490424\n",
      "iteration:  32  cost:  0.6658744728062992\n",
      "iteration:  33  cost:  0.7892704966411597\n",
      "iteration:  34  cost:  0.8885382486060946\n",
      "iteration:  35  cost:  0.7619841790617962\n",
      "iteration:  36  cost:  0.8018075994078545\n",
      "iteration:  37  cost:  0.8005557620985385\n",
      "iteration:  38  cost:  0.7356235004415553\n",
      "iteration:  39  cost:  0.8142803074947023\n",
      "[0.5, 0.806, 0.774, 0.778, 0.89]\n",
      "iteration:  40  cost:  0.7897919468661893\n",
      "iteration:  41  cost:  0.7584589664278476\n",
      "iteration:  42  cost:  0.7747144216213244\n",
      "iteration:  43  cost:  0.7411452300247663\n",
      "iteration:  44  cost:  0.7846777730083266\n",
      "iteration:  45  cost:  0.7207428429071752\n",
      "iteration:  46  cost:  0.739389620788813\n",
      "iteration:  47  cost:  0.7354324572025597\n",
      "iteration:  48  cost:  0.7373106621433404\n",
      "iteration:  49  cost:  0.7446808651000297\n",
      "[0.5, 0.806, 0.774, 0.778, 0.89, 0.924]\n",
      "iteration:  50  cost:  0.7003661812144345\n",
      "iteration:  51  cost:  0.7395749813911356\n",
      "iteration:  52  cost:  0.7618967098619217\n",
      "iteration:  53  cost:  0.6763623132479001\n",
      "iteration:  54  cost:  0.7119472392706324\n",
      "iteration:  55  cost:  0.6986740850578088\n",
      "iteration:  56  cost:  0.7339163004049608\n",
      "iteration:  57  cost:  0.6728609228123175\n",
      "iteration:  58  cost:  0.7578754917217614\n",
      "iteration:  59  cost:  0.7103862749371079\n",
      "[0.5, 0.806, 0.774, 0.778, 0.89, 0.924, 0.9]\n",
      "iteration:  60  cost:  0.8177347349262328\n",
      "iteration:  61  cost:  0.7538085134041487\n",
      "iteration:  62  cost:  0.7219346959161238\n",
      "iteration:  63  cost:  0.7181229842846497\n",
      "iteration:  64  cost:  0.6716398453521171\n",
      "iteration:  65  cost:  0.6180488760314973\n",
      "iteration:  66  cost:  0.7033049477870637\n",
      "iteration:  67  cost:  0.614062956912085\n",
      "iteration:  68  cost:  0.8344477654566773\n",
      "iteration:  69  cost:  0.610501911438246\n",
      "[0.5, 0.806, 0.774, 0.778, 0.89, 0.924, 0.9, 0.916]\n",
      "iteration:  70  cost:  0.6297246630646662\n",
      "iteration:  71  cost:  0.663799117210464\n",
      "iteration:  72  cost:  0.7506530748123427\n",
      "iteration:  73  cost:  0.5820441330942192\n",
      "iteration:  74  cost:  0.6863118451214869\n",
      "iteration:  75  cost:  0.6530265010367005\n",
      "iteration:  76  cost:  0.5419312276539954\n",
      "iteration:  77  cost:  0.5643296616836972\n",
      "iteration:  78  cost:  0.5881092620967673\n",
      "iteration:  79  cost:  0.6602489927644177\n",
      "[0.5, 0.806, 0.774, 0.778, 0.89, 0.924, 0.9, 0.916, 0.924]\n",
      "iteration:  80  cost:  0.581945734335066\n",
      "iteration:  81  cost:  0.6033879636499337\n",
      "iteration:  82  cost:  0.48201646585992924\n",
      "iteration:  83  cost:  0.6566440535658354\n",
      "iteration:  84  cost:  0.6994650554426155\n",
      "iteration:  85  cost:  0.6549511098321781\n",
      "iteration:  86  cost:  0.6080017420862414\n",
      "iteration:  87  cost:  0.6868514728790042\n",
      "iteration:  88  cost:  0.6645205508800726\n",
      "iteration:  89  cost:  0.6389906246540457\n",
      "[0.5, 0.806, 0.774, 0.778, 0.89, 0.924, 0.9, 0.916, 0.924, 0.914]\n",
      "iteration:  90  cost:  0.6353342335800364\n",
      "iteration:  91  cost:  0.7236028331941641\n",
      "iteration:  92  cost:  0.4891496353216014\n",
      "iteration:  93  cost:  0.5787995666474517\n",
      "iteration:  94  cost:  0.5162408181755948\n",
      "iteration:  95  cost:  0.7315602522536221\n",
      "iteration:  96  cost:  0.6060009412500071\n",
      "iteration:  97  cost:  0.5105519045912338\n",
      "iteration:  98  cost:  0.6616690403514868\n",
      "iteration:  99  cost:  0.49415850470328193\n",
      "[0.5, 0.806, 0.774, 0.778, 0.89, 0.924, 0.9, 0.916, 0.924, 0.914, 0.922]\n",
      "iteration:  100  cost:  0.5872074976907701\n",
      "iteration:  101  cost:  0.5807637838886468\n",
      "iteration:  102  cost:  0.5741247728580268\n",
      "iteration:  103  cost:  0.6480938601627889\n",
      "iteration:  104  cost:  0.6591543309092215\n",
      "iteration:  105  cost:  0.5378238725754594\n",
      "iteration:  106  cost:  0.6180231413849758\n",
      "iteration:  107  cost:  0.5615267334294687\n",
      "iteration:  108  cost:  0.642791288421416\n",
      "iteration:  109  cost:  0.5629312210270284\n",
      "[0.5, 0.806, 0.774, 0.778, 0.89, 0.924, 0.9, 0.916, 0.924, 0.914, 0.922, 0.926]\n",
      "iteration:  110  cost:  0.62113569615742\n",
      "iteration:  111  cost:  0.6613798401497852\n",
      "iteration:  112  cost:  0.7180972311253392\n",
      "iteration:  113  cost:  0.6233838093485817\n",
      "iteration:  114  cost:  0.6106046006906124\n",
      "iteration:  115  cost:  0.6072864826323398\n",
      "iteration:  116  cost:  0.5231092685446108\n",
      "iteration:  117  cost:  0.6457717055653212\n",
      "iteration:  118  cost:  0.7200630950297686\n",
      "iteration:  119  cost:  0.6432234463187825\n",
      "[0.5, 0.806, 0.774, 0.778, 0.89, 0.924, 0.9, 0.916, 0.924, 0.914, 0.922, 0.926, 0.93]\n",
      "iteration:  120  cost:  0.42417462185391874\n",
      "iteration:  121  cost:  0.5856167173196556\n",
      "iteration:  122  cost:  0.5413813942677165\n",
      "iteration:  123  cost:  0.5314958949050035\n",
      "iteration:  124  cost:  0.42477515056172577\n",
      "iteration:  125  cost:  0.6247465470951477\n",
      "iteration:  126  cost:  0.6716568198123885\n",
      "iteration:  127  cost:  0.5703697836799355\n",
      "iteration:  128  cost:  0.6537539740371875\n",
      "iteration:  129  cost:  0.5422573120634615\n",
      "[0.5, 0.806, 0.774, 0.778, 0.89, 0.924, 0.9, 0.916, 0.924, 0.914, 0.922, 0.926, 0.93, 0.928]\n",
      "iteration:  130  cost:  0.587094789832237\n",
      "iteration:  131  cost:  0.5266891571813437\n",
      "iteration:  132  cost:  0.47573724841293713\n",
      "iteration:  133  cost:  0.5028869308318745\n",
      "iteration:  134  cost:  0.43086113178530405\n",
      "iteration:  135  cost:  0.6222840790463892\n",
      "iteration:  136  cost:  0.4400392199036919\n",
      "iteration:  137  cost:  0.5439690143999143\n",
      "iteration:  138  cost:  0.5646371346578004\n",
      "iteration:  139  cost:  0.5148813437046951\n",
      "[0.5, 0.806, 0.774, 0.778, 0.89, 0.924, 0.9, 0.916, 0.924, 0.914, 0.922, 0.926, 0.93, 0.928, 0.916]\n",
      "Accuracy for U_6 resize256 :0.8709219858156029\n",
      "\n",
      "\n",
      "Loss History for QCNN circuits, U_6 pca8\n",
      "[0.49]\n",
      "iteration:  0  cost:  1.2188101164244562\n",
      "iteration:  1  cost:  1.2419756121037913\n",
      "iteration:  2  cost:  1.110119570071865\n",
      "iteration:  3  cost:  0.9288257824553102\n",
      "iteration:  4  cost:  0.9559081683652562\n",
      "iteration:  5  cost:  0.9570067677901466\n",
      "iteration:  6  cost:  1.0850960959833948\n",
      "iteration:  7  cost:  0.9926033469982631\n",
      "iteration:  8  cost:  1.0047156620977704\n",
      "iteration:  9  cost:  1.1030364206472227\n",
      "[0.49, 0.484]\n",
      "iteration:  10  cost:  1.0866880431939618\n",
      "iteration:  11  cost:  0.9357515441087707\n",
      "iteration:  12  cost:  0.9537831298201699\n",
      "iteration:  13  cost:  1.1185011176671054\n",
      "iteration:  14  cost:  0.874398338614181\n",
      "iteration:  15  cost:  0.9404930311007647\n",
      "iteration:  16  cost:  1.0385868076002505\n",
      "iteration:  17  cost:  1.0338137261351128\n",
      "iteration:  18  cost:  0.9926290934405816\n",
      "iteration:  19  cost:  0.9476454130140785\n",
      "[0.49, 0.484, 0.558]\n",
      "iteration:  20  cost:  1.0329790126967506\n",
      "iteration:  21  cost:  0.9872355806558734\n",
      "iteration:  22  cost:  1.0106525826251083\n",
      "iteration:  23  cost:  0.9811416305775764\n",
      "iteration:  24  cost:  0.9885989315314706\n",
      "iteration:  25  cost:  0.9429297734637779\n",
      "iteration:  26  cost:  0.9210539244372058\n",
      "iteration:  27  cost:  0.944463531048302\n",
      "iteration:  28  cost:  0.9401846678675371\n",
      "iteration:  29  cost:  0.9364607598846878\n",
      "[0.49, 0.484, 0.558, 0.59]\n",
      "iteration:  30  cost:  0.9850725707026067\n",
      "iteration:  31  cost:  0.8256149607092962\n",
      "iteration:  32  cost:  0.9095943116825761\n",
      "iteration:  33  cost:  0.8921326617520051\n",
      "iteration:  34  cost:  0.8529342085371084\n",
      "iteration:  35  cost:  0.9251739418969903\n",
      "iteration:  36  cost:  0.9184942682286978\n",
      "iteration:  37  cost:  0.8561837670404431\n",
      "iteration:  38  cost:  1.0711321692796452\n",
      "iteration:  39  cost:  1.0260232151722102\n",
      "[0.49, 0.484, 0.558, 0.59, 0.534]\n",
      "iteration:  40  cost:  0.9036082369467467\n",
      "iteration:  41  cost:  0.8505942508154388\n",
      "iteration:  42  cost:  0.8602638138090497\n",
      "iteration:  43  cost:  0.7920907392653449\n",
      "iteration:  44  cost:  0.8223359333340354\n",
      "iteration:  45  cost:  0.9617690385471488\n",
      "iteration:  46  cost:  0.9666847146102502\n",
      "iteration:  47  cost:  0.8609099048922204\n",
      "iteration:  48  cost:  0.8594146023994539\n",
      "iteration:  49  cost:  0.9466336553636462\n",
      "[0.49, 0.484, 0.558, 0.59, 0.534, 0.722]\n",
      "iteration:  50  cost:  0.830849239763164\n",
      "iteration:  51  cost:  0.9035741541373656\n",
      "iteration:  52  cost:  0.8446151823282192\n",
      "iteration:  53  cost:  0.8306978269944326\n",
      "iteration:  54  cost:  0.8412545122756786\n",
      "iteration:  55  cost:  0.7835323066715715\n",
      "iteration:  56  cost:  0.8200530489529478\n",
      "iteration:  57  cost:  0.8484429759619496\n",
      "iteration:  58  cost:  0.8652297454799739\n",
      "iteration:  59  cost:  0.8226720171816035\n",
      "[0.49, 0.484, 0.558, 0.59, 0.534, 0.722, 0.862]\n",
      "iteration:  60  cost:  0.926399431833209\n",
      "iteration:  61  cost:  0.781728376040189\n",
      "iteration:  62  cost:  0.7108867504271004\n",
      "iteration:  63  cost:  0.6391836330728802\n",
      "iteration:  64  cost:  0.6904846775645285\n",
      "iteration:  65  cost:  0.6721249238220903\n",
      "iteration:  66  cost:  0.7167905865576181\n",
      "iteration:  67  cost:  0.794310824959821\n",
      "iteration:  68  cost:  0.712675541740871\n",
      "iteration:  69  cost:  0.664140221232595\n",
      "[0.49, 0.484, 0.558, 0.59, 0.534, 0.722, 0.862, 0.942]\n",
      "iteration:  70  cost:  0.6773112404101272\n",
      "iteration:  71  cost:  0.6422961503586941\n",
      "iteration:  72  cost:  0.6142858247056405\n",
      "iteration:  73  cost:  0.571525582900391\n",
      "iteration:  74  cost:  0.5730766747800881\n",
      "iteration:  75  cost:  0.6387832180393486\n",
      "iteration:  76  cost:  0.6202965327555705\n",
      "iteration:  77  cost:  0.5197335317661336\n",
      "iteration:  78  cost:  0.6206542052520017\n",
      "iteration:  79  cost:  0.5947889762734025\n",
      "[0.49, 0.484, 0.558, 0.59, 0.534, 0.722, 0.862, 0.942, 0.938]\n",
      "iteration:  80  cost:  0.5592654919809122\n",
      "iteration:  81  cost:  0.4819343684514776\n",
      "iteration:  82  cost:  0.481040735990391\n",
      "iteration:  83  cost:  0.47362690104333005\n",
      "iteration:  84  cost:  0.5128928784415421\n",
      "iteration:  85  cost:  0.47389053459672686\n",
      "iteration:  86  cost:  0.5311391824097168\n",
      "iteration:  87  cost:  0.4274732783030059\n",
      "iteration:  88  cost:  0.5460702743060871\n",
      "iteration:  89  cost:  0.4297427187406765\n",
      "[0.49, 0.484, 0.558, 0.59, 0.534, 0.722, 0.862, 0.942, 0.938, 0.956]\n",
      "iteration:  90  cost:  0.4231285222084977\n",
      "iteration:  91  cost:  0.44056557491472903\n",
      "iteration:  92  cost:  0.4871919125070767\n",
      "iteration:  93  cost:  0.40657891015614267\n",
      "iteration:  94  cost:  0.40791256870661174\n",
      "iteration:  95  cost:  0.5757981634733372\n",
      "iteration:  96  cost:  0.4462979706907798\n",
      "iteration:  97  cost:  0.5348419459055594\n",
      "iteration:  98  cost:  0.38111251924068457\n",
      "iteration:  99  cost:  0.4526661833391581\n",
      "[0.49, 0.484, 0.558, 0.59, 0.534, 0.722, 0.862, 0.942, 0.938, 0.956, 0.956]\n",
      "iteration:  100  cost:  0.4543175165373311\n",
      "iteration:  101  cost:  0.4422542126250206\n",
      "iteration:  102  cost:  0.4343346817643743\n",
      "iteration:  103  cost:  0.3504802126129477\n",
      "iteration:  104  cost:  0.45760371480593093\n",
      "iteration:  105  cost:  0.4491098938850907\n",
      "iteration:  106  cost:  0.46489080633484936\n",
      "iteration:  107  cost:  0.38472287090413787\n",
      "iteration:  108  cost:  0.33674945189735345\n",
      "iteration:  109  cost:  0.34595707965278905\n",
      "[0.49, 0.484, 0.558, 0.59, 0.534, 0.722, 0.862, 0.942, 0.938, 0.956, 0.956, 0.966]\n",
      "iteration:  110  cost:  0.27886590399700895\n",
      "iteration:  111  cost:  0.32133471278847475\n",
      "iteration:  112  cost:  0.34385457863622404\n",
      "iteration:  113  cost:  0.36335524692161264\n",
      "iteration:  114  cost:  0.3701281733160293\n",
      "iteration:  115  cost:  0.4078537146963964\n",
      "iteration:  116  cost:  0.28902679977932094\n",
      "iteration:  117  cost:  0.3642332675750833\n",
      "iteration:  118  cost:  0.3131108730187542\n",
      "iteration:  119  cost:  0.34290242950765193\n",
      "[0.49, 0.484, 0.558, 0.59, 0.534, 0.722, 0.862, 0.942, 0.938, 0.956, 0.956, 0.966, 0.968]\n",
      "iteration:  120  cost:  0.3580022002309394\n",
      "iteration:  121  cost:  0.35635471867369584\n",
      "iteration:  122  cost:  0.2830986697835213\n",
      "iteration:  123  cost:  0.31067099373798174\n",
      "iteration:  124  cost:  0.275206813079926\n",
      "iteration:  125  cost:  0.3363506423103337\n",
      "iteration:  126  cost:  0.3260971307262631\n",
      "iteration:  127  cost:  0.3377682373142217\n",
      "iteration:  128  cost:  0.28420516194994433\n",
      "iteration:  129  cost:  0.385386563149225\n",
      "[0.49, 0.484, 0.558, 0.59, 0.534, 0.722, 0.862, 0.942, 0.938, 0.956, 0.956, 0.966, 0.968, 0.97]\n",
      "iteration:  130  cost:  0.22941353463807101\n",
      "iteration:  131  cost:  0.3843205715070799\n",
      "iteration:  132  cost:  0.3297315541290123\n",
      "iteration:  133  cost:  0.2566197250638612\n",
      "iteration:  134  cost:  0.2775612255479536\n",
      "iteration:  135  cost:  0.2886869354239749\n",
      "iteration:  136  cost:  0.2771233543920509\n",
      "iteration:  137  cost:  0.2557423244368877\n",
      "iteration:  138  cost:  0.4319069828674971\n",
      "iteration:  139  cost:  0.21437337610957552\n",
      "[0.49, 0.484, 0.558, 0.59, 0.534, 0.722, 0.862, 0.942, 0.938, 0.956, 0.956, 0.966, 0.968, 0.97, 0.974]\n",
      "iteration:  140  cost:  0.2693228717480344\n",
      "iteration:  141  cost:  0.22811742362480905\n",
      "iteration:  142  cost:  0.2772443181471862\n",
      "iteration:  143  cost:  0.26163688168636867\n",
      "iteration:  144  cost:  0.2518007192544399\n",
      "iteration:  145  cost:  0.24318267501962576\n",
      "iteration:  146  cost:  0.2663702197915756\n",
      "iteration:  147  cost:  0.208428206227923\n",
      "iteration:  148  cost:  0.19621020048427895\n",
      "iteration:  149  cost:  0.363234975836946\n",
      "[0.49, 0.484, 0.558, 0.59, 0.534, 0.722, 0.862, 0.942, 0.938, 0.956, 0.956, 0.966, 0.968, 0.97, 0.974, 0.968]\n",
      "iteration:  150  cost:  0.2932454416529322\n",
      "iteration:  151  cost:  0.2618371096169536\n",
      "iteration:  152  cost:  0.3919468001608751\n",
      "iteration:  153  cost:  0.21661972556830705\n",
      "iteration:  154  cost:  0.18683863895201583\n",
      "iteration:  155  cost:  0.24112600705093068\n",
      "iteration:  156  cost:  0.28720954796584935\n",
      "iteration:  157  cost:  0.16492447214898653\n",
      "iteration:  158  cost:  0.3954371512842011\n",
      "iteration:  159  cost:  0.19078212458536167\n",
      "[0.49, 0.484, 0.558, 0.59, 0.534, 0.722, 0.862, 0.942, 0.938, 0.956, 0.956, 0.966, 0.968, 0.97, 0.974, 0.968, 0.972]\n",
      "iteration:  160  cost:  0.26163767730358534\n",
      "iteration:  161  cost:  0.23567723305617264\n",
      "iteration:  162  cost:  0.19546180026848542\n",
      "iteration:  163  cost:  0.2006788082446532\n",
      "iteration:  164  cost:  0.2808247775275548\n",
      "iteration:  165  cost:  0.2199131152444268\n",
      "iteration:  166  cost:  0.24799916873767455\n",
      "iteration:  167  cost:  0.18195974123771358\n",
      "iteration:  168  cost:  0.17663006620601418\n",
      "iteration:  169  cost:  0.274216199935699\n",
      "[0.49, 0.484, 0.558, 0.59, 0.534, 0.722, 0.862, 0.942, 0.938, 0.956, 0.956, 0.966, 0.968, 0.97, 0.974, 0.968, 0.972, 0.978]\n",
      "iteration:  170  cost:  0.15570129311987174\n",
      "iteration:  171  cost:  0.2414310451995579\n",
      "iteration:  172  cost:  0.203223548505175\n",
      "iteration:  173  cost:  0.2552991424103582\n",
      "iteration:  174  cost:  0.212003910693967\n",
      "iteration:  175  cost:  0.137595347890915\n",
      "iteration:  176  cost:  0.12257535963156765\n",
      "iteration:  177  cost:  0.13894146166501314\n",
      "iteration:  178  cost:  0.25343538458544007\n",
      "iteration:  179  cost:  0.14780515989180004\n",
      "[0.49, 0.484, 0.558, 0.59, 0.534, 0.722, 0.862, 0.942, 0.938, 0.956, 0.956, 0.966, 0.968, 0.97, 0.974, 0.968, 0.972, 0.978, 0.97]\n",
      "iteration:  180  cost:  0.1320372239560935\n",
      "iteration:  181  cost:  0.28261137813362824\n",
      "iteration:  182  cost:  0.17812892403686223\n",
      "iteration:  183  cost:  0.15032292486064958\n",
      "iteration:  184  cost:  0.321734419229444\n",
      "iteration:  185  cost:  0.14582157376756505\n",
      "iteration:  186  cost:  0.1896374186421466\n",
      "iteration:  187  cost:  0.15715961992749478\n",
      "iteration:  188  cost:  0.22651383857547217\n",
      "iteration:  189  cost:  0.13763842811529312\n",
      "[0.49, 0.484, 0.558, 0.59, 0.534, 0.722, 0.862, 0.942, 0.938, 0.956, 0.956, 0.966, 0.968, 0.97, 0.974, 0.968, 0.972, 0.978, 0.97, 0.978]\n",
      "iteration:  190  cost:  0.13603212804253634\n",
      "iteration:  191  cost:  0.1895192337158216\n",
      "iteration:  192  cost:  0.21193259675580406\n",
      "iteration:  193  cost:  0.25544201170797487\n",
      "iteration:  194  cost:  0.14313241653441178\n",
      "iteration:  195  cost:  0.15551834077839408\n",
      "iteration:  196  cost:  0.1640981079257286\n",
      "iteration:  197  cost:  0.1945937368981958\n",
      "iteration:  198  cost:  0.3632748037151975\n",
      "iteration:  199  cost:  0.3060557535576722\n",
      "[0.49, 0.484, 0.558, 0.59, 0.534, 0.722, 0.862, 0.942, 0.938, 0.956, 0.956, 0.966, 0.968, 0.97, 0.974, 0.968, 0.972, 0.978, 0.97, 0.978, 0.976]\n",
      "iteration:  200  cost:  0.22588678608020682\n",
      "iteration:  201  cost:  0.16376225896286176\n",
      "iteration:  202  cost:  0.12307937928131998\n",
      "iteration:  203  cost:  0.2369998283022192\n",
      "iteration:  204  cost:  0.2823005063372685\n",
      "iteration:  205  cost:  0.15579874359672113\n",
      "iteration:  206  cost:  0.14070463087439353\n",
      "iteration:  207  cost:  0.232249295872454\n",
      "iteration:  208  cost:  0.22334712803974494\n",
      "iteration:  209  cost:  0.16047524685268147\n",
      "[0.49, 0.484, 0.558, 0.59, 0.534, 0.722, 0.862, 0.942, 0.938, 0.956, 0.956, 0.966, 0.968, 0.97, 0.974, 0.968, 0.972, 0.978, 0.97, 0.978, 0.976, 0.978]\n",
      "iteration:  210  cost:  0.23820791543300893\n",
      "iteration:  211  cost:  0.1539501588195324\n",
      "iteration:  212  cost:  0.15480418250245942\n",
      "iteration:  213  cost:  0.16517313026238833\n",
      "iteration:  214  cost:  0.08421014725936792\n",
      "iteration:  215  cost:  0.10821525786823523\n",
      "iteration:  216  cost:  0.09669386944865975\n",
      "iteration:  217  cost:  0.17758323412193405\n",
      "iteration:  218  cost:  0.11462638467295358\n",
      "iteration:  219  cost:  0.209830829777082\n",
      "[0.49, 0.484, 0.558, 0.59, 0.534, 0.722, 0.862, 0.942, 0.938, 0.956, 0.956, 0.966, 0.968, 0.97, 0.974, 0.968, 0.972, 0.978, 0.97, 0.978, 0.976, 0.978, 0.978]\n",
      "iteration:  220  cost:  0.27570003015847916\n",
      "iteration:  221  cost:  0.09052523085341707\n",
      "iteration:  222  cost:  0.11494028264201737\n",
      "iteration:  223  cost:  0.13788885050975083\n",
      "iteration:  224  cost:  0.2564336799278861\n",
      "iteration:  225  cost:  0.3065394209620033\n",
      "iteration:  226  cost:  0.11838177823681058\n",
      "iteration:  227  cost:  0.11646182996960164\n",
      "iteration:  228  cost:  0.13041310280997861\n",
      "iteration:  229  cost:  0.2286564435476652\n",
      "[0.49, 0.484, 0.558, 0.59, 0.534, 0.722, 0.862, 0.942, 0.938, 0.956, 0.956, 0.966, 0.968, 0.97, 0.974, 0.968, 0.972, 0.978, 0.97, 0.978, 0.976, 0.978, 0.978, 0.978]\n",
      "iteration:  230  cost:  0.19789011850257995\n",
      "iteration:  231  cost:  0.1520608415521521\n",
      "iteration:  232  cost:  0.10772462809942746\n",
      "iteration:  233  cost:  0.242427071061713\n",
      "iteration:  234  cost:  0.15256751126030596\n",
      "iteration:  235  cost:  0.1388646078874709\n",
      "iteration:  236  cost:  0.12041754808459926\n",
      "iteration:  237  cost:  0.18275575538006308\n",
      "iteration:  238  cost:  0.29962679263439057\n",
      "iteration:  239  cost:  0.141417594242722\n",
      "[0.49, 0.484, 0.558, 0.59, 0.534, 0.722, 0.862, 0.942, 0.938, 0.956, 0.956, 0.966, 0.968, 0.97, 0.974, 0.968, 0.972, 0.978, 0.97, 0.978, 0.976, 0.978, 0.978, 0.978, 0.978]\n",
      "iteration:  240  cost:  0.11516659604976535\n",
      "iteration:  241  cost:  0.14345724031797474\n",
      "iteration:  242  cost:  0.33325957299952746\n",
      "iteration:  243  cost:  0.1760289595943015\n",
      "iteration:  244  cost:  0.23935573566048832\n",
      "iteration:  245  cost:  0.18804885926304224\n",
      "iteration:  246  cost:  0.12957412943798613\n",
      "iteration:  247  cost:  0.13049325948080442\n",
      "iteration:  248  cost:  0.20771298196215057\n",
      "iteration:  249  cost:  0.1201473182333028\n",
      "[0.49, 0.484, 0.558, 0.59, 0.534, 0.722, 0.862, 0.942, 0.938, 0.956, 0.956, 0.966, 0.968, 0.97, 0.974, 0.968, 0.972, 0.978, 0.97, 0.978, 0.976, 0.978, 0.978, 0.978, 0.978, 0.98]\n",
      "iteration:  250  cost:  0.17337067513506413\n",
      "iteration:  251  cost:  0.1903713136440669\n",
      "iteration:  252  cost:  0.2722723457990485\n",
      "iteration:  253  cost:  0.2724594985599623\n",
      "iteration:  254  cost:  0.22103442214321276\n",
      "iteration:  255  cost:  0.20898307926431195\n",
      "iteration:  256  cost:  0.1321321775740362\n",
      "iteration:  257  cost:  0.16437198954015667\n",
      "iteration:  258  cost:  0.18294630757537653\n",
      "iteration:  259  cost:  0.14857287097536\n",
      "[0.49, 0.484, 0.558, 0.59, 0.534, 0.722, 0.862, 0.942, 0.938, 0.956, 0.956, 0.966, 0.968, 0.97, 0.974, 0.968, 0.972, 0.978, 0.97, 0.978, 0.976, 0.978, 0.978, 0.978, 0.978, 0.98, 0.982]\n",
      "iteration:  260  cost:  0.12467905737689154\n",
      "iteration:  261  cost:  0.1228626196803526\n",
      "iteration:  262  cost:  0.1689474671352484\n",
      "iteration:  263  cost:  0.07420388409209037\n",
      "iteration:  264  cost:  0.36628750838371343\n",
      "iteration:  265  cost:  0.175481758539702\n",
      "iteration:  266  cost:  0.09800621126997086\n",
      "iteration:  267  cost:  0.20132775210006348\n",
      "iteration:  268  cost:  0.14941560553276736\n",
      "iteration:  269  cost:  0.15151079195013517\n",
      "[0.49, 0.484, 0.558, 0.59, 0.534, 0.722, 0.862, 0.942, 0.938, 0.956, 0.956, 0.966, 0.968, 0.97, 0.974, 0.968, 0.972, 0.978, 0.97, 0.978, 0.976, 0.978, 0.978, 0.978, 0.978, 0.98, 0.982, 0.98]\n",
      "iteration:  270  cost:  0.1650107760376932\n",
      "iteration:  271  cost:  0.10271504138240482\n",
      "iteration:  272  cost:  0.18787423289881527\n",
      "iteration:  273  cost:  0.09340403539048354\n",
      "iteration:  274  cost:  0.19428577520527096\n",
      "iteration:  275  cost:  0.18878073027133813\n",
      "iteration:  276  cost:  0.13050211371085912\n",
      "iteration:  277  cost:  0.16251985965249977\n",
      "iteration:  278  cost:  0.21190966333512568\n",
      "iteration:  279  cost:  0.14942615727499436\n",
      "[0.49, 0.484, 0.558, 0.59, 0.534, 0.722, 0.862, 0.942, 0.938, 0.956, 0.956, 0.966, 0.968, 0.97, 0.974, 0.968, 0.972, 0.978, 0.97, 0.978, 0.976, 0.978, 0.978, 0.978, 0.978, 0.98, 0.982, 0.98, 0.978]\n",
      "Accuracy for U_6 pca8 :0.9858156028368794\n",
      "\n",
      "\n",
      "Loss History for QCNN circuits, U_6 pca16\n",
      "[0.448]\n",
      "iteration:  0  cost:  1.2337954545021708\n",
      "iteration:  1  cost:  1.0594245974518408\n",
      "iteration:  2  cost:  1.1162756200333321\n",
      "iteration:  3  cost:  1.2688363882918483\n",
      "iteration:  4  cost:  0.9913125248715186\n",
      "iteration:  5  cost:  1.1416296264721193\n",
      "iteration:  6  cost:  0.9494016658056058\n",
      "iteration:  7  cost:  0.9601689534306233\n",
      "iteration:  8  cost:  0.9610872171368261\n",
      "iteration:  9  cost:  0.8360150185018607\n",
      "[0.448, 0.722]\n",
      "iteration:  10  cost:  0.9791360226084292\n",
      "iteration:  11  cost:  0.7454252701861698\n",
      "iteration:  12  cost:  0.9509271085061216\n",
      "iteration:  13  cost:  1.0123901698602609\n",
      "iteration:  14  cost:  0.8742634125374532\n",
      "iteration:  15  cost:  0.7657704070408639\n",
      "iteration:  16  cost:  1.0572592922367827\n",
      "iteration:  17  cost:  0.8768114877254528\n",
      "iteration:  18  cost:  0.8697403179488452\n",
      "iteration:  19  cost:  0.8993537458741444\n",
      "[0.448, 0.722, 0.748]\n",
      "iteration:  20  cost:  0.8015100444373566\n",
      "iteration:  21  cost:  0.7620269915871415\n",
      "iteration:  22  cost:  0.8616080276363098\n",
      "iteration:  23  cost:  0.8285254384833596\n",
      "iteration:  24  cost:  0.9432874535376051\n",
      "iteration:  25  cost:  0.769356287861126\n",
      "iteration:  26  cost:  0.8489868971204518\n",
      "iteration:  27  cost:  0.8365917545188042\n",
      "iteration:  28  cost:  0.7344547710685931\n",
      "iteration:  29  cost:  0.8570285668931406\n",
      "[0.448, 0.722, 0.748, 0.794]\n",
      "iteration:  30  cost:  0.8675252580037258\n",
      "iteration:  31  cost:  0.6616497738213779\n",
      "iteration:  32  cost:  0.6774537815396608\n",
      "iteration:  33  cost:  0.8041258358468261\n",
      "iteration:  34  cost:  0.8953340183795515\n",
      "iteration:  35  cost:  0.8077786605441497\n",
      "iteration:  36  cost:  0.7584244544331088\n",
      "iteration:  37  cost:  0.7432119291182511\n",
      "iteration:  38  cost:  0.805749970401111\n",
      "iteration:  39  cost:  0.6762966581032337\n",
      "[0.448, 0.722, 0.748, 0.794, 0.856]\n",
      "iteration:  40  cost:  0.6846286309917555\n",
      "iteration:  41  cost:  0.7949181814859884\n",
      "iteration:  42  cost:  0.7168135735206692\n",
      "iteration:  43  cost:  0.6877800902273543\n",
      "iteration:  44  cost:  0.6248953443716452\n",
      "iteration:  45  cost:  0.691282870331425\n",
      "iteration:  46  cost:  0.6111947440148416\n",
      "iteration:  47  cost:  0.734859120172639\n",
      "iteration:  48  cost:  0.6533908732288036\n",
      "iteration:  49  cost:  0.6259623500320699\n",
      "[0.448, 0.722, 0.748, 0.794, 0.856, 0.846]\n",
      "iteration:  50  cost:  0.6602869805877917\n",
      "iteration:  51  cost:  0.6223756095488407\n",
      "iteration:  52  cost:  0.6461690636469741\n",
      "iteration:  53  cost:  0.6294057587227434\n",
      "iteration:  54  cost:  0.7053406644055221\n",
      "iteration:  55  cost:  0.6077318329816908\n",
      "iteration:  56  cost:  0.5489238436226402\n",
      "iteration:  57  cost:  0.4807779207524265\n",
      "iteration:  58  cost:  0.5274189435614827\n",
      "iteration:  59  cost:  0.5493655952823697\n",
      "[0.448, 0.722, 0.748, 0.794, 0.856, 0.846, 0.856]\n",
      "iteration:  60  cost:  0.677766572566686\n",
      "iteration:  61  cost:  0.6056156345906589\n",
      "iteration:  62  cost:  0.5560798883576561\n",
      "iteration:  63  cost:  0.6391248174899119\n",
      "iteration:  64  cost:  0.5668616215525764\n",
      "iteration:  65  cost:  0.45790490085489516\n",
      "iteration:  66  cost:  0.6624486949677371\n",
      "iteration:  67  cost:  0.5779007936848426\n",
      "iteration:  68  cost:  0.580913412724166\n",
      "iteration:  69  cost:  0.5258356613269098\n",
      "[0.448, 0.722, 0.748, 0.794, 0.856, 0.846, 0.856, 0.878]\n",
      "iteration:  70  cost:  0.48283640180452814\n",
      "iteration:  71  cost:  0.4698467156553236\n",
      "iteration:  72  cost:  0.43273966967423355\n",
      "iteration:  73  cost:  0.47372604630928383\n",
      "iteration:  74  cost:  0.40728593132856905\n",
      "iteration:  75  cost:  0.6279579879959192\n",
      "iteration:  76  cost:  0.4577968396472084\n",
      "iteration:  77  cost:  0.4522020989047395\n",
      "iteration:  78  cost:  0.38557604855625655\n",
      "iteration:  79  cost:  0.42144928757806516\n",
      "[0.448, 0.722, 0.748, 0.794, 0.856, 0.846, 0.856, 0.878, 0.898]\n",
      "iteration:  80  cost:  0.3890805989269313\n",
      "iteration:  81  cost:  0.44626553435048444\n",
      "iteration:  82  cost:  0.40634284181357705\n",
      "iteration:  83  cost:  0.4142873774634978\n",
      "iteration:  84  cost:  0.3416559465933965\n",
      "iteration:  85  cost:  0.43741806440478115\n",
      "iteration:  86  cost:  0.4480587399620852\n",
      "iteration:  87  cost:  0.5547513613590632\n",
      "iteration:  88  cost:  0.4519480001710493\n",
      "iteration:  89  cost:  0.37954087307927414\n",
      "[0.448, 0.722, 0.748, 0.794, 0.856, 0.846, 0.856, 0.878, 0.898, 0.934]\n",
      "iteration:  90  cost:  0.3899727477194322\n",
      "iteration:  91  cost:  0.39702947469554767\n",
      "iteration:  92  cost:  0.33977262480895226\n",
      "iteration:  93  cost:  0.3818616461620645\n",
      "iteration:  94  cost:  0.3567406337779838\n",
      "iteration:  95  cost:  0.42734234850321834\n",
      "iteration:  96  cost:  0.4251417469481879\n",
      "iteration:  97  cost:  0.3647275951577413\n",
      "iteration:  98  cost:  0.349003458481591\n",
      "iteration:  99  cost:  0.23383221757303896\n",
      "[0.448, 0.722, 0.748, 0.794, 0.856, 0.846, 0.856, 0.878, 0.898, 0.934, 0.948]\n",
      "iteration:  100  cost:  0.31150514261649404\n",
      "iteration:  101  cost:  0.3013803655023172\n",
      "iteration:  102  cost:  0.30704235077290015\n",
      "iteration:  103  cost:  0.4416058432767992\n",
      "iteration:  104  cost:  0.3201459135480607\n",
      "iteration:  105  cost:  0.29268346263766953\n",
      "iteration:  106  cost:  0.22503063378225588\n",
      "iteration:  107  cost:  0.25381950846406653\n",
      "iteration:  108  cost:  0.3547916738921228\n",
      "iteration:  109  cost:  0.25556290047280383\n",
      "[0.448, 0.722, 0.748, 0.794, 0.856, 0.846, 0.856, 0.878, 0.898, 0.934, 0.948, 0.96]\n",
      "iteration:  110  cost:  0.39441346216121415\n",
      "iteration:  111  cost:  0.2701444634956575\n",
      "iteration:  112  cost:  0.28940630680942747\n",
      "iteration:  113  cost:  0.2170520400945795\n",
      "iteration:  114  cost:  0.34403092385831996\n",
      "iteration:  115  cost:  0.30660708146769605\n",
      "iteration:  116  cost:  0.274762072579538\n",
      "iteration:  117  cost:  0.33954067743526734\n",
      "iteration:  118  cost:  0.23178920692138955\n",
      "iteration:  119  cost:  0.30636375972503704\n",
      "[0.448, 0.722, 0.748, 0.794, 0.856, 0.846, 0.856, 0.878, 0.898, 0.934, 0.948, 0.96, 0.97]\n",
      "iteration:  120  cost:  0.390861072042709\n",
      "iteration:  121  cost:  0.37721730120415065\n",
      "iteration:  122  cost:  0.2283961187303304\n",
      "iteration:  123  cost:  0.19651816385509663\n",
      "iteration:  124  cost:  0.34618166017609703\n",
      "iteration:  125  cost:  0.20465978668939375\n",
      "iteration:  126  cost:  0.27012873778771984\n",
      "iteration:  127  cost:  0.2603217007218986\n",
      "iteration:  128  cost:  0.20932599925302003\n",
      "iteration:  129  cost:  0.20041215241265828\n",
      "[0.448, 0.722, 0.748, 0.794, 0.856, 0.846, 0.856, 0.878, 0.898, 0.934, 0.948, 0.96, 0.97, 0.974]\n",
      "iteration:  130  cost:  0.24213026031839135\n",
      "iteration:  131  cost:  0.15784908686802462\n",
      "iteration:  132  cost:  0.2541277985448404\n",
      "iteration:  133  cost:  0.18232587371129166\n",
      "iteration:  134  cost:  0.3144948987121361\n",
      "iteration:  135  cost:  0.20762129949416974\n",
      "iteration:  136  cost:  0.2604832337369078\n",
      "iteration:  137  cost:  0.20061263901238213\n",
      "iteration:  138  cost:  0.20275169817428654\n",
      "iteration:  139  cost:  0.2199832532641773\n",
      "[0.448, 0.722, 0.748, 0.794, 0.856, 0.846, 0.856, 0.878, 0.898, 0.934, 0.948, 0.96, 0.97, 0.974, 0.966]\n",
      "iteration:  140  cost:  0.31800908598803906\n",
      "iteration:  141  cost:  0.26305610302040705\n",
      "iteration:  142  cost:  0.20788766997990465\n",
      "iteration:  143  cost:  0.21861965740741532\n",
      "iteration:  144  cost:  0.310443272456713\n",
      "iteration:  145  cost:  0.267756891854181\n",
      "iteration:  146  cost:  0.2503715645611016\n",
      "iteration:  147  cost:  0.19779063181613218\n",
      "iteration:  148  cost:  0.22785030227120928\n",
      "iteration:  149  cost:  0.22944384647941787\n",
      "[0.448, 0.722, 0.748, 0.794, 0.856, 0.846, 0.856, 0.878, 0.898, 0.934, 0.948, 0.96, 0.97, 0.974, 0.966, 0.968]\n",
      "iteration:  150  cost:  0.2502356947528588\n",
      "iteration:  151  cost:  0.16060805720051735\n",
      "iteration:  152  cost:  0.26355203217250084\n",
      "iteration:  153  cost:  0.19157794442796192\n",
      "iteration:  154  cost:  0.2612863241723033\n",
      "iteration:  155  cost:  0.1836790431639276\n",
      "iteration:  156  cost:  0.14674263257214532\n",
      "iteration:  157  cost:  0.16965505229322558\n",
      "iteration:  158  cost:  0.16101730638765066\n",
      "iteration:  159  cost:  0.25240330811587247\n",
      "[0.448, 0.722, 0.748, 0.794, 0.856, 0.846, 0.856, 0.878, 0.898, 0.934, 0.948, 0.96, 0.97, 0.974, 0.966, 0.968, 0.97]\n",
      "iteration:  160  cost:  0.16073740942764292\n",
      "iteration:  161  cost:  0.16558679293352035\n",
      "iteration:  162  cost:  0.14109356704993772\n",
      "iteration:  163  cost:  0.2645238330908555\n",
      "iteration:  164  cost:  0.13843084566613117\n",
      "iteration:  165  cost:  0.20074688033248453\n",
      "iteration:  166  cost:  0.23777308674914469\n",
      "iteration:  167  cost:  0.2522659176991013\n",
      "iteration:  168  cost:  0.325798990798387\n",
      "iteration:  169  cost:  0.229964984510162\n",
      "[0.448, 0.722, 0.748, 0.794, 0.856, 0.846, 0.856, 0.878, 0.898, 0.934, 0.948, 0.96, 0.97, 0.974, 0.966, 0.968, 0.97, 0.972]\n",
      "iteration:  170  cost:  0.11734151246379175\n",
      "iteration:  171  cost:  0.2858946397084021\n",
      "iteration:  172  cost:  0.13049065151113085\n",
      "iteration:  173  cost:  0.1543381169098753\n",
      "iteration:  174  cost:  0.19692231846953484\n",
      "iteration:  175  cost:  0.17240830323436998\n",
      "iteration:  176  cost:  0.198007769240065\n",
      "iteration:  177  cost:  0.34192476829914364\n",
      "iteration:  178  cost:  0.24840227116280134\n",
      "iteration:  179  cost:  0.20485859784807647\n",
      "[0.448, 0.722, 0.748, 0.794, 0.856, 0.846, 0.856, 0.878, 0.898, 0.934, 0.948, 0.96, 0.97, 0.974, 0.966, 0.968, 0.97, 0.972, 0.964]\n",
      "Accuracy for U_6 pca16 :0.984869976359338\n",
      "Epoch 1/10\n",
      "396/396 [==============================] - 1s 960us/step - loss: 0.1080 - val_loss: 0.0363\n",
      "Epoch 2/10\n",
      "396/396 [==============================] - 0s 744us/step - loss: 0.0326 - val_loss: 0.0274\n",
      "Epoch 3/10\n",
      "396/396 [==============================] - 0s 770us/step - loss: 0.0270 - val_loss: 0.0249\n",
      "Epoch 4/10\n",
      "396/396 [==============================] - 0s 902us/step - loss: 0.0243 - val_loss: 0.0229\n",
      "Epoch 5/10\n",
      "396/396 [==============================] - 0s 780us/step - loss: 0.0224 - val_loss: 0.0210\n",
      "Epoch 6/10\n",
      "396/396 [==============================] - 0s 760us/step - loss: 0.0211 - val_loss: 0.0199\n",
      "Epoch 7/10\n",
      "396/396 [==============================] - 0s 777us/step - loss: 0.0197 - val_loss: 0.0192\n",
      "Epoch 8/10\n",
      "396/396 [==============================] - 0s 761us/step - loss: 0.0193 - val_loss: 0.0187\n",
      "Epoch 9/10\n",
      "396/396 [==============================] - 0s 768us/step - loss: 0.0187 - val_loss: 0.0182\n",
      "Epoch 10/10\n",
      "396/396 [==============================] - 0s 778us/step - loss: 0.0187 - val_loss: 0.0179\n",
      "\n",
      "\n",
      "Loss History for QCNN circuits, U_6 autoencoder8\n",
      "[0.386]\n",
      "iteration:  0  cost:  1.0351572988846625\n",
      "iteration:  1  cost:  1.266603555592758\n",
      "iteration:  2  cost:  1.204722939397913\n",
      "iteration:  3  cost:  1.238994496149731\n",
      "iteration:  4  cost:  1.1573007931672226\n",
      "iteration:  5  cost:  1.244702751363806\n",
      "iteration:  6  cost:  1.0880347979753362\n",
      "iteration:  7  cost:  1.198630801260418\n",
      "iteration:  8  cost:  1.1296480169867265\n",
      "iteration:  9  cost:  1.1279076082310298\n",
      "[0.386, 0.394]\n",
      "iteration:  10  cost:  1.0813054209448725\n",
      "iteration:  11  cost:  1.0720450693292178\n",
      "iteration:  12  cost:  1.0691184954588855\n",
      "iteration:  13  cost:  1.0621256004127888\n",
      "iteration:  14  cost:  1.0537089879823238\n",
      "iteration:  15  cost:  1.0585674125624989\n",
      "iteration:  16  cost:  1.0635764350203052\n",
      "iteration:  17  cost:  1.0529659289234363\n",
      "iteration:  18  cost:  1.0361677140796692\n",
      "iteration:  19  cost:  0.9929315853282918\n",
      "[0.386, 0.394, 0.508]\n",
      "iteration:  20  cost:  0.9755600780944553\n",
      "iteration:  21  cost:  1.047108957435924\n",
      "iteration:  22  cost:  0.9852434414292489\n",
      "iteration:  23  cost:  0.9902639462536742\n",
      "iteration:  24  cost:  0.9764980780623256\n",
      "iteration:  25  cost:  0.9665797295803986\n",
      "iteration:  26  cost:  0.9456757156868528\n",
      "iteration:  27  cost:  0.9417673141638356\n",
      "iteration:  28  cost:  0.935847819233284\n",
      "iteration:  29  cost:  0.9082974915407276\n",
      "[0.386, 0.394, 0.508, 0.872]\n",
      "iteration:  30  cost:  0.952517958722217\n",
      "iteration:  31  cost:  0.8858585366655026\n",
      "iteration:  32  cost:  0.9058644215587877\n",
      "iteration:  33  cost:  0.8817521654154509\n",
      "iteration:  34  cost:  0.8874443783379902\n",
      "iteration:  35  cost:  0.8950714731986227\n",
      "iteration:  36  cost:  0.9262186839069337\n",
      "iteration:  37  cost:  0.9115674134536162\n",
      "iteration:  38  cost:  0.9149743520426541\n",
      "iteration:  39  cost:  0.801241579728199\n",
      "[0.386, 0.394, 0.508, 0.872, 0.762]\n",
      "iteration:  40  cost:  0.8056953938517004\n",
      "iteration:  41  cost:  0.8667688743458752\n",
      "iteration:  42  cost:  0.8783049242948681\n",
      "iteration:  43  cost:  0.8631611780616234\n",
      "iteration:  44  cost:  0.7941025167319029\n",
      "iteration:  45  cost:  0.8168816306105985\n",
      "iteration:  46  cost:  0.8203260094473868\n",
      "iteration:  47  cost:  0.7801162920347627\n",
      "iteration:  48  cost:  0.7798403084744164\n",
      "iteration:  49  cost:  0.745383330116183\n",
      "[0.386, 0.394, 0.508, 0.872, 0.762, 0.768]\n",
      "iteration:  50  cost:  0.863648015814542\n",
      "iteration:  51  cost:  0.7972778233782862\n",
      "iteration:  52  cost:  0.7768554494319582\n",
      "iteration:  53  cost:  0.7278995040883148\n",
      "iteration:  54  cost:  0.7570078793942672\n",
      "iteration:  55  cost:  0.7840473127001155\n",
      "iteration:  56  cost:  0.7561795764829189\n",
      "iteration:  57  cost:  0.6638704354546501\n",
      "iteration:  58  cost:  0.7452690718851231\n",
      "iteration:  59  cost:  0.7385264737599401\n",
      "[0.386, 0.394, 0.508, 0.872, 0.762, 0.768, 0.846]\n",
      "iteration:  60  cost:  0.6549735419151657\n",
      "iteration:  61  cost:  0.6698745917116135\n",
      "iteration:  62  cost:  0.6565311551386093\n",
      "iteration:  63  cost:  0.7754519793028051\n",
      "iteration:  64  cost:  0.7089265167986796\n",
      "iteration:  65  cost:  0.6613778564531675\n",
      "iteration:  66  cost:  0.6696570949963219\n",
      "iteration:  67  cost:  0.6829895308796385\n",
      "iteration:  68  cost:  0.656403911335342\n",
      "iteration:  69  cost:  0.6817078201054474\n",
      "[0.386, 0.394, 0.508, 0.872, 0.762, 0.768, 0.846, 0.844]\n",
      "iteration:  70  cost:  0.7285237406746708\n",
      "iteration:  71  cost:  0.678761725493441\n",
      "iteration:  72  cost:  0.5939017920365852\n",
      "iteration:  73  cost:  0.6990549603974311\n",
      "iteration:  74  cost:  0.6708545491713436\n",
      "iteration:  75  cost:  0.6974023474421034\n",
      "iteration:  76  cost:  0.5989404503715077\n",
      "iteration:  77  cost:  0.6154699306473524\n",
      "iteration:  78  cost:  0.7196431663106196\n",
      "iteration:  79  cost:  0.5964977394329939\n",
      "[0.386, 0.394, 0.508, 0.872, 0.762, 0.768, 0.846, 0.844, 0.84]\n",
      "iteration:  80  cost:  0.6737589203300383\n",
      "iteration:  81  cost:  0.6377205421289163\n",
      "iteration:  82  cost:  0.6765422424028916\n",
      "iteration:  83  cost:  0.5975845577269596\n",
      "iteration:  84  cost:  0.7445325430913309\n",
      "iteration:  85  cost:  0.6197067571853413\n",
      "iteration:  86  cost:  0.6800014655604747\n",
      "iteration:  87  cost:  0.6227748844627566\n",
      "iteration:  88  cost:  0.5659314004226039\n",
      "iteration:  89  cost:  0.5973743251599374\n",
      "[0.386, 0.394, 0.508, 0.872, 0.762, 0.768, 0.846, 0.844, 0.84, 0.858]\n",
      "iteration:  90  cost:  0.592734699319218\n",
      "iteration:  91  cost:  0.7451557697651766\n",
      "iteration:  92  cost:  0.5800693201723113\n",
      "iteration:  93  cost:  0.5839977226863856\n",
      "iteration:  94  cost:  0.5924457843319257\n",
      "iteration:  95  cost:  0.6538033248007443\n",
      "iteration:  96  cost:  0.6644148467587894\n",
      "iteration:  97  cost:  0.6510669716873891\n",
      "iteration:  98  cost:  0.7286103471739941\n",
      "iteration:  99  cost:  0.6070170466621293\n",
      "[0.386, 0.394, 0.508, 0.872, 0.762, 0.768, 0.846, 0.844, 0.84, 0.858, 0.924]\n",
      "iteration:  100  cost:  0.6259221337242028\n",
      "iteration:  101  cost:  0.5836392937974267\n",
      "iteration:  102  cost:  0.6526520664319132\n",
      "iteration:  103  cost:  0.6384883519980976\n",
      "iteration:  104  cost:  0.5674895345015354\n",
      "iteration:  105  cost:  0.5921182573291208\n",
      "iteration:  106  cost:  0.7352145119322947\n",
      "iteration:  107  cost:  0.6025974819653084\n",
      "iteration:  108  cost:  0.6366210112641025\n",
      "iteration:  109  cost:  0.6754665967295739\n",
      "[0.386, 0.394, 0.508, 0.872, 0.762, 0.768, 0.846, 0.844, 0.84, 0.858, 0.924, 0.922]\n",
      "iteration:  110  cost:  0.5570706458121648\n",
      "iteration:  111  cost:  0.6207562391769683\n",
      "iteration:  112  cost:  0.6642033311394648\n",
      "iteration:  113  cost:  0.5735017521571826\n",
      "iteration:  114  cost:  0.5376228960976804\n",
      "iteration:  115  cost:  0.5546205861108252\n",
      "iteration:  116  cost:  0.6486336529981205\n",
      "iteration:  117  cost:  0.4894955264876436\n",
      "iteration:  118  cost:  0.6798268960881119\n",
      "iteration:  119  cost:  0.7385611999952877\n",
      "[0.386, 0.394, 0.508, 0.872, 0.762, 0.768, 0.846, 0.844, 0.84, 0.858, 0.924, 0.922, 0.908]\n",
      "iteration:  120  cost:  0.6741415411181428\n",
      "iteration:  121  cost:  0.6807176992867255\n",
      "iteration:  122  cost:  0.5699890577396178\n",
      "iteration:  123  cost:  0.6106734901723977\n",
      "iteration:  124  cost:  0.5910749673287997\n",
      "iteration:  125  cost:  0.6057972013149429\n",
      "iteration:  126  cost:  0.6281579946072843\n",
      "iteration:  127  cost:  0.7052952620161825\n",
      "iteration:  128  cost:  0.6133950820913203\n",
      "iteration:  129  cost:  0.5500556225067752\n",
      "[0.386, 0.394, 0.508, 0.872, 0.762, 0.768, 0.846, 0.844, 0.84, 0.858, 0.924, 0.922, 0.908, 0.964]\n",
      "iteration:  130  cost:  0.5788210956816505\n",
      "iteration:  131  cost:  0.5696351703581819\n",
      "iteration:  132  cost:  0.5882252109257536\n",
      "iteration:  133  cost:  0.7134144670037442\n",
      "iteration:  134  cost:  0.5945154695387207\n",
      "iteration:  135  cost:  0.5748339749099065\n",
      "iteration:  136  cost:  0.5761850360356207\n",
      "iteration:  137  cost:  0.4792386791431298\n",
      "iteration:  138  cost:  0.5882150333101385\n",
      "iteration:  139  cost:  0.6398253108876955\n",
      "[0.386, 0.394, 0.508, 0.872, 0.762, 0.768, 0.846, 0.844, 0.84, 0.858, 0.924, 0.922, 0.908, 0.964, 0.89]\n",
      "Accuracy for U_6 autoencoder8 :0.8936170212765957\n",
      "Epoch 1/10\n",
      "396/396 [==============================] - 1s 982us/step - loss: 0.0938 - val_loss: 0.0276\n",
      "Epoch 2/10\n",
      "396/396 [==============================] - 0s 934us/step - loss: 0.0261 - val_loss: 0.0213\n",
      "Epoch 3/10\n",
      "396/396 [==============================] - 0s 815us/step - loss: 0.0206 - val_loss: 0.0173\n",
      "Epoch 4/10\n",
      "396/396 [==============================] - 0s 817us/step - loss: 0.0168 - val_loss: 0.0149\n",
      "Epoch 5/10\n",
      "396/396 [==============================] - 0s 793us/step - loss: 0.0149 - val_loss: 0.0136\n",
      "Epoch 6/10\n",
      "396/396 [==============================] - 0s 800us/step - loss: 0.0135 - val_loss: 0.0127\n",
      "Epoch 7/10\n",
      "396/396 [==============================] - 0s 799us/step - loss: 0.0125 - val_loss: 0.0119\n",
      "Epoch 8/10\n",
      "396/396 [==============================] - 0s 814us/step - loss: 0.0118 - val_loss: 0.0114\n",
      "Epoch 9/10\n",
      "396/396 [==============================] - 0s 806us/step - loss: 0.0114 - val_loss: 0.0109\n",
      "Epoch 10/10\n",
      "396/396 [==============================] - 0s 814us/step - loss: 0.0109 - val_loss: 0.0106\n",
      "\n",
      "\n",
      "Loss History for QCNN circuits, U_6 autoencoder16\n",
      "[0.422]\n",
      "iteration:  0  cost:  1.0696323214228125\n",
      "iteration:  1  cost:  1.0887648736014721\n",
      "iteration:  2  cost:  1.121685611531071\n",
      "iteration:  3  cost:  1.0523744249693632\n",
      "iteration:  4  cost:  0.9616398520905746\n",
      "iteration:  5  cost:  1.0768421206775916\n",
      "iteration:  6  cost:  0.9361416177201626\n",
      "iteration:  7  cost:  0.9825049600911592\n",
      "iteration:  8  cost:  1.007719893106406\n",
      "iteration:  9  cost:  0.9289457151286671\n",
      "[0.422, 0.642]\n",
      "iteration:  10  cost:  0.9212153422458758\n",
      "iteration:  11  cost:  0.9403970514293676\n",
      "iteration:  12  cost:  0.9289755997323684\n",
      "iteration:  13  cost:  0.9189552131419296\n",
      "iteration:  14  cost:  0.9408225128060412\n",
      "iteration:  15  cost:  0.7884418339870735\n",
      "iteration:  16  cost:  0.8607091185857711\n",
      "iteration:  17  cost:  0.8877748536510137\n",
      "iteration:  18  cost:  0.8939360110782067\n",
      "iteration:  19  cost:  0.7875626280129164\n",
      "[0.422, 0.642, 0.774]\n",
      "iteration:  20  cost:  0.87786863061531\n",
      "iteration:  21  cost:  0.7225867409273655\n",
      "iteration:  22  cost:  0.8218266592560749\n",
      "iteration:  23  cost:  0.6903437333059627\n",
      "iteration:  24  cost:  0.8378103943399983\n",
      "iteration:  25  cost:  0.6478757111832967\n",
      "iteration:  26  cost:  0.7711490849729047\n",
      "iteration:  27  cost:  0.8145872905953404\n",
      "iteration:  28  cost:  0.737372989677548\n",
      "iteration:  29  cost:  0.7724333817796664\n",
      "[0.422, 0.642, 0.774, 0.75]\n",
      "iteration:  30  cost:  0.7523822944926566\n",
      "iteration:  31  cost:  0.7417132890061161\n",
      "iteration:  32  cost:  0.6472120276497267\n",
      "iteration:  33  cost:  0.7516744576238782\n",
      "iteration:  34  cost:  0.6890978460939233\n",
      "iteration:  35  cost:  0.6474392790019664\n",
      "iteration:  36  cost:  0.6911096160410867\n",
      "iteration:  37  cost:  0.738279480370487\n",
      "iteration:  38  cost:  0.6823736372132392\n",
      "iteration:  39  cost:  0.7080285669677784\n",
      "[0.422, 0.642, 0.774, 0.75, 0.822]\n",
      "iteration:  40  cost:  0.647087013632243\n",
      "iteration:  41  cost:  0.6750759486055614\n",
      "iteration:  42  cost:  0.7412247308537835\n",
      "iteration:  43  cost:  0.9111585096960012\n",
      "iteration:  44  cost:  0.7063018739825844\n",
      "iteration:  45  cost:  0.6355291083688916\n",
      "iteration:  46  cost:  0.7318198647398816\n",
      "iteration:  47  cost:  0.6059209621902315\n",
      "iteration:  48  cost:  0.6510866254629203\n",
      "iteration:  49  cost:  0.5924730496150752\n",
      "[0.422, 0.642, 0.774, 0.75, 0.822, 0.878]\n",
      "iteration:  50  cost:  0.6624692099546818\n",
      "iteration:  51  cost:  0.6795156061793165\n",
      "iteration:  52  cost:  0.6205869763123681\n",
      "iteration:  53  cost:  0.654243543138653\n",
      "iteration:  54  cost:  0.6818098713394412\n",
      "iteration:  55  cost:  0.7024327438687209\n",
      "iteration:  56  cost:  0.7167933618498075\n",
      "iteration:  57  cost:  0.6155680709966923\n",
      "iteration:  58  cost:  0.740026933617001\n",
      "iteration:  59  cost:  0.7241389218600324\n",
      "[0.422, 0.642, 0.774, 0.75, 0.822, 0.878, 0.86]\n",
      "iteration:  60  cost:  0.5283113220435243\n",
      "iteration:  61  cost:  0.5093242250485548\n",
      "iteration:  62  cost:  0.49491791105573574\n",
      "iteration:  63  cost:  0.5892023397551918\n",
      "iteration:  64  cost:  0.6049914965275002\n",
      "iteration:  65  cost:  0.6817609577313516\n",
      "iteration:  66  cost:  0.6356607070716227\n",
      "iteration:  67  cost:  0.663890180102296\n",
      "iteration:  68  cost:  0.6448867768843148\n",
      "iteration:  69  cost:  0.6548551138259475\n",
      "[0.422, 0.642, 0.774, 0.75, 0.822, 0.878, 0.86, 0.886]\n",
      "iteration:  70  cost:  0.5030293477237785\n",
      "iteration:  71  cost:  0.5673673184865425\n",
      "iteration:  72  cost:  0.595960140892565\n",
      "iteration:  73  cost:  0.6886839397708527\n",
      "iteration:  74  cost:  0.6142920750359615\n",
      "iteration:  75  cost:  0.6519158119004015\n",
      "iteration:  76  cost:  0.5405197421984327\n",
      "iteration:  77  cost:  0.6405176578568844\n",
      "iteration:  78  cost:  0.6782473395359535\n",
      "iteration:  79  cost:  0.5914364561394485\n",
      "[0.422, 0.642, 0.774, 0.75, 0.822, 0.878, 0.86, 0.886, 0.888]\n",
      "iteration:  80  cost:  0.5129476775783983\n",
      "iteration:  81  cost:  0.5877558123052612\n",
      "iteration:  82  cost:  0.7657780866690278\n",
      "iteration:  83  cost:  0.6541113336330416\n",
      "iteration:  84  cost:  0.5335132053834952\n",
      "iteration:  85  cost:  0.592634386330443\n",
      "iteration:  86  cost:  0.6952085960006378\n",
      "iteration:  87  cost:  0.5966851226676222\n",
      "iteration:  88  cost:  0.531644130294621\n",
      "iteration:  89  cost:  0.6949639867252922\n",
      "[0.422, 0.642, 0.774, 0.75, 0.822, 0.878, 0.86, 0.886, 0.888, 0.864]\n",
      "iteration:  90  cost:  0.5634339806981482\n",
      "iteration:  91  cost:  0.5952602222104109\n",
      "iteration:  92  cost:  0.7415515177803113\n",
      "iteration:  93  cost:  0.6179705633629087\n",
      "iteration:  94  cost:  0.5460173048896485\n",
      "iteration:  95  cost:  0.7716374258948353\n",
      "iteration:  96  cost:  0.6394578219612341\n",
      "iteration:  97  cost:  0.6187299412539147\n",
      "iteration:  98  cost:  0.6044230937778778\n",
      "iteration:  99  cost:  0.6128456315459212\n",
      "[0.422, 0.642, 0.774, 0.75, 0.822, 0.878, 0.86, 0.886, 0.888, 0.864, 0.944]\n",
      "iteration:  100  cost:  0.6320855436568789\n",
      "iteration:  101  cost:  0.5392046380119015\n",
      "iteration:  102  cost:  0.6141126253289672\n",
      "iteration:  103  cost:  0.5516474372075496\n",
      "iteration:  104  cost:  0.5939921152523319\n",
      "iteration:  105  cost:  0.7004713860353298\n",
      "iteration:  106  cost:  0.6939126732680484\n",
      "iteration:  107  cost:  0.6638420753339805\n",
      "iteration:  108  cost:  0.6215645117168872\n",
      "iteration:  109  cost:  0.5449223021058763\n",
      "[0.422, 0.642, 0.774, 0.75, 0.822, 0.878, 0.86, 0.886, 0.888, 0.864, 0.944, 0.936]\n",
      "iteration:  110  cost:  0.5409896556433911\n",
      "iteration:  111  cost:  0.6131582007970886\n",
      "iteration:  112  cost:  0.5643953287545485\n",
      "iteration:  113  cost:  0.6583062356937631\n",
      "iteration:  114  cost:  0.5540652236662265\n",
      "iteration:  115  cost:  0.5996119812970415\n",
      "iteration:  116  cost:  0.5800242488385312\n",
      "iteration:  117  cost:  0.6248725308170507\n",
      "iteration:  118  cost:  0.537052483087164\n",
      "iteration:  119  cost:  0.5559649398733663\n",
      "[0.422, 0.642, 0.774, 0.75, 0.822, 0.878, 0.86, 0.886, 0.888, 0.864, 0.944, 0.936, 0.94]\n",
      "iteration:  120  cost:  0.5206679140122831\n",
      "iteration:  121  cost:  0.509755162781788\n",
      "iteration:  122  cost:  0.5707250028371915\n",
      "iteration:  123  cost:  0.6523428635268678\n",
      "iteration:  124  cost:  0.5345859596923962\n",
      "iteration:  125  cost:  0.5639823924742283\n",
      "iteration:  126  cost:  0.49434196345562575\n",
      "iteration:  127  cost:  0.6525120698973563\n",
      "iteration:  128  cost:  0.6265496093011081\n",
      "iteration:  129  cost:  0.5282443333570923\n",
      "[0.422, 0.642, 0.774, 0.75, 0.822, 0.878, 0.86, 0.886, 0.888, 0.864, 0.944, 0.936, 0.94, 0.918]\n",
      "Accuracy for U_6 autoencoder16 :0.9030732860520094\n",
      "\n",
      "\n",
      "Loss History for QCNN circuits, U_9 resize256\n",
      "[0.47]\n",
      "iteration:  0  cost:  1.0203309214722747\n",
      "iteration:  1  cost:  1.0370714941440102\n",
      "iteration:  2  cost:  1.0020647838687955\n",
      "iteration:  3  cost:  1.0713359145611436\n",
      "iteration:  4  cost:  1.0053161681950913\n",
      "iteration:  5  cost:  1.0463796758209383\n",
      "iteration:  6  cost:  1.019790883693188\n",
      "iteration:  7  cost:  1.0430391031494528\n",
      "iteration:  8  cost:  1.0352923460275245\n",
      "iteration:  9  cost:  1.0203952151763866\n",
      "[0.47, 0.498]\n",
      "iteration:  10  cost:  0.9985345756714011\n",
      "iteration:  11  cost:  1.0465543806647803\n",
      "iteration:  12  cost:  1.0351011087747248\n",
      "iteration:  13  cost:  1.00802841100593\n",
      "iteration:  14  cost:  1.0347652909351228\n",
      "iteration:  15  cost:  1.0082645470101284\n",
      "iteration:  16  cost:  1.0211417824763211\n",
      "iteration:  17  cost:  1.0077701679434676\n",
      "iteration:  18  cost:  0.9857269547382778\n",
      "iteration:  19  cost:  1.0233136035742272\n",
      "[0.47, 0.498, 0.564]\n",
      "iteration:  20  cost:  0.9903523339512849\n",
      "iteration:  21  cost:  1.0019338238485387\n",
      "iteration:  22  cost:  1.0043830361661454\n",
      "iteration:  23  cost:  0.985226622614883\n",
      "iteration:  24  cost:  0.9901642703812489\n",
      "iteration:  25  cost:  1.0137663903469565\n",
      "iteration:  26  cost:  1.024364717317998\n",
      "iteration:  27  cost:  1.0022419769925128\n",
      "iteration:  28  cost:  0.9821337579440419\n",
      "iteration:  29  cost:  0.9975021898292086\n",
      "[0.47, 0.498, 0.564, 0.646]\n",
      "iteration:  30  cost:  0.9828914981338862\n",
      "iteration:  31  cost:  0.9949368441607532\n",
      "iteration:  32  cost:  0.9804158165941681\n",
      "iteration:  33  cost:  0.9741162990956524\n",
      "iteration:  34  cost:  0.978931562742117\n",
      "iteration:  35  cost:  0.9854878601579289\n",
      "iteration:  36  cost:  0.9794694978147228\n",
      "iteration:  37  cost:  0.9926343442733535\n",
      "iteration:  38  cost:  0.9943897394324249\n",
      "iteration:  39  cost:  0.9855654354475217\n",
      "[0.47, 0.498, 0.564, 0.646, 0.71]\n",
      "iteration:  40  cost:  0.9659405327077119\n",
      "iteration:  41  cost:  0.9736817114857138\n",
      "iteration:  42  cost:  0.9777937266742576\n",
      "iteration:  43  cost:  0.9944234099243878\n",
      "iteration:  44  cost:  0.9681848000266089\n",
      "iteration:  45  cost:  0.9724410104893686\n",
      "iteration:  46  cost:  0.9854086430786181\n",
      "iteration:  47  cost:  0.9836462566356162\n",
      "iteration:  48  cost:  0.9734460606782619\n",
      "iteration:  49  cost:  0.9953112939751928\n",
      "[0.47, 0.498, 0.564, 0.646, 0.71, 0.73]\n",
      "iteration:  50  cost:  0.9747881302474901\n",
      "iteration:  51  cost:  0.9585613939802284\n",
      "iteration:  52  cost:  0.9647089630654048\n",
      "iteration:  53  cost:  0.9692367168623032\n",
      "iteration:  54  cost:  0.9816142101548947\n",
      "iteration:  55  cost:  0.9647530728642095\n",
      "iteration:  56  cost:  0.9866692142415586\n",
      "iteration:  57  cost:  0.9622842165797184\n",
      "iteration:  58  cost:  0.9565935618411591\n",
      "iteration:  59  cost:  0.9595546105224642\n",
      "[0.47, 0.498, 0.564, 0.646, 0.71, 0.73, 0.77]\n",
      "iteration:  60  cost:  0.9595228534440223\n",
      "iteration:  61  cost:  0.9766753853483938\n",
      "iteration:  62  cost:  0.9719566242100526\n",
      "iteration:  63  cost:  0.9615471842665367\n",
      "iteration:  64  cost:  0.9682703357102806\n",
      "iteration:  65  cost:  0.9637439856036382\n",
      "iteration:  66  cost:  0.9839007292301827\n",
      "iteration:  67  cost:  0.9511338753637045\n",
      "iteration:  68  cost:  0.9659299067573741\n",
      "iteration:  69  cost:  0.9581523730611781\n",
      "[0.47, 0.498, 0.564, 0.646, 0.71, 0.73, 0.77, 0.796]\n",
      "iteration:  70  cost:  0.9869412014528092\n",
      "iteration:  71  cost:  0.9674579144863996\n",
      "iteration:  72  cost:  0.9544812625346889\n",
      "iteration:  73  cost:  0.9533251718598094\n",
      "iteration:  74  cost:  0.9395427755475607\n",
      "iteration:  75  cost:  0.9311630695262137\n",
      "iteration:  76  cost:  0.9349714535281648\n",
      "iteration:  77  cost:  0.9345631930127176\n",
      "iteration:  78  cost:  0.9604931544970897\n",
      "iteration:  79  cost:  0.949989385696301\n",
      "[0.47, 0.498, 0.564, 0.646, 0.71, 0.73, 0.77, 0.796, 0.804]\n",
      "iteration:  80  cost:  0.9481032200527388\n",
      "iteration:  81  cost:  0.9415273040199952\n",
      "iteration:  82  cost:  0.9452638990183339\n",
      "iteration:  83  cost:  0.9498517170491358\n",
      "iteration:  84  cost:  0.9592665406864965\n",
      "iteration:  85  cost:  0.9694655423152114\n",
      "iteration:  86  cost:  0.9671605449880987\n",
      "iteration:  87  cost:  0.9452811938041021\n",
      "iteration:  88  cost:  0.9761715468478112\n",
      "iteration:  89  cost:  0.9570657721047159\n",
      "[0.47, 0.498, 0.564, 0.646, 0.71, 0.73, 0.77, 0.796, 0.804, 0.824]\n",
      "iteration:  90  cost:  0.9484353739022547\n",
      "iteration:  91  cost:  0.9310421490055026\n",
      "iteration:  92  cost:  0.96604590828469\n",
      "iteration:  93  cost:  0.9511707061029316\n",
      "iteration:  94  cost:  0.9431020216562405\n",
      "iteration:  95  cost:  0.970397798311417\n",
      "iteration:  96  cost:  0.9320381767270327\n",
      "iteration:  97  cost:  0.9358896526205794\n",
      "iteration:  98  cost:  0.9535209986651689\n",
      "iteration:  99  cost:  0.9235071636636946\n",
      "[0.47, 0.498, 0.564, 0.646, 0.71, 0.73, 0.77, 0.796, 0.804, 0.824, 0.84]\n",
      "iteration:  100  cost:  0.9354552622184471\n",
      "iteration:  101  cost:  0.9323550286951888\n",
      "iteration:  102  cost:  0.9392482010437412\n",
      "iteration:  103  cost:  0.9510687316136093\n",
      "iteration:  104  cost:  0.9237008067489272\n",
      "iteration:  105  cost:  0.914425539056094\n",
      "iteration:  106  cost:  0.9509604255193013\n",
      "iteration:  107  cost:  0.9417440477207059\n",
      "iteration:  108  cost:  0.9445814280004586\n",
      "iteration:  109  cost:  0.9158406472267999\n",
      "[0.47, 0.498, 0.564, 0.646, 0.71, 0.73, 0.77, 0.796, 0.804, 0.824, 0.84, 0.844]\n",
      "iteration:  110  cost:  0.9346612889874184\n",
      "iteration:  111  cost:  0.9154779392641911\n",
      "iteration:  112  cost:  0.9572037338368433\n",
      "iteration:  113  cost:  0.9344039856635394\n",
      "iteration:  114  cost:  0.9395638710252608\n",
      "iteration:  115  cost:  0.9396984487209553\n",
      "iteration:  116  cost:  0.9057979713467904\n",
      "iteration:  117  cost:  0.8943200409977833\n",
      "iteration:  118  cost:  0.9382737925766982\n",
      "iteration:  119  cost:  0.8967608773044915\n",
      "[0.47, 0.498, 0.564, 0.646, 0.71, 0.73, 0.77, 0.796, 0.804, 0.824, 0.84, 0.844, 0.85]\n",
      "iteration:  120  cost:  0.941651915579496\n",
      "iteration:  121  cost:  0.9163036262159778\n",
      "iteration:  122  cost:  0.9028651904666697\n",
      "iteration:  123  cost:  0.9103964035824536\n",
      "iteration:  124  cost:  0.934800915598625\n",
      "iteration:  125  cost:  0.9462672741018225\n",
      "iteration:  126  cost:  0.9211363188415175\n",
      "iteration:  127  cost:  0.9110965333161984\n",
      "iteration:  128  cost:  0.9312880603839665\n",
      "iteration:  129  cost:  0.8971562844731179\n",
      "[0.47, 0.498, 0.564, 0.646, 0.71, 0.73, 0.77, 0.796, 0.804, 0.824, 0.84, 0.844, 0.85, 0.862]\n",
      "iteration:  130  cost:  0.901924627539904\n",
      "iteration:  131  cost:  0.9453091432564779\n",
      "iteration:  132  cost:  0.9193320275623933\n",
      "iteration:  133  cost:  0.8998863478247437\n",
      "iteration:  134  cost:  0.9298076116204836\n",
      "iteration:  135  cost:  0.9146641628590882\n",
      "iteration:  136  cost:  0.9327818791340188\n",
      "iteration:  137  cost:  0.8779692185221458\n",
      "iteration:  138  cost:  0.8827488109434423\n",
      "iteration:  139  cost:  0.906998033753403\n",
      "[0.47, 0.498, 0.564, 0.646, 0.71, 0.73, 0.77, 0.796, 0.804, 0.824, 0.84, 0.844, 0.85, 0.862, 0.862]\n",
      "iteration:  140  cost:  0.916350357894235\n",
      "iteration:  141  cost:  0.8588301410062559\n",
      "iteration:  142  cost:  0.8932814333854678\n",
      "iteration:  143  cost:  0.8773209883064352\n",
      "iteration:  144  cost:  0.8852858901443106\n",
      "iteration:  145  cost:  0.899377067499743\n",
      "iteration:  146  cost:  0.926950450788991\n",
      "iteration:  147  cost:  0.9218475752802029\n",
      "iteration:  148  cost:  0.8879160895991727\n",
      "iteration:  149  cost:  0.8495327511536718\n",
      "[0.47, 0.498, 0.564, 0.646, 0.71, 0.73, 0.77, 0.796, 0.804, 0.824, 0.84, 0.844, 0.85, 0.862, 0.862, 0.858]\n",
      "iteration:  150  cost:  0.9108242227987159\n",
      "iteration:  151  cost:  0.8554840320828887\n",
      "iteration:  152  cost:  0.9034407875851648\n",
      "iteration:  153  cost:  0.8900948077070248\n",
      "iteration:  154  cost:  0.877281690782482\n",
      "iteration:  155  cost:  0.8966985157207749\n",
      "iteration:  156  cost:  0.9127992689058605\n",
      "iteration:  157  cost:  0.8832341507855598\n",
      "iteration:  158  cost:  0.8829591584995895\n",
      "iteration:  159  cost:  0.8570501285932438\n",
      "[0.47, 0.498, 0.564, 0.646, 0.71, 0.73, 0.77, 0.796, 0.804, 0.824, 0.84, 0.844, 0.85, 0.862, 0.862, 0.858, 0.866]\n",
      "iteration:  160  cost:  0.909447373742244\n",
      "iteration:  161  cost:  0.900537473561406\n",
      "iteration:  162  cost:  0.8847440444006351\n",
      "iteration:  163  cost:  0.9045582313850905\n",
      "iteration:  164  cost:  0.8835696394957531\n",
      "iteration:  165  cost:  0.8509480345395437\n",
      "iteration:  166  cost:  0.9117321461900678\n",
      "iteration:  167  cost:  0.8671474798484495\n",
      "iteration:  168  cost:  0.9069547412806132\n",
      "iteration:  169  cost:  0.8599719506202055\n",
      "[0.47, 0.498, 0.564, 0.646, 0.71, 0.73, 0.77, 0.796, 0.804, 0.824, 0.84, 0.844, 0.85, 0.862, 0.862, 0.858, 0.866, 0.882]\n",
      "iteration:  170  cost:  0.8710782775761078\n",
      "iteration:  171  cost:  0.8723167063470243\n",
      "iteration:  172  cost:  0.8478449042726285\n",
      "iteration:  173  cost:  0.837032499452336\n",
      "iteration:  174  cost:  0.8481661676668018\n",
      "iteration:  175  cost:  0.854724057018408\n",
      "iteration:  176  cost:  0.8627709781127847\n",
      "iteration:  177  cost:  0.845555876311966\n",
      "iteration:  178  cost:  0.8330664492026828\n",
      "iteration:  179  cost:  0.822261901775156\n",
      "[0.47, 0.498, 0.564, 0.646, 0.71, 0.73, 0.77, 0.796, 0.804, 0.824, 0.84, 0.844, 0.85, 0.862, 0.862, 0.858, 0.866, 0.882, 0.888]\n",
      "iteration:  180  cost:  0.8377421790777535\n",
      "iteration:  181  cost:  0.8208948292596758\n",
      "iteration:  182  cost:  0.8789674033970926\n",
      "iteration:  183  cost:  0.8585586752881443\n",
      "iteration:  184  cost:  0.8587085980630933\n",
      "iteration:  185  cost:  0.8583710425269837\n",
      "iteration:  186  cost:  0.8637984392773492\n",
      "iteration:  187  cost:  0.8543428373789161\n",
      "iteration:  188  cost:  0.8185769812453115\n",
      "iteration:  189  cost:  0.8406364752248827\n",
      "[0.47, 0.498, 0.564, 0.646, 0.71, 0.73, 0.77, 0.796, 0.804, 0.824, 0.84, 0.844, 0.85, 0.862, 0.862, 0.858, 0.866, 0.882, 0.888, 0.888]\n",
      "iteration:  190  cost:  0.8162061061185394\n",
      "iteration:  191  cost:  0.8311024292284425\n",
      "iteration:  192  cost:  0.8409732741752193\n",
      "iteration:  193  cost:  0.8222901252139692\n",
      "iteration:  194  cost:  0.8821024065903219\n",
      "iteration:  195  cost:  0.8494740052564619\n",
      "iteration:  196  cost:  0.8117336724764586\n",
      "iteration:  197  cost:  0.8645707299157109\n",
      "iteration:  198  cost:  0.783917331651456\n",
      "iteration:  199  cost:  0.8220961020084842\n",
      "[0.47, 0.498, 0.564, 0.646, 0.71, 0.73, 0.77, 0.796, 0.804, 0.824, 0.84, 0.844, 0.85, 0.862, 0.862, 0.858, 0.866, 0.882, 0.888, 0.888, 0.89]\n",
      "iteration:  200  cost:  0.856610256624743\n",
      "iteration:  201  cost:  0.8197207096480768\n",
      "iteration:  202  cost:  0.8811532327338614\n",
      "iteration:  203  cost:  0.8014388521313757\n",
      "iteration:  204  cost:  0.830796979879919\n",
      "iteration:  205  cost:  0.803662530963034\n",
      "iteration:  206  cost:  0.8295552656607214\n",
      "iteration:  207  cost:  0.7674090625314567\n",
      "iteration:  208  cost:  0.7758995505882548\n",
      "iteration:  209  cost:  0.7612178573620848\n",
      "[0.47, 0.498, 0.564, 0.646, 0.71, 0.73, 0.77, 0.796, 0.804, 0.824, 0.84, 0.844, 0.85, 0.862, 0.862, 0.858, 0.866, 0.882, 0.888, 0.888, 0.89, 0.902]\n",
      "iteration:  210  cost:  0.8307983493021116\n",
      "iteration:  211  cost:  0.7989164552949056\n",
      "iteration:  212  cost:  0.796710640967803\n",
      "iteration:  213  cost:  0.8173380441204486\n",
      "iteration:  214  cost:  0.7943654664099788\n",
      "iteration:  215  cost:  0.867618160102534\n",
      "iteration:  216  cost:  0.785232515634184\n",
      "iteration:  217  cost:  0.8530452787128321\n",
      "iteration:  218  cost:  0.7404528926129855\n",
      "iteration:  219  cost:  0.8301944182523424\n",
      "[0.47, 0.498, 0.564, 0.646, 0.71, 0.73, 0.77, 0.796, 0.804, 0.824, 0.84, 0.844, 0.85, 0.862, 0.862, 0.858, 0.866, 0.882, 0.888, 0.888, 0.89, 0.902, 0.912]\n",
      "iteration:  220  cost:  0.7909745972055204\n",
      "iteration:  221  cost:  0.8126836596686212\n",
      "iteration:  222  cost:  0.8242071343235426\n",
      "iteration:  223  cost:  0.7817828009873913\n",
      "iteration:  224  cost:  0.9065640417188549\n",
      "iteration:  225  cost:  0.7833090923413765\n",
      "iteration:  226  cost:  0.8268698265542284\n",
      "iteration:  227  cost:  0.7548605960309511\n",
      "iteration:  228  cost:  0.7866019617212953\n",
      "iteration:  229  cost:  0.7632242582655809\n",
      "[0.47, 0.498, 0.564, 0.646, 0.71, 0.73, 0.77, 0.796, 0.804, 0.824, 0.84, 0.844, 0.85, 0.862, 0.862, 0.858, 0.866, 0.882, 0.888, 0.888, 0.89, 0.902, 0.912, 0.922]\n",
      "iteration:  230  cost:  0.8050738272064774\n",
      "iteration:  231  cost:  0.8522822298857633\n",
      "iteration:  232  cost:  0.796917368757132\n",
      "iteration:  233  cost:  0.8176197953035631\n",
      "iteration:  234  cost:  0.7163460175716548\n",
      "iteration:  235  cost:  0.7602899552094027\n",
      "iteration:  236  cost:  0.7294033696863462\n",
      "iteration:  237  cost:  0.727513852129621\n",
      "iteration:  238  cost:  0.7863462147912973\n",
      "iteration:  239  cost:  0.785428173454857\n",
      "[0.47, 0.498, 0.564, 0.646, 0.71, 0.73, 0.77, 0.796, 0.804, 0.824, 0.84, 0.844, 0.85, 0.862, 0.862, 0.858, 0.866, 0.882, 0.888, 0.888, 0.89, 0.902, 0.912, 0.922, 0.924]\n",
      "iteration:  240  cost:  0.7644013848160408\n",
      "iteration:  241  cost:  0.7744409354239149\n",
      "iteration:  242  cost:  0.7284367651422197\n",
      "iteration:  243  cost:  0.7513856631153925\n",
      "iteration:  244  cost:  0.7045853552519697\n",
      "iteration:  245  cost:  0.7583036859731674\n",
      "iteration:  246  cost:  0.7746996938458389\n",
      "iteration:  247  cost:  0.6977260545981986\n",
      "iteration:  248  cost:  0.7626740721784212\n",
      "iteration:  249  cost:  0.7883654784319293\n",
      "[0.47, 0.498, 0.564, 0.646, 0.71, 0.73, 0.77, 0.796, 0.804, 0.824, 0.84, 0.844, 0.85, 0.862, 0.862, 0.858, 0.866, 0.882, 0.888, 0.888, 0.89, 0.902, 0.912, 0.922, 0.924, 0.91]\n",
      "Accuracy for U_9 resize256 :0.9271867612293144\n",
      "\n",
      "\n",
      "Loss History for QCNN circuits, U_9 pca8\n",
      "[0.522]\n",
      "iteration:  0  cost:  0.9911412506659576\n",
      "iteration:  1  cost:  0.9837073131465114\n",
      "iteration:  2  cost:  0.9772675100450355\n",
      "iteration:  3  cost:  0.9792513836463372\n",
      "iteration:  4  cost:  1.008638546139625\n",
      "iteration:  5  cost:  1.0149837067751406\n",
      "iteration:  6  cost:  0.9972887931318374\n",
      "iteration:  7  cost:  0.9867323806232839\n",
      "iteration:  8  cost:  1.022365154112712\n",
      "iteration:  9  cost:  0.9695038352755893\n",
      "[0.522, 0.554]\n",
      "iteration:  10  cost:  0.9979988730320305\n",
      "iteration:  11  cost:  0.9560378681949069\n",
      "iteration:  12  cost:  0.9912127116220943\n",
      "iteration:  13  cost:  0.9291450353220199\n",
      "iteration:  14  cost:  0.9560277323316317\n",
      "iteration:  15  cost:  0.9689365251038923\n",
      "iteration:  16  cost:  0.9487597605549027\n",
      "iteration:  17  cost:  0.9443708009179462\n",
      "iteration:  18  cost:  1.00069391931954\n",
      "iteration:  19  cost:  0.9360921149154148\n",
      "[0.522, 0.554, 0.632]\n",
      "iteration:  20  cost:  0.9320561770238969\n",
      "iteration:  21  cost:  0.9951837544219738\n",
      "iteration:  22  cost:  0.9524583555572823\n",
      "iteration:  23  cost:  0.9818749841658291\n",
      "iteration:  24  cost:  0.9529343310421339\n",
      "iteration:  25  cost:  0.9422967788955736\n",
      "iteration:  26  cost:  0.9732286303674741\n",
      "iteration:  27  cost:  0.9530887014975218\n",
      "iteration:  28  cost:  0.9567765374639524\n",
      "iteration:  29  cost:  0.9760550350070545\n",
      "[0.522, 0.554, 0.632, 0.678]\n",
      "iteration:  30  cost:  0.9936502807275592\n",
      "iteration:  31  cost:  1.0067881023316745\n",
      "iteration:  32  cost:  0.9936436654960616\n",
      "iteration:  33  cost:  0.947419473335462\n",
      "iteration:  34  cost:  0.9442461354299572\n",
      "iteration:  35  cost:  0.9215769642718322\n",
      "iteration:  36  cost:  0.9467457493977096\n",
      "iteration:  37  cost:  0.9446327500129829\n",
      "iteration:  38  cost:  0.9797098541985235\n",
      "iteration:  39  cost:  0.9443866504740704\n",
      "[0.522, 0.554, 0.632, 0.678, 0.744]\n",
      "iteration:  40  cost:  0.9817285491758955\n",
      "iteration:  41  cost:  0.953601792834898\n",
      "iteration:  42  cost:  0.9268815748609021\n",
      "iteration:  43  cost:  0.9567648482844207\n",
      "iteration:  44  cost:  0.9357352960885857\n",
      "iteration:  45  cost:  0.8975907393530506\n",
      "iteration:  46  cost:  0.9306495043356081\n",
      "iteration:  47  cost:  0.9256997332700615\n",
      "iteration:  48  cost:  0.91312739029843\n",
      "iteration:  49  cost:  0.9568691246014421\n",
      "[0.522, 0.554, 0.632, 0.678, 0.744, 0.784]\n",
      "iteration:  50  cost:  0.9619328380907884\n",
      "iteration:  51  cost:  0.9257922898815244\n",
      "iteration:  52  cost:  0.9350707947054576\n",
      "iteration:  53  cost:  0.9598926498182608\n",
      "iteration:  54  cost:  0.9366933488909618\n",
      "iteration:  55  cost:  0.9354705745478623\n",
      "iteration:  56  cost:  0.8891739559444097\n",
      "iteration:  57  cost:  0.9544493390580807\n",
      "iteration:  58  cost:  0.9101521646085899\n",
      "iteration:  59  cost:  0.92220664068406\n",
      "[0.522, 0.554, 0.632, 0.678, 0.744, 0.784, 0.8]\n",
      "iteration:  60  cost:  0.9018534550811809\n",
      "iteration:  61  cost:  0.9466249918873549\n",
      "iteration:  62  cost:  0.8992332082955832\n",
      "iteration:  63  cost:  0.9125911729066758\n",
      "iteration:  64  cost:  0.8774699443978047\n",
      "iteration:  65  cost:  0.9056449620306606\n",
      "iteration:  66  cost:  0.9034773729360129\n",
      "iteration:  67  cost:  0.8775764004280123\n",
      "iteration:  68  cost:  0.8635434278576151\n",
      "iteration:  69  cost:  0.8874812732560864\n",
      "[0.522, 0.554, 0.632, 0.678, 0.744, 0.784, 0.8, 0.818]\n",
      "iteration:  70  cost:  0.9058739121287851\n",
      "iteration:  71  cost:  0.9361838305661475\n",
      "iteration:  72  cost:  0.8468461386394539\n",
      "iteration:  73  cost:  0.9050371467052502\n",
      "iteration:  74  cost:  0.8720794541318085\n",
      "iteration:  75  cost:  0.877419254561423\n",
      "iteration:  76  cost:  0.887763596203727\n",
      "iteration:  77  cost:  0.8943066771444101\n",
      "iteration:  78  cost:  0.8773852958329698\n",
      "iteration:  79  cost:  0.8335966872227043\n",
      "[0.522, 0.554, 0.632, 0.678, 0.744, 0.784, 0.8, 0.818, 0.84]\n",
      "iteration:  80  cost:  0.8634982425888863\n",
      "iteration:  81  cost:  0.8772900066675078\n",
      "iteration:  82  cost:  0.9104477027059571\n",
      "iteration:  83  cost:  0.8303007514237428\n",
      "iteration:  84  cost:  0.8645685278379296\n",
      "iteration:  85  cost:  0.9234271625904056\n",
      "iteration:  86  cost:  0.8743657426858877\n",
      "iteration:  87  cost:  0.8827257056617088\n",
      "iteration:  88  cost:  0.8767578784520472\n",
      "iteration:  89  cost:  0.880635599351087\n",
      "[0.522, 0.554, 0.632, 0.678, 0.744, 0.784, 0.8, 0.818, 0.84, 0.872]\n",
      "iteration:  90  cost:  0.8816281879697985\n",
      "iteration:  91  cost:  0.8025547317318193\n",
      "iteration:  92  cost:  0.8599430453398178\n",
      "iteration:  93  cost:  0.8573054662989668\n",
      "iteration:  94  cost:  0.900186207063266\n",
      "iteration:  95  cost:  0.833061314074083\n",
      "iteration:  96  cost:  0.8691694913608241\n",
      "iteration:  97  cost:  0.8757497469481456\n",
      "iteration:  98  cost:  0.8567834451371162\n",
      "iteration:  99  cost:  0.84593947081128\n",
      "[0.522, 0.554, 0.632, 0.678, 0.744, 0.784, 0.8, 0.818, 0.84, 0.872, 0.896]\n",
      "iteration:  100  cost:  0.820902280054184\n",
      "iteration:  101  cost:  0.8658968330770008\n",
      "iteration:  102  cost:  0.8478174786135587\n",
      "iteration:  103  cost:  0.8457744466557202\n",
      "iteration:  104  cost:  0.8157623802771792\n",
      "iteration:  105  cost:  0.8292974175669637\n",
      "iteration:  106  cost:  0.8265980760369147\n",
      "iteration:  107  cost:  0.8383694843960473\n",
      "iteration:  108  cost:  0.800458089028816\n",
      "iteration:  109  cost:  0.8420551891832198\n",
      "[0.522, 0.554, 0.632, 0.678, 0.744, 0.784, 0.8, 0.818, 0.84, 0.872, 0.896, 0.924]\n",
      "iteration:  110  cost:  0.8415446477947682\n",
      "iteration:  111  cost:  0.8391123406635006\n",
      "iteration:  112  cost:  0.821180657056561\n",
      "iteration:  113  cost:  0.8368853948955328\n",
      "iteration:  114  cost:  0.8135092723230892\n",
      "iteration:  115  cost:  0.8286314262109744\n",
      "iteration:  116  cost:  0.7854968675142214\n",
      "iteration:  117  cost:  0.7954467960117093\n",
      "iteration:  118  cost:  0.8369623321425985\n",
      "iteration:  119  cost:  0.7872403890588094\n",
      "[0.522, 0.554, 0.632, 0.678, 0.744, 0.784, 0.8, 0.818, 0.84, 0.872, 0.896, 0.924, 0.946]\n",
      "iteration:  120  cost:  0.8381252009502638\n",
      "iteration:  121  cost:  0.8206376706967872\n",
      "iteration:  122  cost:  0.8043282728753616\n",
      "iteration:  123  cost:  0.8037332806576045\n",
      "iteration:  124  cost:  0.8007120382432482\n",
      "iteration:  125  cost:  0.8238594979293229\n",
      "iteration:  126  cost:  0.8289643817484119\n",
      "iteration:  127  cost:  0.7898590025833302\n",
      "iteration:  128  cost:  0.791190590243542\n",
      "iteration:  129  cost:  0.8071127538470821\n",
      "[0.522, 0.554, 0.632, 0.678, 0.744, 0.784, 0.8, 0.818, 0.84, 0.872, 0.896, 0.924, 0.946, 0.956]\n",
      "iteration:  130  cost:  0.7883837981817241\n",
      "iteration:  131  cost:  0.8044896147501145\n",
      "iteration:  132  cost:  0.7761411216609807\n",
      "iteration:  133  cost:  0.7933825407953096\n",
      "iteration:  134  cost:  0.7690834448535858\n",
      "iteration:  135  cost:  0.8047936750197721\n",
      "iteration:  136  cost:  0.7796447727193366\n",
      "iteration:  137  cost:  0.7796478915676873\n",
      "iteration:  138  cost:  0.8412825378643417\n",
      "iteration:  139  cost:  0.7591378108254563\n",
      "[0.522, 0.554, 0.632, 0.678, 0.744, 0.784, 0.8, 0.818, 0.84, 0.872, 0.896, 0.924, 0.946, 0.956, 0.964]\n",
      "iteration:  140  cost:  0.828137777910145\n",
      "iteration:  141  cost:  0.8229589698075547\n",
      "iteration:  142  cost:  0.7877237895090452\n",
      "iteration:  143  cost:  0.7770711597582186\n",
      "iteration:  144  cost:  0.780718140718242\n",
      "iteration:  145  cost:  0.7667697905719828\n",
      "iteration:  146  cost:  0.8064892170060755\n",
      "iteration:  147  cost:  0.7592566798337779\n",
      "iteration:  148  cost:  0.803259046265762\n",
      "iteration:  149  cost:  0.7991040561591797\n",
      "[0.522, 0.554, 0.632, 0.678, 0.744, 0.784, 0.8, 0.818, 0.84, 0.872, 0.896, 0.924, 0.946, 0.956, 0.964, 0.956]\n",
      "iteration:  150  cost:  0.7446411188688532\n",
      "iteration:  151  cost:  0.8038349282519479\n",
      "iteration:  152  cost:  0.7824675663775514\n",
      "iteration:  153  cost:  0.8024399262472641\n",
      "iteration:  154  cost:  0.7715357613480345\n",
      "iteration:  155  cost:  0.8111510865003859\n",
      "iteration:  156  cost:  0.739240877790173\n",
      "iteration:  157  cost:  0.8143316296235703\n",
      "iteration:  158  cost:  0.7680699902319228\n",
      "iteration:  159  cost:  0.819692930844599\n",
      "[0.522, 0.554, 0.632, 0.678, 0.744, 0.784, 0.8, 0.818, 0.84, 0.872, 0.896, 0.924, 0.946, 0.956, 0.964, 0.956, 0.96]\n",
      "iteration:  160  cost:  0.7511227152398103\n",
      "iteration:  161  cost:  0.7605548707158453\n",
      "iteration:  162  cost:  0.7585568880186361\n",
      "iteration:  163  cost:  0.7444606036469252\n",
      "iteration:  164  cost:  0.7730098204335744\n",
      "iteration:  165  cost:  0.7753967699843761\n",
      "iteration:  166  cost:  0.7859054759933903\n",
      "iteration:  167  cost:  0.7827749341933863\n",
      "iteration:  168  cost:  0.7241600599281293\n",
      "iteration:  169  cost:  0.7422605286017319\n",
      "[0.522, 0.554, 0.632, 0.678, 0.744, 0.784, 0.8, 0.818, 0.84, 0.872, 0.896, 0.924, 0.946, 0.956, 0.964, 0.956, 0.96, 0.958]\n",
      "iteration:  170  cost:  0.7189952881518897\n",
      "iteration:  171  cost:  0.776911842873419\n",
      "iteration:  172  cost:  0.7652150075312057\n",
      "iteration:  173  cost:  0.7112465096756059\n",
      "iteration:  174  cost:  0.718862480765586\n",
      "iteration:  175  cost:  0.7406933782682948\n",
      "iteration:  176  cost:  0.741353192602417\n",
      "iteration:  177  cost:  0.7401795456088216\n",
      "iteration:  178  cost:  0.7388262605690394\n",
      "iteration:  179  cost:  0.7780575786397389\n",
      "[0.522, 0.554, 0.632, 0.678, 0.744, 0.784, 0.8, 0.818, 0.84, 0.872, 0.896, 0.924, 0.946, 0.956, 0.964, 0.956, 0.96, 0.958, 0.954]\n",
      "Accuracy for U_9 pca8 :0.9640661938534278\n",
      "\n",
      "\n",
      "Loss History for QCNN circuits, U_9 pca16\n",
      "[0.352]\n",
      "iteration:  0  cost:  1.0043380271481304\n",
      "iteration:  1  cost:  1.0292834665323867\n",
      "iteration:  2  cost:  1.014875523640352\n",
      "iteration:  3  cost:  1.0041366832277823\n",
      "iteration:  4  cost:  1.0096704965885854\n",
      "iteration:  5  cost:  1.0049395908418568\n",
      "iteration:  6  cost:  1.0341647768019024\n",
      "iteration:  7  cost:  1.0274243844099464\n",
      "iteration:  8  cost:  1.0158337847711545\n",
      "iteration:  9  cost:  1.028609587306387\n",
      "[0.352, 0.352]\n",
      "iteration:  10  cost:  0.9973229069019497\n",
      "iteration:  11  cost:  1.0098331489119805\n",
      "iteration:  12  cost:  1.0278701011600337\n",
      "iteration:  13  cost:  1.0085276349695782\n",
      "iteration:  14  cost:  0.9985396359196115\n",
      "iteration:  15  cost:  1.0125482572673707\n",
      "iteration:  16  cost:  1.0135437898596615\n",
      "iteration:  17  cost:  0.9937207567067893\n",
      "iteration:  18  cost:  1.0033545968879798\n",
      "iteration:  19  cost:  1.0004482852360344\n",
      "[0.352, 0.352, 0.362]\n",
      "iteration:  20  cost:  0.9952498056445961\n",
      "iteration:  21  cost:  1.023798333140364\n",
      "iteration:  22  cost:  1.0157145232287563\n",
      "iteration:  23  cost:  0.9930136327986651\n",
      "iteration:  24  cost:  1.0140614219645574\n",
      "iteration:  25  cost:  0.9923123459039729\n",
      "iteration:  26  cost:  1.001736163903554\n",
      "iteration:  27  cost:  1.0238941411066205\n",
      "iteration:  28  cost:  1.000777648907059\n",
      "iteration:  29  cost:  0.9993906232757388\n",
      "[0.352, 0.352, 0.362, 0.408]\n",
      "iteration:  30  cost:  1.0002298537398568\n",
      "iteration:  31  cost:  0.998333607161159\n",
      "iteration:  32  cost:  0.9973089351200451\n",
      "iteration:  33  cost:  0.9778114538548078\n",
      "iteration:  34  cost:  0.9770228492756697\n",
      "iteration:  35  cost:  0.9961632260410185\n",
      "iteration:  36  cost:  1.0131393632458474\n",
      "iteration:  37  cost:  0.9909463812263904\n",
      "iteration:  38  cost:  0.9765463029859007\n",
      "iteration:  39  cost:  0.9813747693478073\n",
      "[0.352, 0.352, 0.362, 0.408, 0.474]\n",
      "iteration:  40  cost:  0.9896790162553952\n",
      "iteration:  41  cost:  1.000453070649736\n",
      "iteration:  42  cost:  0.9923660226639273\n",
      "iteration:  43  cost:  1.0122076613125675\n",
      "iteration:  44  cost:  1.0101139238841916\n",
      "iteration:  45  cost:  1.0240264753038277\n",
      "iteration:  46  cost:  0.988785051790077\n",
      "iteration:  47  cost:  1.0024866091797164\n",
      "iteration:  48  cost:  1.014611198785557\n",
      "iteration:  49  cost:  0.9636213796395151\n",
      "[0.352, 0.352, 0.362, 0.408, 0.474, 0.556]\n",
      "iteration:  50  cost:  1.0018471338449302\n",
      "iteration:  51  cost:  0.9859201778708825\n",
      "iteration:  52  cost:  0.9791600064546533\n",
      "iteration:  53  cost:  0.9845821683370566\n",
      "iteration:  54  cost:  0.9961385463557981\n",
      "iteration:  55  cost:  0.9832409837490743\n",
      "iteration:  56  cost:  0.979988759495624\n",
      "iteration:  57  cost:  0.9821024255047426\n",
      "iteration:  58  cost:  0.9954245213225282\n",
      "iteration:  59  cost:  0.9770284858081186\n",
      "[0.352, 0.352, 0.362, 0.408, 0.474, 0.556, 0.602]\n",
      "iteration:  60  cost:  1.0047685687467054\n",
      "iteration:  61  cost:  0.9918160143638423\n",
      "iteration:  62  cost:  0.9838720470817975\n",
      "iteration:  63  cost:  0.9742188142648375\n",
      "iteration:  64  cost:  0.9920762319030233\n",
      "iteration:  65  cost:  1.0168924936539177\n",
      "iteration:  66  cost:  0.9803510248861125\n",
      "iteration:  67  cost:  0.9750990667063933\n",
      "iteration:  68  cost:  1.0004269670873291\n",
      "iteration:  69  cost:  1.0055058088270816\n",
      "[0.352, 0.352, 0.362, 0.408, 0.474, 0.556, 0.602, 0.616]\n",
      "iteration:  70  cost:  0.9678614718492853\n",
      "iteration:  71  cost:  0.9782338508682872\n",
      "iteration:  72  cost:  0.9852921447392647\n",
      "iteration:  73  cost:  1.0264537861431713\n",
      "iteration:  74  cost:  0.9925658788208842\n",
      "iteration:  75  cost:  0.9997452225654176\n",
      "iteration:  76  cost:  0.9754788224898436\n",
      "iteration:  77  cost:  1.0069623915319936\n",
      "iteration:  78  cost:  0.9779983987762538\n",
      "iteration:  79  cost:  0.9753975092979548\n",
      "[0.352, 0.352, 0.362, 0.408, 0.474, 0.556, 0.602, 0.616, 0.618]\n",
      "iteration:  80  cost:  0.9852074518628468\n",
      "iteration:  81  cost:  0.9814846467228697\n",
      "iteration:  82  cost:  0.9761881353440629\n",
      "iteration:  83  cost:  1.0123153818969697\n",
      "iteration:  84  cost:  0.9689859012050038\n",
      "iteration:  85  cost:  0.9853241397134628\n",
      "iteration:  86  cost:  0.9837509828061188\n",
      "iteration:  87  cost:  0.9662794701937982\n",
      "iteration:  88  cost:  0.9741175159843749\n",
      "iteration:  89  cost:  0.9539947688989259\n",
      "[0.352, 0.352, 0.362, 0.408, 0.474, 0.556, 0.602, 0.616, 0.618, 0.63]\n",
      "iteration:  90  cost:  0.9630104571236181\n",
      "iteration:  91  cost:  0.992917301232918\n",
      "iteration:  92  cost:  0.9867365646485601\n",
      "iteration:  93  cost:  0.9862590818917664\n",
      "iteration:  94  cost:  0.9548296509349226\n",
      "iteration:  95  cost:  0.9807749189395287\n",
      "iteration:  96  cost:  0.9760129453264393\n",
      "iteration:  97  cost:  0.9626233147207777\n",
      "iteration:  98  cost:  0.986876576310603\n",
      "iteration:  99  cost:  1.0041048325381392\n",
      "[0.352, 0.352, 0.362, 0.408, 0.474, 0.556, 0.602, 0.616, 0.618, 0.63, 0.632]\n",
      "iteration:  100  cost:  0.9898229669756244\n",
      "iteration:  101  cost:  0.9816269424691885\n",
      "iteration:  102  cost:  0.9878082092968211\n",
      "iteration:  103  cost:  0.9696051600092171\n",
      "iteration:  104  cost:  0.9790325320209018\n",
      "iteration:  105  cost:  0.9753990443145284\n",
      "iteration:  106  cost:  0.9996231742323007\n",
      "iteration:  107  cost:  0.9851027480820876\n",
      "iteration:  108  cost:  0.9867964531439684\n",
      "iteration:  109  cost:  0.9820271246947045\n",
      "[0.352, 0.352, 0.362, 0.408, 0.474, 0.556, 0.602, 0.616, 0.618, 0.63, 0.632, 0.63]\n",
      "iteration:  110  cost:  0.9804133862679366\n",
      "iteration:  111  cost:  0.9660230809749691\n",
      "iteration:  112  cost:  0.9850167900227546\n",
      "iteration:  113  cost:  0.9872391465658354\n",
      "iteration:  114  cost:  0.9670627597559974\n",
      "iteration:  115  cost:  0.9626133680468323\n",
      "iteration:  116  cost:  0.9987971365999485\n",
      "iteration:  117  cost:  0.974430507819925\n",
      "iteration:  118  cost:  0.9888429937472322\n",
      "iteration:  119  cost:  0.9916519354741626\n",
      "[0.352, 0.352, 0.362, 0.408, 0.474, 0.556, 0.602, 0.616, 0.618, 0.63, 0.632, 0.63, 0.632]\n",
      "iteration:  120  cost:  1.011668761834279\n",
      "iteration:  121  cost:  0.9833906384648929\n",
      "iteration:  122  cost:  0.9682508882302732\n",
      "iteration:  123  cost:  0.9906991093277121\n",
      "iteration:  124  cost:  0.9936773472289832\n",
      "iteration:  125  cost:  0.9791350714726192\n",
      "iteration:  126  cost:  0.9325700620291788\n",
      "iteration:  127  cost:  0.9922944558904849\n",
      "iteration:  128  cost:  0.9936936522409713\n",
      "iteration:  129  cost:  0.958086450586762\n",
      "[0.352, 0.352, 0.362, 0.408, 0.474, 0.556, 0.602, 0.616, 0.618, 0.63, 0.632, 0.63, 0.632, 0.638]\n",
      "iteration:  130  cost:  0.9805533252471441\n",
      "iteration:  131  cost:  0.9931232660835253\n",
      "iteration:  132  cost:  0.9621274229423973\n",
      "iteration:  133  cost:  0.9855102039766553\n",
      "iteration:  134  cost:  0.9692170908840282\n",
      "iteration:  135  cost:  0.9761863692971019\n",
      "iteration:  136  cost:  0.9998241099441184\n",
      "iteration:  137  cost:  0.974908671911329\n",
      "iteration:  138  cost:  0.959837087439501\n",
      "iteration:  139  cost:  0.9805841894559544\n",
      "[0.352, 0.352, 0.362, 0.408, 0.474, 0.556, 0.602, 0.616, 0.618, 0.63, 0.632, 0.63, 0.632, 0.638, 0.646]\n",
      "iteration:  140  cost:  0.9723858980121556\n",
      "iteration:  141  cost:  0.9587201296423113\n",
      "iteration:  142  cost:  0.9883577422413207\n",
      "iteration:  143  cost:  0.9909131734303809\n",
      "iteration:  144  cost:  0.9852573090309565\n",
      "iteration:  145  cost:  0.9719934055639163\n",
      "iteration:  146  cost:  0.95273830526323\n",
      "iteration:  147  cost:  0.9693249454274728\n",
      "iteration:  148  cost:  0.9742561230261682\n",
      "iteration:  149  cost:  0.9463779296297881\n",
      "[0.352, 0.352, 0.362, 0.408, 0.474, 0.556, 0.602, 0.616, 0.618, 0.63, 0.632, 0.63, 0.632, 0.638, 0.646, 0.652]\n",
      "iteration:  150  cost:  0.9937674775816804\n",
      "iteration:  151  cost:  0.9640453098502512\n",
      "iteration:  152  cost:  0.9754925738995085\n",
      "iteration:  153  cost:  0.9509508366574366\n",
      "iteration:  154  cost:  0.9762787788449327\n",
      "iteration:  155  cost:  0.9411997342257439\n",
      "iteration:  156  cost:  0.9682134933688848\n",
      "iteration:  157  cost:  0.9686062711941775\n",
      "iteration:  158  cost:  0.9967290154106371\n",
      "iteration:  159  cost:  0.9569276288195104\n",
      "[0.352, 0.352, 0.362, 0.408, 0.474, 0.556, 0.602, 0.616, 0.618, 0.63, 0.632, 0.63, 0.632, 0.638, 0.646, 0.652, 0.668]\n",
      "iteration:  160  cost:  0.9855983769382334\n",
      "iteration:  161  cost:  0.9701513743194051\n",
      "iteration:  162  cost:  0.9628421295717742\n",
      "iteration:  163  cost:  0.9681697297174793\n",
      "iteration:  164  cost:  0.9401638952710707\n",
      "iteration:  165  cost:  0.9545047152810626\n",
      "iteration:  166  cost:  0.9569628984265431\n",
      "iteration:  167  cost:  0.9663138703300738\n",
      "iteration:  168  cost:  0.9749239676913176\n",
      "iteration:  169  cost:  0.9699270130287992\n",
      "[0.352, 0.352, 0.362, 0.408, 0.474, 0.556, 0.602, 0.616, 0.618, 0.63, 0.632, 0.63, 0.632, 0.638, 0.646, 0.652, 0.668, 0.702]\n",
      "iteration:  170  cost:  0.9567647385592595\n",
      "iteration:  171  cost:  0.9504567680580581\n",
      "iteration:  172  cost:  0.9553386570810093\n",
      "iteration:  173  cost:  0.9667651447001552\n",
      "iteration:  174  cost:  0.977018143866118\n",
      "iteration:  175  cost:  0.9613612852641896\n",
      "iteration:  176  cost:  0.9583406434888738\n",
      "iteration:  177  cost:  0.953617420005991\n",
      "iteration:  178  cost:  0.964620390250629\n",
      "iteration:  179  cost:  0.9483634480272461\n",
      "[0.352, 0.352, 0.362, 0.408, 0.474, 0.556, 0.602, 0.616, 0.618, 0.63, 0.632, 0.63, 0.632, 0.638, 0.646, 0.652, 0.668, 0.702, 0.74]\n",
      "iteration:  180  cost:  0.9595758234308738\n",
      "iteration:  181  cost:  0.9770369494735154\n",
      "iteration:  182  cost:  0.931092782091544\n",
      "iteration:  183  cost:  0.9243405133312378\n",
      "iteration:  184  cost:  0.9455380182807883\n",
      "iteration:  185  cost:  0.9503046914740169\n",
      "iteration:  186  cost:  0.9500323023789395\n",
      "iteration:  187  cost:  0.9549354933790951\n",
      "iteration:  188  cost:  0.9692609951384337\n",
      "iteration:  189  cost:  0.941093632141953\n",
      "[0.352, 0.352, 0.362, 0.408, 0.474, 0.556, 0.602, 0.616, 0.618, 0.63, 0.632, 0.63, 0.632, 0.638, 0.646, 0.652, 0.668, 0.702, 0.74, 0.792]\n",
      "iteration:  190  cost:  0.9325391547638947\n",
      "iteration:  191  cost:  0.9414188985018529\n",
      "iteration:  192  cost:  0.9324362334149743\n",
      "iteration:  193  cost:  0.9250513769365041\n",
      "iteration:  194  cost:  0.9407526864289574\n",
      "iteration:  195  cost:  0.9619184244700238\n",
      "iteration:  196  cost:  0.9627597752074571\n",
      "iteration:  197  cost:  0.9776293069991611\n",
      "iteration:  198  cost:  0.9204513691513375\n",
      "iteration:  199  cost:  0.9500176658393208\n",
      "[0.352, 0.352, 0.362, 0.408, 0.474, 0.556, 0.602, 0.616, 0.618, 0.63, 0.632, 0.63, 0.632, 0.638, 0.646, 0.652, 0.668, 0.702, 0.74, 0.792, 0.822]\n",
      "iteration:  200  cost:  0.9253978203257656\n",
      "iteration:  201  cost:  0.9217628308477102\n",
      "iteration:  202  cost:  0.9276272307705942\n",
      "iteration:  203  cost:  0.9415811898643489\n",
      "iteration:  204  cost:  0.9148314593082313\n",
      "iteration:  205  cost:  0.90847738649031\n",
      "iteration:  206  cost:  0.9263312130340684\n",
      "iteration:  207  cost:  0.8952884534826727\n",
      "iteration:  208  cost:  0.899411063116553\n",
      "iteration:  209  cost:  0.9112364457469571\n",
      "[0.352, 0.352, 0.362, 0.408, 0.474, 0.556, 0.602, 0.616, 0.618, 0.63, 0.632, 0.63, 0.632, 0.638, 0.646, 0.652, 0.668, 0.702, 0.74, 0.792, 0.822, 0.828]\n",
      "iteration:  210  cost:  0.9239404788755244\n",
      "iteration:  211  cost:  0.8880723140609375\n",
      "iteration:  212  cost:  0.9054549319533013\n",
      "iteration:  213  cost:  0.9118641774423405\n",
      "iteration:  214  cost:  0.900003279708376\n",
      "iteration:  215  cost:  0.9379711917999306\n",
      "iteration:  216  cost:  0.8925225210966004\n",
      "iteration:  217  cost:  0.8909105647776724\n",
      "iteration:  218  cost:  0.9190848611375343\n",
      "iteration:  219  cost:  0.8901315986708416\n",
      "[0.352, 0.352, 0.362, 0.408, 0.474, 0.556, 0.602, 0.616, 0.618, 0.63, 0.632, 0.63, 0.632, 0.638, 0.646, 0.652, 0.668, 0.702, 0.74, 0.792, 0.822, 0.828, 0.83]\n",
      "iteration:  220  cost:  0.9151484568651292\n",
      "iteration:  221  cost:  0.8894473583179322\n",
      "iteration:  222  cost:  0.9135391311648626\n",
      "iteration:  223  cost:  0.9189807861224456\n",
      "iteration:  224  cost:  0.8843695183729074\n",
      "iteration:  225  cost:  0.9057634237457921\n",
      "iteration:  226  cost:  0.9028520620371816\n",
      "iteration:  227  cost:  0.8779714567381499\n",
      "iteration:  228  cost:  0.8683251268827923\n",
      "iteration:  229  cost:  0.8777241090573702\n",
      "[0.352, 0.352, 0.362, 0.408, 0.474, 0.556, 0.602, 0.616, 0.618, 0.63, 0.632, 0.63, 0.632, 0.638, 0.646, 0.652, 0.668, 0.702, 0.74, 0.792, 0.822, 0.828, 0.83, 0.84]\n",
      "iteration:  230  cost:  0.897450510411106\n",
      "iteration:  231  cost:  0.8884574743810311\n",
      "iteration:  232  cost:  0.8494606254714171\n",
      "iteration:  233  cost:  0.8773612888108745\n",
      "iteration:  234  cost:  0.9056523356186968\n",
      "iteration:  235  cost:  0.8928443371571326\n",
      "iteration:  236  cost:  0.8732812005997307\n",
      "iteration:  237  cost:  0.8875781694779569\n",
      "iteration:  238  cost:  0.8926581313443467\n",
      "iteration:  239  cost:  0.8852199467382842\n",
      "[0.352, 0.352, 0.362, 0.408, 0.474, 0.556, 0.602, 0.616, 0.618, 0.63, 0.632, 0.63, 0.632, 0.638, 0.646, 0.652, 0.668, 0.702, 0.74, 0.792, 0.822, 0.828, 0.83, 0.84, 0.846]\n",
      "iteration:  240  cost:  0.8572592204627106\n",
      "iteration:  241  cost:  0.9059037026174078\n",
      "iteration:  242  cost:  0.8545408381594344\n",
      "iteration:  243  cost:  0.8853993037083133\n",
      "iteration:  244  cost:  0.8912009763786437\n",
      "iteration:  245  cost:  0.8411836116624255\n",
      "iteration:  246  cost:  0.8756467682688057\n",
      "iteration:  247  cost:  0.84180694002257\n",
      "iteration:  248  cost:  0.8820720489935502\n",
      "iteration:  249  cost:  0.8416443834730187\n",
      "[0.352, 0.352, 0.362, 0.408, 0.474, 0.556, 0.602, 0.616, 0.618, 0.63, 0.632, 0.63, 0.632, 0.638, 0.646, 0.652, 0.668, 0.702, 0.74, 0.792, 0.822, 0.828, 0.83, 0.84, 0.846, 0.85]\n",
      "iteration:  250  cost:  0.8924564794316834\n",
      "iteration:  251  cost:  0.8663235140780197\n",
      "iteration:  252  cost:  0.8552708522856084\n",
      "iteration:  253  cost:  0.8716018478375226\n",
      "iteration:  254  cost:  0.8688006128831699\n",
      "iteration:  255  cost:  0.9089943065325963\n",
      "iteration:  256  cost:  0.8493792199302957\n",
      "iteration:  257  cost:  0.8420002070999919\n",
      "iteration:  258  cost:  0.8541919085235343\n",
      "iteration:  259  cost:  0.8816020833823803\n",
      "[0.352, 0.352, 0.362, 0.408, 0.474, 0.556, 0.602, 0.616, 0.618, 0.63, 0.632, 0.63, 0.632, 0.638, 0.646, 0.652, 0.668, 0.702, 0.74, 0.792, 0.822, 0.828, 0.83, 0.84, 0.846, 0.85, 0.862]\n",
      "iteration:  260  cost:  0.8654171184490487\n",
      "iteration:  261  cost:  0.8571935498434532\n",
      "iteration:  262  cost:  0.8292588314175451\n",
      "iteration:  263  cost:  0.836246498669139\n",
      "iteration:  264  cost:  0.8770177410113068\n",
      "iteration:  265  cost:  0.8540021461325702\n",
      "iteration:  266  cost:  0.8221726851259747\n",
      "iteration:  267  cost:  0.8078039881073229\n",
      "iteration:  268  cost:  0.8726212696629605\n",
      "iteration:  269  cost:  0.8134670764868766\n",
      "[0.352, 0.352, 0.362, 0.408, 0.474, 0.556, 0.602, 0.616, 0.618, 0.63, 0.632, 0.63, 0.632, 0.638, 0.646, 0.652, 0.668, 0.702, 0.74, 0.792, 0.822, 0.828, 0.83, 0.84, 0.846, 0.85, 0.862, 0.868]\n",
      "iteration:  270  cost:  0.8340880385906999\n",
      "iteration:  271  cost:  0.8815647514756993\n",
      "iteration:  272  cost:  0.8795847260947366\n",
      "iteration:  273  cost:  0.8287875338187166\n",
      "iteration:  274  cost:  0.8635284971110185\n",
      "iteration:  275  cost:  0.8656897345190856\n",
      "iteration:  276  cost:  0.8027477822191006\n",
      "iteration:  277  cost:  0.8590504577717181\n",
      "iteration:  278  cost:  0.8365952651445085\n",
      "iteration:  279  cost:  0.8643535588668435\n",
      "[0.352, 0.352, 0.362, 0.408, 0.474, 0.556, 0.602, 0.616, 0.618, 0.63, 0.632, 0.63, 0.632, 0.638, 0.646, 0.652, 0.668, 0.702, 0.74, 0.792, 0.822, 0.828, 0.83, 0.84, 0.846, 0.85, 0.862, 0.868, 0.882]\n",
      "iteration:  280  cost:  0.8336866496130871\n",
      "iteration:  281  cost:  0.8474385405901934\n",
      "iteration:  282  cost:  0.8550943478221583\n",
      "iteration:  283  cost:  0.8453470194101866\n",
      "iteration:  284  cost:  0.8656054299773901\n",
      "iteration:  285  cost:  0.8308617017231957\n",
      "iteration:  286  cost:  0.8168537631876489\n",
      "iteration:  287  cost:  0.8087013729709001\n",
      "iteration:  288  cost:  0.9013462011252007\n",
      "iteration:  289  cost:  0.8267901408637018\n",
      "[0.352, 0.352, 0.362, 0.408, 0.474, 0.556, 0.602, 0.616, 0.618, 0.63, 0.632, 0.63, 0.632, 0.638, 0.646, 0.652, 0.668, 0.702, 0.74, 0.792, 0.822, 0.828, 0.83, 0.84, 0.846, 0.85, 0.862, 0.868, 0.882, 0.894]\n",
      "iteration:  290  cost:  0.8431613702024997\n",
      "iteration:  291  cost:  0.8470595945931109\n",
      "iteration:  292  cost:  0.8345592234997571\n",
      "iteration:  293  cost:  0.8806557826692941\n",
      "iteration:  294  cost:  0.8559958087593762\n",
      "iteration:  295  cost:  0.8546358986329338\n",
      "iteration:  296  cost:  0.81085674719927\n",
      "iteration:  297  cost:  0.8431209065932892\n",
      "iteration:  298  cost:  0.8407780778975298\n",
      "iteration:  299  cost:  0.7958812919489133\n",
      "[0.352, 0.352, 0.362, 0.408, 0.474, 0.556, 0.602, 0.616, 0.618, 0.63, 0.632, 0.63, 0.632, 0.638, 0.646, 0.652, 0.668, 0.702, 0.74, 0.792, 0.822, 0.828, 0.83, 0.84, 0.846, 0.85, 0.862, 0.868, 0.882, 0.894, 0.91]\n",
      "iteration:  300  cost:  0.832896555990595\n",
      "iteration:  301  cost:  0.8025884739294636\n",
      "iteration:  302  cost:  0.8439062899993175\n",
      "iteration:  303  cost:  0.8098215294913311\n",
      "iteration:  304  cost:  0.8232450301343716\n",
      "iteration:  305  cost:  0.841862369396624\n",
      "iteration:  306  cost:  0.862478741088401\n",
      "iteration:  307  cost:  0.8171869682269401\n",
      "iteration:  308  cost:  0.8002750076435451\n",
      "iteration:  309  cost:  0.8296675165371634\n",
      "[0.352, 0.352, 0.362, 0.408, 0.474, 0.556, 0.602, 0.616, 0.618, 0.63, 0.632, 0.63, 0.632, 0.638, 0.646, 0.652, 0.668, 0.702, 0.74, 0.792, 0.822, 0.828, 0.83, 0.84, 0.846, 0.85, 0.862, 0.868, 0.882, 0.894, 0.91, 0.922]\n",
      "iteration:  310  cost:  0.7956037082082105\n",
      "iteration:  311  cost:  0.8164093331866645\n",
      "iteration:  312  cost:  0.7931594496250781\n",
      "iteration:  313  cost:  0.8429647586049266\n",
      "iteration:  314  cost:  0.823986408178211\n",
      "iteration:  315  cost:  0.7736549645750311\n",
      "iteration:  316  cost:  0.8253693733300015\n",
      "iteration:  317  cost:  0.7757960813798498\n",
      "iteration:  318  cost:  0.8250646468357397\n",
      "iteration:  319  cost:  0.7920787073446772\n",
      "[0.352, 0.352, 0.362, 0.408, 0.474, 0.556, 0.602, 0.616, 0.618, 0.63, 0.632, 0.63, 0.632, 0.638, 0.646, 0.652, 0.668, 0.702, 0.74, 0.792, 0.822, 0.828, 0.83, 0.84, 0.846, 0.85, 0.862, 0.868, 0.882, 0.894, 0.91, 0.922, 0.936]\n",
      "iteration:  320  cost:  0.826282429636051\n",
      "iteration:  321  cost:  0.8250372336679009\n",
      "iteration:  322  cost:  0.8176917285054701\n",
      "iteration:  323  cost:  0.7664934481313866\n",
      "iteration:  324  cost:  0.7952138230784889\n",
      "iteration:  325  cost:  0.8642855429410026\n",
      "iteration:  326  cost:  0.8328688775694857\n",
      "iteration:  327  cost:  0.8198300717988161\n",
      "iteration:  328  cost:  0.8062568083546999\n",
      "iteration:  329  cost:  0.7841192831718573\n",
      "[0.352, 0.352, 0.362, 0.408, 0.474, 0.556, 0.602, 0.616, 0.618, 0.63, 0.632, 0.63, 0.632, 0.638, 0.646, 0.652, 0.668, 0.702, 0.74, 0.792, 0.822, 0.828, 0.83, 0.84, 0.846, 0.85, 0.862, 0.868, 0.882, 0.894, 0.91, 0.922, 0.936, 0.948]\n",
      "iteration:  330  cost:  0.8011777429023336\n",
      "iteration:  331  cost:  0.7840447549762272\n",
      "iteration:  332  cost:  0.7658947275617605\n",
      "iteration:  333  cost:  0.8012823747982338\n",
      "iteration:  334  cost:  0.7880337934465252\n",
      "iteration:  335  cost:  0.8208840659790728\n",
      "iteration:  336  cost:  0.78833055294277\n",
      "iteration:  337  cost:  0.8086740258367504\n",
      "iteration:  338  cost:  0.8027222336277915\n",
      "iteration:  339  cost:  0.785246204005254\n",
      "[0.352, 0.352, 0.362, 0.408, 0.474, 0.556, 0.602, 0.616, 0.618, 0.63, 0.632, 0.63, 0.632, 0.638, 0.646, 0.652, 0.668, 0.702, 0.74, 0.792, 0.822, 0.828, 0.83, 0.84, 0.846, 0.85, 0.862, 0.868, 0.882, 0.894, 0.91, 0.922, 0.936, 0.948, 0.958]\n",
      "iteration:  340  cost:  0.8043364211079715\n",
      "iteration:  341  cost:  0.7991055259893112\n",
      "iteration:  342  cost:  0.7620792524699\n",
      "iteration:  343  cost:  0.78915328180809\n",
      "iteration:  344  cost:  0.7777919269123393\n",
      "iteration:  345  cost:  0.767058307751849\n",
      "iteration:  346  cost:  0.8252799586220909\n",
      "iteration:  347  cost:  0.8128426157255205\n",
      "iteration:  348  cost:  0.8033627064720481\n",
      "iteration:  349  cost:  0.7752299981291554\n",
      "[0.352, 0.352, 0.362, 0.408, 0.474, 0.556, 0.602, 0.616, 0.618, 0.63, 0.632, 0.63, 0.632, 0.638, 0.646, 0.652, 0.668, 0.702, 0.74, 0.792, 0.822, 0.828, 0.83, 0.84, 0.846, 0.85, 0.862, 0.868, 0.882, 0.894, 0.91, 0.922, 0.936, 0.948, 0.958, 0.966]\n",
      "iteration:  350  cost:  0.7624129922359627\n",
      "iteration:  351  cost:  0.7656755414397763\n",
      "iteration:  352  cost:  0.8220962359170488\n",
      "iteration:  353  cost:  0.8091796018113943\n",
      "iteration:  354  cost:  0.786602473044599\n",
      "iteration:  355  cost:  0.7868183049811379\n",
      "iteration:  356  cost:  0.7605282267661062\n",
      "iteration:  357  cost:  0.8030749949478349\n",
      "iteration:  358  cost:  0.7930584004121163\n",
      "iteration:  359  cost:  0.7907008803419447\n",
      "[0.352, 0.352, 0.362, 0.408, 0.474, 0.556, 0.602, 0.616, 0.618, 0.63, 0.632, 0.63, 0.632, 0.638, 0.646, 0.652, 0.668, 0.702, 0.74, 0.792, 0.822, 0.828, 0.83, 0.84, 0.846, 0.85, 0.862, 0.868, 0.882, 0.894, 0.91, 0.922, 0.936, 0.948, 0.958, 0.966, 0.966]\n",
      "iteration:  360  cost:  0.7943451208170622\n",
      "iteration:  361  cost:  0.7573676614233688\n",
      "iteration:  362  cost:  0.7867252933790025\n",
      "iteration:  363  cost:  0.7685613731312669\n",
      "iteration:  364  cost:  0.7589362016928278\n",
      "iteration:  365  cost:  0.7830173094813729\n",
      "iteration:  366  cost:  0.7877033243828103\n",
      "iteration:  367  cost:  0.820988906766635\n",
      "iteration:  368  cost:  0.7690552061385882\n",
      "iteration:  369  cost:  0.7546791978960631\n",
      "[0.352, 0.352, 0.362, 0.408, 0.474, 0.556, 0.602, 0.616, 0.618, 0.63, 0.632, 0.63, 0.632, 0.638, 0.646, 0.652, 0.668, 0.702, 0.74, 0.792, 0.822, 0.828, 0.83, 0.84, 0.846, 0.85, 0.862, 0.868, 0.882, 0.894, 0.91, 0.922, 0.936, 0.948, 0.958, 0.966, 0.966, 0.978]\n",
      "iteration:  370  cost:  0.79596874880721\n",
      "iteration:  371  cost:  0.7640258413844668\n",
      "iteration:  372  cost:  0.7908170827294275\n",
      "iteration:  373  cost:  0.7441873236546922\n",
      "iteration:  374  cost:  0.8088078848649722\n",
      "iteration:  375  cost:  0.7457208158790829\n",
      "iteration:  376  cost:  0.7713836450880277\n",
      "iteration:  377  cost:  0.7903209105813509\n",
      "iteration:  378  cost:  0.7671111048670575\n",
      "iteration:  379  cost:  0.7524687839101994\n",
      "[0.352, 0.352, 0.362, 0.408, 0.474, 0.556, 0.602, 0.616, 0.618, 0.63, 0.632, 0.63, 0.632, 0.638, 0.646, 0.652, 0.668, 0.702, 0.74, 0.792, 0.822, 0.828, 0.83, 0.84, 0.846, 0.85, 0.862, 0.868, 0.882, 0.894, 0.91, 0.922, 0.936, 0.948, 0.958, 0.966, 0.966, 0.978, 0.98]\n",
      "iteration:  380  cost:  0.7995161905052492\n",
      "iteration:  381  cost:  0.7547393222793508\n",
      "iteration:  382  cost:  0.7439151888657236\n",
      "iteration:  383  cost:  0.7558271498297714\n",
      "iteration:  384  cost:  0.7651567920108943\n",
      "iteration:  385  cost:  0.7463571099923674\n",
      "iteration:  386  cost:  0.7852482449058504\n",
      "iteration:  387  cost:  0.7675807233477204\n",
      "iteration:  388  cost:  0.7877967656655634\n",
      "iteration:  389  cost:  0.7466211595575237\n",
      "[0.352, 0.352, 0.362, 0.408, 0.474, 0.556, 0.602, 0.616, 0.618, 0.63, 0.632, 0.63, 0.632, 0.638, 0.646, 0.652, 0.668, 0.702, 0.74, 0.792, 0.822, 0.828, 0.83, 0.84, 0.846, 0.85, 0.862, 0.868, 0.882, 0.894, 0.91, 0.922, 0.936, 0.948, 0.958, 0.966, 0.966, 0.978, 0.98, 0.976]\n",
      "iteration:  390  cost:  0.7866188883032506\n",
      "iteration:  391  cost:  0.7509747393717106\n",
      "iteration:  392  cost:  0.7609380707320526\n",
      "iteration:  393  cost:  0.7747100903027154\n",
      "iteration:  394  cost:  0.7789576404364315\n",
      "iteration:  395  cost:  0.7343290867458405\n",
      "iteration:  396  cost:  0.7419720836843662\n",
      "iteration:  397  cost:  0.7893832116116134\n",
      "iteration:  398  cost:  0.752141950523921\n",
      "iteration:  399  cost:  0.7514202695951662\n",
      "Accuracy for U_9 pca16 :0.9787234042553191\n",
      "Epoch 1/10\n",
      "396/396 [==============================] - 1s 1ms/step - loss: 0.1075 - val_loss: 0.0379\n",
      "Epoch 2/10\n",
      "396/396 [==============================] - 0s 763us/step - loss: 0.0335 - val_loss: 0.0273\n",
      "Epoch 3/10\n",
      "396/396 [==============================] - 0s 764us/step - loss: 0.0270 - val_loss: 0.0243\n",
      "Epoch 4/10\n",
      "396/396 [==============================] - 0s 755us/step - loss: 0.0240 - val_loss: 0.0220\n",
      "Epoch 5/10\n",
      "396/396 [==============================] - 0s 757us/step - loss: 0.0219 - val_loss: 0.0207\n",
      "Epoch 6/10\n",
      "396/396 [==============================] - 0s 767us/step - loss: 0.0207 - val_loss: 0.0197\n",
      "Epoch 7/10\n",
      "396/396 [==============================] - 0s 764us/step - loss: 0.0200 - val_loss: 0.0189\n",
      "Epoch 8/10\n",
      "396/396 [==============================] - 0s 773us/step - loss: 0.0189 - val_loss: 0.0184\n",
      "Epoch 9/10\n",
      "396/396 [==============================] - 0s 791us/step - loss: 0.0187 - val_loss: 0.0180\n",
      "Epoch 10/10\n",
      "396/396 [==============================] - 0s 755us/step - loss: 0.0181 - val_loss: 0.0177\n",
      "\n",
      "\n",
      "Loss History for QCNN circuits, U_9 autoencoder8\n",
      "[0.486]\n",
      "iteration:  0  cost:  1.0995537240263693\n",
      "iteration:  1  cost:  1.0511664364229873\n",
      "iteration:  2  cost:  1.085363587533257\n",
      "iteration:  3  cost:  1.035065281621721\n",
      "iteration:  4  cost:  1.0237079955754282\n",
      "iteration:  5  cost:  1.0829423904620812\n",
      "iteration:  6  cost:  1.0384980833791213\n",
      "iteration:  7  cost:  1.03021710346014\n",
      "iteration:  8  cost:  1.0857296077417211\n",
      "iteration:  9  cost:  1.0680411259162623\n",
      "[0.486, 0.486]\n",
      "iteration:  10  cost:  1.0865237261984775\n",
      "iteration:  11  cost:  0.9773863291991269\n",
      "iteration:  12  cost:  0.9506870289930052\n",
      "iteration:  13  cost:  1.0316684221448926\n",
      "iteration:  14  cost:  1.0369009319437905\n",
      "iteration:  15  cost:  1.0808535998748738\n",
      "iteration:  16  cost:  1.0368369324750872\n",
      "iteration:  17  cost:  1.0155751494255056\n",
      "iteration:  18  cost:  0.9855725946121181\n",
      "iteration:  19  cost:  1.0161932385140884\n",
      "[0.486, 0.486, 0.46]\n",
      "iteration:  20  cost:  1.0266391907965797\n",
      "iteration:  21  cost:  1.002439049965865\n",
      "iteration:  22  cost:  1.0384412471587958\n",
      "iteration:  23  cost:  1.0306706492070339\n",
      "iteration:  24  cost:  1.0142661917424793\n",
      "iteration:  25  cost:  1.0260380561553897\n",
      "iteration:  26  cost:  0.9986229793781548\n",
      "iteration:  27  cost:  1.0134718289249103\n",
      "iteration:  28  cost:  1.0110285734833473\n",
      "iteration:  29  cost:  1.0158282327181036\n",
      "[0.486, 0.486, 0.46, 0.46]\n",
      "iteration:  30  cost:  1.0289207797932434\n",
      "iteration:  31  cost:  1.0272882650513615\n",
      "iteration:  32  cost:  0.9961878425916558\n",
      "iteration:  33  cost:  1.0057485463594087\n",
      "iteration:  34  cost:  0.9830904296117828\n",
      "iteration:  35  cost:  0.9892800592004805\n",
      "iteration:  36  cost:  0.9833859541780282\n",
      "iteration:  37  cost:  0.9804556962685157\n",
      "iteration:  38  cost:  1.0104853770278228\n",
      "iteration:  39  cost:  0.9870015897970704\n",
      "[0.486, 0.486, 0.46, 0.46, 0.578]\n",
      "iteration:  40  cost:  0.9729711312480152\n",
      "iteration:  41  cost:  0.972659275135772\n",
      "iteration:  42  cost:  0.9815383291111849\n",
      "iteration:  43  cost:  0.9817884844297453\n",
      "iteration:  44  cost:  0.9912351425586917\n",
      "iteration:  45  cost:  0.9594403327556417\n",
      "iteration:  46  cost:  0.9601013404123734\n",
      "iteration:  47  cost:  0.9851391001548628\n",
      "iteration:  48  cost:  0.9753772157425327\n",
      "iteration:  49  cost:  0.9661170592857663\n",
      "[0.486, 0.486, 0.46, 0.46, 0.578, 0.684]\n",
      "iteration:  50  cost:  0.9842500404639566\n",
      "iteration:  51  cost:  0.9707439443443245\n",
      "iteration:  52  cost:  0.9784433128112673\n",
      "iteration:  53  cost:  0.9408792612043604\n",
      "iteration:  54  cost:  0.9730845880649109\n",
      "iteration:  55  cost:  0.9693395028154796\n",
      "iteration:  56  cost:  0.9535106344168293\n",
      "iteration:  57  cost:  0.9713400277507298\n",
      "iteration:  58  cost:  0.9738660026107315\n",
      "iteration:  59  cost:  0.9699505669559112\n",
      "[0.486, 0.486, 0.46, 0.46, 0.578, 0.684, 0.67]\n",
      "iteration:  60  cost:  0.9447140322641009\n",
      "iteration:  61  cost:  0.9306338324349589\n",
      "iteration:  62  cost:  0.9711593577554819\n",
      "iteration:  63  cost:  0.9744310520565079\n",
      "iteration:  64  cost:  0.9630524026899319\n",
      "iteration:  65  cost:  0.9603117340717404\n",
      "iteration:  66  cost:  0.9337970907537\n",
      "iteration:  67  cost:  0.9497197422928884\n",
      "iteration:  68  cost:  0.9635292930225466\n",
      "iteration:  69  cost:  0.9378296450690666\n",
      "[0.486, 0.486, 0.46, 0.46, 0.578, 0.684, 0.67, 0.66]\n",
      "iteration:  70  cost:  0.941718308815111\n",
      "iteration:  71  cost:  0.9681329312824566\n",
      "iteration:  72  cost:  0.9317569416706071\n",
      "iteration:  73  cost:  0.9342426277388768\n",
      "iteration:  74  cost:  0.9374425806795657\n",
      "iteration:  75  cost:  0.9675699560085386\n",
      "iteration:  76  cost:  0.9364282918537318\n",
      "iteration:  77  cost:  0.9325053333068216\n",
      "iteration:  78  cost:  0.9427645263509621\n",
      "iteration:  79  cost:  0.9531626393462111\n",
      "[0.486, 0.486, 0.46, 0.46, 0.578, 0.684, 0.67, 0.66, 0.66]\n",
      "iteration:  80  cost:  0.9309699151632949\n",
      "iteration:  81  cost:  0.9329794369715824\n",
      "iteration:  82  cost:  0.9574033647079742\n",
      "iteration:  83  cost:  0.9300565307060231\n",
      "iteration:  84  cost:  0.9572814711114656\n",
      "iteration:  85  cost:  0.9248167299077132\n",
      "iteration:  86  cost:  0.9283673090600147\n",
      "iteration:  87  cost:  0.9111314276591123\n",
      "iteration:  88  cost:  0.9379001678731426\n",
      "iteration:  89  cost:  0.8900185385141277\n",
      "[0.486, 0.486, 0.46, 0.46, 0.578, 0.684, 0.67, 0.66, 0.66, 0.664]\n",
      "iteration:  90  cost:  0.9509617093674825\n",
      "iteration:  91  cost:  0.9513715446509045\n",
      "iteration:  92  cost:  0.927867259198099\n",
      "iteration:  93  cost:  0.9491292441501301\n",
      "iteration:  94  cost:  0.9530483501583887\n",
      "iteration:  95  cost:  0.9299401360306753\n",
      "iteration:  96  cost:  0.9255760344304191\n",
      "iteration:  97  cost:  0.9320878290244373\n",
      "iteration:  98  cost:  0.9272699090073102\n",
      "iteration:  99  cost:  0.9154266102665912\n",
      "[0.486, 0.486, 0.46, 0.46, 0.578, 0.684, 0.67, 0.66, 0.66, 0.664, 0.668]\n",
      "iteration:  100  cost:  0.9237132534025767\n",
      "iteration:  101  cost:  0.9066793386944835\n",
      "iteration:  102  cost:  0.930257271203915\n",
      "iteration:  103  cost:  1.0047200145005846\n",
      "iteration:  104  cost:  0.9273568685110248\n",
      "iteration:  105  cost:  0.9086737058497576\n",
      "iteration:  106  cost:  0.9363805344305817\n",
      "iteration:  107  cost:  0.8961454218445211\n",
      "iteration:  108  cost:  0.8909825229160225\n",
      "iteration:  109  cost:  0.9011095696021666\n",
      "[0.486, 0.486, 0.46, 0.46, 0.578, 0.684, 0.67, 0.66, 0.66, 0.664, 0.668, 0.68]\n",
      "iteration:  110  cost:  0.9523324030203407\n",
      "iteration:  111  cost:  0.9158694189500725\n",
      "iteration:  112  cost:  0.9149664185155924\n",
      "iteration:  113  cost:  0.9270514625777376\n",
      "iteration:  114  cost:  0.9449973043514089\n",
      "iteration:  115  cost:  0.9373140843668162\n",
      "iteration:  116  cost:  0.9310589453882645\n",
      "iteration:  117  cost:  0.944196587996764\n",
      "iteration:  118  cost:  0.9663759822746506\n",
      "iteration:  119  cost:  0.9399208766834245\n",
      "[0.486, 0.486, 0.46, 0.46, 0.578, 0.684, 0.67, 0.66, 0.66, 0.664, 0.668, 0.68, 0.706]\n",
      "iteration:  120  cost:  0.953018117158759\n",
      "iteration:  121  cost:  0.912128217175091\n",
      "iteration:  122  cost:  0.9000265355626701\n",
      "iteration:  123  cost:  0.9153597829121458\n",
      "iteration:  124  cost:  0.9459259224564801\n",
      "iteration:  125  cost:  0.9118321873781753\n",
      "iteration:  126  cost:  0.9373969403046851\n",
      "iteration:  127  cost:  0.909857252928892\n",
      "iteration:  128  cost:  0.9158222378187082\n",
      "iteration:  129  cost:  0.887842148271557\n",
      "[0.486, 0.486, 0.46, 0.46, 0.578, 0.684, 0.67, 0.66, 0.66, 0.664, 0.668, 0.68, 0.706, 0.724]\n",
      "iteration:  130  cost:  0.9118751854912037\n",
      "iteration:  131  cost:  0.9300620871291025\n",
      "iteration:  132  cost:  0.9149168682963763\n",
      "iteration:  133  cost:  0.9302495911087845\n",
      "iteration:  134  cost:  0.8861039306492802\n",
      "iteration:  135  cost:  0.9248484704027503\n",
      "iteration:  136  cost:  0.9167398037824228\n",
      "iteration:  137  cost:  0.8962219345244945\n",
      "iteration:  138  cost:  0.8933775243684425\n",
      "iteration:  139  cost:  0.9098412639467499\n",
      "[0.486, 0.486, 0.46, 0.46, 0.578, 0.684, 0.67, 0.66, 0.66, 0.664, 0.668, 0.68, 0.706, 0.724, 0.742]\n",
      "iteration:  140  cost:  0.9063498638185219\n",
      "iteration:  141  cost:  0.8946535003311084\n",
      "iteration:  142  cost:  0.9375949611800999\n",
      "iteration:  143  cost:  0.9491168958447826\n",
      "iteration:  144  cost:  0.9085383010167399\n",
      "iteration:  145  cost:  0.9434183712045501\n",
      "iteration:  146  cost:  0.908047276628885\n",
      "iteration:  147  cost:  0.8604887068634942\n",
      "iteration:  148  cost:  0.8713468632323614\n",
      "iteration:  149  cost:  0.9328369765972182\n",
      "[0.486, 0.486, 0.46, 0.46, 0.578, 0.684, 0.67, 0.66, 0.66, 0.664, 0.668, 0.68, 0.706, 0.724, 0.742, 0.744]\n",
      "iteration:  150  cost:  0.9381045744526405\n",
      "iteration:  151  cost:  0.8779533580750701\n",
      "iteration:  152  cost:  0.9355466830641623\n",
      "iteration:  153  cost:  0.9153716305326989\n",
      "iteration:  154  cost:  0.8364856010078955\n",
      "iteration:  155  cost:  0.9447911910440564\n",
      "iteration:  156  cost:  0.9100898075645506\n",
      "iteration:  157  cost:  0.933906820478443\n",
      "iteration:  158  cost:  0.8525103036948518\n",
      "iteration:  159  cost:  0.9372140194027188\n",
      "[0.486, 0.486, 0.46, 0.46, 0.578, 0.684, 0.67, 0.66, 0.66, 0.664, 0.668, 0.68, 0.706, 0.724, 0.742, 0.744, 0.754]\n",
      "iteration:  160  cost:  0.8910854348890399\n",
      "iteration:  161  cost:  0.8940135454074949\n",
      "iteration:  162  cost:  0.9236550382665524\n",
      "iteration:  163  cost:  0.918284481596697\n",
      "iteration:  164  cost:  0.9226771808096912\n",
      "iteration:  165  cost:  0.8949219362660277\n",
      "iteration:  166  cost:  0.911468480466052\n",
      "iteration:  167  cost:  0.9185679256826544\n",
      "iteration:  168  cost:  0.8573568842429417\n",
      "iteration:  169  cost:  0.9012800953122414\n",
      "[0.486, 0.486, 0.46, 0.46, 0.578, 0.684, 0.67, 0.66, 0.66, 0.664, 0.668, 0.68, 0.706, 0.724, 0.742, 0.744, 0.754, 0.76]\n",
      "iteration:  170  cost:  0.90751489974371\n",
      "iteration:  171  cost:  0.9159916327495401\n",
      "iteration:  172  cost:  0.9085701757974598\n",
      "iteration:  173  cost:  0.8858870957433467\n",
      "iteration:  174  cost:  0.8994142487349659\n",
      "iteration:  175  cost:  0.9099246423393497\n",
      "iteration:  176  cost:  0.9018759363555781\n",
      "iteration:  177  cost:  0.879239497684396\n",
      "iteration:  178  cost:  0.8815551994546734\n",
      "iteration:  179  cost:  0.8889896902757255\n",
      "[0.486, 0.486, 0.46, 0.46, 0.578, 0.684, 0.67, 0.66, 0.66, 0.664, 0.668, 0.68, 0.706, 0.724, 0.742, 0.744, 0.754, 0.76, 0.766]\n",
      "iteration:  180  cost:  0.9074017615063974\n",
      "iteration:  181  cost:  0.9020265396081928\n",
      "iteration:  182  cost:  0.8781592603425943\n",
      "iteration:  183  cost:  0.9425107261696037\n",
      "iteration:  184  cost:  0.8660098274990699\n",
      "iteration:  185  cost:  0.8779049477207014\n",
      "iteration:  186  cost:  0.8707336993837741\n",
      "iteration:  187  cost:  0.8720288435282539\n",
      "iteration:  188  cost:  0.9224053757549738\n",
      "iteration:  189  cost:  0.9152069506632808\n",
      "[0.486, 0.486, 0.46, 0.46, 0.578, 0.684, 0.67, 0.66, 0.66, 0.664, 0.668, 0.68, 0.706, 0.724, 0.742, 0.744, 0.754, 0.76, 0.766, 0.778]\n",
      "iteration:  190  cost:  0.8926397903575406\n",
      "iteration:  191  cost:  0.917704212049625\n",
      "iteration:  192  cost:  0.8673696178737224\n",
      "iteration:  193  cost:  0.9174061175395343\n",
      "iteration:  194  cost:  0.8449202883521076\n",
      "iteration:  195  cost:  0.8829703817552239\n",
      "iteration:  196  cost:  0.9047468371679512\n",
      "iteration:  197  cost:  0.880921246307069\n",
      "iteration:  198  cost:  0.9127706263577339\n",
      "iteration:  199  cost:  0.9230114777562415\n",
      "[0.486, 0.486, 0.46, 0.46, 0.578, 0.684, 0.67, 0.66, 0.66, 0.664, 0.668, 0.68, 0.706, 0.724, 0.742, 0.744, 0.754, 0.76, 0.766, 0.778, 0.796]\n",
      "iteration:  200  cost:  0.8997370979084858\n",
      "iteration:  201  cost:  0.8799130117984215\n",
      "iteration:  202  cost:  0.9015384944315444\n",
      "iteration:  203  cost:  0.9057159343229244\n",
      "iteration:  204  cost:  0.8629479164098861\n",
      "iteration:  205  cost:  0.9005274941508459\n",
      "iteration:  206  cost:  0.8927226780517478\n",
      "iteration:  207  cost:  0.8838317266742497\n",
      "iteration:  208  cost:  0.9203068744820666\n",
      "iteration:  209  cost:  0.9097527169005712\n",
      "[0.486, 0.486, 0.46, 0.46, 0.578, 0.684, 0.67, 0.66, 0.66, 0.664, 0.668, 0.68, 0.706, 0.724, 0.742, 0.744, 0.754, 0.76, 0.766, 0.778, 0.796, 0.816]\n",
      "iteration:  210  cost:  0.9188455265478613\n",
      "iteration:  211  cost:  0.8912587084226865\n",
      "iteration:  212  cost:  0.9075244317065557\n",
      "iteration:  213  cost:  0.9070799907915922\n",
      "iteration:  214  cost:  0.8787502326147099\n",
      "iteration:  215  cost:  0.8406170324837129\n",
      "iteration:  216  cost:  0.9135261067219353\n",
      "iteration:  217  cost:  0.8717139212214811\n",
      "iteration:  218  cost:  0.8471619645629059\n",
      "iteration:  219  cost:  0.8854651793386087\n",
      "[0.486, 0.486, 0.46, 0.46, 0.578, 0.684, 0.67, 0.66, 0.66, 0.664, 0.668, 0.68, 0.706, 0.724, 0.742, 0.744, 0.754, 0.76, 0.766, 0.778, 0.796, 0.816, 0.832]\n",
      "iteration:  220  cost:  0.878966293264546\n",
      "iteration:  221  cost:  0.8289747623117358\n",
      "iteration:  222  cost:  0.9351777676614823\n",
      "iteration:  223  cost:  0.8162854615948241\n",
      "iteration:  224  cost:  0.8707361941942602\n",
      "iteration:  225  cost:  0.8936955007395277\n",
      "iteration:  226  cost:  0.8778187586097066\n",
      "iteration:  227  cost:  0.9192382904832447\n",
      "iteration:  228  cost:  0.8400062935038365\n",
      "iteration:  229  cost:  0.9033829319585416\n",
      "[0.486, 0.486, 0.46, 0.46, 0.578, 0.684, 0.67, 0.66, 0.66, 0.664, 0.668, 0.68, 0.706, 0.724, 0.742, 0.744, 0.754, 0.76, 0.766, 0.778, 0.796, 0.816, 0.832, 0.842]\n",
      "iteration:  230  cost:  0.8515370013190006\n",
      "iteration:  231  cost:  0.8473917967370684\n",
      "iteration:  232  cost:  0.8351455597799852\n",
      "iteration:  233  cost:  0.8636439263832546\n",
      "iteration:  234  cost:  0.9041110945273262\n",
      "iteration:  235  cost:  0.8797401957166078\n",
      "iteration:  236  cost:  0.8407202449369515\n",
      "iteration:  237  cost:  0.9180237278066907\n",
      "iteration:  238  cost:  0.8701694037758423\n",
      "iteration:  239  cost:  0.9020612108179986\n",
      "[0.486, 0.486, 0.46, 0.46, 0.578, 0.684, 0.67, 0.66, 0.66, 0.664, 0.668, 0.68, 0.706, 0.724, 0.742, 0.744, 0.754, 0.76, 0.766, 0.778, 0.796, 0.816, 0.832, 0.842, 0.848]\n",
      "iteration:  240  cost:  0.9253732794047161\n",
      "iteration:  241  cost:  0.8738547968563014\n",
      "iteration:  242  cost:  0.8552637000836922\n",
      "iteration:  243  cost:  0.8933209746156489\n",
      "iteration:  244  cost:  0.8552479438314804\n",
      "iteration:  245  cost:  0.8729605329888959\n",
      "iteration:  246  cost:  0.8668011027134362\n",
      "iteration:  247  cost:  0.8387994331734185\n",
      "iteration:  248  cost:  0.8869172377736918\n",
      "iteration:  249  cost:  0.8451353953883641\n",
      "[0.486, 0.486, 0.46, 0.46, 0.578, 0.684, 0.67, 0.66, 0.66, 0.664, 0.668, 0.68, 0.706, 0.724, 0.742, 0.744, 0.754, 0.76, 0.766, 0.778, 0.796, 0.816, 0.832, 0.842, 0.848, 0.86]\n",
      "iteration:  250  cost:  0.8941267769743688\n",
      "iteration:  251  cost:  0.8484604242128174\n",
      "iteration:  252  cost:  0.8631636014176106\n",
      "iteration:  253  cost:  0.8802566513782655\n",
      "iteration:  254  cost:  0.8949421146287212\n",
      "iteration:  255  cost:  0.8877506130584076\n",
      "iteration:  256  cost:  0.8909225972805932\n",
      "iteration:  257  cost:  0.854665696589781\n",
      "iteration:  258  cost:  0.8377831372065231\n",
      "iteration:  259  cost:  0.8316227707584054\n",
      "[0.486, 0.486, 0.46, 0.46, 0.578, 0.684, 0.67, 0.66, 0.66, 0.664, 0.668, 0.68, 0.706, 0.724, 0.742, 0.744, 0.754, 0.76, 0.766, 0.778, 0.796, 0.816, 0.832, 0.842, 0.848, 0.86, 0.874]\n",
      "iteration:  260  cost:  0.890878219747885\n",
      "iteration:  261  cost:  0.8445010527749865\n",
      "iteration:  262  cost:  0.8471689610173133\n",
      "iteration:  263  cost:  0.8375127363813603\n",
      "iteration:  264  cost:  0.854594782448495\n",
      "iteration:  265  cost:  0.83233375707524\n",
      "iteration:  266  cost:  0.8576427983209615\n",
      "iteration:  267  cost:  0.8641968594445512\n",
      "iteration:  268  cost:  0.8498304202818387\n",
      "iteration:  269  cost:  0.873621893146852\n",
      "[0.486, 0.486, 0.46, 0.46, 0.578, 0.684, 0.67, 0.66, 0.66, 0.664, 0.668, 0.68, 0.706, 0.724, 0.742, 0.744, 0.754, 0.76, 0.766, 0.778, 0.796, 0.816, 0.832, 0.842, 0.848, 0.86, 0.874, 0.87]\n",
      "iteration:  270  cost:  0.861464222212216\n",
      "iteration:  271  cost:  0.9112932032124123\n",
      "iteration:  272  cost:  0.9062784101798013\n",
      "iteration:  273  cost:  0.8907250526857042\n",
      "iteration:  274  cost:  0.8349665486461695\n",
      "iteration:  275  cost:  0.8300659732429209\n",
      "iteration:  276  cost:  0.9214206768597295\n",
      "iteration:  277  cost:  0.8619798319604719\n",
      "iteration:  278  cost:  0.8317932833916953\n",
      "iteration:  279  cost:  0.8505247600201256\n",
      "[0.486, 0.486, 0.46, 0.46, 0.578, 0.684, 0.67, 0.66, 0.66, 0.664, 0.668, 0.68, 0.706, 0.724, 0.742, 0.744, 0.754, 0.76, 0.766, 0.778, 0.796, 0.816, 0.832, 0.842, 0.848, 0.86, 0.874, 0.87, 0.884]\n",
      "iteration:  280  cost:  0.8632184083780227\n",
      "iteration:  281  cost:  0.8210198448337848\n",
      "iteration:  282  cost:  0.8435559897154815\n",
      "iteration:  283  cost:  0.8482520055906475\n",
      "iteration:  284  cost:  0.8764399639194744\n",
      "iteration:  285  cost:  0.8728290112735838\n",
      "iteration:  286  cost:  0.8199053662696721\n",
      "iteration:  287  cost:  0.8436329674574813\n",
      "iteration:  288  cost:  0.8466102127831471\n",
      "iteration:  289  cost:  0.8544229268720952\n",
      "[0.486, 0.486, 0.46, 0.46, 0.578, 0.684, 0.67, 0.66, 0.66, 0.664, 0.668, 0.68, 0.706, 0.724, 0.742, 0.744, 0.754, 0.76, 0.766, 0.778, 0.796, 0.816, 0.832, 0.842, 0.848, 0.86, 0.874, 0.87, 0.884, 0.892]\n",
      "iteration:  290  cost:  0.8300002673765836\n",
      "iteration:  291  cost:  0.8606874050224722\n",
      "iteration:  292  cost:  0.8167446445911728\n",
      "iteration:  293  cost:  0.8493308935669209\n",
      "iteration:  294  cost:  0.8712153041024476\n",
      "iteration:  295  cost:  0.8490671992354987\n",
      "iteration:  296  cost:  0.8194367848324068\n",
      "iteration:  297  cost:  0.8598439206828317\n",
      "iteration:  298  cost:  0.8488580847415362\n",
      "iteration:  299  cost:  0.8083180369975892\n",
      "[0.486, 0.486, 0.46, 0.46, 0.578, 0.684, 0.67, 0.66, 0.66, 0.664, 0.668, 0.68, 0.706, 0.724, 0.742, 0.744, 0.754, 0.76, 0.766, 0.778, 0.796, 0.816, 0.832, 0.842, 0.848, 0.86, 0.874, 0.87, 0.884, 0.892, 0.898]\n",
      "iteration:  300  cost:  0.8431784705205309\n",
      "iteration:  301  cost:  0.8571497827051734\n",
      "iteration:  302  cost:  0.8057384247307974\n",
      "iteration:  303  cost:  0.8452445434591439\n",
      "iteration:  304  cost:  0.8519220511780703\n",
      "iteration:  305  cost:  0.8562848868876946\n",
      "iteration:  306  cost:  0.8739128735339726\n",
      "iteration:  307  cost:  0.8395983526326344\n",
      "iteration:  308  cost:  0.8708542274618901\n",
      "iteration:  309  cost:  0.8501868311484047\n",
      "[0.486, 0.486, 0.46, 0.46, 0.578, 0.684, 0.67, 0.66, 0.66, 0.664, 0.668, 0.68, 0.706, 0.724, 0.742, 0.744, 0.754, 0.76, 0.766, 0.778, 0.796, 0.816, 0.832, 0.842, 0.848, 0.86, 0.874, 0.87, 0.884, 0.892, 0.898, 0.9]\n",
      "iteration:  310  cost:  0.8351091552427563\n",
      "iteration:  311  cost:  0.840274205086747\n",
      "iteration:  312  cost:  0.8449765730383948\n",
      "iteration:  313  cost:  0.8371524156402866\n",
      "iteration:  314  cost:  0.8338376691082086\n",
      "iteration:  315  cost:  0.8612800261721515\n",
      "iteration:  316  cost:  0.8309490309438103\n",
      "iteration:  317  cost:  0.8263278142041435\n",
      "iteration:  318  cost:  0.8302672285849124\n",
      "iteration:  319  cost:  0.8328294018556588\n",
      "[0.486, 0.486, 0.46, 0.46, 0.578, 0.684, 0.67, 0.66, 0.66, 0.664, 0.668, 0.68, 0.706, 0.724, 0.742, 0.744, 0.754, 0.76, 0.766, 0.778, 0.796, 0.816, 0.832, 0.842, 0.848, 0.86, 0.874, 0.87, 0.884, 0.892, 0.898, 0.9, 0.892]\n",
      "iteration:  320  cost:  0.8498055513725014\n",
      "iteration:  321  cost:  0.7835700874098618\n",
      "iteration:  322  cost:  0.81604287922623\n",
      "iteration:  323  cost:  0.8363652214556488\n",
      "iteration:  324  cost:  0.8214828479808696\n",
      "iteration:  325  cost:  0.8616416476223634\n",
      "iteration:  326  cost:  0.8260101303650197\n",
      "iteration:  327  cost:  0.8578824621728218\n",
      "iteration:  328  cost:  0.8485768695933078\n",
      "iteration:  329  cost:  0.8237755427167059\n",
      "[0.486, 0.486, 0.46, 0.46, 0.578, 0.684, 0.67, 0.66, 0.66, 0.664, 0.668, 0.68, 0.706, 0.724, 0.742, 0.744, 0.754, 0.76, 0.766, 0.778, 0.796, 0.816, 0.832, 0.842, 0.848, 0.86, 0.874, 0.87, 0.884, 0.892, 0.898, 0.9, 0.892, 0.888]\n",
      "Accuracy for U_9 autoencoder8 :0.8945626477541371\n",
      "Epoch 1/10\n",
      "396/396 [==============================] - 1s 1ms/step - loss: 0.0949 - val_loss: 0.0287\n",
      "Epoch 2/10\n",
      "396/396 [==============================] - 0s 761us/step - loss: 0.0268 - val_loss: 0.0223\n",
      "Epoch 3/10\n",
      "396/396 [==============================] - 0s 799us/step - loss: 0.0218 - val_loss: 0.0181\n",
      "Epoch 4/10\n",
      "396/396 [==============================] - 0s 796us/step - loss: 0.0175 - val_loss: 0.0156\n",
      "Epoch 5/10\n",
      "396/396 [==============================] - 0s 801us/step - loss: 0.0153 - val_loss: 0.0141\n",
      "Epoch 6/10\n",
      "396/396 [==============================] - 0s 829us/step - loss: 0.0140 - val_loss: 0.0130\n",
      "Epoch 7/10\n",
      "396/396 [==============================] - 0s 801us/step - loss: 0.0129 - val_loss: 0.0122\n",
      "Epoch 8/10\n",
      "396/396 [==============================] - 0s 796us/step - loss: 0.0123 - val_loss: 0.0116\n",
      "Epoch 9/10\n",
      "396/396 [==============================] - 0s 794us/step - loss: 0.0116 - val_loss: 0.0111\n",
      "Epoch 10/10\n",
      "396/396 [==============================] - 0s 828us/step - loss: 0.0112 - val_loss: 0.0106\n",
      "\n",
      "\n",
      "Loss History for QCNN circuits, U_9 autoencoder16\n",
      "[0.416]\n",
      "iteration:  0  cost:  1.0485110833600386\n",
      "iteration:  1  cost:  1.0033047986709673\n",
      "iteration:  2  cost:  1.0395530877152401\n",
      "iteration:  3  cost:  1.0222848978952805\n",
      "iteration:  4  cost:  1.045625757966491\n",
      "iteration:  5  cost:  1.0198637924723084\n",
      "iteration:  6  cost:  1.0817290494810654\n",
      "iteration:  7  cost:  1.0388485972994268\n",
      "iteration:  8  cost:  1.0271792822167962\n",
      "iteration:  9  cost:  1.0383495553699975\n",
      "[0.416, 0.444]\n",
      "iteration:  10  cost:  1.0157308171322392\n",
      "iteration:  11  cost:  0.9584797162433278\n",
      "iteration:  12  cost:  1.012825185434461\n",
      "iteration:  13  cost:  0.978306516342345\n",
      "iteration:  14  cost:  1.0090913578235803\n",
      "iteration:  15  cost:  1.0205107542263547\n",
      "iteration:  16  cost:  1.03617495047135\n",
      "iteration:  17  cost:  1.0172779443502558\n",
      "iteration:  18  cost:  1.002868587966577\n",
      "iteration:  19  cost:  0.9786757392523638\n",
      "[0.416, 0.444, 0.452]\n",
      "iteration:  20  cost:  0.9865742632914869\n",
      "iteration:  21  cost:  1.0029273337611553\n",
      "iteration:  22  cost:  0.9968557177176024\n",
      "iteration:  23  cost:  1.0215370872556655\n",
      "iteration:  24  cost:  0.9707638420867517\n",
      "iteration:  25  cost:  1.0233820911155154\n",
      "iteration:  26  cost:  0.9155942213936794\n",
      "iteration:  27  cost:  0.9780918793861979\n",
      "iteration:  28  cost:  0.9763850031948814\n",
      "iteration:  29  cost:  0.9824359887628644\n",
      "[0.416, 0.444, 0.452, 0.476]\n",
      "iteration:  30  cost:  0.9729214843283098\n",
      "iteration:  31  cost:  0.9658570483872798\n",
      "iteration:  32  cost:  0.9723513732372419\n",
      "iteration:  33  cost:  0.9594035346850108\n",
      "iteration:  34  cost:  0.969587405493464\n",
      "iteration:  35  cost:  0.9606403562711033\n",
      "iteration:  36  cost:  0.9750804111439286\n",
      "iteration:  37  cost:  0.9461081008406517\n",
      "iteration:  38  cost:  0.9704479204502343\n",
      "iteration:  39  cost:  0.9799929222131414\n",
      "[0.416, 0.444, 0.452, 0.476, 0.668]\n",
      "iteration:  40  cost:  0.9548400017837783\n",
      "iteration:  41  cost:  0.9442542122966155\n",
      "iteration:  42  cost:  0.9604440006294428\n",
      "iteration:  43  cost:  0.9375139880115421\n",
      "iteration:  44  cost:  0.9756578368682183\n",
      "iteration:  45  cost:  0.9270234808133031\n",
      "iteration:  46  cost:  0.9566244689126359\n",
      "iteration:  47  cost:  0.9383595777159205\n",
      "iteration:  48  cost:  0.9575169194089018\n",
      "iteration:  49  cost:  0.9592561879924704\n",
      "[0.416, 0.444, 0.452, 0.476, 0.668, 0.816]\n",
      "iteration:  50  cost:  0.9385053444835283\n",
      "iteration:  51  cost:  0.9576366078645566\n",
      "iteration:  52  cost:  0.9378377233242726\n",
      "iteration:  53  cost:  0.9451097507775572\n",
      "iteration:  54  cost:  0.9498814288793325\n",
      "iteration:  55  cost:  0.9282463908252027\n",
      "iteration:  56  cost:  0.9664714525524047\n",
      "iteration:  57  cost:  0.9447137917416658\n",
      "iteration:  58  cost:  0.9336279898499504\n",
      "iteration:  59  cost:  0.9477612295663398\n",
      "[0.416, 0.444, 0.452, 0.476, 0.668, 0.816, 0.892]\n",
      "iteration:  60  cost:  0.9582781732344451\n",
      "iteration:  61  cost:  0.9584865479805755\n",
      "iteration:  62  cost:  0.9417909180142406\n",
      "iteration:  63  cost:  0.9428641757893717\n",
      "iteration:  64  cost:  0.9556591371420083\n",
      "iteration:  65  cost:  0.95017804638161\n",
      "iteration:  66  cost:  0.9466264983633056\n",
      "iteration:  67  cost:  0.950524319160915\n",
      "iteration:  68  cost:  0.9278021632100051\n",
      "iteration:  69  cost:  0.9204878833649001\n",
      "[0.416, 0.444, 0.452, 0.476, 0.668, 0.816, 0.892, 0.922]\n",
      "iteration:  70  cost:  0.9406901449327093\n",
      "iteration:  71  cost:  0.9383726259885367\n",
      "iteration:  72  cost:  0.9438597971172413\n",
      "iteration:  73  cost:  0.9381589700039971\n",
      "iteration:  74  cost:  0.9279549407794516\n",
      "iteration:  75  cost:  0.9379652084764958\n",
      "iteration:  76  cost:  0.9396943060705928\n",
      "iteration:  77  cost:  0.9311194325097931\n",
      "iteration:  78  cost:  0.9385926402959446\n",
      "iteration:  79  cost:  0.9384229331330937\n",
      "[0.416, 0.444, 0.452, 0.476, 0.668, 0.816, 0.892, 0.922, 0.954]\n",
      "iteration:  80  cost:  0.916225480799506\n",
      "iteration:  81  cost:  0.9309496257979969\n",
      "iteration:  82  cost:  0.9192100557438746\n",
      "iteration:  83  cost:  0.9402168115193832\n",
      "iteration:  84  cost:  0.949996628968249\n",
      "iteration:  85  cost:  0.9364998226400449\n",
      "iteration:  86  cost:  0.9542431841895591\n",
      "iteration:  87  cost:  0.9257474272983829\n",
      "iteration:  88  cost:  0.9396797116913457\n",
      "iteration:  89  cost:  0.9275106148730464\n",
      "[0.416, 0.444, 0.452, 0.476, 0.668, 0.816, 0.892, 0.922, 0.954, 0.964]\n",
      "iteration:  90  cost:  0.9273550352845912\n",
      "iteration:  91  cost:  0.9249196454253356\n",
      "iteration:  92  cost:  0.9398485149736038\n",
      "iteration:  93  cost:  0.9291547303450142\n",
      "iteration:  94  cost:  0.9162066520100071\n",
      "iteration:  95  cost:  0.9497813344297361\n",
      "iteration:  96  cost:  0.9220679779719073\n",
      "iteration:  97  cost:  0.9266808168535485\n",
      "iteration:  98  cost:  0.9229318369304598\n",
      "iteration:  99  cost:  0.9228527197785097\n",
      "[0.416, 0.444, 0.452, 0.476, 0.668, 0.816, 0.892, 0.922, 0.954, 0.964, 0.956]\n",
      "iteration:  100  cost:  0.932721682662216\n",
      "iteration:  101  cost:  0.9295388713416601\n",
      "iteration:  102  cost:  0.933300143953835\n",
      "iteration:  103  cost:  0.9249057544502368\n",
      "iteration:  104  cost:  0.920347129483692\n",
      "iteration:  105  cost:  0.9278689034819522\n",
      "iteration:  106  cost:  0.9229379044076812\n",
      "iteration:  107  cost:  0.9138702636143676\n",
      "iteration:  108  cost:  0.930535777120756\n",
      "iteration:  109  cost:  0.9303357109756011\n",
      "[0.416, 0.444, 0.452, 0.476, 0.668, 0.816, 0.892, 0.922, 0.954, 0.964, 0.956, 0.944]\n",
      "Accuracy for U_9 autoencoder16 :0.9479905437352246\n",
      "\n",
      "\n",
      "Loss History for QCNN circuits, U_13 resize256\n",
      "[0.738]\n",
      "iteration:  0  cost:  0.9408339133374873\n",
      "iteration:  1  cost:  0.8892897390766931\n",
      "iteration:  2  cost:  0.878209849128365\n",
      "iteration:  3  cost:  0.8960975509826069\n",
      "iteration:  4  cost:  0.8860028066115873\n",
      "iteration:  5  cost:  0.8701886699363053\n",
      "iteration:  6  cost:  0.8720650945951529\n",
      "iteration:  7  cost:  0.8748408725966508\n",
      "iteration:  8  cost:  0.8568594628706252\n",
      "iteration:  9  cost:  0.8309124079282415\n",
      "[0.738, 0.606]\n",
      "iteration:  10  cost:  0.86276784692635\n",
      "iteration:  11  cost:  0.855064328052301\n",
      "iteration:  12  cost:  0.8842475950075497\n",
      "iteration:  13  cost:  0.9080687131477572\n",
      "iteration:  14  cost:  0.8806197726868251\n",
      "iteration:  15  cost:  0.817082231798354\n",
      "iteration:  16  cost:  0.851394034229794\n",
      "iteration:  17  cost:  0.9270303949709023\n",
      "iteration:  18  cost:  0.966173444216207\n",
      "iteration:  19  cost:  0.9441869240143451\n",
      "[0.738, 0.606, 0.83]\n",
      "iteration:  20  cost:  0.8325914225069664\n",
      "iteration:  21  cost:  0.8472578281833247\n",
      "iteration:  22  cost:  0.8845939900694253\n",
      "iteration:  23  cost:  0.8605485363333029\n",
      "iteration:  24  cost:  0.8696106787269388\n",
      "iteration:  25  cost:  0.8746566500354757\n",
      "iteration:  26  cost:  0.8588469264885715\n",
      "iteration:  27  cost:  0.8580525728002422\n",
      "iteration:  28  cost:  0.7878965003895182\n",
      "iteration:  29  cost:  0.7921533228275556\n",
      "[0.738, 0.606, 0.83, 0.758]\n",
      "iteration:  30  cost:  0.8797790397203309\n",
      "iteration:  31  cost:  0.8203927573997448\n",
      "iteration:  32  cost:  0.8415129407027855\n",
      "iteration:  33  cost:  0.7890115485965226\n",
      "iteration:  34  cost:  0.9360760537139288\n",
      "iteration:  35  cost:  0.8365690567152504\n",
      "iteration:  36  cost:  0.8878243195622291\n",
      "iteration:  37  cost:  0.890782491321482\n",
      "iteration:  38  cost:  0.7992795663186917\n",
      "iteration:  39  cost:  0.7966129019755381\n",
      "[0.738, 0.606, 0.83, 0.758, 0.782]\n",
      "iteration:  40  cost:  0.8103350372435366\n",
      "iteration:  41  cost:  0.7675019108392072\n",
      "iteration:  42  cost:  0.8206760027018584\n",
      "iteration:  43  cost:  0.8949970799236843\n",
      "iteration:  44  cost:  0.8357946553532019\n",
      "iteration:  45  cost:  0.876677819777856\n",
      "iteration:  46  cost:  0.796419226760823\n",
      "iteration:  47  cost:  0.8380216095230207\n",
      "iteration:  48  cost:  0.8539164867422406\n",
      "iteration:  49  cost:  0.8649663260778171\n",
      "[0.738, 0.606, 0.83, 0.758, 0.782, 0.856]\n",
      "iteration:  50  cost:  0.8588697617205732\n",
      "iteration:  51  cost:  0.8411472660069892\n",
      "iteration:  52  cost:  0.8410344662926903\n",
      "iteration:  53  cost:  0.8587496480381677\n",
      "iteration:  54  cost:  0.8365057760296024\n",
      "iteration:  55  cost:  0.8957857820348449\n",
      "iteration:  56  cost:  0.8457099811804476\n",
      "iteration:  57  cost:  0.8298196647186483\n",
      "iteration:  58  cost:  0.8057215731153028\n",
      "iteration:  59  cost:  0.7945099077501315\n",
      "[0.738, 0.606, 0.83, 0.758, 0.782, 0.856, 0.886]\n",
      "iteration:  60  cost:  0.8275574009066802\n",
      "iteration:  61  cost:  0.8290193675813993\n",
      "iteration:  62  cost:  0.8014272668754657\n",
      "iteration:  63  cost:  0.7706354441711072\n",
      "iteration:  64  cost:  0.7672124947925313\n",
      "iteration:  65  cost:  0.7123509058243083\n",
      "iteration:  66  cost:  0.7577626196497225\n",
      "iteration:  67  cost:  0.8053633968459326\n",
      "iteration:  68  cost:  0.8472698392877962\n",
      "iteration:  69  cost:  0.810156319132971\n",
      "[0.738, 0.606, 0.83, 0.758, 0.782, 0.856, 0.886, 0.764]\n",
      "Accuracy for U_13 resize256 :0.7645390070921986\n",
      "\n",
      "\n",
      "Loss History for QCNN circuits, U_13 pca8\n",
      "[0.466]\n",
      "iteration:  0  cost:  1.202126143943536\n",
      "iteration:  1  cost:  1.3257810090433364\n",
      "iteration:  2  cost:  1.2774746209824257\n",
      "iteration:  3  cost:  1.0988470236304642\n",
      "iteration:  4  cost:  1.0857133724365198\n",
      "iteration:  5  cost:  1.1005400553792044\n",
      "iteration:  6  cost:  1.0296168487715027\n",
      "iteration:  7  cost:  1.0510040420714548\n",
      "iteration:  8  cost:  1.0666076044483845\n",
      "iteration:  9  cost:  0.9483763695808335\n",
      "[0.466, 0.554]\n",
      "iteration:  10  cost:  0.9329338272073159\n",
      "iteration:  11  cost:  0.9779807585644409\n",
      "iteration:  12  cost:  0.877759623950134\n",
      "iteration:  13  cost:  1.0290114989803485\n",
      "iteration:  14  cost:  0.9333945979330524\n",
      "iteration:  15  cost:  1.1122998557427612\n",
      "iteration:  16  cost:  1.0093995896309784\n",
      "iteration:  17  cost:  0.9073004259389501\n",
      "iteration:  18  cost:  0.7391784684955699\n",
      "iteration:  19  cost:  0.7792189577786242\n",
      "[0.466, 0.554, 0.802]\n",
      "iteration:  20  cost:  0.7718559236934559\n",
      "iteration:  21  cost:  0.7398861391760145\n",
      "iteration:  22  cost:  0.6290481567223191\n",
      "iteration:  23  cost:  0.6786951747350873\n",
      "iteration:  24  cost:  0.5397116948900814\n",
      "iteration:  25  cost:  0.49480087184294064\n",
      "iteration:  26  cost:  0.5625848368615203\n",
      "iteration:  27  cost:  0.5073638904921547\n",
      "iteration:  28  cost:  0.4694913798724081\n",
      "iteration:  29  cost:  0.503529861173154\n",
      "[0.466, 0.554, 0.802, 0.954]\n",
      "iteration:  30  cost:  0.4124964783881663\n",
      "iteration:  31  cost:  0.4375795556451792\n",
      "iteration:  32  cost:  0.38639304677711833\n",
      "iteration:  33  cost:  0.3739513562648121\n",
      "iteration:  34  cost:  0.37770642586193076\n",
      "iteration:  35  cost:  0.3943565453999651\n",
      "iteration:  36  cost:  0.4320526533286328\n",
      "iteration:  37  cost:  0.39199759763286396\n",
      "iteration:  38  cost:  0.28788208891656386\n",
      "iteration:  39  cost:  0.30656284155839775\n",
      "[0.466, 0.554, 0.802, 0.954, 0.948]\n",
      "iteration:  40  cost:  0.29228951294283073\n",
      "iteration:  41  cost:  0.3543017909457764\n",
      "iteration:  42  cost:  0.3461849228703592\n",
      "iteration:  43  cost:  0.4204644672022553\n",
      "iteration:  44  cost:  0.34321423994138506\n",
      "iteration:  45  cost:  0.46258406011909897\n",
      "iteration:  46  cost:  0.2403880333596833\n",
      "iteration:  47  cost:  0.22563883980347677\n",
      "iteration:  48  cost:  0.27810517554855546\n",
      "iteration:  49  cost:  0.3031704799773279\n",
      "[0.466, 0.554, 0.802, 0.954, 0.948, 0.954]\n",
      "iteration:  50  cost:  0.27680179248115805\n",
      "iteration:  51  cost:  0.233384177762049\n",
      "iteration:  52  cost:  0.233244971848782\n",
      "iteration:  53  cost:  0.19136353004642376\n",
      "iteration:  54  cost:  0.25256499340176036\n",
      "iteration:  55  cost:  0.22171574309802125\n",
      "iteration:  56  cost:  0.18047551355810657\n",
      "iteration:  57  cost:  0.38070818532219924\n",
      "iteration:  58  cost:  0.33630655258386066\n",
      "iteration:  59  cost:  0.30065009063776693\n",
      "[0.466, 0.554, 0.802, 0.954, 0.948, 0.954, 0.96]\n",
      "iteration:  60  cost:  0.15226832159524556\n",
      "iteration:  61  cost:  0.34194125244425694\n",
      "iteration:  62  cost:  0.3975582266537707\n",
      "iteration:  63  cost:  0.23414044029839445\n",
      "iteration:  64  cost:  0.3098677801636903\n",
      "iteration:  65  cost:  0.2954024717483844\n",
      "iteration:  66  cost:  0.20600503601980072\n",
      "iteration:  67  cost:  0.36909277075743285\n",
      "iteration:  68  cost:  0.288750751687943\n",
      "iteration:  69  cost:  0.2642805016111466\n",
      "[0.466, 0.554, 0.802, 0.954, 0.948, 0.954, 0.96, 0.956]\n",
      "iteration:  70  cost:  0.3647397193996545\n",
      "iteration:  71  cost:  0.3359835454114357\n",
      "iteration:  72  cost:  0.17645676412181563\n",
      "iteration:  73  cost:  0.304653354528002\n",
      "iteration:  74  cost:  0.23356417346841074\n",
      "iteration:  75  cost:  0.24637239033266517\n",
      "iteration:  76  cost:  0.31811083749878455\n",
      "iteration:  77  cost:  0.19219831487870315\n",
      "iteration:  78  cost:  0.23548743153230461\n",
      "iteration:  79  cost:  0.25499059917569566\n",
      "[0.466, 0.554, 0.802, 0.954, 0.948, 0.954, 0.96, 0.956, 0.964]\n",
      "iteration:  80  cost:  0.24985392961567893\n",
      "iteration:  81  cost:  0.17304680923477325\n",
      "iteration:  82  cost:  0.19461984451176956\n",
      "iteration:  83  cost:  0.27551497584970835\n",
      "iteration:  84  cost:  0.08922625013839697\n",
      "iteration:  85  cost:  0.147472660905593\n",
      "iteration:  86  cost:  0.560518066561722\n",
      "iteration:  87  cost:  0.2765313859089871\n",
      "iteration:  88  cost:  0.3012921679511406\n",
      "iteration:  89  cost:  0.2506188717282887\n",
      "[0.466, 0.554, 0.802, 0.954, 0.948, 0.954, 0.96, 0.956, 0.964, 0.968]\n",
      "iteration:  90  cost:  0.21127986380902913\n",
      "iteration:  91  cost:  0.2389515877915428\n",
      "iteration:  92  cost:  0.2263268314109183\n",
      "iteration:  93  cost:  0.4085882288615304\n",
      "iteration:  94  cost:  0.15506659755968077\n",
      "iteration:  95  cost:  0.17280988547979628\n",
      "iteration:  96  cost:  0.21521699592774357\n",
      "iteration:  97  cost:  0.32233484770228293\n",
      "iteration:  98  cost:  0.19790972062127613\n",
      "iteration:  99  cost:  0.23983071663292255\n",
      "[0.466, 0.554, 0.802, 0.954, 0.948, 0.954, 0.96, 0.956, 0.964, 0.968, 0.968]\n",
      "iteration:  100  cost:  0.34800322993442656\n",
      "iteration:  101  cost:  0.16278806872553261\n",
      "iteration:  102  cost:  0.148901956271956\n",
      "iteration:  103  cost:  0.2540622757722815\n",
      "iteration:  104  cost:  0.2818354499633962\n",
      "iteration:  105  cost:  0.2349134528253784\n",
      "iteration:  106  cost:  0.13707273590730934\n",
      "iteration:  107  cost:  0.2056003465101507\n",
      "iteration:  108  cost:  0.2847470881069811\n",
      "iteration:  109  cost:  0.212076080874156\n",
      "[0.466, 0.554, 0.802, 0.954, 0.948, 0.954, 0.96, 0.956, 0.964, 0.968, 0.968, 0.968]\n",
      "iteration:  110  cost:  0.2597532941968306\n",
      "iteration:  111  cost:  0.34224048075580527\n",
      "iteration:  112  cost:  0.16698637038717343\n",
      "iteration:  113  cost:  0.1721219950683812\n",
      "iteration:  114  cost:  0.19870704981627632\n",
      "iteration:  115  cost:  0.13086100582814975\n",
      "iteration:  116  cost:  0.12380320693545971\n",
      "iteration:  117  cost:  0.12433867194831372\n",
      "iteration:  118  cost:  0.2716648795861595\n",
      "iteration:  119  cost:  0.17097296817160493\n",
      "[0.466, 0.554, 0.802, 0.954, 0.948, 0.954, 0.96, 0.956, 0.964, 0.968, 0.968, 0.968, 0.972]\n",
      "iteration:  120  cost:  0.32101851846182833\n",
      "iteration:  121  cost:  0.17279442858969282\n",
      "iteration:  122  cost:  0.16949261861247944\n",
      "iteration:  123  cost:  0.24791501822140852\n",
      "iteration:  124  cost:  0.15079397870921007\n",
      "iteration:  125  cost:  0.14275624115666805\n",
      "iteration:  126  cost:  0.23837519201621749\n",
      "iteration:  127  cost:  0.21912178776225436\n",
      "iteration:  128  cost:  0.3035722360557842\n",
      "iteration:  129  cost:  0.15738318937085422\n",
      "[0.466, 0.554, 0.802, 0.954, 0.948, 0.954, 0.96, 0.956, 0.964, 0.968, 0.968, 0.968, 0.972, 0.972]\n",
      "iteration:  130  cost:  0.2379537271055286\n",
      "iteration:  131  cost:  0.3402658410039367\n",
      "iteration:  132  cost:  0.13515577356263064\n",
      "iteration:  133  cost:  0.27900151786187516\n",
      "iteration:  134  cost:  0.12988285482726472\n",
      "iteration:  135  cost:  0.19980007433964783\n",
      "iteration:  136  cost:  0.17199937714153607\n",
      "iteration:  137  cost:  0.18439123866532367\n",
      "iteration:  138  cost:  0.23531228000873244\n",
      "iteration:  139  cost:  0.15149394898110163\n",
      "[0.466, 0.554, 0.802, 0.954, 0.948, 0.954, 0.96, 0.956, 0.964, 0.968, 0.968, 0.968, 0.972, 0.972, 0.97]\n",
      "iteration:  140  cost:  0.14206648600694524\n",
      "iteration:  141  cost:  0.18119829422233713\n",
      "iteration:  142  cost:  0.1627193439367665\n",
      "iteration:  143  cost:  0.17589733354183557\n",
      "iteration:  144  cost:  0.2903770247361017\n",
      "iteration:  145  cost:  0.1471716147131911\n",
      "iteration:  146  cost:  0.1897105172162308\n",
      "iteration:  147  cost:  0.14684678229462617\n",
      "iteration:  148  cost:  0.23000910081544987\n",
      "iteration:  149  cost:  0.11040059601396848\n",
      "[0.466, 0.554, 0.802, 0.954, 0.948, 0.954, 0.96, 0.956, 0.964, 0.968, 0.968, 0.968, 0.972, 0.972, 0.97, 0.968]\n",
      "Accuracy for U_13 pca8 :0.9773049645390071\n",
      "\n",
      "\n",
      "Loss History for QCNN circuits, U_13 pca16\n",
      "[0.522]\n",
      "iteration:  0  cost:  0.9439605679792733\n",
      "iteration:  1  cost:  1.158543245023783\n",
      "iteration:  2  cost:  0.9212465831772046\n",
      "iteration:  3  cost:  1.2187140454379968\n",
      "iteration:  4  cost:  0.8335819379555158\n",
      "iteration:  5  cost:  1.0445376840647274\n",
      "iteration:  6  cost:  0.9737344260666894\n",
      "iteration:  7  cost:  0.8781912820951863\n",
      "iteration:  8  cost:  0.9000872030611666\n",
      "iteration:  9  cost:  0.8356250008021238\n",
      "[0.522, 0.534]\n",
      "iteration:  10  cost:  1.007361628872618\n",
      "iteration:  11  cost:  0.9086613646962942\n",
      "iteration:  12  cost:  1.1085985419489388\n",
      "iteration:  13  cost:  0.9403655869869203\n",
      "iteration:  14  cost:  0.8476096616058463\n",
      "iteration:  15  cost:  0.7861808053583151\n",
      "iteration:  16  cost:  0.8326356850254535\n",
      "iteration:  17  cost:  0.8446261364987849\n",
      "iteration:  18  cost:  0.8056469072154137\n",
      "iteration:  19  cost:  0.7825344323001453\n",
      "[0.522, 0.534, 0.69]\n",
      "iteration:  20  cost:  0.8377501170026871\n",
      "iteration:  21  cost:  0.8249735923691998\n",
      "iteration:  22  cost:  0.7237041613503492\n",
      "iteration:  23  cost:  0.7892872266724917\n",
      "iteration:  24  cost:  0.8895700829585198\n",
      "iteration:  25  cost:  0.7424249135057803\n",
      "iteration:  26  cost:  0.8943358787228859\n",
      "iteration:  27  cost:  0.7739547055720922\n",
      "iteration:  28  cost:  0.7871467763778588\n",
      "iteration:  29  cost:  0.7546450833016908\n",
      "[0.522, 0.534, 0.69, 0.764]\n",
      "iteration:  30  cost:  0.8128995303200115\n",
      "iteration:  31  cost:  0.8935332237458564\n",
      "iteration:  32  cost:  0.827910519824246\n",
      "iteration:  33  cost:  0.892747160576147\n",
      "iteration:  34  cost:  0.8367168218754871\n",
      "iteration:  35  cost:  0.7208762262815046\n",
      "iteration:  36  cost:  0.6406380051873417\n",
      "iteration:  37  cost:  0.6001851051165569\n",
      "iteration:  38  cost:  0.754127580928902\n",
      "iteration:  39  cost:  0.8772082379703714\n",
      "[0.522, 0.534, 0.69, 0.764, 0.818]\n",
      "iteration:  40  cost:  0.6867376693684412\n",
      "iteration:  41  cost:  0.8313735159761276\n",
      "iteration:  42  cost:  0.6569926515256541\n",
      "iteration:  43  cost:  0.6429278385765259\n",
      "iteration:  44  cost:  0.7123000136432276\n",
      "iteration:  45  cost:  0.5484527165359152\n",
      "iteration:  46  cost:  0.6618673807979755\n",
      "iteration:  47  cost:  0.5862596234598625\n",
      "iteration:  48  cost:  0.6456750530705884\n",
      "iteration:  49  cost:  0.6203629072164554\n",
      "[0.522, 0.534, 0.69, 0.764, 0.818, 0.89]\n",
      "iteration:  50  cost:  0.6478837421999182\n",
      "iteration:  51  cost:  0.533402194429812\n",
      "iteration:  52  cost:  0.6782956869617205\n",
      "iteration:  53  cost:  0.48244279947565233\n",
      "iteration:  54  cost:  0.46071112902751565\n",
      "iteration:  55  cost:  0.5604482093269134\n",
      "iteration:  56  cost:  0.48848984195624673\n",
      "iteration:  57  cost:  0.4774702144067816\n",
      "iteration:  58  cost:  0.5263084925661852\n",
      "iteration:  59  cost:  0.5502409839945551\n",
      "[0.522, 0.534, 0.69, 0.764, 0.818, 0.89, 0.926]\n",
      "iteration:  60  cost:  0.496276187894106\n",
      "iteration:  61  cost:  0.42085972847056424\n",
      "iteration:  62  cost:  0.49124890883095274\n",
      "iteration:  63  cost:  0.4500836326878586\n",
      "iteration:  64  cost:  0.5010493441238308\n",
      "iteration:  65  cost:  0.41075050526044493\n",
      "iteration:  66  cost:  0.4401026250822793\n",
      "iteration:  67  cost:  0.5645460591037672\n",
      "iteration:  68  cost:  0.49538914422256186\n",
      "iteration:  69  cost:  0.45101918945801\n",
      "[0.522, 0.534, 0.69, 0.764, 0.818, 0.89, 0.926, 0.938]\n",
      "iteration:  70  cost:  0.41289359165399625\n",
      "iteration:  71  cost:  0.3199746267650454\n",
      "iteration:  72  cost:  0.5346585893152196\n",
      "iteration:  73  cost:  0.3745923894556217\n",
      "iteration:  74  cost:  0.3801410081579364\n",
      "iteration:  75  cost:  0.387329843522512\n",
      "iteration:  76  cost:  0.4813555940468492\n",
      "iteration:  77  cost:  0.3533150952774482\n",
      "iteration:  78  cost:  0.33981288887124966\n",
      "iteration:  79  cost:  0.3082656400546555\n",
      "[0.522, 0.534, 0.69, 0.764, 0.818, 0.89, 0.926, 0.938, 0.958]\n",
      "iteration:  80  cost:  0.29736896552514136\n",
      "iteration:  81  cost:  0.36198325280139726\n",
      "iteration:  82  cost:  0.37932253076935285\n",
      "iteration:  83  cost:  0.2884604669920078\n",
      "iteration:  84  cost:  0.27085133114929755\n",
      "iteration:  85  cost:  0.37728621509671234\n",
      "iteration:  86  cost:  0.2934555636733943\n",
      "iteration:  87  cost:  0.3624535881243364\n",
      "iteration:  88  cost:  0.2582102359605304\n",
      "iteration:  89  cost:  0.4035898633677544\n",
      "[0.522, 0.534, 0.69, 0.764, 0.818, 0.89, 0.926, 0.938, 0.958, 0.958]\n",
      "iteration:  90  cost:  0.26988052108238336\n",
      "iteration:  91  cost:  0.24829497234665596\n",
      "iteration:  92  cost:  0.2661198939780525\n",
      "iteration:  93  cost:  0.30356360255146514\n",
      "iteration:  94  cost:  0.330601261640135\n",
      "iteration:  95  cost:  0.22802204475372176\n",
      "iteration:  96  cost:  0.33720115504550785\n",
      "iteration:  97  cost:  0.19809210369207167\n",
      "iteration:  98  cost:  0.15504638572815918\n",
      "iteration:  99  cost:  0.21296313072207615\n",
      "[0.522, 0.534, 0.69, 0.764, 0.818, 0.89, 0.926, 0.938, 0.958, 0.958, 0.964]\n",
      "iteration:  100  cost:  0.26115623802260246\n",
      "iteration:  101  cost:  0.24241208098065165\n",
      "iteration:  102  cost:  0.19758954310124038\n",
      "iteration:  103  cost:  0.24415729192145516\n",
      "iteration:  104  cost:  0.22050496188241278\n",
      "iteration:  105  cost:  0.3320596292168513\n",
      "iteration:  106  cost:  0.34157896128940707\n",
      "iteration:  107  cost:  0.2502851071075256\n",
      "iteration:  108  cost:  0.17838033117436997\n",
      "iteration:  109  cost:  0.32657198959810524\n",
      "[0.522, 0.534, 0.69, 0.764, 0.818, 0.89, 0.926, 0.938, 0.958, 0.958, 0.964, 0.966]\n",
      "iteration:  110  cost:  0.23982211002626305\n",
      "iteration:  111  cost:  0.24708070172021532\n",
      "iteration:  112  cost:  0.12894109649615138\n",
      "iteration:  113  cost:  0.33190928729684294\n",
      "iteration:  114  cost:  0.18434326127442943\n",
      "iteration:  115  cost:  0.30452692205719684\n",
      "iteration:  116  cost:  0.18033774517515172\n",
      "iteration:  117  cost:  0.1359466095248915\n",
      "iteration:  118  cost:  0.1777178074243313\n",
      "iteration:  119  cost:  0.23307029495296802\n",
      "[0.522, 0.534, 0.69, 0.764, 0.818, 0.89, 0.926, 0.938, 0.958, 0.958, 0.964, 0.966, 0.966]\n",
      "iteration:  120  cost:  0.22349967154579845\n",
      "iteration:  121  cost:  0.19989449915355137\n",
      "iteration:  122  cost:  0.3205468228779688\n",
      "iteration:  123  cost:  0.20876449632493121\n",
      "iteration:  124  cost:  0.24201298430915064\n",
      "iteration:  125  cost:  0.19323493058485405\n",
      "iteration:  126  cost:  0.2005622598655011\n",
      "iteration:  127  cost:  0.2824548251051733\n",
      "iteration:  128  cost:  0.26284021172159666\n",
      "iteration:  129  cost:  0.24839739231796623\n",
      "[0.522, 0.534, 0.69, 0.764, 0.818, 0.89, 0.926, 0.938, 0.958, 0.958, 0.964, 0.966, 0.966, 0.968]\n",
      "iteration:  130  cost:  0.19691108352511846\n",
      "iteration:  131  cost:  0.20144909567287594\n",
      "iteration:  132  cost:  0.25862917685507747\n",
      "iteration:  133  cost:  0.275726657052021\n",
      "iteration:  134  cost:  0.18646637682012596\n",
      "iteration:  135  cost:  0.1271299952001356\n",
      "iteration:  136  cost:  0.1662405819417154\n",
      "iteration:  137  cost:  0.3118783771560899\n",
      "iteration:  138  cost:  0.2038121224673998\n",
      "iteration:  139  cost:  0.16248548779982797\n",
      "[0.522, 0.534, 0.69, 0.764, 0.818, 0.89, 0.926, 0.938, 0.958, 0.958, 0.964, 0.966, 0.966, 0.968, 0.966]\n",
      "iteration:  140  cost:  0.13944068146812671\n",
      "iteration:  141  cost:  0.2937401441823286\n",
      "iteration:  142  cost:  0.20288173024322334\n",
      "iteration:  143  cost:  0.15627807938900248\n",
      "iteration:  144  cost:  0.12902842857730645\n",
      "iteration:  145  cost:  0.13760877002438268\n",
      "iteration:  146  cost:  0.44330599837516615\n",
      "iteration:  147  cost:  0.26230197606908784\n",
      "iteration:  148  cost:  0.2535700071233616\n",
      "iteration:  149  cost:  0.12131344250409237\n",
      "[0.522, 0.534, 0.69, 0.764, 0.818, 0.89, 0.926, 0.938, 0.958, 0.958, 0.964, 0.966, 0.966, 0.968, 0.966, 0.966]\n",
      "iteration:  150  cost:  0.15467274562557687\n",
      "iteration:  151  cost:  0.1648575129893507\n",
      "iteration:  152  cost:  0.19262088526524782\n",
      "iteration:  153  cost:  0.1292190133221583\n",
      "iteration:  154  cost:  0.39416916855293477\n",
      "iteration:  155  cost:  0.11323867292934602\n",
      "iteration:  156  cost:  0.21111208712056848\n",
      "iteration:  157  cost:  0.1312979625527483\n",
      "iteration:  158  cost:  0.2511551716551145\n",
      "iteration:  159  cost:  0.1381137970511263\n",
      "[0.522, 0.534, 0.69, 0.764, 0.818, 0.89, 0.926, 0.938, 0.958, 0.958, 0.964, 0.966, 0.966, 0.968, 0.966, 0.966, 0.968]\n",
      "iteration:  160  cost:  0.23326314044651789\n",
      "iteration:  161  cost:  0.18612163002244964\n",
      "iteration:  162  cost:  0.2828996275261241\n",
      "iteration:  163  cost:  0.22027723228272983\n",
      "iteration:  164  cost:  0.13468321954713486\n",
      "iteration:  165  cost:  0.2748106188995429\n",
      "iteration:  166  cost:  0.10648531644763247\n",
      "iteration:  167  cost:  0.1518525022092882\n",
      "iteration:  168  cost:  0.14853572090246037\n",
      "iteration:  169  cost:  0.14754580726206004\n",
      "[0.522, 0.534, 0.69, 0.764, 0.818, 0.89, 0.926, 0.938, 0.958, 0.958, 0.964, 0.966, 0.966, 0.968, 0.966, 0.966, 0.968, 0.962]\n",
      "Accuracy for U_13 pca16 :0.9721040189125295\n",
      "Epoch 1/10\n",
      "396/396 [==============================] - 1s 953us/step - loss: 0.1091 - val_loss: 0.0340\n",
      "Epoch 2/10\n",
      "396/396 [==============================] - 0s 740us/step - loss: 0.0318 - val_loss: 0.0259\n",
      "Epoch 3/10\n",
      "396/396 [==============================] - 0s 764us/step - loss: 0.0253 - val_loss: 0.0226\n",
      "Epoch 4/10\n",
      "396/396 [==============================] - 0s 784us/step - loss: 0.0225 - val_loss: 0.0207\n",
      "Epoch 5/10\n",
      "396/396 [==============================] - 0s 913us/step - loss: 0.0207 - val_loss: 0.0195\n",
      "Epoch 6/10\n",
      "396/396 [==============================] - 0s 756us/step - loss: 0.0198 - val_loss: 0.0189\n",
      "Epoch 7/10\n",
      "396/396 [==============================] - 0s 775us/step - loss: 0.0193 - val_loss: 0.0184\n",
      "Epoch 8/10\n",
      "396/396 [==============================] - 0s 759us/step - loss: 0.0185 - val_loss: 0.0179\n",
      "Epoch 9/10\n",
      "396/396 [==============================] - 0s 778us/step - loss: 0.0180 - val_loss: 0.0176\n",
      "Epoch 10/10\n",
      "396/396 [==============================] - 0s 784us/step - loss: 0.0179 - val_loss: 0.0174\n",
      "\n",
      "\n",
      "Loss History for QCNN circuits, U_13 autoencoder8\n",
      "[0.504]\n",
      "iteration:  0  cost:  1.6629022863718583\n",
      "iteration:  1  cost:  1.2898218566180555\n",
      "iteration:  2  cost:  1.3386977989266091\n",
      "iteration:  3  cost:  1.3047818823076773\n",
      "iteration:  4  cost:  0.9564362640029058\n",
      "iteration:  5  cost:  0.8395492898449836\n",
      "iteration:  6  cost:  1.2431782244819036\n",
      "iteration:  7  cost:  1.1963782122222457\n",
      "iteration:  8  cost:  1.1353294137218872\n",
      "iteration:  9  cost:  1.0315121162438858\n",
      "[0.504, 0.464]\n",
      "iteration:  10  cost:  0.9503532953225681\n",
      "iteration:  11  cost:  0.9957897349378725\n",
      "iteration:  12  cost:  0.9253512307981202\n",
      "iteration:  13  cost:  0.9178004425222471\n",
      "iteration:  14  cost:  0.8512088870032553\n",
      "iteration:  15  cost:  1.0544186771007766\n",
      "iteration:  16  cost:  1.0779620248177857\n",
      "iteration:  17  cost:  1.0639943991456804\n",
      "iteration:  18  cost:  0.715869816306048\n",
      "iteration:  19  cost:  0.9144707593735766\n",
      "[0.504, 0.464, 0.542]\n",
      "iteration:  20  cost:  1.0299678033110253\n",
      "iteration:  21  cost:  0.7688363031015909\n",
      "iteration:  22  cost:  0.865260695758224\n",
      "iteration:  23  cost:  0.8501281914559624\n",
      "iteration:  24  cost:  0.7399600499246328\n",
      "iteration:  25  cost:  0.7896727606113721\n",
      "iteration:  26  cost:  0.7571443674180859\n",
      "iteration:  27  cost:  0.5480219372925745\n",
      "iteration:  28  cost:  0.8395171486537876\n",
      "iteration:  29  cost:  0.7492479350930523\n",
      "[0.504, 0.464, 0.542, 0.626]\n",
      "iteration:  30  cost:  0.6255495943702152\n",
      "iteration:  31  cost:  0.655327246830174\n",
      "iteration:  32  cost:  0.8948852648306703\n",
      "iteration:  33  cost:  0.7239287512406151\n",
      "iteration:  34  cost:  0.6108966229428292\n",
      "iteration:  35  cost:  0.7686167591635866\n",
      "iteration:  36  cost:  0.7965897023973905\n",
      "iteration:  37  cost:  0.5865828688031779\n",
      "iteration:  38  cost:  0.6013241206004873\n",
      "iteration:  39  cost:  0.7505594011941248\n",
      "[0.504, 0.464, 0.542, 0.626, 0.816]\n",
      "iteration:  40  cost:  0.5990346710607265\n",
      "iteration:  41  cost:  0.7552514234829887\n",
      "iteration:  42  cost:  0.6412333465997\n",
      "iteration:  43  cost:  0.5384170905963217\n",
      "iteration:  44  cost:  0.636976818252676\n",
      "iteration:  45  cost:  0.7142123294296019\n",
      "iteration:  46  cost:  0.7615319761361634\n",
      "iteration:  47  cost:  0.610975746186002\n",
      "iteration:  48  cost:  0.6773644760606501\n",
      "iteration:  49  cost:  0.6769939053274502\n",
      "[0.504, 0.464, 0.542, 0.626, 0.816, 0.876]\n",
      "iteration:  50  cost:  0.6012558591598769\n",
      "iteration:  51  cost:  0.623895836599408\n",
      "iteration:  52  cost:  0.5655516895687266\n",
      "iteration:  53  cost:  0.5791656247116509\n",
      "iteration:  54  cost:  0.5614393547322455\n",
      "iteration:  55  cost:  0.6427551726330468\n",
      "iteration:  56  cost:  0.6029986867504129\n",
      "iteration:  57  cost:  0.547946980419014\n",
      "iteration:  58  cost:  0.5480155404913475\n",
      "iteration:  59  cost:  0.6073002682381635\n",
      "[0.504, 0.464, 0.542, 0.626, 0.816, 0.876, 0.906]\n",
      "iteration:  60  cost:  0.5796620986473277\n",
      "iteration:  61  cost:  0.5392174250055339\n",
      "iteration:  62  cost:  0.6478711787062734\n",
      "iteration:  63  cost:  0.5723324853548931\n",
      "iteration:  64  cost:  0.4942605494536152\n",
      "iteration:  65  cost:  0.6372482282007843\n",
      "iteration:  66  cost:  0.5116897159112962\n",
      "iteration:  67  cost:  0.564023464470138\n",
      "iteration:  68  cost:  0.5160950761640385\n",
      "iteration:  69  cost:  0.4583344219953293\n",
      "[0.504, 0.464, 0.542, 0.626, 0.816, 0.876, 0.906, 0.93]\n",
      "iteration:  70  cost:  0.4191260164627084\n",
      "iteration:  71  cost:  0.39111073969487575\n",
      "iteration:  72  cost:  0.5172013766965414\n",
      "iteration:  73  cost:  0.4508369353383151\n",
      "iteration:  74  cost:  0.5333184676044036\n",
      "iteration:  75  cost:  0.5181338193333505\n",
      "iteration:  76  cost:  0.37718925146909044\n",
      "iteration:  77  cost:  0.6867235910420431\n",
      "iteration:  78  cost:  0.4323727890803596\n",
      "iteration:  79  cost:  0.38422171282574696\n",
      "[0.504, 0.464, 0.542, 0.626, 0.816, 0.876, 0.906, 0.93, 0.914]\n",
      "iteration:  80  cost:  0.4884576358022531\n",
      "iteration:  81  cost:  0.3989704842121926\n",
      "iteration:  82  cost:  0.4592928058842207\n",
      "iteration:  83  cost:  0.3309355086451753\n",
      "iteration:  84  cost:  0.49607586480971816\n",
      "iteration:  85  cost:  0.5298878007826149\n",
      "iteration:  86  cost:  0.39484209699974615\n",
      "iteration:  87  cost:  0.45720861148270386\n",
      "iteration:  88  cost:  0.40123421693661654\n",
      "iteration:  89  cost:  0.45691646276489206\n",
      "[0.504, 0.464, 0.542, 0.626, 0.816, 0.876, 0.906, 0.93, 0.914, 0.948]\n",
      "iteration:  90  cost:  0.5361939466263478\n",
      "iteration:  91  cost:  0.48464365112307617\n",
      "iteration:  92  cost:  0.367135231406807\n",
      "iteration:  93  cost:  0.3631208204894278\n",
      "iteration:  94  cost:  0.38854225099518147\n",
      "iteration:  95  cost:  0.4486629293591126\n",
      "iteration:  96  cost:  0.41905113280305833\n",
      "iteration:  97  cost:  0.4880754411388496\n",
      "iteration:  98  cost:  0.3438830879949719\n",
      "iteration:  99  cost:  0.3554778299669416\n",
      "[0.504, 0.464, 0.542, 0.626, 0.816, 0.876, 0.906, 0.93, 0.914, 0.948, 0.94]\n",
      "iteration:  100  cost:  0.4226819523035234\n",
      "iteration:  101  cost:  0.41361110299944054\n",
      "iteration:  102  cost:  0.5100793777793547\n",
      "iteration:  103  cost:  0.4506691037839285\n",
      "iteration:  104  cost:  0.4469408984245042\n",
      "iteration:  105  cost:  0.5052169798939844\n",
      "iteration:  106  cost:  0.39509622504303393\n",
      "iteration:  107  cost:  0.47718096731344434\n",
      "iteration:  108  cost:  0.39235751114532247\n",
      "iteration:  109  cost:  0.4096897109449474\n",
      "[0.504, 0.464, 0.542, 0.626, 0.816, 0.876, 0.906, 0.93, 0.914, 0.948, 0.94, 0.944]\n",
      "iteration:  110  cost:  0.3812107696913741\n",
      "iteration:  111  cost:  0.44819907451740937\n",
      "iteration:  112  cost:  0.5279836115300395\n",
      "iteration:  113  cost:  0.3897013694300588\n",
      "iteration:  114  cost:  0.40634521635630927\n",
      "iteration:  115  cost:  0.38576222442324787\n",
      "iteration:  116  cost:  0.3436605569525129\n",
      "iteration:  117  cost:  0.2935644397492906\n",
      "iteration:  118  cost:  0.3763048621129622\n",
      "iteration:  119  cost:  0.375246038473742\n",
      "[0.504, 0.464, 0.542, 0.626, 0.816, 0.876, 0.906, 0.93, 0.914, 0.948, 0.94, 0.944, 0.938]\n",
      "Accuracy for U_13 autoencoder8 :0.9191489361702128\n",
      "Epoch 1/10\n",
      "396/396 [==============================] - 1s 1ms/step - loss: 0.0956 - val_loss: 0.0284\n",
      "Epoch 2/10\n",
      "396/396 [==============================] - 0s 780us/step - loss: 0.0268 - val_loss: 0.0219\n",
      "Epoch 3/10\n",
      "396/396 [==============================] - 0s 999us/step - loss: 0.0212 - val_loss: 0.0178\n",
      "Epoch 4/10\n",
      "396/396 [==============================] - 0s 796us/step - loss: 0.0175 - val_loss: 0.0152\n",
      "Epoch 5/10\n",
      "396/396 [==============================] - 0s 794us/step - loss: 0.0150 - val_loss: 0.0137\n",
      "Epoch 6/10\n",
      "396/396 [==============================] - 0s 833us/step - loss: 0.0137 - val_loss: 0.0127\n",
      "Epoch 7/10\n",
      "396/396 [==============================] - 0s 799us/step - loss: 0.0127 - val_loss: 0.0119\n",
      "Epoch 8/10\n",
      "396/396 [==============================] - 0s 809us/step - loss: 0.0119 - val_loss: 0.0115\n",
      "Epoch 9/10\n",
      "396/396 [==============================] - 0s 836us/step - loss: 0.0115 - val_loss: 0.0110\n",
      "Epoch 10/10\n",
      "396/396 [==============================] - 0s 805us/step - loss: 0.0112 - val_loss: 0.0107\n",
      "\n",
      "\n",
      "Loss History for QCNN circuits, U_13 autoencoder16\n",
      "[0.272]\n",
      "iteration:  0  cost:  1.2965397894664803\n",
      "iteration:  1  cost:  1.3711332156745653\n",
      "iteration:  2  cost:  1.4875260483183623\n",
      "iteration:  3  cost:  1.2672567502831789\n",
      "iteration:  4  cost:  1.246912365419334\n",
      "iteration:  5  cost:  1.3985467293042748\n",
      "iteration:  6  cost:  1.3469269676844713\n",
      "iteration:  7  cost:  1.3774546521411937\n",
      "iteration:  8  cost:  1.3673024827821962\n",
      "iteration:  9  cost:  1.3578079398785405\n",
      "[0.272, 0.284]\n",
      "iteration:  10  cost:  1.1558932280379188\n",
      "iteration:  11  cost:  1.2168471925171465\n",
      "iteration:  12  cost:  1.1648285270855605\n",
      "iteration:  13  cost:  1.3363661899971597\n",
      "iteration:  14  cost:  1.0185077458933463\n",
      "iteration:  15  cost:  1.0139749169587184\n",
      "iteration:  16  cost:  1.1750648767396819\n",
      "iteration:  17  cost:  0.9245515004775896\n",
      "iteration:  18  cost:  0.8804866795066075\n",
      "iteration:  19  cost:  0.8678170378866372\n",
      "[0.272, 0.284, 0.728]\n",
      "iteration:  20  cost:  0.8886889583001636\n",
      "iteration:  21  cost:  0.7873490280941162\n",
      "iteration:  22  cost:  0.7963120064914508\n",
      "iteration:  23  cost:  0.7539086363371887\n",
      "iteration:  24  cost:  0.6677118275362104\n",
      "iteration:  25  cost:  0.8115060057881271\n",
      "iteration:  26  cost:  0.6368622501668978\n",
      "iteration:  27  cost:  0.8466523745039344\n",
      "iteration:  28  cost:  0.665478190246899\n",
      "iteration:  29  cost:  0.6532598527382126\n",
      "[0.272, 0.284, 0.728, 0.85]\n",
      "iteration:  30  cost:  0.602027296320577\n",
      "iteration:  31  cost:  0.6086197944483788\n",
      "iteration:  32  cost:  0.5577089094106972\n",
      "iteration:  33  cost:  0.5564035400469298\n",
      "iteration:  34  cost:  0.6166602789153759\n",
      "iteration:  35  cost:  0.5521556263994087\n",
      "iteration:  36  cost:  0.8100181341735039\n",
      "iteration:  37  cost:  0.6753155650932762\n",
      "iteration:  38  cost:  0.6898415238351293\n",
      "iteration:  39  cost:  0.6342179597048225\n",
      "[0.272, 0.284, 0.728, 0.85, 0.862]\n",
      "iteration:  40  cost:  0.6504185479419223\n",
      "iteration:  41  cost:  0.5974588871544141\n",
      "iteration:  42  cost:  0.7309782052430174\n",
      "iteration:  43  cost:  0.6991291727921933\n",
      "iteration:  44  cost:  0.7216837938388171\n",
      "iteration:  45  cost:  0.4976193956148574\n",
      "iteration:  46  cost:  0.6998792607758676\n",
      "iteration:  47  cost:  0.5157905381971042\n",
      "iteration:  48  cost:  0.5418512190189603\n",
      "iteration:  49  cost:  0.6588943762832996\n",
      "[0.272, 0.284, 0.728, 0.85, 0.862, 0.848]\n",
      "iteration:  50  cost:  0.45519656785631324\n",
      "iteration:  51  cost:  0.41735891296059935\n",
      "iteration:  52  cost:  0.7818235109010668\n",
      "iteration:  53  cost:  0.5284377592376991\n",
      "iteration:  54  cost:  0.6885610762900127\n",
      "iteration:  55  cost:  0.5802163596564696\n",
      "iteration:  56  cost:  0.5524762396014735\n",
      "iteration:  57  cost:  0.4475285412065358\n",
      "iteration:  58  cost:  0.4590108573425424\n",
      "iteration:  59  cost:  0.6044403792193335\n",
      "[0.272, 0.284, 0.728, 0.85, 0.862, 0.848, 0.848]\n",
      "iteration:  60  cost:  0.597944451265931\n",
      "iteration:  61  cost:  0.5146257011460782\n",
      "iteration:  62  cost:  0.511571834253753\n",
      "iteration:  63  cost:  0.6183168060668536\n",
      "iteration:  64  cost:  0.6216794664607395\n",
      "iteration:  65  cost:  0.7105544882409833\n",
      "iteration:  66  cost:  0.5596890759855628\n",
      "iteration:  67  cost:  0.4770280770106629\n",
      "iteration:  68  cost:  0.6130373132588107\n",
      "iteration:  69  cost:  0.4040210665832551\n",
      "[0.272, 0.284, 0.728, 0.85, 0.862, 0.848, 0.848, 0.902]\n",
      "iteration:  70  cost:  0.6690464514823025\n",
      "iteration:  71  cost:  0.5719774089532981\n",
      "iteration:  72  cost:  0.4666147493963642\n",
      "iteration:  73  cost:  0.6222712292289208\n",
      "iteration:  74  cost:  0.6909204297271085\n",
      "iteration:  75  cost:  0.5598430844008196\n",
      "iteration:  76  cost:  0.5628161981051801\n",
      "iteration:  77  cost:  0.519526810475875\n",
      "iteration:  78  cost:  0.621391279001303\n",
      "iteration:  79  cost:  0.5549578714709242\n",
      "[0.272, 0.284, 0.728, 0.85, 0.862, 0.848, 0.848, 0.902, 0.892]\n",
      "iteration:  80  cost:  0.4874278514679345\n",
      "iteration:  81  cost:  0.7765545468400086\n",
      "iteration:  82  cost:  0.5657119099638023\n",
      "iteration:  83  cost:  0.4855250445860081\n",
      "iteration:  84  cost:  0.5932493967040995\n",
      "iteration:  85  cost:  0.4330411649222233\n",
      "iteration:  86  cost:  0.5306609455029965\n",
      "iteration:  87  cost:  0.4909914501954093\n",
      "iteration:  88  cost:  0.6121663314803364\n",
      "iteration:  89  cost:  0.5041844923620106\n",
      "[0.272, 0.284, 0.728, 0.85, 0.862, 0.848, 0.848, 0.902, 0.892, 0.876]\n",
      "iteration:  90  cost:  0.490846715338562\n",
      "iteration:  91  cost:  0.5493809207732201\n",
      "iteration:  92  cost:  0.5227836272195029\n",
      "iteration:  93  cost:  0.5671189403665666\n",
      "iteration:  94  cost:  0.5142419004802615\n",
      "iteration:  95  cost:  0.3725077888359637\n",
      "iteration:  96  cost:  0.459238852575185\n",
      "iteration:  97  cost:  0.5384575468859017\n",
      "iteration:  98  cost:  0.5237179101658921\n",
      "iteration:  99  cost:  0.6011049822297315\n",
      "[0.272, 0.284, 0.728, 0.85, 0.862, 0.848, 0.848, 0.902, 0.892, 0.876, 0.882]\n",
      "iteration:  100  cost:  0.4880473794139637\n",
      "iteration:  101  cost:  0.531788931623897\n",
      "iteration:  102  cost:  0.529015604001653\n",
      "iteration:  103  cost:  0.5684088737047714\n",
      "iteration:  104  cost:  0.635585095964435\n",
      "iteration:  105  cost:  0.568584602178061\n",
      "iteration:  106  cost:  0.544990204334808\n",
      "iteration:  107  cost:  0.504276898442587\n",
      "iteration:  108  cost:  0.5092586346288662\n",
      "iteration:  109  cost:  0.568940580559979\n",
      "[0.272, 0.284, 0.728, 0.85, 0.862, 0.848, 0.848, 0.902, 0.892, 0.876, 0.882, 0.892]\n",
      "iteration:  110  cost:  0.4591872693787842\n",
      "iteration:  111  cost:  0.41944663817044925\n",
      "iteration:  112  cost:  0.4026548945127525\n",
      "iteration:  113  cost:  0.603555210338458\n",
      "iteration:  114  cost:  0.5337384250161578\n",
      "iteration:  115  cost:  0.5303699032384257\n",
      "iteration:  116  cost:  0.6269492614485445\n",
      "iteration:  117  cost:  0.4820042541255292\n",
      "iteration:  118  cost:  0.429226041716667\n",
      "iteration:  119  cost:  0.5237610909491515\n",
      "[0.272, 0.284, 0.728, 0.85, 0.862, 0.848, 0.848, 0.902, 0.892, 0.876, 0.882, 0.892, 0.886]\n",
      "iteration:  120  cost:  0.4729238832952991\n",
      "iteration:  121  cost:  0.6296609082887304\n",
      "iteration:  122  cost:  0.535713739612492\n",
      "iteration:  123  cost:  0.5410546593316616\n",
      "iteration:  124  cost:  0.4352900342028405\n",
      "iteration:  125  cost:  0.575568461044252\n",
      "iteration:  126  cost:  0.5591587641468512\n",
      "iteration:  127  cost:  0.6491633196187827\n",
      "iteration:  128  cost:  0.4496165363779342\n",
      "iteration:  129  cost:  0.4053982906946823\n",
      "[0.272, 0.284, 0.728, 0.85, 0.862, 0.848, 0.848, 0.902, 0.892, 0.876, 0.882, 0.892, 0.886, 0.912]\n",
      "iteration:  130  cost:  0.5249593602067124\n",
      "iteration:  131  cost:  0.6075984328486255\n",
      "iteration:  132  cost:  0.5086895477059347\n",
      "iteration:  133  cost:  0.5547603728396916\n",
      "iteration:  134  cost:  0.48972995550644405\n",
      "iteration:  135  cost:  0.42472821464014965\n",
      "iteration:  136  cost:  0.5830493818128164\n",
      "iteration:  137  cost:  0.5148376052969974\n",
      "iteration:  138  cost:  0.5313713659530941\n",
      "iteration:  139  cost:  0.5011530026538541\n",
      "[0.272, 0.284, 0.728, 0.85, 0.862, 0.848, 0.848, 0.902, 0.892, 0.876, 0.882, 0.892, 0.886, 0.912, 0.902]\n",
      "iteration:  140  cost:  0.43195707961811863\n",
      "iteration:  141  cost:  0.5809086676217942\n",
      "iteration:  142  cost:  0.44542420349483836\n",
      "iteration:  143  cost:  0.6207333001728401\n",
      "iteration:  144  cost:  0.5881540879606453\n",
      "iteration:  145  cost:  0.4924802631838585\n",
      "iteration:  146  cost:  0.5768125270260552\n",
      "iteration:  147  cost:  0.48326692075191047\n",
      "iteration:  148  cost:  0.615894985772968\n",
      "iteration:  149  cost:  0.6476941497185099\n",
      "[0.272, 0.284, 0.728, 0.85, 0.862, 0.848, 0.848, 0.902, 0.892, 0.876, 0.882, 0.892, 0.886, 0.912, 0.902, 0.9]\n",
      "iteration:  150  cost:  0.43993946396180783\n",
      "iteration:  151  cost:  0.4716707523681425\n",
      "iteration:  152  cost:  0.35502457680690985\n",
      "iteration:  153  cost:  0.4503083698823366\n",
      "iteration:  154  cost:  0.47162143906693826\n",
      "iteration:  155  cost:  0.3911834807650274\n",
      "iteration:  156  cost:  0.42853054608542435\n",
      "iteration:  157  cost:  0.467261082981489\n",
      "iteration:  158  cost:  0.5110731714315605\n",
      "iteration:  159  cost:  0.5059604456186955\n",
      "[0.272, 0.284, 0.728, 0.85, 0.862, 0.848, 0.848, 0.902, 0.892, 0.876, 0.882, 0.892, 0.886, 0.912, 0.902, 0.9, 0.874]\n",
      "Accuracy for U_13 autoencoder16 :0.88274231678487\n",
      "\n",
      "\n",
      "Loss History for QCNN circuits, U_14 resize256\n",
      "[0.538]\n",
      "iteration:  0  cost:  1.0430678539933227\n",
      "iteration:  1  cost:  1.0067612116239226\n",
      "iteration:  2  cost:  1.1049837977152461\n",
      "iteration:  3  cost:  1.059521138794194\n",
      "iteration:  4  cost:  1.0212893133607468\n",
      "iteration:  5  cost:  0.9703359249087065\n",
      "iteration:  6  cost:  0.9887372838370243\n",
      "iteration:  7  cost:  0.9071936937726502\n",
      "iteration:  8  cost:  0.8711554303767154\n",
      "iteration:  9  cost:  0.9140111414152698\n",
      "[0.538, 0.698]\n",
      "iteration:  10  cost:  0.9265376224484982\n",
      "iteration:  11  cost:  0.917085502178938\n",
      "iteration:  12  cost:  0.8756210330666134\n",
      "iteration:  13  cost:  0.9928612649360912\n",
      "iteration:  14  cost:  0.9718026864351086\n",
      "iteration:  15  cost:  0.923559633630319\n",
      "iteration:  16  cost:  0.9345472515448777\n",
      "iteration:  17  cost:  0.9089391398782005\n",
      "iteration:  18  cost:  0.8951609582095408\n",
      "iteration:  19  cost:  0.8604114527949435\n",
      "[0.538, 0.698, 0.876]\n",
      "iteration:  20  cost:  0.8031982362766885\n",
      "iteration:  21  cost:  0.8278085151220793\n",
      "iteration:  22  cost:  0.8445435816778465\n",
      "iteration:  23  cost:  0.8393187741049506\n",
      "iteration:  24  cost:  0.8966414985244725\n",
      "iteration:  25  cost:  0.8161387596751749\n",
      "iteration:  26  cost:  0.8509426289399596\n",
      "iteration:  27  cost:  0.819827056542565\n",
      "iteration:  28  cost:  0.8576071763184454\n",
      "iteration:  29  cost:  0.88425915036076\n",
      "[0.538, 0.698, 0.876, 0.902]\n",
      "iteration:  30  cost:  0.8683198548984398\n",
      "iteration:  31  cost:  0.7826218428594474\n",
      "iteration:  32  cost:  0.8145460980968541\n",
      "iteration:  33  cost:  0.7182686572058092\n",
      "iteration:  34  cost:  0.810203024707886\n",
      "iteration:  35  cost:  0.7399594567189726\n",
      "iteration:  36  cost:  0.7923683713056223\n",
      "iteration:  37  cost:  0.7802767547189262\n",
      "iteration:  38  cost:  0.7936777054256866\n",
      "iteration:  39  cost:  0.8209758044948213\n",
      "[0.538, 0.698, 0.876, 0.902, 0.874]\n",
      "iteration:  40  cost:  0.7770208746448308\n",
      "iteration:  41  cost:  0.7766655550035486\n",
      "iteration:  42  cost:  0.7272475002812396\n",
      "iteration:  43  cost:  0.6914782024480723\n",
      "iteration:  44  cost:  0.7916806455925917\n",
      "iteration:  45  cost:  0.7608569292383917\n",
      "iteration:  46  cost:  0.7797201957440456\n",
      "iteration:  47  cost:  0.7493534846480234\n",
      "iteration:  48  cost:  0.7352531381185254\n",
      "iteration:  49  cost:  0.7251268321848279\n",
      "[0.538, 0.698, 0.876, 0.902, 0.874, 0.818]\n",
      "Accuracy for U_14 resize256 :0.8052009456264776\n",
      "\n",
      "\n",
      "Loss History for QCNN circuits, U_14 pca8\n",
      "[0.454]\n",
      "iteration:  0  cost:  1.0983420009554896\n",
      "iteration:  1  cost:  1.0251179469988452\n",
      "iteration:  2  cost:  0.9963526035254029\n",
      "iteration:  3  cost:  1.012276939244145\n",
      "iteration:  4  cost:  0.9815604984232074\n",
      "iteration:  5  cost:  0.9953835924286396\n",
      "iteration:  6  cost:  1.108207678041208\n",
      "iteration:  7  cost:  0.9881214222790317\n",
      "iteration:  8  cost:  0.9086504102439206\n",
      "iteration:  9  cost:  0.8201752258578832\n",
      "[0.454, 0.694]\n",
      "iteration:  10  cost:  0.9081963098658222\n",
      "iteration:  11  cost:  0.7917377983462134\n",
      "iteration:  12  cost:  0.889577401928494\n",
      "iteration:  13  cost:  0.8071860196173897\n",
      "iteration:  14  cost:  0.7852795802873043\n",
      "iteration:  15  cost:  0.8704022966511274\n",
      "iteration:  16  cost:  0.6836844439312503\n",
      "iteration:  17  cost:  0.7938458309987142\n",
      "iteration:  18  cost:  0.7859055743561236\n",
      "iteration:  19  cost:  0.642316975062097\n",
      "[0.454, 0.694, 0.834]\n",
      "iteration:  20  cost:  0.6361393489082193\n",
      "iteration:  21  cost:  0.7642809932909319\n",
      "iteration:  22  cost:  0.5889508293103405\n",
      "iteration:  23  cost:  0.6079683734308293\n",
      "iteration:  24  cost:  0.5879811331959249\n",
      "iteration:  25  cost:  0.5217675570288232\n",
      "iteration:  26  cost:  0.6356119435583009\n",
      "iteration:  27  cost:  0.47400003702507215\n",
      "iteration:  28  cost:  0.4776595269585209\n",
      "iteration:  29  cost:  0.46442330879981325\n",
      "[0.454, 0.694, 0.834, 0.942]\n",
      "iteration:  30  cost:  0.5302485767214223\n",
      "iteration:  31  cost:  0.5301173413827797\n",
      "iteration:  32  cost:  0.5974801958625031\n",
      "iteration:  33  cost:  0.4395332298705618\n",
      "iteration:  34  cost:  0.5474611071409416\n",
      "iteration:  35  cost:  0.46391165589265443\n",
      "iteration:  36  cost:  0.5513792297296521\n",
      "iteration:  37  cost:  0.4238734761322928\n",
      "iteration:  38  cost:  0.4453364812663233\n",
      "iteration:  39  cost:  0.433659443641795\n",
      "[0.454, 0.694, 0.834, 0.942, 0.968]\n",
      "iteration:  40  cost:  0.5376034717837517\n",
      "iteration:  41  cost:  0.48363790729635475\n",
      "iteration:  42  cost:  0.4062643309509677\n",
      "iteration:  43  cost:  0.3938530836141054\n",
      "iteration:  44  cost:  0.4220140567266138\n",
      "iteration:  45  cost:  0.41338898303632954\n",
      "iteration:  46  cost:  0.3267839758938601\n",
      "iteration:  47  cost:  0.4335576807559767\n",
      "iteration:  48  cost:  0.32892793070095855\n",
      "iteration:  49  cost:  0.30632335101966635\n",
      "[0.454, 0.694, 0.834, 0.942, 0.968, 0.966]\n",
      "iteration:  50  cost:  0.5191604738766222\n",
      "iteration:  51  cost:  0.37989899077511824\n",
      "iteration:  52  cost:  0.3431012437480071\n",
      "iteration:  53  cost:  0.3059110566975691\n",
      "iteration:  54  cost:  0.282881084412255\n",
      "iteration:  55  cost:  0.35435258554752425\n",
      "iteration:  56  cost:  0.33273003085232966\n",
      "iteration:  57  cost:  0.3656831176014111\n",
      "iteration:  58  cost:  0.3229830112313837\n",
      "iteration:  59  cost:  0.2502899177316854\n",
      "[0.454, 0.694, 0.834, 0.942, 0.968, 0.966, 0.976]\n",
      "iteration:  60  cost:  0.24034140496148917\n",
      "iteration:  61  cost:  0.2734084612984692\n",
      "iteration:  62  cost:  0.24572961594975293\n",
      "iteration:  63  cost:  0.26131060075494866\n",
      "iteration:  64  cost:  0.2928048834474101\n",
      "iteration:  65  cost:  0.25961929052978194\n",
      "iteration:  66  cost:  0.21638067394912583\n",
      "iteration:  67  cost:  0.318024239788028\n",
      "iteration:  68  cost:  0.23654917342223442\n",
      "iteration:  69  cost:  0.27611857428491016\n",
      "[0.454, 0.694, 0.834, 0.942, 0.968, 0.966, 0.976, 0.976]\n",
      "iteration:  70  cost:  0.3518526871597555\n",
      "iteration:  71  cost:  0.27722704833057554\n",
      "iteration:  72  cost:  0.311186694339057\n",
      "iteration:  73  cost:  0.3600459654590518\n",
      "iteration:  74  cost:  0.29816383675083635\n",
      "iteration:  75  cost:  0.30137590436415523\n",
      "iteration:  76  cost:  0.23608699748393458\n",
      "iteration:  77  cost:  0.23199719223349477\n",
      "iteration:  78  cost:  0.2779750750522772\n",
      "iteration:  79  cost:  0.16414660862738178\n",
      "[0.454, 0.694, 0.834, 0.942, 0.968, 0.966, 0.976, 0.976, 0.976]\n",
      "iteration:  80  cost:  0.24000075326763717\n",
      "iteration:  81  cost:  0.2426395243899265\n",
      "iteration:  82  cost:  0.24759201048952043\n",
      "iteration:  83  cost:  0.3177074030824757\n",
      "iteration:  84  cost:  0.29027924083500806\n",
      "iteration:  85  cost:  0.23235120888148264\n",
      "iteration:  86  cost:  0.2449238533675862\n",
      "iteration:  87  cost:  0.22036666663994456\n",
      "iteration:  88  cost:  0.294157367189319\n",
      "iteration:  89  cost:  0.2110491705363832\n",
      "[0.454, 0.694, 0.834, 0.942, 0.968, 0.966, 0.976, 0.976, 0.976, 0.976]\n",
      "iteration:  90  cost:  0.2934628706126423\n",
      "iteration:  91  cost:  0.12134408877192428\n",
      "iteration:  92  cost:  0.1882315105576621\n",
      "iteration:  93  cost:  0.2754704079661416\n",
      "iteration:  94  cost:  0.3347530899477892\n",
      "iteration:  95  cost:  0.15362451126645327\n",
      "iteration:  96  cost:  0.19971922243974594\n",
      "iteration:  97  cost:  0.23123053674355667\n",
      "iteration:  98  cost:  0.19239152003297005\n",
      "iteration:  99  cost:  0.1915584511461129\n",
      "[0.454, 0.694, 0.834, 0.942, 0.968, 0.966, 0.976, 0.976, 0.976, 0.976, 0.976]\n",
      "iteration:  100  cost:  0.3830446315689953\n",
      "iteration:  101  cost:  0.29207833846371817\n",
      "iteration:  102  cost:  0.2040242969003829\n",
      "iteration:  103  cost:  0.23037623734735754\n",
      "iteration:  104  cost:  0.15262350526378124\n",
      "iteration:  105  cost:  0.4257353067923013\n",
      "iteration:  106  cost:  0.27239780698098626\n",
      "iteration:  107  cost:  0.2254768287526577\n",
      "iteration:  108  cost:  0.29457878941421656\n",
      "iteration:  109  cost:  0.24682143030318682\n",
      "[0.454, 0.694, 0.834, 0.942, 0.968, 0.966, 0.976, 0.976, 0.976, 0.976, 0.976, 0.976]\n",
      "iteration:  110  cost:  0.25910509798498366\n",
      "iteration:  111  cost:  0.19780497273656678\n",
      "iteration:  112  cost:  0.1842623621690845\n",
      "iteration:  113  cost:  0.2203054839174879\n",
      "iteration:  114  cost:  0.21585417182686847\n",
      "iteration:  115  cost:  0.18503036810551035\n",
      "iteration:  116  cost:  0.36066647514642386\n",
      "iteration:  117  cost:  0.32360126035002457\n",
      "iteration:  118  cost:  0.3101175526596758\n",
      "iteration:  119  cost:  0.29777234883111087\n",
      "[0.454, 0.694, 0.834, 0.942, 0.968, 0.966, 0.976, 0.976, 0.976, 0.976, 0.976, 0.976, 0.976]\n",
      "iteration:  120  cost:  0.40103773244823543\n",
      "iteration:  121  cost:  0.22178402640271816\n",
      "iteration:  122  cost:  0.2961822753293743\n",
      "iteration:  123  cost:  0.20835029134731645\n",
      "iteration:  124  cost:  0.12519974136513823\n",
      "iteration:  125  cost:  0.165796189072588\n",
      "iteration:  126  cost:  0.21562910508360492\n",
      "iteration:  127  cost:  0.1894116931889555\n",
      "iteration:  128  cost:  0.17003810915496184\n",
      "iteration:  129  cost:  0.18154077291863094\n",
      "[0.454, 0.694, 0.834, 0.942, 0.968, 0.966, 0.976, 0.976, 0.976, 0.976, 0.976, 0.976, 0.976, 0.976]\n",
      "iteration:  130  cost:  0.13952112865114036\n",
      "iteration:  131  cost:  0.297536526432137\n",
      "iteration:  132  cost:  0.22351672410377305\n",
      "iteration:  133  cost:  0.1894139854261425\n",
      "iteration:  134  cost:  0.3143447919027323\n",
      "iteration:  135  cost:  0.1520541824283128\n",
      "iteration:  136  cost:  0.25864003621709386\n",
      "iteration:  137  cost:  0.31368597254857433\n",
      "iteration:  138  cost:  0.16330716660215816\n",
      "iteration:  139  cost:  0.14523192797320805\n",
      "[0.454, 0.694, 0.834, 0.942, 0.968, 0.966, 0.976, 0.976, 0.976, 0.976, 0.976, 0.976, 0.976, 0.976, 0.974]\n",
      "Accuracy for U_14 pca8 :0.968321513002364\n",
      "\n",
      "\n",
      "Loss History for QCNN circuits, U_14 pca16\n",
      "[0.636]\n",
      "iteration:  0  cost:  0.9511504827305299\n",
      "iteration:  1  cost:  0.882930849050385\n",
      "iteration:  2  cost:  0.9252478971068747\n",
      "iteration:  3  cost:  1.0120064320516802\n",
      "iteration:  4  cost:  0.9589149122986821\n",
      "iteration:  5  cost:  0.9038566137943096\n",
      "iteration:  6  cost:  0.9232941483021954\n",
      "iteration:  7  cost:  0.921244176057657\n",
      "iteration:  8  cost:  0.8118048134039015\n",
      "iteration:  9  cost:  0.8779385405725165\n",
      "[0.636, 0.722]\n",
      "iteration:  10  cost:  0.9205916136032899\n",
      "iteration:  11  cost:  0.8191146946033626\n",
      "iteration:  12  cost:  0.8799491719431545\n",
      "iteration:  13  cost:  0.8782211876415876\n",
      "iteration:  14  cost:  0.8155832994633943\n",
      "iteration:  15  cost:  0.8010583095121114\n",
      "iteration:  16  cost:  0.7804243934118437\n",
      "iteration:  17  cost:  0.8574353401791024\n",
      "iteration:  18  cost:  0.8407210271979183\n",
      "iteration:  19  cost:  0.8120701223706114\n",
      "[0.636, 0.722, 0.812]\n",
      "iteration:  20  cost:  0.8225265073836421\n",
      "iteration:  21  cost:  0.843538490781744\n",
      "iteration:  22  cost:  0.7246577087493554\n",
      "iteration:  23  cost:  0.7372246770149218\n",
      "iteration:  24  cost:  0.7124176841880933\n",
      "iteration:  25  cost:  0.7027279327282399\n",
      "iteration:  26  cost:  0.8078495575571977\n",
      "iteration:  27  cost:  0.6905391948352184\n",
      "iteration:  28  cost:  0.7538904242199116\n",
      "iteration:  29  cost:  0.7239175880806641\n",
      "[0.636, 0.722, 0.812, 0.916]\n",
      "iteration:  30  cost:  0.6883757634788408\n",
      "iteration:  31  cost:  0.6537149715472159\n",
      "iteration:  32  cost:  0.7204546369857927\n",
      "iteration:  33  cost:  0.6931582930466856\n",
      "iteration:  34  cost:  0.5932286936501268\n",
      "iteration:  35  cost:  0.6656611727592755\n",
      "iteration:  36  cost:  0.6817878219471057\n",
      "iteration:  37  cost:  0.5606883244643412\n",
      "iteration:  38  cost:  0.628618450375737\n",
      "iteration:  39  cost:  0.5379666268331953\n",
      "[0.636, 0.722, 0.812, 0.916, 0.946]\n",
      "iteration:  40  cost:  0.5360488778958941\n",
      "iteration:  41  cost:  0.5182584295908568\n",
      "iteration:  42  cost:  0.573790595887224\n",
      "iteration:  43  cost:  0.5704278054337216\n",
      "iteration:  44  cost:  0.4875261880690543\n",
      "iteration:  45  cost:  0.6115276937190002\n",
      "iteration:  46  cost:  0.5315601896397107\n",
      "iteration:  47  cost:  0.46207595815505237\n",
      "iteration:  48  cost:  0.4536401880898422\n",
      "iteration:  49  cost:  0.48093240921467095\n",
      "[0.636, 0.722, 0.812, 0.916, 0.946, 0.954]\n",
      "iteration:  50  cost:  0.48014735152413246\n",
      "iteration:  51  cost:  0.40572031697890504\n",
      "iteration:  52  cost:  0.5007894491963373\n",
      "iteration:  53  cost:  0.37927706730877103\n",
      "iteration:  54  cost:  0.45949690204881144\n",
      "iteration:  55  cost:  0.3792599578595993\n",
      "iteration:  56  cost:  0.3314464686573194\n",
      "iteration:  57  cost:  0.4594296824778168\n",
      "iteration:  58  cost:  0.3562566240723002\n",
      "iteration:  59  cost:  0.4253859991717123\n",
      "[0.636, 0.722, 0.812, 0.916, 0.946, 0.954, 0.958]\n",
      "iteration:  60  cost:  0.4255707486320459\n",
      "iteration:  61  cost:  0.2804927900722852\n",
      "iteration:  62  cost:  0.41641121320972396\n",
      "iteration:  63  cost:  0.3524533065155232\n",
      "iteration:  64  cost:  0.37819403116527167\n",
      "iteration:  65  cost:  0.32599394597327874\n",
      "iteration:  66  cost:  0.4394944853386169\n",
      "iteration:  67  cost:  0.4527850483133924\n",
      "iteration:  68  cost:  0.34722762050085587\n",
      "iteration:  69  cost:  0.4070277234515352\n",
      "[0.636, 0.722, 0.812, 0.916, 0.946, 0.954, 0.958, 0.96]\n",
      "iteration:  70  cost:  0.4278564168940936\n",
      "iteration:  71  cost:  0.37072947968255365\n",
      "iteration:  72  cost:  0.30282782355256943\n",
      "iteration:  73  cost:  0.35624952123659365\n",
      "iteration:  74  cost:  0.374637252851356\n",
      "iteration:  75  cost:  0.374569540573405\n",
      "iteration:  76  cost:  0.3595588270469007\n",
      "iteration:  77  cost:  0.3322594551676844\n",
      "iteration:  78  cost:  0.3903629451252064\n",
      "iteration:  79  cost:  0.2908448568468773\n",
      "[0.636, 0.722, 0.812, 0.916, 0.946, 0.954, 0.958, 0.96, 0.96]\n",
      "iteration:  80  cost:  0.3568880335946152\n",
      "iteration:  81  cost:  0.27823838774625126\n",
      "iteration:  82  cost:  0.3451158528236323\n",
      "iteration:  83  cost:  0.3086217402362823\n",
      "iteration:  84  cost:  0.29688838237263626\n",
      "iteration:  85  cost:  0.2918692235822561\n",
      "iteration:  86  cost:  0.26051921495584035\n",
      "iteration:  87  cost:  0.305279695003982\n",
      "iteration:  88  cost:  0.25197910811998964\n",
      "iteration:  89  cost:  0.2693303026100133\n",
      "[0.636, 0.722, 0.812, 0.916, 0.946, 0.954, 0.958, 0.96, 0.96, 0.962]\n",
      "iteration:  90  cost:  0.24592407632802563\n",
      "iteration:  91  cost:  0.35935566122498186\n",
      "iteration:  92  cost:  0.267235971422054\n",
      "iteration:  93  cost:  0.2846775395323361\n",
      "iteration:  94  cost:  0.355280062051503\n",
      "iteration:  95  cost:  0.39178902333756105\n",
      "iteration:  96  cost:  0.39888150399016387\n",
      "iteration:  97  cost:  0.30992569747307924\n",
      "iteration:  98  cost:  0.3046297738040245\n",
      "iteration:  99  cost:  0.26847709184908236\n",
      "[0.636, 0.722, 0.812, 0.916, 0.946, 0.954, 0.958, 0.96, 0.96, 0.962, 0.962]\n",
      "iteration:  100  cost:  0.3245938100008376\n",
      "iteration:  101  cost:  0.3174923056631591\n",
      "iteration:  102  cost:  0.22624619697320664\n",
      "iteration:  103  cost:  0.3112166945243548\n",
      "iteration:  104  cost:  0.30217173208822234\n",
      "iteration:  105  cost:  0.2758878689968003\n",
      "iteration:  106  cost:  0.3097348703019574\n",
      "iteration:  107  cost:  0.2727207946867838\n",
      "iteration:  108  cost:  0.22558938812944632\n",
      "iteration:  109  cost:  0.20248189358137306\n",
      "[0.636, 0.722, 0.812, 0.916, 0.946, 0.954, 0.958, 0.96, 0.96, 0.962, 0.962, 0.964]\n",
      "iteration:  110  cost:  0.32325983875755704\n",
      "iteration:  111  cost:  0.3097324033496895\n",
      "iteration:  112  cost:  0.26606743614421996\n",
      "iteration:  113  cost:  0.2795987476806131\n",
      "iteration:  114  cost:  0.2698796382030939\n",
      "iteration:  115  cost:  0.2773919338371086\n",
      "iteration:  116  cost:  0.3402786437449681\n",
      "iteration:  117  cost:  0.3017973892368677\n",
      "iteration:  118  cost:  0.30264571174997984\n",
      "iteration:  119  cost:  0.34579928599931675\n",
      "[0.636, 0.722, 0.812, 0.916, 0.946, 0.954, 0.958, 0.96, 0.96, 0.962, 0.962, 0.964, 0.964]\n",
      "iteration:  120  cost:  0.3124789730711654\n",
      "iteration:  121  cost:  0.3220477214254442\n",
      "iteration:  122  cost:  0.2800693938112297\n",
      "iteration:  123  cost:  0.2711976182678897\n",
      "iteration:  124  cost:  0.30759497717331125\n",
      "iteration:  125  cost:  0.29254001084503684\n",
      "iteration:  126  cost:  0.34847468411037424\n",
      "iteration:  127  cost:  0.2625978989314006\n",
      "iteration:  128  cost:  0.26200643399993917\n",
      "iteration:  129  cost:  0.30081873775121076\n",
      "[0.636, 0.722, 0.812, 0.916, 0.946, 0.954, 0.958, 0.96, 0.96, 0.962, 0.962, 0.964, 0.964, 0.96]\n",
      "Accuracy for U_14 pca16 :0.9839243498817967\n",
      "Epoch 1/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.1075 - val_loss: 0.0378\n",
      "Epoch 2/10\n",
      "396/396 [==============================] - 1s 1ms/step - loss: 0.0339 - val_loss: 0.0268\n",
      "Epoch 3/10\n",
      "396/396 [==============================] - 1s 1ms/step - loss: 0.0263 - val_loss: 0.0234\n",
      "Epoch 4/10\n",
      "396/396 [==============================] - 1s 1ms/step - loss: 0.0233 - val_loss: 0.0217\n",
      "Epoch 5/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.0218 - val_loss: 0.0205\n",
      "Epoch 6/10\n",
      "396/396 [==============================] - 1s 1ms/step - loss: 0.0208 - val_loss: 0.0198\n",
      "Epoch 7/10\n",
      "396/396 [==============================] - 1s 1ms/step - loss: 0.0199 - val_loss: 0.0191\n",
      "Epoch 8/10\n",
      "396/396 [==============================] - 1s 1ms/step - loss: 0.0193 - val_loss: 0.0186\n",
      "Epoch 9/10\n",
      "396/396 [==============================] - 1s 1ms/step - loss: 0.0189 - val_loss: 0.0182\n",
      "Epoch 10/10\n",
      "396/396 [==============================] - 1s 1ms/step - loss: 0.0185 - val_loss: 0.0179\n",
      "\n",
      "\n",
      "Loss History for QCNN circuits, U_14 autoencoder8\n",
      "[0.264]\n",
      "iteration:  0  cost:  1.1026248214604424\n",
      "iteration:  1  cost:  1.1158655010066825\n",
      "iteration:  2  cost:  1.0910870883883252\n",
      "iteration:  3  cost:  1.0266895945841576\n",
      "iteration:  4  cost:  1.0771393721200127\n",
      "iteration:  5  cost:  1.0217808146213196\n",
      "iteration:  6  cost:  1.0054482568532797\n",
      "iteration:  7  cost:  0.9882078397432862\n",
      "iteration:  8  cost:  0.9858956043999673\n",
      "iteration:  9  cost:  0.9321212059669363\n",
      "[0.264, 0.738]\n",
      "iteration:  10  cost:  0.9356982995511894\n",
      "iteration:  11  cost:  0.9327398089593367\n",
      "iteration:  12  cost:  0.8821410726751969\n",
      "iteration:  13  cost:  0.9048138878544502\n",
      "iteration:  14  cost:  0.8572596737877456\n",
      "iteration:  15  cost:  0.8178453353790424\n",
      "iteration:  16  cost:  0.8091327549562465\n",
      "iteration:  17  cost:  0.8234837088476007\n",
      "iteration:  18  cost:  0.718789281634602\n",
      "iteration:  19  cost:  0.8128800119109562\n",
      "[0.264, 0.738, 0.904]\n",
      "iteration:  20  cost:  0.7099102363696201\n",
      "iteration:  21  cost:  0.7652417003223007\n",
      "iteration:  22  cost:  0.7694071513728479\n",
      "iteration:  23  cost:  0.7053699743965478\n",
      "iteration:  24  cost:  0.7391217914218609\n",
      "iteration:  25  cost:  0.7011474248444624\n",
      "iteration:  26  cost:  0.7394378684595653\n",
      "iteration:  27  cost:  0.6603693329294168\n",
      "iteration:  28  cost:  0.7126306957923148\n",
      "iteration:  29  cost:  0.7186764754852607\n",
      "[0.264, 0.738, 0.904, 0.906]\n",
      "iteration:  30  cost:  0.7463656948381275\n",
      "iteration:  31  cost:  0.6675090053574896\n",
      "iteration:  32  cost:  0.7134566746886516\n",
      "iteration:  33  cost:  0.7608053606187325\n",
      "iteration:  34  cost:  0.6288815947552454\n",
      "iteration:  35  cost:  0.631769174894539\n",
      "iteration:  36  cost:  0.7233165007466624\n",
      "iteration:  37  cost:  0.6596083686360332\n",
      "iteration:  38  cost:  0.6969751392967598\n",
      "iteration:  39  cost:  0.559347601132772\n",
      "[0.264, 0.738, 0.904, 0.906, 0.928]\n",
      "iteration:  40  cost:  0.6541111835522784\n",
      "iteration:  41  cost:  0.7182287290774648\n",
      "iteration:  42  cost:  0.6484070979706367\n",
      "iteration:  43  cost:  0.6724698910677137\n",
      "iteration:  44  cost:  0.7134930596635445\n",
      "iteration:  45  cost:  0.6507262185873735\n",
      "iteration:  46  cost:  0.5931295600010782\n",
      "iteration:  47  cost:  0.7103225066062302\n",
      "iteration:  48  cost:  0.6420906439047397\n",
      "iteration:  49  cost:  0.5792773769420018\n",
      "[0.264, 0.738, 0.904, 0.906, 0.928, 0.936]\n",
      "iteration:  50  cost:  0.6133540476792897\n",
      "iteration:  51  cost:  0.5715239917603373\n",
      "iteration:  52  cost:  0.6786347680584411\n",
      "iteration:  53  cost:  0.581656349731476\n",
      "iteration:  54  cost:  0.5780280138173773\n",
      "iteration:  55  cost:  0.5856382034742108\n",
      "iteration:  56  cost:  0.6181651168314485\n",
      "iteration:  57  cost:  0.6981720696880519\n",
      "iteration:  58  cost:  0.6248559100458764\n",
      "iteration:  59  cost:  0.6531873728466877\n",
      "[0.264, 0.738, 0.904, 0.906, 0.928, 0.936, 0.932]\n",
      "iteration:  60  cost:  0.5949239354290995\n",
      "iteration:  61  cost:  0.594060956000798\n",
      "iteration:  62  cost:  0.6782124656913124\n",
      "iteration:  63  cost:  0.6969275789726871\n",
      "iteration:  64  cost:  0.5538535668928394\n",
      "iteration:  65  cost:  0.6115592993276084\n",
      "iteration:  66  cost:  0.5663391333988779\n",
      "iteration:  67  cost:  0.4977840383237823\n",
      "iteration:  68  cost:  0.6134356259934496\n",
      "iteration:  69  cost:  0.6132436842493556\n",
      "[0.264, 0.738, 0.904, 0.906, 0.928, 0.936, 0.932, 0.96]\n",
      "iteration:  70  cost:  0.5693748918279443\n",
      "iteration:  71  cost:  0.5991022099821299\n",
      "iteration:  72  cost:  0.5278112711412725\n",
      "iteration:  73  cost:  0.6017346382999696\n",
      "iteration:  74  cost:  0.5986466192979344\n",
      "iteration:  75  cost:  0.5766620104703744\n",
      "iteration:  76  cost:  0.6134524610542559\n",
      "iteration:  77  cost:  0.5709688716281291\n",
      "iteration:  78  cost:  0.6011446804925225\n",
      "iteration:  79  cost:  0.5459646886491911\n",
      "[0.264, 0.738, 0.904, 0.906, 0.928, 0.936, 0.932, 0.96, 0.956]\n",
      "iteration:  80  cost:  0.6267279627640824\n",
      "iteration:  81  cost:  0.5438850489307806\n",
      "iteration:  82  cost:  0.5314244367746541\n",
      "iteration:  83  cost:  0.5374856193684109\n",
      "iteration:  84  cost:  0.519264229982221\n",
      "iteration:  85  cost:  0.5204759868010014\n",
      "iteration:  86  cost:  0.5020693405955943\n",
      "iteration:  87  cost:  0.5137454261681694\n",
      "iteration:  88  cost:  0.5873799452051494\n",
      "iteration:  89  cost:  0.61271916135408\n",
      "[0.264, 0.738, 0.904, 0.906, 0.928, 0.936, 0.932, 0.96, 0.956, 0.976]\n",
      "iteration:  90  cost:  0.47875069857320307\n",
      "iteration:  91  cost:  0.5273906591473003\n",
      "iteration:  92  cost:  0.5705009930303695\n",
      "iteration:  93  cost:  0.4999158709995853\n",
      "iteration:  94  cost:  0.5376350930653172\n",
      "iteration:  95  cost:  0.5192988355250917\n",
      "iteration:  96  cost:  0.5478974656753927\n",
      "iteration:  97  cost:  0.5285857752250288\n",
      "iteration:  98  cost:  0.4693884968160379\n",
      "iteration:  99  cost:  0.538988322115987\n",
      "[0.264, 0.738, 0.904, 0.906, 0.928, 0.936, 0.932, 0.96, 0.956, 0.976, 0.992]\n",
      "iteration:  100  cost:  0.48199606883379376\n",
      "iteration:  101  cost:  0.5471265311937519\n",
      "iteration:  102  cost:  0.4753148172934283\n",
      "iteration:  103  cost:  0.5346971622715169\n",
      "iteration:  104  cost:  0.5091364114192796\n",
      "iteration:  105  cost:  0.4818970923845868\n",
      "iteration:  106  cost:  0.5262706458342132\n",
      "iteration:  107  cost:  0.5373048247118636\n",
      "iteration:  108  cost:  0.44748465167952234\n",
      "iteration:  109  cost:  0.4314064039631149\n",
      "[0.264, 0.738, 0.904, 0.906, 0.928, 0.936, 0.932, 0.96, 0.956, 0.976, 0.992, 0.992]\n",
      "iteration:  110  cost:  0.4108751507232211\n",
      "iteration:  111  cost:  0.5089244662942821\n",
      "iteration:  112  cost:  0.4406488516102678\n",
      "iteration:  113  cost:  0.49601862454185963\n",
      "iteration:  114  cost:  0.4493094195052276\n",
      "iteration:  115  cost:  0.5585392424616434\n",
      "iteration:  116  cost:  0.45944621807001335\n",
      "iteration:  117  cost:  0.46809088684344574\n",
      "iteration:  118  cost:  0.4275448136202943\n",
      "iteration:  119  cost:  0.4726496162714299\n",
      "[0.264, 0.738, 0.904, 0.906, 0.928, 0.936, 0.932, 0.96, 0.956, 0.976, 0.992, 0.992, 0.99]\n",
      "iteration:  120  cost:  0.40031647486691113\n",
      "iteration:  121  cost:  0.4464877237932264\n",
      "iteration:  122  cost:  0.48665527473272335\n",
      "iteration:  123  cost:  0.4874609996775957\n",
      "iteration:  124  cost:  0.4777882203258861\n",
      "iteration:  125  cost:  0.4044823746081765\n",
      "iteration:  126  cost:  0.47016043634930216\n",
      "iteration:  127  cost:  0.48574810857591133\n",
      "iteration:  128  cost:  0.4800687093955183\n",
      "iteration:  129  cost:  0.3965296742057587\n",
      "[0.264, 0.738, 0.904, 0.906, 0.928, 0.936, 0.932, 0.96, 0.956, 0.976, 0.992, 0.992, 0.99, 0.986]\n",
      "Accuracy for U_14 autoencoder8 :0.9933806146572104\n",
      "Epoch 1/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.0949 - val_loss: 0.0277\n",
      "Epoch 2/10\n",
      "396/396 [==============================] - 1s 1ms/step - loss: 0.0266 - val_loss: 0.0225\n",
      "Epoch 3/10\n",
      "396/396 [==============================] - 1s 1ms/step - loss: 0.0214 - val_loss: 0.0183\n",
      "Epoch 4/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.0177 - val_loss: 0.0155\n",
      "Epoch 5/10\n",
      "396/396 [==============================] - 1s 1ms/step - loss: 0.0154 - val_loss: 0.0138\n",
      "Epoch 6/10\n",
      "396/396 [==============================] - 1s 1ms/step - loss: 0.0137 - val_loss: 0.0126\n",
      "Epoch 7/10\n",
      "396/396 [==============================] - 1s 1ms/step - loss: 0.0127 - val_loss: 0.0120\n",
      "Epoch 8/10\n",
      "396/396 [==============================] - 1s 1ms/step - loss: 0.0119 - val_loss: 0.0114\n",
      "Epoch 9/10\n",
      "396/396 [==============================] - 1s 1ms/step - loss: 0.0115 - val_loss: 0.0110\n",
      "Epoch 10/10\n",
      "396/396 [==============================] - 1s 1ms/step - loss: 0.0111 - val_loss: 0.0107\n",
      "\n",
      "\n",
      "Loss History for QCNN circuits, U_14 autoencoder16\n",
      "[0.488]\n",
      "iteration:  0  cost:  1.473316611461533\n",
      "iteration:  1  cost:  1.24019889463055\n",
      "iteration:  2  cost:  1.3739388482983521\n",
      "iteration:  3  cost:  0.9036671125295845\n",
      "iteration:  4  cost:  1.1752012270165382\n",
      "iteration:  5  cost:  0.7667103628189003\n",
      "iteration:  6  cost:  0.6862850658657343\n",
      "iteration:  7  cost:  0.6969261699486801\n",
      "iteration:  8  cost:  0.7221905108550218\n",
      "iteration:  9  cost:  0.8784806262215131\n",
      "[0.488, 0.806]\n",
      "iteration:  10  cost:  0.7943906118164419\n",
      "iteration:  11  cost:  0.7874488963497386\n",
      "iteration:  12  cost:  0.7802583435618123\n",
      "iteration:  13  cost:  0.6975442810443137\n",
      "iteration:  14  cost:  0.8480910156927753\n",
      "iteration:  15  cost:  0.7285896592415118\n",
      "iteration:  16  cost:  0.7845561116879081\n",
      "iteration:  17  cost:  0.8199535825962637\n",
      "iteration:  18  cost:  0.817455722557918\n",
      "iteration:  19  cost:  0.9294108517996739\n",
      "[0.488, 0.806, 0.78]\n",
      "iteration:  20  cost:  0.8422112844775137\n",
      "iteration:  21  cost:  0.6847539511096834\n",
      "iteration:  22  cost:  0.7444459442868161\n",
      "iteration:  23  cost:  0.690532027643958\n",
      "iteration:  24  cost:  0.7689097084052696\n",
      "iteration:  25  cost:  0.7693918077988772\n",
      "iteration:  26  cost:  0.7387702873986511\n",
      "iteration:  27  cost:  0.7640649714117758\n",
      "iteration:  28  cost:  0.8376132848666467\n",
      "iteration:  29  cost:  0.6232686837205507\n",
      "[0.488, 0.806, 0.78, 0.86]\n",
      "iteration:  30  cost:  0.6061349161358521\n",
      "iteration:  31  cost:  0.7568648886665175\n",
      "iteration:  32  cost:  0.5746761302950685\n",
      "iteration:  33  cost:  0.7656847387391504\n",
      "iteration:  34  cost:  0.598771012338719\n",
      "iteration:  35  cost:  0.6147852924637704\n",
      "iteration:  36  cost:  0.6720302993119879\n",
      "iteration:  37  cost:  0.6853048732924033\n",
      "iteration:  38  cost:  0.6968166975150271\n",
      "iteration:  39  cost:  0.7189960612977657\n",
      "[0.488, 0.806, 0.78, 0.86, 0.814]\n",
      "iteration:  40  cost:  0.6912234817315693\n",
      "iteration:  41  cost:  0.6452252142862543\n",
      "iteration:  42  cost:  0.6932311108731392\n",
      "iteration:  43  cost:  0.6437963702263942\n",
      "iteration:  44  cost:  0.6649469725739354\n",
      "iteration:  45  cost:  0.6821101740599442\n",
      "iteration:  46  cost:  0.5974480661531415\n",
      "iteration:  47  cost:  0.6316878848752581\n",
      "iteration:  48  cost:  0.6496582774290569\n",
      "iteration:  49  cost:  0.7394064004449828\n",
      "[0.488, 0.806, 0.78, 0.86, 0.814, 0.924]\n",
      "iteration:  50  cost:  0.5949888874331927\n",
      "iteration:  51  cost:  0.6881951306904436\n",
      "iteration:  52  cost:  0.6456816417094138\n",
      "iteration:  53  cost:  0.6088248763840183\n",
      "iteration:  54  cost:  0.6613092725924141\n",
      "iteration:  55  cost:  0.6108982875684661\n",
      "iteration:  56  cost:  0.49910634625021716\n",
      "iteration:  57  cost:  0.6224102911706342\n",
      "iteration:  58  cost:  0.5482387984481352\n",
      "iteration:  59  cost:  0.6254648570542871\n",
      "[0.488, 0.806, 0.78, 0.86, 0.814, 0.924, 0.884]\n",
      "iteration:  60  cost:  0.6665086916920181\n",
      "iteration:  61  cost:  0.601606165264092\n",
      "iteration:  62  cost:  0.6343702780137317\n",
      "iteration:  63  cost:  0.5420703471221483\n",
      "iteration:  64  cost:  0.5923329353043318\n",
      "iteration:  65  cost:  0.6260970095992104\n",
      "iteration:  66  cost:  0.7018511826874024\n",
      "iteration:  67  cost:  0.5536674728772053\n",
      "iteration:  68  cost:  0.5868735575656957\n",
      "iteration:  69  cost:  0.625956171503851\n",
      "[0.488, 0.806, 0.78, 0.86, 0.814, 0.924, 0.884, 0.89]\n",
      "iteration:  70  cost:  0.5314507014455371\n",
      "iteration:  71  cost:  0.5427293869367632\n",
      "iteration:  72  cost:  0.654152510105684\n",
      "iteration:  73  cost:  0.485757179952052\n",
      "iteration:  74  cost:  0.5950629568625933\n",
      "iteration:  75  cost:  0.5390337085199276\n",
      "iteration:  76  cost:  0.5181055902390707\n",
      "iteration:  77  cost:  0.59431177164686\n",
      "iteration:  78  cost:  0.5812447588824997\n",
      "iteration:  79  cost:  0.5539562245089723\n",
      "[0.488, 0.806, 0.78, 0.86, 0.814, 0.924, 0.884, 0.89, 0.866]\n",
      "Accuracy for U_14 autoencoder16 :0.8903073286052009\n",
      "\n",
      "\n",
      "Loss History for QCNN circuits, U_15 resize256\n",
      "[0.1]\n",
      "iteration:  0  cost:  1.0991669080215336\n",
      "iteration:  1  cost:  1.11266970016052\n",
      "iteration:  2  cost:  1.1203273937072482\n",
      "iteration:  3  cost:  1.1351656529657446\n",
      "iteration:  4  cost:  1.1367007818811339\n",
      "iteration:  5  cost:  1.089388879729107\n",
      "iteration:  6  cost:  1.0956518605006271\n",
      "iteration:  7  cost:  1.1255861397910945\n",
      "iteration:  8  cost:  1.0861349541487582\n",
      "iteration:  9  cost:  1.0903824843235277\n",
      "[0.1, 0.208]\n",
      "iteration:  10  cost:  1.0697649539984437\n",
      "iteration:  11  cost:  1.0661495890111563\n",
      "iteration:  12  cost:  1.0186946452603565\n",
      "iteration:  13  cost:  1.0018411824377857\n",
      "iteration:  14  cost:  0.9981282948671459\n",
      "iteration:  15  cost:  0.9866646358849871\n",
      "iteration:  16  cost:  1.0021852229792525\n",
      "iteration:  17  cost:  0.9872432931703865\n",
      "iteration:  18  cost:  0.9667463370866183\n",
      "iteration:  19  cost:  0.9280197152822056\n",
      "[0.1, 0.208, 0.864]\n",
      "iteration:  20  cost:  0.9277113796583268\n",
      "iteration:  21  cost:  0.9078284903910384\n",
      "iteration:  22  cost:  0.8851290953475496\n",
      "iteration:  23  cost:  0.8894237157535132\n",
      "iteration:  24  cost:  0.8782287027538832\n",
      "iteration:  25  cost:  0.8707170867577753\n",
      "iteration:  26  cost:  0.8440222244052288\n",
      "iteration:  27  cost:  0.8169306384518515\n",
      "iteration:  28  cost:  0.8462079899154752\n",
      "iteration:  29  cost:  0.8487264484414796\n",
      "[0.1, 0.208, 0.864, 0.902]\n",
      "iteration:  30  cost:  0.7987959616696128\n",
      "iteration:  31  cost:  0.8079342005713063\n",
      "iteration:  32  cost:  0.8272115602798473\n",
      "iteration:  33  cost:  0.8285341281794689\n",
      "iteration:  34  cost:  0.7660335366705427\n",
      "iteration:  35  cost:  0.7895479927223059\n",
      "iteration:  36  cost:  0.7889161914079882\n",
      "iteration:  37  cost:  0.7097170253491094\n",
      "iteration:  38  cost:  0.7575567623838111\n",
      "iteration:  39  cost:  0.7986755866443016\n",
      "[0.1, 0.208, 0.864, 0.902, 0.878]\n",
      "iteration:  40  cost:  0.7321024908769954\n",
      "iteration:  41  cost:  0.699456057065771\n",
      "iteration:  42  cost:  0.6853372744772384\n",
      "iteration:  43  cost:  0.6943913987321204\n",
      "iteration:  44  cost:  0.781764263943948\n",
      "iteration:  45  cost:  0.8215391684862245\n",
      "iteration:  46  cost:  0.8405570040567999\n",
      "iteration:  47  cost:  0.7074956062144154\n",
      "iteration:  48  cost:  0.8382996400564429\n",
      "iteration:  49  cost:  0.7717001294794141\n",
      "[0.1, 0.208, 0.864, 0.902, 0.878, 0.876]\n",
      "iteration:  50  cost:  0.684091649186101\n",
      "iteration:  51  cost:  0.7510840935726861\n",
      "iteration:  52  cost:  0.6949406653701302\n",
      "iteration:  53  cost:  0.6640569640045328\n",
      "iteration:  54  cost:  0.6566898938428313\n",
      "iteration:  55  cost:  0.7702330691251731\n",
      "iteration:  56  cost:  0.7502015580775218\n",
      "iteration:  57  cost:  0.6661197201876529\n",
      "iteration:  58  cost:  0.7574442190663937\n",
      "iteration:  59  cost:  0.6818551155000329\n",
      "[0.1, 0.208, 0.864, 0.902, 0.878, 0.876, 0.89]\n",
      "iteration:  60  cost:  0.7037351229444995\n",
      "iteration:  61  cost:  0.6845373045273832\n",
      "iteration:  62  cost:  0.7026744490735498\n",
      "iteration:  63  cost:  0.6932102642155299\n",
      "iteration:  64  cost:  0.6917944939725718\n",
      "iteration:  65  cost:  0.6108461386998504\n",
      "iteration:  66  cost:  0.6791068790843883\n",
      "iteration:  67  cost:  0.6547403618575148\n",
      "iteration:  68  cost:  0.634226423143794\n",
      "iteration:  69  cost:  0.6394337020388128\n",
      "[0.1, 0.208, 0.864, 0.902, 0.878, 0.876, 0.89, 0.908]\n",
      "iteration:  70  cost:  0.6423198765807259\n",
      "iteration:  71  cost:  0.6466168316867023\n",
      "iteration:  72  cost:  0.6027966345032696\n",
      "iteration:  73  cost:  0.7039729900535738\n",
      "iteration:  74  cost:  0.6729616406626342\n",
      "iteration:  75  cost:  0.7549979867928875\n",
      "iteration:  76  cost:  0.6425318470550448\n",
      "iteration:  77  cost:  0.5529749377976114\n",
      "iteration:  78  cost:  0.5995031602213702\n",
      "iteration:  79  cost:  0.6103144435569781\n",
      "[0.1, 0.208, 0.864, 0.902, 0.878, 0.876, 0.89, 0.908, 0.916]\n",
      "iteration:  80  cost:  0.5792442747790179\n",
      "iteration:  81  cost:  0.6483776586034666\n",
      "iteration:  82  cost:  0.5636112564177668\n",
      "iteration:  83  cost:  0.628234202374572\n",
      "iteration:  84  cost:  0.6563781617394426\n",
      "iteration:  85  cost:  0.5367682826003836\n",
      "iteration:  86  cost:  0.5985683169394366\n",
      "iteration:  87  cost:  0.6519744819208801\n",
      "iteration:  88  cost:  0.5644094843264553\n",
      "iteration:  89  cost:  0.5602196626424872\n",
      "[0.1, 0.208, 0.864, 0.902, 0.878, 0.876, 0.89, 0.908, 0.916, 0.918]\n",
      "iteration:  90  cost:  0.6060615514216398\n",
      "iteration:  91  cost:  0.5129171468246007\n",
      "iteration:  92  cost:  0.6033928537140837\n",
      "iteration:  93  cost:  0.5412302912507091\n",
      "iteration:  94  cost:  0.5929525489290025\n",
      "iteration:  95  cost:  0.5757705290550602\n",
      "iteration:  96  cost:  0.5667804595741818\n",
      "iteration:  97  cost:  0.5212994123599395\n",
      "iteration:  98  cost:  0.4999100908995954\n",
      "iteration:  99  cost:  0.5410232795593836\n",
      "[0.1, 0.208, 0.864, 0.902, 0.878, 0.876, 0.89, 0.908, 0.916, 0.918, 0.93]\n",
      "iteration:  100  cost:  0.5308836599588206\n",
      "iteration:  101  cost:  0.6966923201241666\n",
      "iteration:  102  cost:  0.5129639322815377\n",
      "iteration:  103  cost:  0.5855628732553183\n",
      "iteration:  104  cost:  0.606935976764631\n",
      "iteration:  105  cost:  0.5024636092732974\n",
      "iteration:  106  cost:  0.5257721709651417\n",
      "iteration:  107  cost:  0.4851860692963148\n",
      "iteration:  108  cost:  0.5062508999668744\n",
      "iteration:  109  cost:  0.6138798113627335\n",
      "[0.1, 0.208, 0.864, 0.902, 0.878, 0.876, 0.89, 0.908, 0.916, 0.918, 0.93, 0.946]\n",
      "iteration:  110  cost:  0.510497225519556\n",
      "iteration:  111  cost:  0.5264736418623412\n",
      "iteration:  112  cost:  0.6081849629700755\n",
      "iteration:  113  cost:  0.5410657695196958\n",
      "iteration:  114  cost:  0.5001618380012909\n",
      "iteration:  115  cost:  0.5283214093059275\n",
      "iteration:  116  cost:  0.5427845210375735\n",
      "iteration:  117  cost:  0.4856089921910317\n",
      "iteration:  118  cost:  0.6129977590624077\n",
      "iteration:  119  cost:  0.5608079780773658\n",
      "[0.1, 0.208, 0.864, 0.902, 0.878, 0.876, 0.89, 0.908, 0.916, 0.918, 0.93, 0.946, 0.956]\n",
      "iteration:  120  cost:  0.4947334287223613\n",
      "iteration:  121  cost:  0.4954712756120142\n",
      "iteration:  122  cost:  0.5309072398488771\n",
      "iteration:  123  cost:  0.5848322362240828\n",
      "iteration:  124  cost:  0.5015795331577028\n",
      "iteration:  125  cost:  0.5045824290935098\n",
      "iteration:  126  cost:  0.4113946008220695\n",
      "iteration:  127  cost:  0.5105067899334292\n",
      "iteration:  128  cost:  0.5201493997686342\n",
      "iteration:  129  cost:  0.4443346372676792\n",
      "[0.1, 0.208, 0.864, 0.902, 0.878, 0.876, 0.89, 0.908, 0.916, 0.918, 0.93, 0.946, 0.956, 0.956]\n",
      "iteration:  130  cost:  0.45497205139361335\n",
      "iteration:  131  cost:  0.5223072954101061\n",
      "iteration:  132  cost:  0.5105881158838672\n",
      "iteration:  133  cost:  0.37167442878597334\n",
      "iteration:  134  cost:  0.4108103859767571\n",
      "iteration:  135  cost:  0.4382425043939219\n",
      "iteration:  136  cost:  0.4428847859374159\n",
      "iteration:  137  cost:  0.47869916110274\n",
      "iteration:  138  cost:  0.40316010488239507\n",
      "iteration:  139  cost:  0.5821591535455147\n",
      "[0.1, 0.208, 0.864, 0.902, 0.878, 0.876, 0.89, 0.908, 0.916, 0.918, 0.93, 0.946, 0.956, 0.956, 0.954]\n",
      "iteration:  140  cost:  0.5578574112173307\n",
      "iteration:  141  cost:  0.3898391725251734\n",
      "iteration:  142  cost:  0.481607377590651\n",
      "iteration:  143  cost:  0.44285008399028575\n",
      "iteration:  144  cost:  0.4789186519205241\n",
      "iteration:  145  cost:  0.4592925606776211\n",
      "iteration:  146  cost:  0.4035077782653919\n",
      "iteration:  147  cost:  0.4844562257047822\n",
      "iteration:  148  cost:  0.4360081891550696\n",
      "iteration:  149  cost:  0.4371838257853078\n",
      "[0.1, 0.208, 0.864, 0.902, 0.878, 0.876, 0.89, 0.908, 0.916, 0.918, 0.93, 0.946, 0.956, 0.956, 0.954, 0.952]\n",
      "Accuracy for U_15 resize256 :0.9588652482269504\n",
      "\n",
      "\n",
      "Loss History for QCNN circuits, U_15 pca8\n",
      "[0.508]\n",
      "iteration:  0  cost:  0.9943446306119041\n",
      "iteration:  1  cost:  1.0154885710955883\n",
      "iteration:  2  cost:  0.9590679531175484\n",
      "iteration:  3  cost:  0.9921569412845261\n",
      "iteration:  4  cost:  0.9892425295863422\n",
      "iteration:  5  cost:  0.9501429097949793\n",
      "iteration:  6  cost:  0.9858509945952375\n",
      "iteration:  7  cost:  0.9825998151745325\n",
      "iteration:  8  cost:  0.9585779219853907\n",
      "iteration:  9  cost:  0.9221385114235935\n",
      "[0.508, 0.694]\n",
      "iteration:  10  cost:  0.8925939425462077\n",
      "iteration:  11  cost:  0.8714355526686272\n",
      "iteration:  12  cost:  0.9324676076235126\n",
      "iteration:  13  cost:  0.8714331914597199\n",
      "iteration:  14  cost:  0.8718109724124627\n",
      "iteration:  15  cost:  0.8771288883637832\n",
      "iteration:  16  cost:  0.8109866763649143\n",
      "iteration:  17  cost:  0.8020989773063385\n",
      "iteration:  18  cost:  0.7938160301424838\n",
      "iteration:  19  cost:  0.8344200150066082\n",
      "[0.508, 0.694, 0.946]\n",
      "iteration:  20  cost:  0.7945994245818513\n",
      "iteration:  21  cost:  0.8024215611716401\n",
      "iteration:  22  cost:  0.7640510568090643\n",
      "iteration:  23  cost:  0.7747277606255569\n",
      "iteration:  24  cost:  0.7247455081124413\n",
      "iteration:  25  cost:  0.7440814886373797\n",
      "iteration:  26  cost:  0.7463655392933177\n",
      "iteration:  27  cost:  0.7184630027519501\n",
      "iteration:  28  cost:  0.6890002786202709\n",
      "iteration:  29  cost:  0.7015094772762589\n",
      "[0.508, 0.694, 0.946, 0.972]\n",
      "iteration:  30  cost:  0.6948181133237407\n",
      "iteration:  31  cost:  0.7689810932509813\n",
      "iteration:  32  cost:  0.7375425953813077\n",
      "iteration:  33  cost:  0.7025150933630541\n",
      "iteration:  34  cost:  0.7244949909748971\n",
      "iteration:  35  cost:  0.6218278270968802\n",
      "iteration:  36  cost:  0.6915543709104327\n",
      "iteration:  37  cost:  0.6832486431421162\n",
      "iteration:  38  cost:  0.7325513794940898\n",
      "iteration:  39  cost:  0.6083783304012713\n",
      "[0.508, 0.694, 0.946, 0.972, 0.974]\n",
      "iteration:  40  cost:  0.6934191923203809\n",
      "iteration:  41  cost:  0.6305190730678705\n",
      "iteration:  42  cost:  0.6575641238125752\n",
      "iteration:  43  cost:  0.6618979682197116\n",
      "iteration:  44  cost:  0.6851995001285575\n",
      "iteration:  45  cost:  0.5833403577196781\n",
      "iteration:  46  cost:  0.6243882078196551\n",
      "iteration:  47  cost:  0.6321581508197696\n",
      "iteration:  48  cost:  0.6826651877092413\n",
      "iteration:  49  cost:  0.6752781532988128\n",
      "[0.508, 0.694, 0.946, 0.972, 0.974, 0.976]\n",
      "iteration:  50  cost:  0.595619508730958\n",
      "iteration:  51  cost:  0.5857438684068135\n",
      "iteration:  52  cost:  0.6463574608892351\n",
      "iteration:  53  cost:  0.6076797449175158\n",
      "iteration:  54  cost:  0.6381124611769875\n",
      "iteration:  55  cost:  0.6243410420433887\n",
      "iteration:  56  cost:  0.6381938107496274\n",
      "iteration:  57  cost:  0.6643514321633512\n",
      "iteration:  58  cost:  0.6313038862744722\n",
      "iteration:  59  cost:  0.6854600018982482\n",
      "[0.508, 0.694, 0.946, 0.972, 0.974, 0.976, 0.976]\n",
      "iteration:  60  cost:  0.5854324562104801\n",
      "iteration:  61  cost:  0.6219437209378875\n",
      "iteration:  62  cost:  0.5868160591571598\n",
      "iteration:  63  cost:  0.5960327045762405\n",
      "iteration:  64  cost:  0.6250901881297931\n",
      "iteration:  65  cost:  0.5749042325700292\n",
      "iteration:  66  cost:  0.6051369561100017\n",
      "iteration:  67  cost:  0.5980306144701902\n",
      "iteration:  68  cost:  0.6521420246130901\n",
      "iteration:  69  cost:  0.6001509915647136\n",
      "[0.508, 0.694, 0.946, 0.972, 0.974, 0.976, 0.976, 0.978]\n",
      "iteration:  70  cost:  0.5885485336304819\n",
      "iteration:  71  cost:  0.5909996167119622\n",
      "iteration:  72  cost:  0.6366501106226918\n",
      "iteration:  73  cost:  0.5987865734850985\n",
      "iteration:  74  cost:  0.5414488864030239\n",
      "iteration:  75  cost:  0.6044347637770207\n",
      "iteration:  76  cost:  0.5545986356359979\n",
      "iteration:  77  cost:  0.5674916463103415\n",
      "iteration:  78  cost:  0.5687427547971252\n",
      "iteration:  79  cost:  0.6243456876067731\n",
      "[0.508, 0.694, 0.946, 0.972, 0.974, 0.976, 0.976, 0.978, 0.978]\n",
      "iteration:  80  cost:  0.557120310478883\n",
      "iteration:  81  cost:  0.7211276317268452\n",
      "iteration:  82  cost:  0.6020812703311735\n",
      "iteration:  83  cost:  0.6047580548480422\n",
      "iteration:  84  cost:  0.576260652936471\n",
      "iteration:  85  cost:  0.5821292727921046\n",
      "iteration:  86  cost:  0.5537443940364937\n",
      "iteration:  87  cost:  0.5674736150942776\n",
      "iteration:  88  cost:  0.6354194126687867\n",
      "iteration:  89  cost:  0.5592480903662668\n",
      "[0.508, 0.694, 0.946, 0.972, 0.974, 0.976, 0.976, 0.978, 0.978, 0.978]\n",
      "iteration:  90  cost:  0.6421553205848604\n",
      "iteration:  91  cost:  0.5658480915151044\n",
      "iteration:  92  cost:  0.5585706839586488\n",
      "iteration:  93  cost:  0.6035359214789262\n",
      "iteration:  94  cost:  0.6126204004914936\n",
      "iteration:  95  cost:  0.6283392065427538\n",
      "iteration:  96  cost:  0.5861797301524426\n",
      "iteration:  97  cost:  0.5410129247543121\n",
      "iteration:  98  cost:  0.5893170629963567\n",
      "iteration:  99  cost:  0.6453331678644332\n",
      "[0.508, 0.694, 0.946, 0.972, 0.974, 0.976, 0.976, 0.978, 0.978, 0.978, 0.976]\n",
      "Accuracy for U_15 pca8 :0.9862884160756501\n",
      "\n",
      "\n",
      "Loss History for QCNN circuits, U_15 pca16\n",
      "[0.622]\n",
      "iteration:  0  cost:  0.9676265411196293\n",
      "iteration:  1  cost:  1.0233194571799518\n",
      "iteration:  2  cost:  0.9632784392916165\n",
      "iteration:  3  cost:  0.9952209434301906\n",
      "iteration:  4  cost:  0.9386742194509613\n",
      "iteration:  5  cost:  0.9750377271262886\n",
      "iteration:  6  cost:  0.9558022652276353\n",
      "iteration:  7  cost:  0.9832436405892945\n",
      "iteration:  8  cost:  0.9666157298862526\n",
      "iteration:  9  cost:  0.9397676657584586\n",
      "[0.622, 0.62]\n",
      "iteration:  10  cost:  0.9974522951784469\n",
      "iteration:  11  cost:  0.9465066217776511\n",
      "iteration:  12  cost:  0.9370847622731617\n",
      "iteration:  13  cost:  0.9478457654948876\n",
      "iteration:  14  cost:  0.9667920086520116\n",
      "iteration:  15  cost:  0.948837661441484\n",
      "iteration:  16  cost:  0.9654690317474214\n",
      "iteration:  17  cost:  0.9386430265076815\n",
      "iteration:  18  cost:  0.9136992127336931\n",
      "iteration:  19  cost:  0.8757046364906713\n",
      "[0.622, 0.62, 0.62]\n",
      "iteration:  20  cost:  0.9694197720653922\n",
      "iteration:  21  cost:  0.9093993700691447\n",
      "iteration:  22  cost:  0.9229481343790372\n",
      "iteration:  23  cost:  0.9512339586932829\n",
      "iteration:  24  cost:  0.920860454983892\n",
      "iteration:  25  cost:  0.9151383422144629\n",
      "iteration:  26  cost:  0.9907481617161775\n",
      "iteration:  27  cost:  0.913597980508728\n",
      "iteration:  28  cost:  0.9422684009015626\n",
      "iteration:  29  cost:  0.9193717766327899\n",
      "[0.622, 0.62, 0.62, 0.638]\n",
      "iteration:  30  cost:  0.9410575512071175\n",
      "iteration:  31  cost:  0.926425928851259\n",
      "iteration:  32  cost:  0.9690877754361275\n",
      "iteration:  33  cost:  0.9527749403022038\n",
      "iteration:  34  cost:  0.9357753994581338\n",
      "iteration:  35  cost:  0.9170330968834952\n",
      "iteration:  36  cost:  0.9277415755751179\n",
      "iteration:  37  cost:  0.9293396596779578\n",
      "iteration:  38  cost:  0.9192672138891251\n",
      "iteration:  39  cost:  0.8393861831974089\n",
      "[0.622, 0.62, 0.62, 0.638, 0.728]\n",
      "iteration:  40  cost:  0.9200832922739923\n",
      "iteration:  41  cost:  0.9201047032173402\n",
      "iteration:  42  cost:  0.8826166324168915\n",
      "iteration:  43  cost:  0.9070492659657766\n",
      "iteration:  44  cost:  0.896630243335739\n",
      "iteration:  45  cost:  0.8949790466720247\n",
      "iteration:  46  cost:  0.8637356184245271\n",
      "iteration:  47  cost:  0.912774196085882\n",
      "iteration:  48  cost:  0.9033134575190445\n",
      "iteration:  49  cost:  0.8571233385385588\n",
      "[0.622, 0.62, 0.62, 0.638, 0.728, 0.77]\n",
      "iteration:  50  cost:  0.8937515263833617\n",
      "iteration:  51  cost:  0.8860762396435687\n",
      "iteration:  52  cost:  0.8065772438745183\n",
      "iteration:  53  cost:  0.8004377463719936\n",
      "iteration:  54  cost:  0.8444493458857798\n",
      "iteration:  55  cost:  0.8511303813002865\n",
      "iteration:  56  cost:  0.8439679372000077\n",
      "iteration:  57  cost:  0.8272601757546556\n",
      "iteration:  58  cost:  0.8220447373209077\n",
      "iteration:  59  cost:  0.9173467479303861\n",
      "[0.622, 0.62, 0.62, 0.638, 0.728, 0.77, 0.778]\n",
      "iteration:  60  cost:  0.868050172960421\n",
      "iteration:  61  cost:  0.7874771260075636\n",
      "iteration:  62  cost:  0.7883902227264536\n",
      "iteration:  63  cost:  0.8517223818166586\n",
      "iteration:  64  cost:  0.7590205117582031\n",
      "iteration:  65  cost:  0.730795172830979\n",
      "iteration:  66  cost:  0.802106503663588\n",
      "iteration:  67  cost:  0.8264841003237667\n",
      "iteration:  68  cost:  0.7852982443298525\n",
      "iteration:  69  cost:  0.8291755974877562\n",
      "[0.622, 0.62, 0.62, 0.638, 0.728, 0.77, 0.778, 0.806]\n",
      "iteration:  70  cost:  0.7571337915676974\n",
      "iteration:  71  cost:  0.7550271944226461\n",
      "iteration:  72  cost:  0.8018091529236283\n",
      "iteration:  73  cost:  0.7567938253498855\n",
      "iteration:  74  cost:  0.8118461728319027\n",
      "iteration:  75  cost:  0.7242626421548084\n",
      "iteration:  76  cost:  0.8189358142297158\n",
      "iteration:  77  cost:  0.8265668093227895\n",
      "iteration:  78  cost:  0.7398607159068574\n",
      "iteration:  79  cost:  0.7911847317688508\n",
      "[0.622, 0.62, 0.62, 0.638, 0.728, 0.77, 0.778, 0.806, 0.88]\n",
      "iteration:  80  cost:  0.7778205352211057\n",
      "iteration:  81  cost:  0.6836958094842054\n",
      "iteration:  82  cost:  0.7390795472770477\n",
      "iteration:  83  cost:  0.7663136737203631\n",
      "iteration:  84  cost:  0.8375700483303823\n",
      "iteration:  85  cost:  0.7202598388517265\n",
      "iteration:  86  cost:  0.7880148428213445\n",
      "iteration:  87  cost:  0.8197265570820608\n",
      "iteration:  88  cost:  0.6698324863929547\n",
      "iteration:  89  cost:  0.775002922815214\n",
      "[0.622, 0.62, 0.62, 0.638, 0.728, 0.77, 0.778, 0.806, 0.88, 0.954]\n",
      "iteration:  90  cost:  0.7625172581874102\n",
      "iteration:  91  cost:  0.7325066089412925\n",
      "iteration:  92  cost:  0.7348296260268969\n",
      "iteration:  93  cost:  0.7392497101326891\n",
      "iteration:  94  cost:  0.7926185938393724\n",
      "iteration:  95  cost:  0.7589997655779426\n",
      "iteration:  96  cost:  0.7135755407735291\n",
      "iteration:  97  cost:  0.6955164772022375\n",
      "iteration:  98  cost:  0.6926611854938932\n",
      "iteration:  99  cost:  0.718665275276776\n",
      "[0.622, 0.62, 0.62, 0.638, 0.728, 0.77, 0.778, 0.806, 0.88, 0.954, 0.98]\n",
      "iteration:  100  cost:  0.7375802345589639\n",
      "iteration:  101  cost:  0.6770179041601562\n",
      "iteration:  102  cost:  0.684973540270574\n",
      "iteration:  103  cost:  0.7029991502712918\n",
      "iteration:  104  cost:  0.7741443116638878\n",
      "iteration:  105  cost:  0.705846257490636\n",
      "iteration:  106  cost:  0.7064919671962193\n",
      "iteration:  107  cost:  0.6655816225051736\n",
      "iteration:  108  cost:  0.7567371845903075\n",
      "iteration:  109  cost:  0.7370394522461047\n",
      "[0.622, 0.62, 0.62, 0.638, 0.728, 0.77, 0.778, 0.806, 0.88, 0.954, 0.98, 0.988]\n",
      "iteration:  110  cost:  0.699238953353739\n",
      "iteration:  111  cost:  0.6921919779922601\n",
      "iteration:  112  cost:  0.7108021830177449\n",
      "iteration:  113  cost:  0.6916904179120003\n",
      "iteration:  114  cost:  0.7548342551779754\n",
      "iteration:  115  cost:  0.6869378173403511\n",
      "iteration:  116  cost:  0.7124352429709717\n",
      "iteration:  117  cost:  0.7713210955535856\n",
      "iteration:  118  cost:  0.6423167168226191\n",
      "iteration:  119  cost:  0.7013642977071797\n",
      "[0.622, 0.62, 0.62, 0.638, 0.728, 0.77, 0.778, 0.806, 0.88, 0.954, 0.98, 0.988, 0.988]\n",
      "iteration:  120  cost:  0.6795678508946165\n",
      "iteration:  121  cost:  0.7389192744758298\n",
      "iteration:  122  cost:  0.6754607265559133\n",
      "iteration:  123  cost:  0.6810409324275786\n",
      "iteration:  124  cost:  0.645700027553424\n",
      "iteration:  125  cost:  0.6184971290767841\n",
      "iteration:  126  cost:  0.6497627191837607\n",
      "iteration:  127  cost:  0.6430125511859274\n",
      "iteration:  128  cost:  0.6963007746199871\n",
      "iteration:  129  cost:  0.6770632140207813\n",
      "[0.622, 0.62, 0.62, 0.638, 0.728, 0.77, 0.778, 0.806, 0.88, 0.954, 0.98, 0.988, 0.988, 0.984]\n",
      "iteration:  130  cost:  0.6720956124310071\n",
      "iteration:  131  cost:  0.6602915720870182\n",
      "iteration:  132  cost:  0.6495505661311164\n",
      "iteration:  133  cost:  0.6832412628038194\n",
      "iteration:  134  cost:  0.6932234509577699\n",
      "iteration:  135  cost:  0.7174351047815974\n",
      "iteration:  136  cost:  0.7173492049692972\n",
      "iteration:  137  cost:  0.6645574839059308\n",
      "iteration:  138  cost:  0.6269335476239596\n",
      "iteration:  139  cost:  0.7252206671831095\n",
      "[0.622, 0.62, 0.62, 0.638, 0.728, 0.77, 0.778, 0.806, 0.88, 0.954, 0.98, 0.988, 0.988, 0.984, 0.988]\n",
      "iteration:  140  cost:  0.7181820080837917\n",
      "iteration:  141  cost:  0.6379027780198836\n",
      "iteration:  142  cost:  0.6359974725370657\n",
      "iteration:  143  cost:  0.6964707315302846\n",
      "iteration:  144  cost:  0.6800924852841473\n",
      "iteration:  145  cost:  0.6320057635671118\n",
      "iteration:  146  cost:  0.6386657207722828\n",
      "iteration:  147  cost:  0.6412106341460375\n",
      "iteration:  148  cost:  0.6698325856871539\n",
      "iteration:  149  cost:  0.6026969512229194\n",
      "[0.622, 0.62, 0.62, 0.638, 0.728, 0.77, 0.778, 0.806, 0.88, 0.954, 0.98, 0.988, 0.988, 0.984, 0.988, 0.984]\n",
      "iteration:  150  cost:  0.6447544732849686\n",
      "iteration:  151  cost:  0.6303061845097981\n",
      "iteration:  152  cost:  0.6414238174737825\n",
      "iteration:  153  cost:  0.6483893635679623\n",
      "iteration:  154  cost:  0.645164300772975\n",
      "iteration:  155  cost:  0.62017980182742\n",
      "iteration:  156  cost:  0.6791538342556759\n",
      "iteration:  157  cost:  0.6119629841624558\n",
      "iteration:  158  cost:  0.631483360833523\n",
      "iteration:  159  cost:  0.5902655803768052\n",
      "[0.622, 0.62, 0.62, 0.638, 0.728, 0.77, 0.778, 0.806, 0.88, 0.954, 0.98, 0.988, 0.988, 0.984, 0.988, 0.984, 0.976]\n",
      "Accuracy for U_15 pca16 :0.9598108747044918\n",
      "Epoch 1/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.1096 - val_loss: 0.0349\n",
      "Epoch 2/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.0321 - val_loss: 0.0276\n",
      "Epoch 3/10\n",
      "396/396 [==============================] - 1s 1ms/step - loss: 0.0270 - val_loss: 0.0247\n",
      "Epoch 4/10\n",
      "396/396 [==============================] - 1s 1ms/step - loss: 0.0244 - val_loss: 0.0223\n",
      "Epoch 5/10\n",
      "396/396 [==============================] - 1s 1ms/step - loss: 0.0218 - val_loss: 0.0205\n",
      "Epoch 6/10\n",
      "396/396 [==============================] - 1s 1ms/step - loss: 0.0205 - val_loss: 0.0194\n",
      "Epoch 7/10\n",
      "396/396 [==============================] - 1s 1ms/step - loss: 0.0196 - val_loss: 0.0187\n",
      "Epoch 8/10\n",
      "396/396 [==============================] - 1s 1ms/step - loss: 0.0187 - val_loss: 0.0182\n",
      "Epoch 9/10\n",
      "396/396 [==============================] - 1s 1ms/step - loss: 0.0185 - val_loss: 0.0179\n",
      "Epoch 10/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.0181 - val_loss: 0.0177\n",
      "\n",
      "\n",
      "Loss History for QCNN circuits, U_15 autoencoder8\n",
      "[0.22]\n",
      "iteration:  0  cost:  1.1240139569313234\n",
      "iteration:  1  cost:  1.0996409060731656\n",
      "iteration:  2  cost:  1.2143057374057742\n",
      "iteration:  3  cost:  1.1498455775414904\n",
      "iteration:  4  cost:  1.1183822798976468\n",
      "iteration:  5  cost:  1.1424873894078627\n",
      "iteration:  6  cost:  1.0554239150687632\n",
      "iteration:  7  cost:  1.0813013620343594\n",
      "iteration:  8  cost:  1.0212095250233724\n",
      "iteration:  9  cost:  1.0609240179172685\n",
      "[0.22, 0.444]\n",
      "iteration:  10  cost:  1.0035886583075664\n",
      "iteration:  11  cost:  1.0045179008480307\n",
      "iteration:  12  cost:  0.9903369950206735\n",
      "iteration:  13  cost:  1.0029681027549513\n",
      "iteration:  14  cost:  0.9495233790111643\n",
      "iteration:  15  cost:  0.9484689435471129\n",
      "iteration:  16  cost:  0.9866122455491174\n",
      "iteration:  17  cost:  0.969146680379316\n",
      "iteration:  18  cost:  0.9324278106962209\n",
      "iteration:  19  cost:  0.9187902636883777\n",
      "[0.22, 0.444, 0.742]\n",
      "iteration:  20  cost:  0.8976232377357561\n",
      "iteration:  21  cost:  0.8878872322272012\n",
      "iteration:  22  cost:  0.9033565061203973\n",
      "iteration:  23  cost:  0.9150510965972584\n",
      "iteration:  24  cost:  0.9049230539804024\n",
      "iteration:  25  cost:  0.923126446860511\n",
      "iteration:  26  cost:  0.873916277724333\n",
      "iteration:  27  cost:  0.8731137084688001\n",
      "iteration:  28  cost:  0.8630288756622626\n",
      "iteration:  29  cost:  0.8677279855283302\n",
      "[0.22, 0.444, 0.742, 0.842]\n",
      "iteration:  30  cost:  0.8924081253761647\n",
      "iteration:  31  cost:  0.850894066498578\n",
      "iteration:  32  cost:  0.886267771527944\n",
      "iteration:  33  cost:  0.8405412197946914\n",
      "iteration:  34  cost:  0.8529324944719577\n",
      "iteration:  35  cost:  0.8452077337110869\n",
      "iteration:  36  cost:  0.8599421718398985\n",
      "iteration:  37  cost:  0.8561430301831925\n",
      "iteration:  38  cost:  0.8671786571114393\n",
      "iteration:  39  cost:  0.8308034018058901\n",
      "[0.22, 0.444, 0.742, 0.842, 0.86]\n",
      "iteration:  40  cost:  0.837831456202498\n",
      "iteration:  41  cost:  0.8264826710906658\n",
      "iteration:  42  cost:  0.7929467403594327\n",
      "iteration:  43  cost:  0.8458901396372412\n",
      "iteration:  44  cost:  0.777747509234108\n",
      "iteration:  45  cost:  0.83767913233966\n",
      "iteration:  46  cost:  0.7892305784629038\n",
      "iteration:  47  cost:  0.7976633425253681\n",
      "iteration:  48  cost:  0.8108002880287986\n",
      "iteration:  49  cost:  0.797611730312735\n",
      "[0.22, 0.444, 0.742, 0.842, 0.86, 0.922]\n",
      "iteration:  50  cost:  0.7960162949831223\n",
      "iteration:  51  cost:  0.8500235113423504\n",
      "iteration:  52  cost:  0.8146635343095966\n",
      "iteration:  53  cost:  0.7652504092775325\n",
      "iteration:  54  cost:  0.7676761299316546\n",
      "iteration:  55  cost:  0.8248316840548654\n",
      "iteration:  56  cost:  0.7655146089313007\n",
      "iteration:  57  cost:  0.779233862408389\n",
      "iteration:  58  cost:  0.7773287555006599\n",
      "iteration:  59  cost:  0.7407573267976919\n",
      "[0.22, 0.444, 0.742, 0.842, 0.86, 0.922, 0.954]\n",
      "iteration:  60  cost:  0.7330966900902215\n",
      "iteration:  61  cost:  0.8075724604564536\n",
      "iteration:  62  cost:  0.744403206346\n",
      "iteration:  63  cost:  0.730052076808698\n",
      "iteration:  64  cost:  0.7288266547882418\n",
      "iteration:  65  cost:  0.7731945129374697\n",
      "iteration:  66  cost:  0.776913753605929\n",
      "iteration:  67  cost:  0.736723027226691\n",
      "iteration:  68  cost:  0.7364254968764637\n",
      "iteration:  69  cost:  0.72377909615068\n",
      "[0.22, 0.444, 0.742, 0.842, 0.86, 0.922, 0.954, 0.974]\n",
      "iteration:  70  cost:  0.7650241314771884\n",
      "iteration:  71  cost:  0.6975623479315409\n",
      "iteration:  72  cost:  0.7001064478543683\n",
      "iteration:  73  cost:  0.7753171684405603\n",
      "iteration:  74  cost:  0.7168773166029727\n",
      "iteration:  75  cost:  0.7371257686350633\n",
      "iteration:  76  cost:  0.6961855197113774\n",
      "iteration:  77  cost:  0.6968014872663475\n",
      "iteration:  78  cost:  0.698085263198275\n",
      "iteration:  79  cost:  0.7190519975687062\n",
      "[0.22, 0.444, 0.742, 0.842, 0.86, 0.922, 0.954, 0.974, 0.974]\n",
      "iteration:  80  cost:  0.6984197867607392\n",
      "iteration:  81  cost:  0.7161226526171987\n",
      "iteration:  82  cost:  0.7224121609959435\n",
      "iteration:  83  cost:  0.7334952642619715\n",
      "iteration:  84  cost:  0.6959897563079539\n",
      "iteration:  85  cost:  0.6945174301786328\n",
      "iteration:  86  cost:  0.7417863645338698\n",
      "iteration:  87  cost:  0.6943877071465113\n",
      "iteration:  88  cost:  0.6654343513295886\n",
      "iteration:  89  cost:  0.7208634722502478\n",
      "[0.22, 0.444, 0.742, 0.842, 0.86, 0.922, 0.954, 0.974, 0.974, 0.98]\n",
      "iteration:  90  cost:  0.6681765630925129\n",
      "iteration:  91  cost:  0.6753822445179953\n",
      "iteration:  92  cost:  0.6878456175818499\n",
      "iteration:  93  cost:  0.7075414163145508\n",
      "iteration:  94  cost:  0.6710919239727084\n",
      "iteration:  95  cost:  0.6774591414998384\n",
      "iteration:  96  cost:  0.6463296497658536\n",
      "iteration:  97  cost:  0.6931878203467958\n",
      "iteration:  98  cost:  0.6579655649523319\n",
      "iteration:  99  cost:  0.6807308700529233\n",
      "[0.22, 0.444, 0.742, 0.842, 0.86, 0.922, 0.954, 0.974, 0.974, 0.98, 0.978]\n",
      "iteration:  100  cost:  0.7162442597101378\n",
      "iteration:  101  cost:  0.6434911403311232\n",
      "iteration:  102  cost:  0.6670474716421471\n",
      "iteration:  103  cost:  0.6879178012771152\n",
      "iteration:  104  cost:  0.6729447859938418\n",
      "iteration:  105  cost:  0.6750599367990039\n",
      "iteration:  106  cost:  0.6596510451801934\n",
      "iteration:  107  cost:  0.6676450171019512\n",
      "iteration:  108  cost:  0.6946384005082105\n",
      "iteration:  109  cost:  0.6536437228251235\n",
      "[0.22, 0.444, 0.742, 0.842, 0.86, 0.922, 0.954, 0.974, 0.974, 0.98, 0.978, 0.98]\n",
      "iteration:  110  cost:  0.6683930624004135\n",
      "iteration:  111  cost:  0.6714415270905046\n",
      "iteration:  112  cost:  0.5844316302149939\n",
      "iteration:  113  cost:  0.6851021175707517\n",
      "iteration:  114  cost:  0.6162904168784955\n",
      "iteration:  115  cost:  0.6058029855697317\n",
      "iteration:  116  cost:  0.5960598818959317\n",
      "iteration:  117  cost:  0.6207895861757919\n",
      "iteration:  118  cost:  0.6305835405374732\n",
      "iteration:  119  cost:  0.6255429332247203\n",
      "[0.22, 0.444, 0.742, 0.842, 0.86, 0.922, 0.954, 0.974, 0.974, 0.98, 0.978, 0.98, 0.974]\n",
      "Accuracy for U_15 autoencoder8 :0.9654846335697399\n",
      "Epoch 1/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.1001 - val_loss: 0.0295\n",
      "Epoch 2/10\n",
      "396/396 [==============================] - 1s 1ms/step - loss: 0.0280 - val_loss: 0.0225\n",
      "Epoch 3/10\n",
      "396/396 [==============================] - 1s 1ms/step - loss: 0.0220 - val_loss: 0.0190\n",
      "Epoch 4/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.0183 - val_loss: 0.0162\n",
      "Epoch 5/10\n",
      "396/396 [==============================] - 1s 1ms/step - loss: 0.0159 - val_loss: 0.0146\n",
      "Epoch 6/10\n",
      "396/396 [==============================] - 1s 1ms/step - loss: 0.0145 - val_loss: 0.0137\n",
      "Epoch 7/10\n",
      "396/396 [==============================] - 1s 1ms/step - loss: 0.0137 - val_loss: 0.0130\n",
      "Epoch 8/10\n",
      "396/396 [==============================] - 1s 1ms/step - loss: 0.0133 - val_loss: 0.0126\n",
      "Epoch 9/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.0129 - val_loss: 0.0121\n",
      "Epoch 10/10\n",
      "396/396 [==============================] - 1s 1ms/step - loss: 0.0122 - val_loss: 0.0118\n",
      "\n",
      "\n",
      "Loss History for QCNN circuits, U_15 autoencoder16\n",
      "[0.59]\n",
      "iteration:  0  cost:  0.9809124663540248\n",
      "iteration:  1  cost:  0.9862530831314816\n",
      "iteration:  2  cost:  1.000531564855173\n",
      "iteration:  3  cost:  0.9537487499091211\n",
      "iteration:  4  cost:  0.9930104797315127\n",
      "iteration:  5  cost:  0.9507968282154353\n",
      "iteration:  6  cost:  0.8795111852683525\n",
      "iteration:  7  cost:  0.9476375951658232\n",
      "iteration:  8  cost:  0.9558752035434628\n",
      "iteration:  9  cost:  0.8971355859884926\n",
      "[0.59, 0.772]\n",
      "iteration:  10  cost:  0.9388070575033914\n",
      "iteration:  11  cost:  0.9323456181702884\n",
      "iteration:  12  cost:  0.8909922857080869\n",
      "iteration:  13  cost:  0.9240315852636656\n",
      "iteration:  14  cost:  0.895604891858493\n",
      "iteration:  15  cost:  0.877016903632933\n",
      "iteration:  16  cost:  0.8695321794289006\n",
      "iteration:  17  cost:  0.8658288196644777\n",
      "iteration:  18  cost:  0.8563912104448625\n",
      "iteration:  19  cost:  0.9017955257675777\n",
      "[0.59, 0.772, 0.844]\n",
      "iteration:  20  cost:  0.8664519645848917\n",
      "iteration:  21  cost:  0.8659656566474753\n",
      "iteration:  22  cost:  0.8239345933474024\n",
      "iteration:  23  cost:  0.8118756954274013\n",
      "iteration:  24  cost:  0.8437727230866208\n",
      "iteration:  25  cost:  0.8948064648274976\n",
      "iteration:  26  cost:  0.8063596429779335\n",
      "iteration:  27  cost:  0.8821580978784533\n",
      "iteration:  28  cost:  0.8467879239959537\n",
      "iteration:  29  cost:  0.8096090553401821\n",
      "[0.59, 0.772, 0.844, 0.808]\n",
      "iteration:  30  cost:  0.8279459967087806\n",
      "iteration:  31  cost:  0.8206249050533032\n",
      "iteration:  32  cost:  0.8355208627419395\n",
      "iteration:  33  cost:  0.8098084368500491\n",
      "iteration:  34  cost:  0.8573745050745637\n",
      "iteration:  35  cost:  0.8483108463907585\n",
      "iteration:  36  cost:  0.7662640615234639\n",
      "iteration:  37  cost:  0.8076531187609736\n",
      "iteration:  38  cost:  0.759553253060425\n",
      "iteration:  39  cost:  0.7997449165746218\n",
      "[0.59, 0.772, 0.844, 0.808, 0.754]\n",
      "Accuracy for U_15 autoencoder16 :0.7725768321513002\n",
      "\n",
      "\n",
      "Loss History for QCNN circuits, U_SO4 resize256\n",
      "[0.46]\n",
      "iteration:  0  cost:  1.0076691609662976\n",
      "iteration:  1  cost:  1.2838086041175665\n",
      "iteration:  2  cost:  0.787526312092322\n",
      "iteration:  3  cost:  0.7840671836306524\n",
      "iteration:  4  cost:  0.9983092411416209\n",
      "iteration:  5  cost:  0.7088977823848578\n",
      "iteration:  6  cost:  0.8785103032027017\n",
      "iteration:  7  cost:  0.8507952131395515\n",
      "iteration:  8  cost:  0.8500775567517489\n",
      "iteration:  9  cost:  0.6462607513341392\n",
      "[0.46, 0.782]\n",
      "iteration:  10  cost:  0.7462761043785942\n",
      "iteration:  11  cost:  0.6489763694447493\n",
      "iteration:  12  cost:  0.6767959616465881\n",
      "iteration:  13  cost:  0.68028700038175\n",
      "iteration:  14  cost:  0.6002902180312513\n",
      "iteration:  15  cost:  0.6106457824390545\n",
      "iteration:  16  cost:  0.6684387406101489\n",
      "iteration:  17  cost:  0.7094583026761851\n",
      "iteration:  18  cost:  0.640552026633912\n",
      "iteration:  19  cost:  0.7185828879243402\n",
      "[0.46, 0.782, 0.942]\n",
      "iteration:  20  cost:  0.711654934458511\n",
      "iteration:  21  cost:  0.6635930535789656\n",
      "iteration:  22  cost:  0.5824261379404889\n",
      "iteration:  23  cost:  0.6578648476856631\n",
      "iteration:  24  cost:  0.6379798920813772\n",
      "iteration:  25  cost:  0.5890089267546401\n",
      "iteration:  26  cost:  0.571111257463693\n",
      "iteration:  27  cost:  0.5971525825649622\n",
      "iteration:  28  cost:  0.4882288882208059\n",
      "iteration:  29  cost:  0.5788585121836477\n",
      "[0.46, 0.782, 0.942, 0.98]\n",
      "iteration:  30  cost:  0.5661182546225413\n",
      "iteration:  31  cost:  0.5764554916116903\n",
      "iteration:  32  cost:  0.5919963340723122\n",
      "iteration:  33  cost:  0.4707521299881251\n",
      "iteration:  34  cost:  0.5282966899930055\n",
      "iteration:  35  cost:  0.4920960413722373\n",
      "iteration:  36  cost:  0.43923443825883896\n",
      "iteration:  37  cost:  0.4518956646074647\n",
      "iteration:  38  cost:  0.39844087880978\n",
      "iteration:  39  cost:  0.43474027836048906\n",
      "[0.46, 0.782, 0.942, 0.98, 0.982]\n",
      "iteration:  40  cost:  0.3875255309156412\n",
      "iteration:  41  cost:  0.3558201039491463\n",
      "iteration:  42  cost:  0.35266750904684857\n",
      "iteration:  43  cost:  0.47988443504259737\n",
      "iteration:  44  cost:  0.4984076441630813\n",
      "iteration:  45  cost:  0.37324052647769923\n",
      "iteration:  46  cost:  0.34387291364382633\n",
      "iteration:  47  cost:  0.39962570988798807\n",
      "iteration:  48  cost:  0.31284879378638253\n",
      "iteration:  49  cost:  0.2993953761826138\n",
      "[0.46, 0.782, 0.942, 0.98, 0.982, 0.986]\n",
      "iteration:  50  cost:  0.4209093087608259\n",
      "iteration:  51  cost:  0.2961319168563143\n",
      "iteration:  52  cost:  0.28688254171009325\n",
      "iteration:  53  cost:  0.44178587353358334\n",
      "iteration:  54  cost:  0.4052507285291871\n",
      "iteration:  55  cost:  0.5643980046842312\n",
      "iteration:  56  cost:  0.3321283261226499\n",
      "iteration:  57  cost:  0.3321665254661745\n",
      "iteration:  58  cost:  0.40099549528233797\n",
      "iteration:  59  cost:  0.3665268515582224\n",
      "[0.46, 0.782, 0.942, 0.98, 0.982, 0.986, 0.982]\n",
      "iteration:  60  cost:  0.2944634668802357\n",
      "iteration:  61  cost:  0.32415561269079624\n",
      "iteration:  62  cost:  0.40338035123018257\n",
      "iteration:  63  cost:  0.3205302445800342\n",
      "iteration:  64  cost:  0.4155637075804605\n",
      "iteration:  65  cost:  0.3227882191953528\n",
      "iteration:  66  cost:  0.38757889210524754\n",
      "iteration:  67  cost:  0.352844201440901\n",
      "iteration:  68  cost:  0.32317512206690124\n",
      "iteration:  69  cost:  0.3437022734213808\n",
      "[0.46, 0.782, 0.942, 0.98, 0.982, 0.986, 0.982, 0.98]\n",
      "Accuracy for U_SO4 resize256 :0.9820330969267139\n",
      "\n",
      "\n",
      "Loss History for QCNN circuits, U_SO4 pca8\n",
      "[0.128]\n",
      "iteration:  0  cost:  1.159119497872669\n",
      "iteration:  1  cost:  1.1468236086539583\n",
      "iteration:  2  cost:  1.1549967112367023\n",
      "iteration:  3  cost:  1.124513010141633\n",
      "iteration:  4  cost:  1.0849918876690368\n",
      "iteration:  5  cost:  1.0618846518005072\n",
      "iteration:  6  cost:  1.053106992748182\n",
      "iteration:  7  cost:  1.0166516265338956\n",
      "iteration:  8  cost:  1.041129855512348\n",
      "iteration:  9  cost:  1.0209549577657562\n",
      "[0.128, 0.462]\n",
      "iteration:  10  cost:  0.9856642356493853\n",
      "iteration:  11  cost:  0.9659496029510657\n",
      "iteration:  12  cost:  0.9393087162203994\n",
      "iteration:  13  cost:  0.9194283028961633\n",
      "iteration:  14  cost:  0.936534942642038\n",
      "iteration:  15  cost:  0.918800751861523\n",
      "iteration:  16  cost:  0.9144312409332045\n",
      "iteration:  17  cost:  0.9082260442839605\n",
      "iteration:  18  cost:  0.8791488295681634\n",
      "iteration:  19  cost:  0.8863846398813944\n",
      "[0.128, 0.462, 0.928]\n",
      "iteration:  20  cost:  0.8582473565077474\n",
      "iteration:  21  cost:  0.8020258296314534\n",
      "iteration:  22  cost:  0.8030702936222635\n",
      "iteration:  23  cost:  0.7933640454130803\n",
      "iteration:  24  cost:  0.7541030108575606\n",
      "iteration:  25  cost:  0.7392989035391669\n",
      "iteration:  26  cost:  0.675938143466633\n",
      "iteration:  27  cost:  0.7116418072295119\n",
      "iteration:  28  cost:  0.6926860509857358\n",
      "iteration:  29  cost:  0.6715134567946586\n",
      "[0.128, 0.462, 0.928, 0.984]\n",
      "iteration:  30  cost:  0.6432289222920099\n",
      "iteration:  31  cost:  0.6614217898728776\n",
      "iteration:  32  cost:  0.6395957028582958\n",
      "iteration:  33  cost:  0.5824538707798588\n",
      "iteration:  34  cost:  0.5756196285022849\n",
      "iteration:  35  cost:  0.5749021594747767\n",
      "iteration:  36  cost:  0.598338579868929\n",
      "iteration:  37  cost:  0.5323281104225763\n",
      "iteration:  38  cost:  0.5659226717511334\n",
      "iteration:  39  cost:  0.5223113724037818\n",
      "[0.128, 0.462, 0.928, 0.984, 0.988]\n",
      "iteration:  40  cost:  0.5712354703761195\n",
      "iteration:  41  cost:  0.4646767659451248\n",
      "iteration:  42  cost:  0.5123899348100484\n",
      "iteration:  43  cost:  0.5575754594065704\n",
      "iteration:  44  cost:  0.5583142817980234\n",
      "iteration:  45  cost:  0.4820383501608375\n",
      "iteration:  46  cost:  0.6901369240276907\n",
      "iteration:  47  cost:  0.5042211476646321\n",
      "iteration:  48  cost:  0.4779194498411452\n",
      "iteration:  49  cost:  0.47208499540485993\n",
      "[0.128, 0.462, 0.928, 0.984, 0.988, 0.984]\n",
      "iteration:  50  cost:  0.4682502764550234\n",
      "iteration:  51  cost:  0.47918711098206573\n",
      "iteration:  52  cost:  0.4724592748125109\n",
      "iteration:  53  cost:  0.4630394558452648\n",
      "iteration:  54  cost:  0.4587066343598549\n",
      "iteration:  55  cost:  0.4487592199584948\n",
      "iteration:  56  cost:  0.45146487180648426\n",
      "iteration:  57  cost:  0.505006287187729\n",
      "iteration:  58  cost:  0.4894645936101796\n",
      "iteration:  59  cost:  0.47816153437197484\n",
      "[0.128, 0.462, 0.928, 0.984, 0.988, 0.984, 0.984]\n",
      "iteration:  60  cost:  0.4086099886169716\n",
      "iteration:  61  cost:  0.4292320666421534\n",
      "iteration:  62  cost:  0.42923761217225975\n",
      "iteration:  63  cost:  0.453137410387464\n",
      "iteration:  64  cost:  0.4027019695576708\n",
      "iteration:  65  cost:  0.4274156350755074\n",
      "iteration:  66  cost:  0.4733167893242978\n",
      "iteration:  67  cost:  0.3989495715105605\n",
      "iteration:  68  cost:  0.44097359836629335\n",
      "iteration:  69  cost:  0.4298148936221395\n",
      "[0.128, 0.462, 0.928, 0.984, 0.988, 0.984, 0.984, 0.982]\n",
      "Accuracy for U_SO4 pca8 :0.9900709219858156\n",
      "\n",
      "\n",
      "Loss History for QCNN circuits, U_SO4 pca16\n",
      "[0.772]\n",
      "iteration:  0  cost:  0.9036354256208936\n",
      "iteration:  1  cost:  0.8456676792193855\n",
      "iteration:  2  cost:  0.885546815228146\n",
      "iteration:  3  cost:  0.8508296659428219\n",
      "iteration:  4  cost:  0.785119057117898\n",
      "iteration:  5  cost:  0.7574870553008648\n",
      "iteration:  6  cost:  0.7867241354356962\n",
      "iteration:  7  cost:  0.7604669063476771\n",
      "iteration:  8  cost:  0.6943536054720555\n",
      "iteration:  9  cost:  0.6175847848208468\n",
      "[0.772, 0.966]\n",
      "iteration:  10  cost:  0.5988098934814424\n",
      "iteration:  11  cost:  0.5588983118467418\n",
      "iteration:  12  cost:  0.5183136643441028\n",
      "iteration:  13  cost:  0.5622250621351629\n",
      "iteration:  14  cost:  0.6046232735230365\n",
      "iteration:  15  cost:  0.40312856753742715\n",
      "iteration:  16  cost:  0.35567106660185\n",
      "iteration:  17  cost:  0.40182144220563976\n",
      "iteration:  18  cost:  0.3646205116039004\n",
      "iteration:  19  cost:  0.2769231319099037\n",
      "[0.772, 0.966, 0.968]\n",
      "iteration:  20  cost:  0.24400522132931213\n",
      "iteration:  21  cost:  0.2846840754277845\n",
      "iteration:  22  cost:  0.2666269643947124\n",
      "iteration:  23  cost:  0.23519976903766188\n",
      "iteration:  24  cost:  0.2100972616046334\n",
      "iteration:  25  cost:  0.2899533323798995\n",
      "iteration:  26  cost:  0.18633095988254259\n",
      "iteration:  27  cost:  0.231752344599166\n",
      "iteration:  28  cost:  0.31134518913077486\n",
      "iteration:  29  cost:  0.18659473545490216\n",
      "[0.772, 0.966, 0.968, 0.976]\n",
      "iteration:  30  cost:  0.1721024590868158\n",
      "iteration:  31  cost:  0.25246495981459044\n",
      "iteration:  32  cost:  0.22175074261301142\n",
      "iteration:  33  cost:  0.2168177751041673\n",
      "iteration:  34  cost:  0.13400537566022178\n",
      "iteration:  35  cost:  0.13791881942845477\n",
      "iteration:  36  cost:  0.230068043481306\n",
      "iteration:  37  cost:  0.1702607654416971\n",
      "iteration:  38  cost:  0.1558827491177141\n",
      "iteration:  39  cost:  0.14984886915198145\n",
      "[0.772, 0.966, 0.968, 0.976, 0.98]\n",
      "iteration:  40  cost:  0.13229953179385803\n",
      "iteration:  41  cost:  0.09372282831657767\n",
      "iteration:  42  cost:  0.15871165300927365\n",
      "iteration:  43  cost:  0.4221644382558967\n",
      "iteration:  44  cost:  0.1979270393987518\n",
      "iteration:  45  cost:  0.10958521467829935\n",
      "iteration:  46  cost:  0.15288819600377337\n",
      "iteration:  47  cost:  0.1733120131061484\n",
      "iteration:  48  cost:  0.13706419190669256\n",
      "iteration:  49  cost:  0.23057495487813187\n",
      "[0.772, 0.966, 0.968, 0.976, 0.98, 0.978]\n",
      "iteration:  50  cost:  0.1863537275977693\n",
      "iteration:  51  cost:  0.11109417143648927\n",
      "iteration:  52  cost:  0.18212668499216889\n",
      "iteration:  53  cost:  0.1489242723149382\n",
      "iteration:  54  cost:  0.20637763934443648\n",
      "iteration:  55  cost:  0.14083561428292318\n",
      "iteration:  56  cost:  0.1187903885998207\n",
      "iteration:  57  cost:  0.22165846889090232\n",
      "iteration:  58  cost:  0.17761255639541187\n",
      "iteration:  59  cost:  0.09016378781571353\n",
      "[0.772, 0.966, 0.968, 0.976, 0.98, 0.978, 0.98]\n",
      "iteration:  60  cost:  0.13991741257278942\n",
      "iteration:  61  cost:  0.1205510005269986\n",
      "iteration:  62  cost:  0.13102505382628452\n",
      "iteration:  63  cost:  0.180533977966057\n",
      "iteration:  64  cost:  0.3442934488174369\n",
      "iteration:  65  cost:  0.06718765438578765\n",
      "iteration:  66  cost:  0.15764798836907815\n",
      "iteration:  67  cost:  0.10253209984639357\n",
      "iteration:  68  cost:  0.1698858944154735\n",
      "iteration:  69  cost:  0.15822054506535502\n",
      "[0.772, 0.966, 0.968, 0.976, 0.98, 0.978, 0.98, 0.978]\n",
      "iteration:  70  cost:  0.1583086048282019\n",
      "iteration:  71  cost:  0.26208671587469773\n",
      "iteration:  72  cost:  0.10998017182906514\n",
      "iteration:  73  cost:  0.13579775772534158\n",
      "iteration:  74  cost:  0.15909199428536897\n",
      "iteration:  75  cost:  0.21139024883750226\n",
      "iteration:  76  cost:  0.14781817091720195\n",
      "iteration:  77  cost:  0.17845259202217292\n",
      "iteration:  78  cost:  0.16200358691033595\n",
      "iteration:  79  cost:  0.11220890531656189\n",
      "[0.772, 0.966, 0.968, 0.976, 0.98, 0.978, 0.98, 0.978, 0.978]\n",
      "iteration:  80  cost:  0.13213196921851278\n",
      "iteration:  81  cost:  0.15834712639515727\n",
      "iteration:  82  cost:  0.15869027858370566\n",
      "iteration:  83  cost:  0.14580275409424667\n",
      "iteration:  84  cost:  0.17591062730380944\n",
      "iteration:  85  cost:  0.14740004808308846\n",
      "iteration:  86  cost:  0.25582944700325433\n",
      "iteration:  87  cost:  0.22118630743326967\n",
      "iteration:  88  cost:  0.12980245902236687\n",
      "iteration:  89  cost:  0.05653291214616079\n",
      "[0.772, 0.966, 0.968, 0.976, 0.98, 0.978, 0.98, 0.978, 0.978, 0.978]\n",
      "iteration:  90  cost:  0.0642746677246364\n",
      "iteration:  91  cost:  0.1540578065090429\n",
      "iteration:  92  cost:  0.4002320557953055\n",
      "iteration:  93  cost:  0.2581574714875543\n",
      "iteration:  94  cost:  0.13121615306070106\n",
      "iteration:  95  cost:  0.06338044871333216\n",
      "iteration:  96  cost:  0.24983159128944035\n",
      "iteration:  97  cost:  0.1341764518665073\n",
      "iteration:  98  cost:  0.1455129742406356\n",
      "iteration:  99  cost:  0.32678122778070917\n",
      "[0.772, 0.966, 0.968, 0.976, 0.98, 0.978, 0.98, 0.978, 0.978, 0.978, 0.98]\n",
      "iteration:  100  cost:  0.140145784833321\n",
      "iteration:  101  cost:  0.09560645238869739\n",
      "iteration:  102  cost:  0.17762798499759214\n",
      "iteration:  103  cost:  0.10952839170322781\n",
      "iteration:  104  cost:  0.21954743004009766\n",
      "iteration:  105  cost:  0.19781507975468407\n",
      "iteration:  106  cost:  0.07474234334270621\n",
      "iteration:  107  cost:  0.10550012042538888\n",
      "iteration:  108  cost:  0.07791339105429133\n",
      "iteration:  109  cost:  0.11843627826376008\n",
      "[0.772, 0.966, 0.968, 0.976, 0.98, 0.978, 0.98, 0.978, 0.978, 0.978, 0.98, 0.98]\n",
      "iteration:  110  cost:  0.11313065833316943\n",
      "iteration:  111  cost:  0.16309335938320393\n",
      "iteration:  112  cost:  0.14190261747516128\n",
      "iteration:  113  cost:  0.09972713009453335\n",
      "iteration:  114  cost:  0.28681844239598536\n",
      "iteration:  115  cost:  0.07343655510119834\n",
      "iteration:  116  cost:  0.1372573880800765\n",
      "iteration:  117  cost:  0.09878548986143466\n",
      "iteration:  118  cost:  0.16994263978918261\n",
      "iteration:  119  cost:  0.0646394614861906\n",
      "[0.772, 0.966, 0.968, 0.976, 0.98, 0.978, 0.98, 0.978, 0.978, 0.978, 0.98, 0.98, 0.978]\n",
      "iteration:  120  cost:  0.3502320825258359\n",
      "iteration:  121  cost:  0.11615057942112614\n",
      "iteration:  122  cost:  0.0967092881749218\n",
      "iteration:  123  cost:  0.1279746596073556\n",
      "iteration:  124  cost:  0.14039324670355727\n",
      "iteration:  125  cost:  0.04506487408332791\n",
      "iteration:  126  cost:  0.0743750679630195\n",
      "iteration:  127  cost:  0.10859506151854491\n",
      "iteration:  128  cost:  0.1896989284998132\n",
      "iteration:  129  cost:  0.16123159091725078\n",
      "[0.772, 0.966, 0.968, 0.976, 0.98, 0.978, 0.98, 0.978, 0.978, 0.978, 0.98, 0.98, 0.978, 0.976]\n",
      "Accuracy for U_SO4 pca16 :0.9815602836879432\n",
      "Epoch 1/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.1057 - val_loss: 0.0369\n",
      "Epoch 2/10\n",
      "396/396 [==============================] - 1s 1ms/step - loss: 0.0336 - val_loss: 0.0266\n",
      "Epoch 3/10\n",
      "396/396 [==============================] - 1s 1ms/step - loss: 0.0259 - val_loss: 0.0232\n",
      "Epoch 4/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.0229 - val_loss: 0.0212\n",
      "Epoch 5/10\n",
      "396/396 [==============================] - 1s 1ms/step - loss: 0.0212 - val_loss: 0.0200\n",
      "Epoch 6/10\n",
      "396/396 [==============================] - 1s 1ms/step - loss: 0.0200 - val_loss: 0.0192\n",
      "Epoch 7/10\n",
      "396/396 [==============================] - 1s 1ms/step - loss: 0.0195 - val_loss: 0.0186\n",
      "Epoch 8/10\n",
      "396/396 [==============================] - 1s 1ms/step - loss: 0.0188 - val_loss: 0.0182\n",
      "Epoch 9/10\n",
      "396/396 [==============================] - 1s 1ms/step - loss: 0.0183 - val_loss: 0.0179\n",
      "Epoch 10/10\n",
      "396/396 [==============================] - 1s 1ms/step - loss: 0.0180 - val_loss: 0.0177\n",
      "\n",
      "\n",
      "Loss History for QCNN circuits, U_SO4 autoencoder8\n",
      "[0.588]\n",
      "iteration:  0  cost:  1.0109477697094953\n",
      "iteration:  1  cost:  1.053929524308699\n",
      "iteration:  2  cost:  1.000709375936608\n",
      "iteration:  3  cost:  0.9544281199436141\n",
      "iteration:  4  cost:  1.020558979528106\n",
      "iteration:  5  cost:  0.9115278549883707\n",
      "iteration:  6  cost:  0.9558384185634256\n",
      "iteration:  7  cost:  0.8513630016433477\n",
      "iteration:  8  cost:  0.8465262481980212\n",
      "iteration:  9  cost:  0.722235270210932\n",
      "[0.588, 0.776]\n",
      "iteration:  10  cost:  0.7579896608399308\n",
      "iteration:  11  cost:  0.7953796439726797\n",
      "iteration:  12  cost:  0.6153414292550428\n",
      "iteration:  13  cost:  0.6796343583884855\n",
      "iteration:  14  cost:  0.7245477550381558\n",
      "iteration:  15  cost:  0.6505078025929681\n",
      "iteration:  16  cost:  0.6621499060967929\n",
      "iteration:  17  cost:  0.6467099064753445\n",
      "iteration:  18  cost:  0.5490755212556558\n",
      "iteration:  19  cost:  0.5693621415478693\n",
      "[0.588, 0.776, 0.922]\n",
      "iteration:  20  cost:  0.5972195032364399\n",
      "iteration:  21  cost:  0.535314502942056\n",
      "iteration:  22  cost:  0.5558011024483157\n",
      "iteration:  23  cost:  0.604621649178479\n",
      "iteration:  24  cost:  0.48079301219974446\n",
      "iteration:  25  cost:  0.4223632209708798\n",
      "iteration:  26  cost:  0.4718007355878659\n",
      "iteration:  27  cost:  0.5545346568975276\n",
      "iteration:  28  cost:  0.49711258610533837\n",
      "iteration:  29  cost:  0.431287551825871\n",
      "[0.588, 0.776, 0.922, 0.924]\n",
      "iteration:  30  cost:  0.4968327692197115\n",
      "iteration:  31  cost:  0.5049123168669886\n",
      "iteration:  32  cost:  0.5645840838328812\n",
      "iteration:  33  cost:  0.5090152038777646\n",
      "iteration:  34  cost:  0.563585219619878\n",
      "iteration:  35  cost:  0.48543293454474534\n",
      "iteration:  36  cost:  0.5008677572857233\n",
      "iteration:  37  cost:  0.44755322982893503\n",
      "iteration:  38  cost:  0.5132441544723493\n",
      "iteration:  39  cost:  0.4365181183555492\n",
      "[0.588, 0.776, 0.922, 0.924, 0.976]\n",
      "iteration:  40  cost:  0.5309558905679427\n",
      "iteration:  41  cost:  0.5426363509391803\n",
      "iteration:  42  cost:  0.48721099057041456\n",
      "iteration:  43  cost:  0.5593372645926509\n",
      "iteration:  44  cost:  0.4579688115653925\n",
      "iteration:  45  cost:  0.5808357240733831\n",
      "iteration:  46  cost:  0.41529760552514483\n",
      "iteration:  47  cost:  0.5434647526473958\n",
      "iteration:  48  cost:  0.5406478694909059\n",
      "iteration:  49  cost:  0.4640619392766665\n",
      "[0.588, 0.776, 0.922, 0.924, 0.976, 0.97]\n",
      "iteration:  50  cost:  0.5203311261491437\n",
      "iteration:  51  cost:  0.5425737658057721\n",
      "iteration:  52  cost:  0.5295378225050869\n",
      "iteration:  53  cost:  0.4850174209556706\n",
      "iteration:  54  cost:  0.4901540219530435\n",
      "iteration:  55  cost:  0.5091294383451861\n",
      "iteration:  56  cost:  0.5185487435681322\n",
      "iteration:  57  cost:  0.4305750980277125\n",
      "iteration:  58  cost:  0.46529813263320435\n",
      "iteration:  59  cost:  0.4484977466594326\n",
      "[0.588, 0.776, 0.922, 0.924, 0.976, 0.97, 0.968]\n",
      "iteration:  60  cost:  0.4727416532966885\n",
      "iteration:  61  cost:  0.48479481514242173\n",
      "iteration:  62  cost:  0.4829811244835912\n",
      "iteration:  63  cost:  0.5525773592295912\n",
      "iteration:  64  cost:  0.5228555098687583\n",
      "iteration:  65  cost:  0.5198458882205745\n",
      "iteration:  66  cost:  0.47125904525033574\n",
      "iteration:  67  cost:  0.4494560247920407\n",
      "iteration:  68  cost:  0.4966516452732415\n",
      "iteration:  69  cost:  0.5419947907079219\n",
      "[0.588, 0.776, 0.922, 0.924, 0.976, 0.97, 0.968, 0.974]\n",
      "iteration:  70  cost:  0.45474005863411227\n",
      "iteration:  71  cost:  0.5820020646786804\n",
      "iteration:  72  cost:  0.41197622501345926\n",
      "iteration:  73  cost:  0.41675537965875264\n",
      "iteration:  74  cost:  0.41579774345245746\n",
      "iteration:  75  cost:  0.4331655137970782\n",
      "iteration:  76  cost:  0.5452886861051052\n",
      "iteration:  77  cost:  0.3994708354616702\n",
      "iteration:  78  cost:  0.433728826787921\n",
      "iteration:  79  cost:  0.45112753164611014\n",
      "[0.588, 0.776, 0.922, 0.924, 0.976, 0.97, 0.968, 0.974, 0.968]\n",
      "iteration:  80  cost:  0.4276647290533353\n",
      "iteration:  81  cost:  0.5102186136177653\n",
      "iteration:  82  cost:  0.5566746613453278\n",
      "iteration:  83  cost:  0.42533354876714313\n",
      "iteration:  84  cost:  0.5026746144422941\n",
      "iteration:  85  cost:  0.43651825375841846\n",
      "iteration:  86  cost:  0.3324192597819924\n",
      "iteration:  87  cost:  0.4505454278594236\n",
      "iteration:  88  cost:  0.46770249220725646\n",
      "iteration:  89  cost:  0.44539240523302015\n",
      "[0.588, 0.776, 0.922, 0.924, 0.976, 0.97, 0.968, 0.974, 0.968, 0.97]\n",
      "iteration:  90  cost:  0.4857805172358756\n",
      "iteration:  91  cost:  0.5244428799474952\n",
      "iteration:  92  cost:  0.4876615202024539\n",
      "iteration:  93  cost:  0.522779289048209\n",
      "iteration:  94  cost:  0.44417880628830836\n",
      "iteration:  95  cost:  0.5125952808482629\n",
      "iteration:  96  cost:  0.4449131719484765\n",
      "iteration:  97  cost:  0.39703029330920325\n",
      "iteration:  98  cost:  0.4985031757414173\n",
      "iteration:  99  cost:  0.5449515844229839\n",
      "[0.588, 0.776, 0.922, 0.924, 0.976, 0.97, 0.968, 0.974, 0.968, 0.97, 0.968]\n",
      "iteration:  100  cost:  0.3613988581001118\n",
      "iteration:  101  cost:  0.47093513465647446\n",
      "iteration:  102  cost:  0.4783697656248273\n",
      "iteration:  103  cost:  0.5710152753147477\n",
      "iteration:  104  cost:  0.3910791529715712\n",
      "iteration:  105  cost:  0.43763395243797704\n",
      "iteration:  106  cost:  0.4196722973167853\n",
      "iteration:  107  cost:  0.48838775020630537\n",
      "iteration:  108  cost:  0.4297313705805426\n",
      "iteration:  109  cost:  0.48603831860735347\n",
      "[0.588, 0.776, 0.922, 0.924, 0.976, 0.97, 0.968, 0.974, 0.968, 0.97, 0.968, 0.968]\n",
      "iteration:  110  cost:  0.4134166103582511\n",
      "iteration:  111  cost:  0.48194865895523414\n",
      "iteration:  112  cost:  0.3895362836257138\n",
      "iteration:  113  cost:  0.385546550238548\n",
      "iteration:  114  cost:  0.547053280473091\n",
      "iteration:  115  cost:  0.4142522585768542\n",
      "iteration:  116  cost:  0.42975879045327275\n",
      "iteration:  117  cost:  0.4739770996679443\n",
      "iteration:  118  cost:  0.43039372913586327\n",
      "iteration:  119  cost:  0.5768993910973732\n",
      "[0.588, 0.776, 0.922, 0.924, 0.976, 0.97, 0.968, 0.974, 0.968, 0.97, 0.968, 0.968, 0.958]\n",
      "Accuracy for U_SO4 autoencoder8 :0.9716312056737588\n",
      "Epoch 1/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.0935 - val_loss: 0.0287\n",
      "Epoch 2/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.0271 - val_loss: 0.0225\n",
      "Epoch 3/10\n",
      "396/396 [==============================] - 1s 1ms/step - loss: 0.0221 - val_loss: 0.0182\n",
      "Epoch 4/10\n",
      "396/396 [==============================] - 1s 1ms/step - loss: 0.0176 - val_loss: 0.0152\n",
      "Epoch 5/10\n",
      "396/396 [==============================] - 1s 1ms/step - loss: 0.0149 - val_loss: 0.0136\n",
      "Epoch 6/10\n",
      "396/396 [==============================] - 1s 1ms/step - loss: 0.0138 - val_loss: 0.0126\n",
      "Epoch 7/10\n",
      "396/396 [==============================] - 1s 1ms/step - loss: 0.0126 - val_loss: 0.0119\n",
      "Epoch 8/10\n",
      "396/396 [==============================] - 1s 1ms/step - loss: 0.0119 - val_loss: 0.0114\n",
      "Epoch 9/10\n",
      "396/396 [==============================] - 1s 1ms/step - loss: 0.0117 - val_loss: 0.0110\n",
      "Epoch 10/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.0112 - val_loss: 0.0108\n",
      "\n",
      "\n",
      "Loss History for QCNN circuits, U_SO4 autoencoder16\n",
      "[0.548]\n",
      "iteration:  0  cost:  1.0116487604732713\n",
      "iteration:  1  cost:  1.049843135035738\n",
      "iteration:  2  cost:  0.9884939585077767\n",
      "iteration:  3  cost:  0.9979095278030478\n",
      "iteration:  4  cost:  0.9767860867037484\n",
      "iteration:  5  cost:  0.9636926864363733\n",
      "iteration:  6  cost:  0.9883796086742658\n",
      "iteration:  7  cost:  1.0029852048964183\n",
      "iteration:  8  cost:  0.9669308682655514\n",
      "iteration:  9  cost:  0.96351151649539\n",
      "[0.548, 0.638]\n",
      "iteration:  10  cost:  0.991510323087755\n",
      "iteration:  11  cost:  0.9609899194402971\n",
      "iteration:  12  cost:  0.9816633165228033\n",
      "iteration:  13  cost:  0.9173002888396208\n",
      "iteration:  14  cost:  0.970313033165356\n",
      "iteration:  15  cost:  0.8929517807281315\n",
      "iteration:  16  cost:  0.901679062018151\n",
      "iteration:  17  cost:  0.9552548248828963\n",
      "iteration:  18  cost:  0.921852080161425\n",
      "iteration:  19  cost:  0.931426795614447\n",
      "[0.548, 0.638, 0.736]\n",
      "iteration:  20  cost:  0.895075225662693\n",
      "iteration:  21  cost:  0.8124026432997005\n",
      "iteration:  22  cost:  0.8918885119772796\n",
      "iteration:  23  cost:  0.8556543414262988\n",
      "iteration:  24  cost:  0.8788428606606878\n",
      "iteration:  25  cost:  0.8555351841127018\n",
      "iteration:  26  cost:  0.8316377066084943\n",
      "iteration:  27  cost:  0.7733438774626109\n",
      "iteration:  28  cost:  0.8230923334727303\n",
      "iteration:  29  cost:  0.7715202442756337\n",
      "[0.548, 0.638, 0.736, 0.772]\n",
      "iteration:  30  cost:  0.7409344103700586\n",
      "iteration:  31  cost:  0.8145705135465753\n",
      "iteration:  32  cost:  0.7062457875724922\n",
      "iteration:  33  cost:  0.8122161586176674\n",
      "iteration:  34  cost:  0.8989229272170297\n",
      "iteration:  35  cost:  0.7129590826692409\n",
      "iteration:  36  cost:  0.776381934442973\n",
      "iteration:  37  cost:  0.8017861347405243\n",
      "iteration:  38  cost:  0.7159542473749109\n",
      "iteration:  39  cost:  0.7771261083008699\n",
      "[0.548, 0.638, 0.736, 0.772, 0.786]\n",
      "iteration:  40  cost:  0.6924464676089079\n",
      "iteration:  41  cost:  0.8167034287339603\n",
      "iteration:  42  cost:  0.7278014041623965\n",
      "iteration:  43  cost:  0.7998768753042498\n",
      "iteration:  44  cost:  0.6979624586831755\n",
      "iteration:  45  cost:  0.7018492721976907\n",
      "iteration:  46  cost:  0.7662770893228409\n",
      "iteration:  47  cost:  0.750982866067157\n",
      "iteration:  48  cost:  0.6858240416040823\n",
      "iteration:  49  cost:  0.6719572663697404\n",
      "[0.548, 0.638, 0.736, 0.772, 0.786, 0.834]\n",
      "iteration:  50  cost:  0.8381031773122403\n",
      "iteration:  51  cost:  0.6446761513139228\n",
      "iteration:  52  cost:  0.7365162904885303\n",
      "iteration:  53  cost:  0.660804626321899\n",
      "iteration:  54  cost:  0.63520111854995\n",
      "iteration:  55  cost:  0.6716639652354758\n",
      "iteration:  56  cost:  0.5894292046005464\n",
      "iteration:  57  cost:  0.6818752861014461\n",
      "iteration:  58  cost:  0.662298641634689\n",
      "iteration:  59  cost:  0.6967534056790154\n",
      "[0.548, 0.638, 0.736, 0.772, 0.786, 0.834, 0.856]\n",
      "iteration:  60  cost:  0.6623296902239676\n",
      "iteration:  61  cost:  0.6427567381869757\n",
      "iteration:  62  cost:  0.49319169780083105\n",
      "iteration:  63  cost:  0.7580683807373098\n",
      "iteration:  64  cost:  0.6321236431218403\n",
      "iteration:  65  cost:  0.6602010137496092\n",
      "iteration:  66  cost:  0.6540761098921299\n",
      "iteration:  67  cost:  0.6807644686875561\n",
      "iteration:  68  cost:  0.6328093517775596\n",
      "iteration:  69  cost:  0.7405858290260763\n",
      "[0.548, 0.638, 0.736, 0.772, 0.786, 0.834, 0.856, 0.862]\n",
      "iteration:  70  cost:  0.7583441871295562\n",
      "iteration:  71  cost:  0.6115254352274198\n",
      "iteration:  72  cost:  0.5682793133395658\n",
      "iteration:  73  cost:  0.6803280049018889\n",
      "iteration:  74  cost:  0.5414192345508154\n",
      "iteration:  75  cost:  0.6854325009648495\n",
      "iteration:  76  cost:  0.6085326859069918\n",
      "iteration:  77  cost:  0.6839589584622011\n",
      "iteration:  78  cost:  0.5835753383934654\n",
      "iteration:  79  cost:  0.6047063973200699\n",
      "[0.548, 0.638, 0.736, 0.772, 0.786, 0.834, 0.856, 0.862, 0.92]\n",
      "iteration:  80  cost:  0.6700864922071227\n",
      "iteration:  81  cost:  0.6286291913728774\n",
      "iteration:  82  cost:  0.5809353372362192\n",
      "iteration:  83  cost:  0.620200090948225\n",
      "iteration:  84  cost:  0.6245672652928691\n",
      "iteration:  85  cost:  0.6305553956129246\n",
      "iteration:  86  cost:  0.622847752019951\n",
      "iteration:  87  cost:  0.689191625694415\n",
      "iteration:  88  cost:  0.5704673801820068\n",
      "iteration:  89  cost:  0.655940049720202\n",
      "[0.548, 0.638, 0.736, 0.772, 0.786, 0.834, 0.856, 0.862, 0.92, 0.906]\n",
      "iteration:  90  cost:  0.646987757323446\n",
      "iteration:  91  cost:  0.5732933542174982\n",
      "iteration:  92  cost:  0.5649407278715445\n",
      "iteration:  93  cost:  0.6215684988264927\n",
      "iteration:  94  cost:  0.6481683355697077\n",
      "iteration:  95  cost:  0.572790736774392\n",
      "iteration:  96  cost:  0.6400287417273719\n",
      "iteration:  97  cost:  0.4991249359941894\n",
      "iteration:  98  cost:  0.6038093374767223\n",
      "iteration:  99  cost:  0.5768569007384314\n",
      "[0.548, 0.638, 0.736, 0.772, 0.786, 0.834, 0.856, 0.862, 0.92, 0.906, 0.906]\n",
      "iteration:  100  cost:  0.6373181458094254\n",
      "iteration:  101  cost:  0.5552869594524608\n",
      "iteration:  102  cost:  0.5662406573911379\n",
      "iteration:  103  cost:  0.6741341311562934\n",
      "iteration:  104  cost:  0.5820048747747699\n",
      "iteration:  105  cost:  0.5991791652824326\n",
      "iteration:  106  cost:  0.5744398498201901\n",
      "iteration:  107  cost:  0.5423126644606497\n",
      "iteration:  108  cost:  0.6277335009869144\n",
      "iteration:  109  cost:  0.5434418855411536\n",
      "[0.548, 0.638, 0.736, 0.772, 0.786, 0.834, 0.856, 0.862, 0.92, 0.906, 0.906, 0.892]\n",
      "Accuracy for U_SO4 autoencoder16 :0.9073286052009456\n",
      "1th step : \n",
      "\n",
      "\n",
      "Loss History for QCNN circuits, U_TTN resize256\n",
      "[0.706]\n",
      "iteration:  0  cost:  0.9163031844872562\n",
      "iteration:  1  cost:  0.9165146731792434\n",
      "iteration:  2  cost:  0.9195917509962962\n",
      "iteration:  3  cost:  0.9071224689228568\n",
      "iteration:  4  cost:  0.9157352513191452\n",
      "iteration:  5  cost:  0.8738070101758134\n",
      "iteration:  6  cost:  0.8933438781924284\n",
      "iteration:  7  cost:  0.9120332634730177\n",
      "iteration:  8  cost:  0.8665726679743015\n",
      "iteration:  9  cost:  0.8761003087793651\n",
      "[0.706, 0.818]\n",
      "iteration:  10  cost:  0.8985300071077676\n",
      "iteration:  11  cost:  0.865950497524938\n",
      "iteration:  12  cost:  0.8845988692871083\n",
      "iteration:  13  cost:  0.860504675767751\n",
      "iteration:  14  cost:  0.9156880393163165\n",
      "iteration:  15  cost:  0.8908751896773428\n",
      "iteration:  16  cost:  0.863870606773785\n",
      "iteration:  17  cost:  0.8576308933283313\n",
      "iteration:  18  cost:  0.8237883505855187\n",
      "iteration:  19  cost:  0.833228852421884\n",
      "[0.706, 0.818, 0.848]\n",
      "iteration:  20  cost:  0.8299713577609363\n",
      "iteration:  21  cost:  0.8481188955764738\n",
      "iteration:  22  cost:  0.8656934454459507\n",
      "iteration:  23  cost:  0.7839005370191815\n",
      "iteration:  24  cost:  0.833765500446703\n",
      "iteration:  25  cost:  0.786916352674112\n",
      "iteration:  26  cost:  0.8145891128779233\n",
      "iteration:  27  cost:  0.8022911857674625\n",
      "iteration:  28  cost:  0.8422236601428341\n",
      "iteration:  29  cost:  0.8049515721595216\n",
      "[0.706, 0.818, 0.848, 0.858]\n",
      "iteration:  30  cost:  0.8372919210822523\n",
      "iteration:  31  cost:  0.9035584120387086\n",
      "iteration:  32  cost:  0.8133274245049082\n",
      "iteration:  33  cost:  0.8446964597518898\n",
      "iteration:  34  cost:  0.8370358436471679\n",
      "iteration:  35  cost:  0.7973425644538417\n",
      "iteration:  36  cost:  0.7586389413755685\n",
      "iteration:  37  cost:  0.7897271600396175\n",
      "iteration:  38  cost:  0.7795931502778497\n",
      "iteration:  39  cost:  0.7709032951845083\n",
      "[0.706, 0.818, 0.848, 0.858, 0.808]\n",
      "Accuracy for U_TTN resize256 :0.8250591016548463\n",
      "\n",
      "\n",
      "Loss History for QCNN circuits, U_TTN pca8\n",
      "[0.26]\n",
      "iteration:  0  cost:  1.256471360929735\n",
      "iteration:  1  cost:  1.3198967839357412\n",
      "iteration:  2  cost:  1.2343203373465454\n",
      "iteration:  3  cost:  1.074960862364997\n",
      "iteration:  4  cost:  1.0386552108354474\n",
      "iteration:  5  cost:  1.0808890142863798\n",
      "iteration:  6  cost:  0.975089764771706\n",
      "iteration:  7  cost:  0.8906293846582289\n",
      "iteration:  8  cost:  0.8747575552034577\n",
      "iteration:  9  cost:  0.8978569369590569\n",
      "[0.26, 0.85]\n",
      "iteration:  10  cost:  0.8114238892933305\n",
      "iteration:  11  cost:  0.776332799015485\n",
      "iteration:  12  cost:  0.7355456825975257\n",
      "iteration:  13  cost:  0.8251029132193906\n",
      "iteration:  14  cost:  0.7578462308907271\n",
      "iteration:  15  cost:  0.6638676688671853\n",
      "iteration:  16  cost:  0.7687811434952962\n",
      "iteration:  17  cost:  0.5544983700059446\n",
      "iteration:  18  cost:  0.6456151373201274\n",
      "iteration:  19  cost:  0.7006992707716112\n",
      "[0.26, 0.85, 0.848]\n",
      "iteration:  20  cost:  0.730923547140703\n",
      "iteration:  21  cost:  0.6624431741808273\n",
      "iteration:  22  cost:  0.6103035372148736\n",
      "iteration:  23  cost:  0.6771289595101874\n",
      "iteration:  24  cost:  0.6122165387381403\n",
      "iteration:  25  cost:  0.6288802494229101\n",
      "iteration:  26  cost:  0.7505644061302376\n",
      "iteration:  27  cost:  0.5098570194159627\n",
      "iteration:  28  cost:  0.43366411733105553\n",
      "iteration:  29  cost:  0.458413627440266\n",
      "[0.26, 0.85, 0.848, 0.956]\n",
      "iteration:  30  cost:  0.4819859068671846\n",
      "iteration:  31  cost:  0.48905533463626116\n",
      "iteration:  32  cost:  0.4444136767162556\n",
      "iteration:  33  cost:  0.4153664766614438\n",
      "iteration:  34  cost:  0.39976387350978776\n",
      "iteration:  35  cost:  0.469469035851666\n",
      "iteration:  36  cost:  0.4637847676053668\n",
      "iteration:  37  cost:  0.42450569810178956\n",
      "iteration:  38  cost:  0.47352621090475805\n",
      "iteration:  39  cost:  0.44304238867873247\n",
      "[0.26, 0.85, 0.848, 0.956, 0.964]\n",
      "iteration:  40  cost:  0.4165897333837059\n",
      "iteration:  41  cost:  0.37163761766504744\n",
      "iteration:  42  cost:  0.40364794479027016\n",
      "iteration:  43  cost:  0.34087213881622236\n",
      "iteration:  44  cost:  0.41007448418983583\n",
      "iteration:  45  cost:  0.41651485758818585\n",
      "iteration:  46  cost:  0.3680872818826883\n",
      "iteration:  47  cost:  0.3746747741579739\n",
      "iteration:  48  cost:  0.2882424611520837\n",
      "iteration:  49  cost:  0.30966954216084436\n",
      "[0.26, 0.85, 0.848, 0.956, 0.964, 0.962]\n",
      "iteration:  50  cost:  0.40262423868595504\n",
      "iteration:  51  cost:  0.29288054652665485\n",
      "iteration:  52  cost:  0.2873758753260982\n",
      "iteration:  53  cost:  0.31346401215224523\n",
      "iteration:  54  cost:  0.33549420599595625\n",
      "iteration:  55  cost:  0.3474633381364663\n",
      "iteration:  56  cost:  0.30180694269900643\n",
      "iteration:  57  cost:  0.3042472251801443\n",
      "iteration:  58  cost:  0.44968576282189127\n",
      "iteration:  59  cost:  0.5174519189331199\n",
      "[0.26, 0.85, 0.848, 0.956, 0.964, 0.962, 0.968]\n",
      "iteration:  60  cost:  0.38739507646845667\n",
      "iteration:  61  cost:  0.31683617364785965\n",
      "iteration:  62  cost:  0.2419645914494271\n",
      "iteration:  63  cost:  0.4070056485498711\n",
      "iteration:  64  cost:  0.47389448918869886\n",
      "iteration:  65  cost:  0.28708037330024083\n",
      "iteration:  66  cost:  0.34937302915640633\n",
      "iteration:  67  cost:  0.3150996855937302\n",
      "iteration:  68  cost:  0.24741148823760958\n",
      "iteration:  69  cost:  0.3013485832636317\n",
      "[0.26, 0.85, 0.848, 0.956, 0.964, 0.962, 0.968, 0.97]\n",
      "iteration:  70  cost:  0.30877538649737185\n",
      "iteration:  71  cost:  0.28817204299239163\n",
      "iteration:  72  cost:  0.25969133422664653\n",
      "iteration:  73  cost:  0.3395095353823757\n",
      "iteration:  74  cost:  0.3726953508530326\n",
      "iteration:  75  cost:  0.2922089046214017\n",
      "iteration:  76  cost:  0.33238939304611337\n",
      "iteration:  77  cost:  0.4134837820903268\n",
      "iteration:  78  cost:  0.2649613625882067\n",
      "iteration:  79  cost:  0.38932514417577335\n",
      "[0.26, 0.85, 0.848, 0.956, 0.964, 0.962, 0.968, 0.97, 0.974]\n",
      "iteration:  80  cost:  0.24218928602076722\n",
      "iteration:  81  cost:  0.2032200343485969\n",
      "iteration:  82  cost:  0.21305315590270268\n",
      "iteration:  83  cost:  0.24722793425791337\n",
      "iteration:  84  cost:  0.2903395159906161\n",
      "iteration:  85  cost:  0.2933863917205559\n",
      "iteration:  86  cost:  0.24213803267372117\n",
      "iteration:  87  cost:  0.24257225277513897\n",
      "iteration:  88  cost:  0.2854938781737072\n",
      "iteration:  89  cost:  0.19066076568136206\n",
      "[0.26, 0.85, 0.848, 0.956, 0.964, 0.962, 0.968, 0.97, 0.974, 0.97]\n",
      "iteration:  90  cost:  0.2513372673837067\n",
      "iteration:  91  cost:  0.21597134112784147\n",
      "iteration:  92  cost:  0.2133492488135721\n",
      "iteration:  93  cost:  0.29060825423328907\n",
      "iteration:  94  cost:  0.2618633738141982\n",
      "iteration:  95  cost:  0.20671793519394493\n",
      "iteration:  96  cost:  0.3004902534989486\n",
      "iteration:  97  cost:  0.23497117758522304\n",
      "iteration:  98  cost:  0.29735749527228633\n",
      "iteration:  99  cost:  0.26470900261345476\n",
      "[0.26, 0.85, 0.848, 0.956, 0.964, 0.962, 0.968, 0.97, 0.974, 0.97, 0.968]\n",
      "Accuracy for U_TTN pca8 :0.9801418439716312\n",
      "\n",
      "\n",
      "Loss History for QCNN circuits, U_TTN pca16\n",
      "[0.442]\n",
      "iteration:  0  cost:  1.0514712562632489\n",
      "iteration:  1  cost:  1.0003842222683277\n",
      "iteration:  2  cost:  1.0432826939908535\n",
      "iteration:  3  cost:  1.0188701038761272\n",
      "iteration:  4  cost:  1.008059067116872\n",
      "iteration:  5  cost:  1.00781692559205\n",
      "iteration:  6  cost:  0.9994000956144036\n",
      "iteration:  7  cost:  0.9959241437713077\n",
      "iteration:  8  cost:  1.022385765307135\n",
      "iteration:  9  cost:  1.000328151554811\n",
      "[0.442, 0.506]\n",
      "iteration:  10  cost:  1.0026669154421517\n",
      "iteration:  11  cost:  1.0419857057294424\n",
      "iteration:  12  cost:  0.9974695171146611\n",
      "iteration:  13  cost:  0.993673298493313\n",
      "iteration:  14  cost:  1.0116456818872066\n",
      "iteration:  15  cost:  1.006723960874813\n",
      "iteration:  16  cost:  0.9548425720616269\n",
      "iteration:  17  cost:  0.9898607711244561\n",
      "iteration:  18  cost:  0.9783618088135044\n",
      "iteration:  19  cost:  0.979159053457118\n",
      "[0.442, 0.506, 0.606]\n",
      "iteration:  20  cost:  0.9995711852744048\n",
      "iteration:  21  cost:  0.9301741427737708\n",
      "iteration:  22  cost:  0.983937334055229\n",
      "iteration:  23  cost:  0.9716002290152557\n",
      "iteration:  24  cost:  0.9979945923333463\n",
      "iteration:  25  cost:  0.9814099264675731\n",
      "iteration:  26  cost:  0.9500005286523634\n",
      "iteration:  27  cost:  0.9419474656888548\n",
      "iteration:  28  cost:  0.9769364485374212\n",
      "iteration:  29  cost:  0.962062736122935\n",
      "[0.442, 0.506, 0.606, 0.692]\n",
      "iteration:  30  cost:  1.002587092679896\n",
      "iteration:  31  cost:  0.9851434950475891\n",
      "iteration:  32  cost:  0.9483765372349687\n",
      "iteration:  33  cost:  0.9651854718518278\n",
      "iteration:  34  cost:  0.9540655323245262\n",
      "iteration:  35  cost:  0.9227377851651244\n",
      "iteration:  36  cost:  0.9502572622467572\n",
      "iteration:  37  cost:  0.970168312628574\n",
      "iteration:  38  cost:  0.9535866007184118\n",
      "iteration:  39  cost:  0.9695708581637612\n",
      "[0.442, 0.506, 0.606, 0.692, 0.748]\n",
      "iteration:  40  cost:  0.9801941884709227\n",
      "iteration:  41  cost:  0.9312304543487602\n",
      "iteration:  42  cost:  0.9437378616174539\n",
      "iteration:  43  cost:  0.9523785207861616\n",
      "iteration:  44  cost:  0.9535125633396865\n",
      "iteration:  45  cost:  0.9579411638075276\n",
      "iteration:  46  cost:  0.9669708997323816\n",
      "iteration:  47  cost:  0.942369869664594\n",
      "iteration:  48  cost:  0.954991297835644\n",
      "iteration:  49  cost:  0.9362806399225447\n",
      "[0.442, 0.506, 0.606, 0.692, 0.748, 0.788]\n",
      "iteration:  50  cost:  0.9340326416144498\n",
      "iteration:  51  cost:  0.9444370732679684\n",
      "iteration:  52  cost:  0.9381502127963561\n",
      "iteration:  53  cost:  0.9541603335138288\n",
      "iteration:  54  cost:  0.9307991866454103\n",
      "iteration:  55  cost:  0.9352219208782963\n",
      "iteration:  56  cost:  0.9298995197710563\n",
      "iteration:  57  cost:  0.9168269376801013\n",
      "iteration:  58  cost:  0.9039214913518465\n",
      "iteration:  59  cost:  0.9434965677182254\n",
      "[0.442, 0.506, 0.606, 0.692, 0.748, 0.788, 0.824]\n",
      "iteration:  60  cost:  0.938601578891109\n",
      "iteration:  61  cost:  0.935561069839734\n",
      "iteration:  62  cost:  0.9549653199946053\n",
      "iteration:  63  cost:  0.9192112559745874\n",
      "iteration:  64  cost:  0.9110917194691733\n",
      "iteration:  65  cost:  0.9124213587321647\n",
      "iteration:  66  cost:  0.9216125373412347\n",
      "iteration:  67  cost:  0.9207882280539937\n",
      "iteration:  68  cost:  0.9306898931728053\n",
      "iteration:  69  cost:  0.9251229488499502\n",
      "[0.442, 0.506, 0.606, 0.692, 0.748, 0.788, 0.824, 0.872]\n",
      "iteration:  70  cost:  0.906279166578894\n",
      "iteration:  71  cost:  0.9118345959171392\n",
      "iteration:  72  cost:  0.9344940997563388\n",
      "iteration:  73  cost:  0.9074950698754265\n",
      "iteration:  74  cost:  0.8919586408265477\n",
      "iteration:  75  cost:  0.932445900668183\n",
      "iteration:  76  cost:  0.9042210210997275\n",
      "iteration:  77  cost:  0.9202417311023504\n",
      "iteration:  78  cost:  0.9092111883911933\n",
      "iteration:  79  cost:  0.8867339872063965\n",
      "[0.442, 0.506, 0.606, 0.692, 0.748, 0.788, 0.824, 0.872, 0.896]\n",
      "iteration:  80  cost:  0.9115653670313054\n",
      "iteration:  81  cost:  0.9206452915505083\n",
      "iteration:  82  cost:  0.9166115827248066\n",
      "iteration:  83  cost:  0.89178456370399\n",
      "iteration:  84  cost:  0.9326431771632854\n",
      "iteration:  85  cost:  0.8993173888049345\n",
      "iteration:  86  cost:  0.8727151120899188\n",
      "iteration:  87  cost:  0.9095682950734085\n",
      "iteration:  88  cost:  0.86696271570436\n",
      "iteration:  89  cost:  0.87747645220001\n",
      "[0.442, 0.506, 0.606, 0.692, 0.748, 0.788, 0.824, 0.872, 0.896, 0.914]\n",
      "iteration:  90  cost:  0.894374116704867\n",
      "iteration:  91  cost:  0.9403098512943867\n",
      "iteration:  92  cost:  0.851139757912932\n",
      "iteration:  93  cost:  0.871072252093546\n",
      "iteration:  94  cost:  0.8904674477419079\n",
      "iteration:  95  cost:  0.8901285514111663\n",
      "iteration:  96  cost:  0.8954247057761691\n",
      "iteration:  97  cost:  0.8821026244589689\n",
      "iteration:  98  cost:  0.9050116083536224\n",
      "iteration:  99  cost:  0.8804457215185875\n",
      "[0.442, 0.506, 0.606, 0.692, 0.748, 0.788, 0.824, 0.872, 0.896, 0.914, 0.926]\n",
      "iteration:  100  cost:  0.88430654350102\n",
      "iteration:  101  cost:  0.854252541026647\n",
      "iteration:  102  cost:  0.8855360313488464\n",
      "iteration:  103  cost:  0.8800442003342209\n",
      "iteration:  104  cost:  0.8662750829136108\n",
      "iteration:  105  cost:  0.8939907131836402\n",
      "iteration:  106  cost:  0.8969748355383237\n",
      "iteration:  107  cost:  0.8655982780134289\n",
      "iteration:  108  cost:  0.8754098040457217\n",
      "iteration:  109  cost:  0.8638826841212796\n",
      "[0.442, 0.506, 0.606, 0.692, 0.748, 0.788, 0.824, 0.872, 0.896, 0.914, 0.926, 0.936]\n",
      "iteration:  110  cost:  0.8549297991229732\n",
      "iteration:  111  cost:  0.8665418686453741\n",
      "iteration:  112  cost:  0.9069565127257906\n",
      "iteration:  113  cost:  0.8509060099219258\n",
      "iteration:  114  cost:  0.9077334184907733\n",
      "iteration:  115  cost:  0.8814498222642223\n",
      "iteration:  116  cost:  0.8358626791254299\n",
      "iteration:  117  cost:  0.8265243260171067\n",
      "iteration:  118  cost:  0.8728345907030857\n",
      "iteration:  119  cost:  0.8704810316127479\n",
      "[0.442, 0.506, 0.606, 0.692, 0.748, 0.788, 0.824, 0.872, 0.896, 0.914, 0.926, 0.936, 0.94]\n",
      "iteration:  120  cost:  0.8653085295041596\n",
      "iteration:  121  cost:  0.8896802740511527\n",
      "iteration:  122  cost:  0.895144673583224\n",
      "iteration:  123  cost:  0.8726828518004466\n",
      "iteration:  124  cost:  0.8438090100371122\n",
      "iteration:  125  cost:  0.8839880960878052\n",
      "iteration:  126  cost:  0.8564734909847703\n",
      "iteration:  127  cost:  0.8455296931606866\n",
      "iteration:  128  cost:  0.8743694337625001\n",
      "iteration:  129  cost:  0.8638495552610503\n",
      "[0.442, 0.506, 0.606, 0.692, 0.748, 0.788, 0.824, 0.872, 0.896, 0.914, 0.926, 0.936, 0.94, 0.942]\n",
      "iteration:  130  cost:  0.8236378981832648\n",
      "iteration:  131  cost:  0.8397309055401015\n",
      "iteration:  132  cost:  0.8413861961758413\n",
      "iteration:  133  cost:  0.9029344728820675\n",
      "iteration:  134  cost:  0.8731264272386485\n",
      "iteration:  135  cost:  0.8575149658780336\n",
      "iteration:  136  cost:  0.8744971373657284\n",
      "iteration:  137  cost:  0.8651335882793566\n",
      "iteration:  138  cost:  0.8451278949273312\n",
      "iteration:  139  cost:  0.8646547840337234\n",
      "[0.442, 0.506, 0.606, 0.692, 0.748, 0.788, 0.824, 0.872, 0.896, 0.914, 0.926, 0.936, 0.94, 0.942, 0.946]\n",
      "iteration:  140  cost:  0.8502984176420699\n",
      "iteration:  141  cost:  0.8778266176053751\n",
      "iteration:  142  cost:  0.8662951770495814\n",
      "iteration:  143  cost:  0.8441736624986781\n",
      "iteration:  144  cost:  0.8279000040738719\n",
      "iteration:  145  cost:  0.828845565875193\n",
      "iteration:  146  cost:  0.8648231223979185\n",
      "iteration:  147  cost:  0.8795570936860909\n",
      "iteration:  148  cost:  0.8564560128985481\n",
      "iteration:  149  cost:  0.8420043083010417\n",
      "[0.442, 0.506, 0.606, 0.692, 0.748, 0.788, 0.824, 0.872, 0.896, 0.914, 0.926, 0.936, 0.94, 0.942, 0.946, 0.948]\n",
      "iteration:  150  cost:  0.8498890161650523\n",
      "iteration:  151  cost:  0.8307379704216996\n",
      "iteration:  152  cost:  0.8406688210421187\n",
      "iteration:  153  cost:  0.8275347748846061\n",
      "iteration:  154  cost:  0.8533771734004273\n",
      "iteration:  155  cost:  0.8241573136584185\n",
      "iteration:  156  cost:  0.8632467602485814\n",
      "iteration:  157  cost:  0.8525087179263059\n",
      "iteration:  158  cost:  0.8375266075638973\n",
      "iteration:  159  cost:  0.8290203565662319\n",
      "[0.442, 0.506, 0.606, 0.692, 0.748, 0.788, 0.824, 0.872, 0.896, 0.914, 0.926, 0.936, 0.94, 0.942, 0.946, 0.948, 0.948]\n",
      "iteration:  160  cost:  0.8452167606926254\n",
      "iteration:  161  cost:  0.8443032602209949\n",
      "iteration:  162  cost:  0.8139138738568018\n",
      "iteration:  163  cost:  0.9238683616208726\n",
      "iteration:  164  cost:  0.8409086343374649\n",
      "iteration:  165  cost:  0.8422390634470547\n",
      "iteration:  166  cost:  0.8558251628612062\n",
      "iteration:  167  cost:  0.850641749018437\n",
      "iteration:  168  cost:  0.8605719063540913\n",
      "iteration:  169  cost:  0.8899189594588687\n",
      "[0.442, 0.506, 0.606, 0.692, 0.748, 0.788, 0.824, 0.872, 0.896, 0.914, 0.926, 0.936, 0.94, 0.942, 0.946, 0.948, 0.948, 0.946]\n",
      "iteration:  170  cost:  0.828786698974835\n",
      "iteration:  171  cost:  0.807273490690279\n",
      "iteration:  172  cost:  0.8712721347403655\n",
      "iteration:  173  cost:  0.8527339931372717\n",
      "iteration:  174  cost:  0.8270555237425004\n",
      "iteration:  175  cost:  0.8193945629012487\n",
      "iteration:  176  cost:  0.8107057805285437\n",
      "iteration:  177  cost:  0.7970997283311508\n",
      "iteration:  178  cost:  0.8346639013898753\n",
      "iteration:  179  cost:  0.8557911024930703\n",
      "[0.442, 0.506, 0.606, 0.692, 0.748, 0.788, 0.824, 0.872, 0.896, 0.914, 0.926, 0.936, 0.94, 0.942, 0.946, 0.948, 0.948, 0.946, 0.946]\n",
      "iteration:  180  cost:  0.8142570673769689\n",
      "iteration:  181  cost:  0.8511316557600996\n",
      "iteration:  182  cost:  0.8295965515418605\n",
      "iteration:  183  cost:  0.8673344623398788\n",
      "iteration:  184  cost:  0.8405550147620096\n",
      "iteration:  185  cost:  0.8040573199321233\n",
      "iteration:  186  cost:  0.8534449167610809\n",
      "iteration:  187  cost:  0.8288187163114367\n",
      "iteration:  188  cost:  0.8419775200782407\n",
      "iteration:  189  cost:  0.8644483633452096\n",
      "[0.442, 0.506, 0.606, 0.692, 0.748, 0.788, 0.824, 0.872, 0.896, 0.914, 0.926, 0.936, 0.94, 0.942, 0.946, 0.948, 0.948, 0.946, 0.946, 0.952]\n",
      "iteration:  190  cost:  0.8477927526305574\n",
      "iteration:  191  cost:  0.8278465018916265\n",
      "iteration:  192  cost:  0.8617877478834639\n",
      "iteration:  193  cost:  0.8296930048263556\n",
      "iteration:  194  cost:  0.8183020305100865\n",
      "iteration:  195  cost:  0.8218475657299281\n",
      "iteration:  196  cost:  0.8589414702658883\n",
      "iteration:  197  cost:  0.8693471189216964\n",
      "iteration:  198  cost:  0.8347596870105848\n",
      "iteration:  199  cost:  0.8323178768247947\n",
      "[0.442, 0.506, 0.606, 0.692, 0.748, 0.788, 0.824, 0.872, 0.896, 0.914, 0.926, 0.936, 0.94, 0.942, 0.946, 0.948, 0.948, 0.946, 0.946, 0.952, 0.962]\n",
      "iteration:  200  cost:  0.8177878466351661\n",
      "iteration:  201  cost:  0.8901818842290552\n",
      "iteration:  202  cost:  0.8332406396163257\n",
      "iteration:  203  cost:  0.8089926135614384\n",
      "iteration:  204  cost:  0.8388019990878633\n",
      "iteration:  205  cost:  0.8137368205310789\n",
      "iteration:  206  cost:  0.841715230216212\n",
      "iteration:  207  cost:  0.8145390978072673\n",
      "iteration:  208  cost:  0.858992134009233\n",
      "iteration:  209  cost:  0.8430000046700264\n",
      "[0.442, 0.506, 0.606, 0.692, 0.748, 0.788, 0.824, 0.872, 0.896, 0.914, 0.926, 0.936, 0.94, 0.942, 0.946, 0.948, 0.948, 0.946, 0.946, 0.952, 0.962, 0.964]\n",
      "iteration:  210  cost:  0.8300473693259017\n",
      "iteration:  211  cost:  0.8181776207195981\n",
      "iteration:  212  cost:  0.8216382644295821\n",
      "iteration:  213  cost:  0.8595236405524908\n",
      "iteration:  214  cost:  0.8466654045634446\n",
      "iteration:  215  cost:  0.8501182345536817\n",
      "iteration:  216  cost:  0.8710825516507886\n",
      "iteration:  217  cost:  0.8301360319556046\n",
      "iteration:  218  cost:  0.8148281171790037\n",
      "iteration:  219  cost:  0.8422533484305208\n",
      "[0.442, 0.506, 0.606, 0.692, 0.748, 0.788, 0.824, 0.872, 0.896, 0.914, 0.926, 0.936, 0.94, 0.942, 0.946, 0.948, 0.948, 0.946, 0.946, 0.952, 0.962, 0.964, 0.966]\n",
      "iteration:  220  cost:  0.8033743473382835\n",
      "iteration:  221  cost:  0.7999812103737237\n",
      "iteration:  222  cost:  0.8577749637418313\n",
      "iteration:  223  cost:  0.8046778525388983\n",
      "iteration:  224  cost:  0.8197409156410355\n",
      "iteration:  225  cost:  0.8541528845098463\n",
      "iteration:  226  cost:  0.8705760338410474\n",
      "iteration:  227  cost:  0.8451778401178873\n",
      "iteration:  228  cost:  0.7941517875007443\n",
      "iteration:  229  cost:  0.8663331509222693\n",
      "[0.442, 0.506, 0.606, 0.692, 0.748, 0.788, 0.824, 0.872, 0.896, 0.914, 0.926, 0.936, 0.94, 0.942, 0.946, 0.948, 0.948, 0.946, 0.946, 0.952, 0.962, 0.964, 0.966, 0.97]\n",
      "iteration:  230  cost:  0.8475147562271458\n",
      "iteration:  231  cost:  0.8278641644873336\n",
      "iteration:  232  cost:  0.8430282061581402\n",
      "iteration:  233  cost:  0.828928624290583\n",
      "iteration:  234  cost:  0.8080948792498357\n",
      "iteration:  235  cost:  0.8209531477076427\n",
      "iteration:  236  cost:  0.8312225555912324\n",
      "iteration:  237  cost:  0.8275059018124672\n",
      "iteration:  238  cost:  0.8192394871392709\n",
      "iteration:  239  cost:  0.8305768555713303\n",
      "[0.442, 0.506, 0.606, 0.692, 0.748, 0.788, 0.824, 0.872, 0.896, 0.914, 0.926, 0.936, 0.94, 0.942, 0.946, 0.948, 0.948, 0.946, 0.946, 0.952, 0.962, 0.964, 0.966, 0.97, 0.966]\n",
      "iteration:  240  cost:  0.8337104346087316\n",
      "iteration:  241  cost:  0.8151289560316819\n",
      "iteration:  242  cost:  0.879211599087789\n",
      "iteration:  243  cost:  0.8146376366916636\n",
      "iteration:  244  cost:  0.8016509173055075\n",
      "iteration:  245  cost:  0.8217270853800103\n",
      "iteration:  246  cost:  0.8455303720676585\n",
      "iteration:  247  cost:  0.8283664266142994\n",
      "iteration:  248  cost:  0.7986152216160766\n",
      "iteration:  249  cost:  0.8311501850633224\n",
      "[0.442, 0.506, 0.606, 0.692, 0.748, 0.788, 0.824, 0.872, 0.896, 0.914, 0.926, 0.936, 0.94, 0.942, 0.946, 0.948, 0.948, 0.946, 0.946, 0.952, 0.962, 0.964, 0.966, 0.97, 0.966, 0.964]\n",
      "Accuracy for U_TTN pca16 :0.9659574468085106\n",
      "Epoch 1/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.1115 - val_loss: 0.0334\n",
      "Epoch 2/10\n",
      "396/396 [==============================] - 1s 1ms/step - loss: 0.0308 - val_loss: 0.0264\n",
      "Epoch 3/10\n",
      "396/396 [==============================] - 1s 1ms/step - loss: 0.0257 - val_loss: 0.0233\n",
      "Epoch 4/10\n",
      "396/396 [==============================] - 1s 1ms/step - loss: 0.0229 - val_loss: 0.0217\n",
      "Epoch 5/10\n",
      "396/396 [==============================] - 1s 1ms/step - loss: 0.0214 - val_loss: 0.0204\n",
      "Epoch 6/10\n",
      "396/396 [==============================] - 1s 1ms/step - loss: 0.0204 - val_loss: 0.0194\n",
      "Epoch 7/10\n",
      "396/396 [==============================] - 1s 1ms/step - loss: 0.0194 - val_loss: 0.0188\n",
      "Epoch 8/10\n",
      "396/396 [==============================] - 1s 1ms/step - loss: 0.0188 - val_loss: 0.0184\n",
      "Epoch 9/10\n",
      "396/396 [==============================] - 1s 1ms/step - loss: 0.0183 - val_loss: 0.0181\n",
      "Epoch 10/10\n",
      "396/396 [==============================] - 1s 1ms/step - loss: 0.0181 - val_loss: 0.0178\n",
      "\n",
      "\n",
      "Loss History for QCNN circuits, U_TTN autoencoder8\n",
      "[0.486]\n",
      "iteration:  0  cost:  1.1719512920960629\n",
      "iteration:  1  cost:  1.1861089294921705\n",
      "iteration:  2  cost:  1.0799366833883903\n",
      "iteration:  3  cost:  1.1410903129545478\n",
      "iteration:  4  cost:  1.028161920921741\n",
      "iteration:  5  cost:  1.2747064511142039\n",
      "iteration:  6  cost:  1.1178930927442454\n",
      "iteration:  7  cost:  1.0618640121556029\n",
      "iteration:  8  cost:  1.133469535330358\n",
      "iteration:  9  cost:  0.9685132920233821\n",
      "[0.486, 0.486]\n",
      "iteration:  10  cost:  0.9664822815325429\n",
      "iteration:  11  cost:  0.9706552611296408\n",
      "iteration:  12  cost:  0.8273949268522316\n",
      "iteration:  13  cost:  1.0388519346085328\n",
      "iteration:  14  cost:  0.8444072174676457\n",
      "iteration:  15  cost:  0.8303415032176639\n",
      "iteration:  16  cost:  0.9529776772526775\n",
      "iteration:  17  cost:  0.9619685515664779\n",
      "iteration:  18  cost:  0.8443225579363994\n",
      "iteration:  19  cost:  0.8976389459933662\n",
      "[0.486, 0.486, 0.854]\n",
      "iteration:  20  cost:  0.8439270765685081\n",
      "iteration:  21  cost:  0.8471865760095558\n",
      "iteration:  22  cost:  0.8194714939238286\n",
      "iteration:  23  cost:  0.7859607553171115\n",
      "iteration:  24  cost:  0.8220387760894604\n",
      "iteration:  25  cost:  0.8103305128478019\n",
      "iteration:  26  cost:  0.7950891581036879\n",
      "iteration:  27  cost:  0.8053593266078546\n",
      "iteration:  28  cost:  0.8345306257324429\n",
      "iteration:  29  cost:  0.8147256801076727\n",
      "[0.486, 0.486, 0.854, 0.938]\n",
      "iteration:  30  cost:  0.8117516530752701\n",
      "iteration:  31  cost:  0.7565805165356048\n",
      "iteration:  32  cost:  0.764661223300126\n",
      "iteration:  33  cost:  0.7344129248270375\n",
      "iteration:  34  cost:  0.7467320354451656\n",
      "iteration:  35  cost:  0.7586469959735578\n",
      "iteration:  36  cost:  0.7189939705034386\n",
      "iteration:  37  cost:  0.6999001399672683\n",
      "iteration:  38  cost:  0.742565569427443\n",
      "iteration:  39  cost:  0.6995761656986987\n",
      "[0.486, 0.486, 0.854, 0.938, 0.95]\n",
      "iteration:  40  cost:  0.6822954165102197\n",
      "iteration:  41  cost:  0.6799001491313125\n",
      "iteration:  42  cost:  0.6516984601806337\n",
      "iteration:  43  cost:  0.6906802172495462\n",
      "iteration:  44  cost:  0.6377091635962391\n",
      "iteration:  45  cost:  0.669705821601866\n",
      "iteration:  46  cost:  0.6377988969503577\n",
      "iteration:  47  cost:  0.6735548579908398\n",
      "iteration:  48  cost:  0.6496539582307496\n",
      "iteration:  49  cost:  0.6921644227829229\n",
      "[0.486, 0.486, 0.854, 0.938, 0.95, 0.968]\n",
      "iteration:  50  cost:  0.6292451431030098\n",
      "iteration:  51  cost:  0.6305651939964726\n",
      "iteration:  52  cost:  0.6512455256155713\n",
      "iteration:  53  cost:  0.6391888747693689\n",
      "iteration:  54  cost:  0.6258053658065689\n",
      "iteration:  55  cost:  0.5266429807963476\n",
      "iteration:  56  cost:  0.5656687046105229\n",
      "iteration:  57  cost:  0.6016566498621196\n",
      "iteration:  58  cost:  0.5471725973227849\n",
      "iteration:  59  cost:  0.5809611496673882\n",
      "[0.486, 0.486, 0.854, 0.938, 0.95, 0.968, 0.978]\n",
      "iteration:  60  cost:  0.5203284449590503\n",
      "iteration:  61  cost:  0.5285158775849707\n",
      "iteration:  62  cost:  0.5814664142163452\n",
      "iteration:  63  cost:  0.5158299570009394\n",
      "iteration:  64  cost:  0.5547646704310006\n",
      "iteration:  65  cost:  0.4957899270024347\n",
      "iteration:  66  cost:  0.46946111754812053\n",
      "iteration:  67  cost:  0.5917730939661534\n",
      "iteration:  68  cost:  0.42373732921253066\n",
      "iteration:  69  cost:  0.5777449114445531\n",
      "[0.486, 0.486, 0.854, 0.938, 0.95, 0.968, 0.978, 0.94]\n",
      "Accuracy for U_TTN autoencoder8 :0.9437352245862884\n",
      "Epoch 1/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.0944 - val_loss: 0.0290\n",
      "Epoch 2/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.0275 - val_loss: 0.0225\n",
      "Epoch 3/10\n",
      "396/396 [==============================] - 1s 1ms/step - loss: 0.0215 - val_loss: 0.0180\n",
      "Epoch 4/10\n",
      "396/396 [==============================] - 1s 1ms/step - loss: 0.0175 - val_loss: 0.0154\n",
      "Epoch 5/10\n",
      "396/396 [==============================] - 1s 1ms/step - loss: 0.0152 - val_loss: 0.0139\n",
      "Epoch 6/10\n",
      "396/396 [==============================] - 1s 1ms/step - loss: 0.0140 - val_loss: 0.0129\n",
      "Epoch 7/10\n",
      "396/396 [==============================] - 1s 1ms/step - loss: 0.0131 - val_loss: 0.0122\n",
      "Epoch 8/10\n",
      "396/396 [==============================] - 1s 1ms/step - loss: 0.0121 - val_loss: 0.0116\n",
      "Epoch 9/10\n",
      "396/396 [==============================] - 1s 1ms/step - loss: 0.0116 - val_loss: 0.0112\n",
      "Epoch 10/10\n",
      "396/396 [==============================] - 1s 1ms/step - loss: 0.0111 - val_loss: 0.0108\n",
      "\n",
      "\n",
      "Loss History for QCNN circuits, U_TTN autoencoder16\n",
      "[0.834]\n",
      "iteration:  0  cost:  0.7531626242944259\n",
      "iteration:  1  cost:  0.727618375965053\n",
      "iteration:  2  cost:  0.6260354313159298\n",
      "iteration:  3  cost:  0.627922857256028\n",
      "iteration:  4  cost:  0.5862816463234815\n",
      "iteration:  5  cost:  0.5733488135035423\n",
      "iteration:  6  cost:  0.710961952744988\n",
      "iteration:  7  cost:  0.6783859724423112\n",
      "iteration:  8  cost:  0.6347774835495861\n",
      "iteration:  9  cost:  0.637173526808167\n",
      "[0.834, 0.852]\n",
      "iteration:  10  cost:  0.6550565533489002\n",
      "iteration:  11  cost:  0.5810993111933302\n",
      "iteration:  12  cost:  0.67681877609374\n",
      "iteration:  13  cost:  0.6245542856585019\n",
      "iteration:  14  cost:  0.676056602426042\n",
      "iteration:  15  cost:  0.6320333479940315\n",
      "iteration:  16  cost:  0.565045510828934\n",
      "iteration:  17  cost:  0.6315140282270906\n",
      "iteration:  18  cost:  0.6568144775742113\n",
      "iteration:  19  cost:  0.5975305529850573\n",
      "[0.834, 0.852, 0.88]\n",
      "iteration:  20  cost:  0.6340350291953052\n",
      "iteration:  21  cost:  0.6774101517072936\n",
      "iteration:  22  cost:  0.6202895264465881\n",
      "iteration:  23  cost:  0.6097654486551157\n",
      "iteration:  24  cost:  0.6754771472054409\n",
      "iteration:  25  cost:  0.6494587094202424\n",
      "iteration:  26  cost:  0.7215923160735506\n",
      "iteration:  27  cost:  0.6196899745163752\n",
      "iteration:  28  cost:  0.5706973833772756\n",
      "iteration:  29  cost:  0.5622426454334248\n",
      "[0.834, 0.852, 0.88, 0.888]\n",
      "iteration:  30  cost:  0.5485285000816194\n",
      "iteration:  31  cost:  0.7257041125616976\n",
      "iteration:  32  cost:  0.587640591082829\n",
      "iteration:  33  cost:  0.5567119348400466\n",
      "iteration:  34  cost:  0.601625130161228\n",
      "iteration:  35  cost:  0.6145563410042331\n",
      "iteration:  36  cost:  0.7592485977305367\n",
      "iteration:  37  cost:  0.684579793592404\n",
      "iteration:  38  cost:  0.5509232252476512\n",
      "iteration:  39  cost:  0.5278702400201091\n",
      "[0.834, 0.852, 0.88, 0.888, 0.896]\n",
      "iteration:  40  cost:  0.42151833509004233\n",
      "iteration:  41  cost:  0.543761008249484\n",
      "iteration:  42  cost:  0.6102666449825912\n",
      "iteration:  43  cost:  0.5669406282431813\n",
      "iteration:  44  cost:  0.7979562404507942\n",
      "iteration:  45  cost:  0.5661011545411749\n",
      "iteration:  46  cost:  0.5175918969750921\n",
      "iteration:  47  cost:  0.600905973590658\n",
      "iteration:  48  cost:  0.569587337957802\n",
      "iteration:  49  cost:  0.5381523001105186\n",
      "[0.834, 0.852, 0.88, 0.888, 0.896, 0.89]\n",
      "iteration:  50  cost:  0.6355757501084056\n",
      "iteration:  51  cost:  0.6699791396020243\n",
      "iteration:  52  cost:  0.6665982699699176\n",
      "iteration:  53  cost:  0.6775722946352168\n",
      "iteration:  54  cost:  0.5749688772018559\n",
      "iteration:  55  cost:  0.5103782785565504\n",
      "iteration:  56  cost:  0.5883629521022214\n",
      "iteration:  57  cost:  0.5381354698980829\n",
      "iteration:  58  cost:  0.48950414031350126\n",
      "iteration:  59  cost:  0.5317175951793947\n",
      "[0.834, 0.852, 0.88, 0.888, 0.896, 0.89, 0.892]\n",
      "iteration:  60  cost:  0.6076602301083959\n",
      "iteration:  61  cost:  0.4847165191862503\n",
      "iteration:  62  cost:  0.517414802575178\n",
      "iteration:  63  cost:  0.5529248582456456\n",
      "iteration:  64  cost:  0.49938553869472585\n",
      "iteration:  65  cost:  0.6753507458618642\n",
      "iteration:  66  cost:  0.6850572941570365\n",
      "iteration:  67  cost:  0.5327740406910446\n",
      "iteration:  68  cost:  0.5212963857391429\n",
      "iteration:  69  cost:  0.4395041981540351\n",
      "[0.834, 0.852, 0.88, 0.888, 0.896, 0.89, 0.892, 0.878]\n",
      "Accuracy for U_TTN autoencoder16 :0.8515366430260047\n",
      "\n",
      "\n",
      "Loss History for QCNN circuits, U_5 resize256\n",
      "[0.562]\n",
      "iteration:  0  cost:  1.0058542188149273\n",
      "iteration:  1  cost:  1.4120419893873761\n",
      "iteration:  2  cost:  1.3566033082800062\n",
      "iteration:  3  cost:  1.0353331725569683\n",
      "iteration:  4  cost:  1.1274269529846423\n",
      "iteration:  5  cost:  1.0568992128494386\n",
      "iteration:  6  cost:  1.0340908631947063\n",
      "iteration:  7  cost:  0.981896846439996\n",
      "iteration:  8  cost:  0.9096333654942151\n",
      "iteration:  9  cost:  1.1467442585134655\n",
      "[0.562, 0.58]\n",
      "iteration:  10  cost:  0.839970127737467\n",
      "iteration:  11  cost:  1.0038400874195568\n",
      "iteration:  12  cost:  0.9366252552100803\n",
      "iteration:  13  cost:  0.9867238041150125\n",
      "iteration:  14  cost:  0.9726467836819387\n",
      "iteration:  15  cost:  0.9948210462206515\n",
      "iteration:  16  cost:  0.9590290734963495\n",
      "iteration:  17  cost:  0.9565667693203966\n",
      "iteration:  18  cost:  0.9860350629328309\n",
      "iteration:  19  cost:  0.8985893226715932\n",
      "[0.562, 0.58, 0.424]\n",
      "iteration:  20  cost:  1.0168803915447242\n",
      "iteration:  21  cost:  0.8848783260123736\n",
      "iteration:  22  cost:  0.9942955036309897\n",
      "iteration:  23  cost:  0.9897580060998734\n",
      "iteration:  24  cost:  0.9015931984649697\n",
      "iteration:  25  cost:  0.9345712716223068\n",
      "iteration:  26  cost:  0.9162447276142577\n",
      "iteration:  27  cost:  0.8715073270652531\n",
      "iteration:  28  cost:  0.9075471758691919\n",
      "iteration:  29  cost:  0.8584860912356352\n",
      "[0.562, 0.58, 0.424, 0.646]\n",
      "iteration:  30  cost:  0.8914644640953129\n",
      "iteration:  31  cost:  0.8726703597579265\n",
      "iteration:  32  cost:  0.8918550634147716\n",
      "iteration:  33  cost:  0.9214524467561594\n",
      "iteration:  34  cost:  0.7703676396993825\n",
      "iteration:  35  cost:  0.7415208463774232\n",
      "iteration:  36  cost:  0.8015503469196852\n",
      "iteration:  37  cost:  0.8346076255114627\n",
      "iteration:  38  cost:  0.8976359913132467\n",
      "iteration:  39  cost:  0.9158781078740824\n",
      "[0.562, 0.58, 0.424, 0.646, 0.692]\n",
      "iteration:  40  cost:  0.7528392397991348\n",
      "iteration:  41  cost:  0.8180895111739875\n",
      "iteration:  42  cost:  0.8209239482143442\n",
      "iteration:  43  cost:  0.8276603856390284\n",
      "iteration:  44  cost:  0.7978651987958686\n",
      "iteration:  45  cost:  0.8076214924004752\n",
      "iteration:  46  cost:  0.7849847382210494\n",
      "iteration:  47  cost:  0.8221108603135527\n",
      "iteration:  48  cost:  0.8084547978879144\n",
      "iteration:  49  cost:  0.7856472547565165\n",
      "[0.562, 0.58, 0.424, 0.646, 0.692, 0.934]\n",
      "iteration:  50  cost:  0.8667134093224391\n",
      "iteration:  51  cost:  0.8075575055561309\n",
      "iteration:  52  cost:  0.7580259101347566\n",
      "iteration:  53  cost:  0.7983103793869348\n",
      "iteration:  54  cost:  0.679671077184738\n",
      "iteration:  55  cost:  0.7271003235961825\n",
      "iteration:  56  cost:  0.8039588879877337\n",
      "iteration:  57  cost:  0.7859353010315557\n",
      "iteration:  58  cost:  0.7697439394925505\n",
      "iteration:  59  cost:  0.7280946167704251\n",
      "[0.562, 0.58, 0.424, 0.646, 0.692, 0.934, 0.86]\n",
      "iteration:  60  cost:  0.7023620337293484\n",
      "iteration:  61  cost:  0.7836331586058894\n",
      "iteration:  62  cost:  0.7030537498596303\n",
      "iteration:  63  cost:  0.7028792684416509\n",
      "iteration:  64  cost:  0.7164288385499684\n",
      "iteration:  65  cost:  0.7581085549820247\n",
      "iteration:  66  cost:  0.6797994147266457\n",
      "iteration:  67  cost:  0.7047880123174355\n",
      "iteration:  68  cost:  0.6851477632378062\n",
      "iteration:  69  cost:  0.7647695379991439\n",
      "[0.562, 0.58, 0.424, 0.646, 0.692, 0.934, 0.86, 0.93]\n",
      "iteration:  70  cost:  0.7236803519695825\n",
      "iteration:  71  cost:  0.7449847463113224\n",
      "iteration:  72  cost:  0.7005251986243696\n",
      "iteration:  73  cost:  0.6730028764882426\n",
      "iteration:  74  cost:  0.7149911998843385\n",
      "iteration:  75  cost:  0.7181847054883671\n",
      "iteration:  76  cost:  0.7345894410800219\n",
      "iteration:  77  cost:  0.7074218784034333\n",
      "iteration:  78  cost:  0.6784571107373998\n",
      "iteration:  79  cost:  0.6905333117652461\n",
      "[0.562, 0.58, 0.424, 0.646, 0.692, 0.934, 0.86, 0.93, 0.97]\n",
      "iteration:  80  cost:  0.6663044400345619\n",
      "iteration:  81  cost:  0.652301190420439\n",
      "iteration:  82  cost:  0.6473610925427014\n",
      "iteration:  83  cost:  0.6337380718868011\n",
      "iteration:  84  cost:  0.6727148105827111\n",
      "iteration:  85  cost:  0.6909805396699962\n",
      "iteration:  86  cost:  0.6900816923837145\n",
      "iteration:  87  cost:  0.6520427796168103\n",
      "iteration:  88  cost:  0.6345582578569265\n",
      "iteration:  89  cost:  0.6644849914709537\n",
      "[0.562, 0.58, 0.424, 0.646, 0.692, 0.934, 0.86, 0.93, 0.97, 0.944]\n",
      "iteration:  90  cost:  0.6084345652582581\n",
      "iteration:  91  cost:  0.7175366782391004\n",
      "iteration:  92  cost:  0.6053861970462833\n",
      "iteration:  93  cost:  0.6364530718528265\n",
      "iteration:  94  cost:  0.5960746657708881\n",
      "iteration:  95  cost:  0.6348265235464876\n",
      "iteration:  96  cost:  0.5964729879745448\n",
      "iteration:  97  cost:  0.6368601941319316\n",
      "iteration:  98  cost:  0.5944162730541895\n",
      "iteration:  99  cost:  0.726266352593766\n",
      "[0.562, 0.58, 0.424, 0.646, 0.692, 0.934, 0.86, 0.93, 0.97, 0.944, 0.932]\n",
      "iteration:  100  cost:  0.6213375926641042\n",
      "iteration:  101  cost:  0.6129267554270752\n",
      "iteration:  102  cost:  0.5881313951465174\n",
      "iteration:  103  cost:  0.571831351137848\n",
      "iteration:  104  cost:  0.6380721246184088\n",
      "iteration:  105  cost:  0.5835185035943978\n",
      "iteration:  106  cost:  0.6742091663586275\n",
      "iteration:  107  cost:  0.617441088611909\n",
      "iteration:  108  cost:  0.5582038346242318\n",
      "iteration:  109  cost:  0.6184405802237926\n",
      "[0.562, 0.58, 0.424, 0.646, 0.692, 0.934, 0.86, 0.93, 0.97, 0.944, 0.932, 0.898]\n",
      "Accuracy for U_5 resize256 :0.8997635933806146\n",
      "\n",
      "\n",
      "Loss History for QCNN circuits, U_5 pca8\n",
      "[0.556]\n",
      "iteration:  0  cost:  1.4540945066685385\n",
      "iteration:  1  cost:  1.0236401742341585\n",
      "iteration:  2  cost:  1.2636675220593852\n",
      "iteration:  3  cost:  0.845294135060051\n",
      "iteration:  4  cost:  0.7198830880297987\n",
      "iteration:  5  cost:  0.9018104034105877\n",
      "iteration:  6  cost:  0.7843001597687305\n",
      "iteration:  7  cost:  0.621937589215512\n",
      "iteration:  8  cost:  0.7045268542814014\n",
      "iteration:  9  cost:  0.5954748442910691\n",
      "[0.556, 0.878]\n",
      "iteration:  10  cost:  0.5618137730684261\n",
      "iteration:  11  cost:  0.5745188773189381\n",
      "iteration:  12  cost:  0.597649081633639\n",
      "iteration:  13  cost:  0.522188682439226\n",
      "iteration:  14  cost:  0.553850071231908\n",
      "iteration:  15  cost:  0.565197719994338\n",
      "iteration:  16  cost:  0.47819618642373873\n",
      "iteration:  17  cost:  0.4119822443932535\n",
      "iteration:  18  cost:  0.3761731342667913\n",
      "iteration:  19  cost:  0.4896802438876293\n",
      "[0.556, 0.878, 0.948]\n",
      "iteration:  20  cost:  0.3995662914377568\n",
      "iteration:  21  cost:  0.3427728304150472\n",
      "iteration:  22  cost:  0.37629977062975856\n",
      "iteration:  23  cost:  0.305995207882286\n",
      "iteration:  24  cost:  0.2948832231429171\n",
      "iteration:  25  cost:  0.3388772091720555\n",
      "iteration:  26  cost:  0.34012648726937494\n",
      "iteration:  27  cost:  0.2922967410691472\n",
      "iteration:  28  cost:  0.31022814603416643\n",
      "iteration:  29  cost:  0.2474219026282455\n",
      "[0.556, 0.878, 0.948, 0.952]\n",
      "iteration:  30  cost:  0.27104149708531616\n",
      "iteration:  31  cost:  0.2620286479035552\n",
      "iteration:  32  cost:  0.2649078139817127\n",
      "iteration:  33  cost:  0.2302505521810761\n",
      "iteration:  34  cost:  0.29069159391467064\n",
      "iteration:  35  cost:  0.16765335484023108\n",
      "iteration:  36  cost:  0.43049769246527125\n",
      "iteration:  37  cost:  0.2158288704825772\n",
      "iteration:  38  cost:  0.2915505003827142\n",
      "iteration:  39  cost:  0.25797059917054405\n",
      "[0.556, 0.878, 0.948, 0.952, 0.962]\n",
      "iteration:  40  cost:  0.20674410578454672\n",
      "iteration:  41  cost:  0.185031419389189\n",
      "iteration:  42  cost:  0.3112134984450962\n",
      "iteration:  43  cost:  0.3815317446245622\n",
      "iteration:  44  cost:  0.2568426521258243\n",
      "iteration:  45  cost:  0.3452790845234917\n",
      "iteration:  46  cost:  0.5007143999672463\n",
      "iteration:  47  cost:  0.22705107575405248\n",
      "iteration:  48  cost:  0.1844453208296524\n",
      "iteration:  49  cost:  0.22220457585481068\n",
      "[0.556, 0.878, 0.948, 0.952, 0.962, 0.96]\n",
      "iteration:  50  cost:  0.1943927423287442\n",
      "iteration:  51  cost:  0.1396088382975197\n",
      "iteration:  52  cost:  0.1994258502018425\n",
      "iteration:  53  cost:  0.15401344406486817\n",
      "iteration:  54  cost:  0.10783609366164047\n",
      "iteration:  55  cost:  0.34753743460243736\n",
      "iteration:  56  cost:  0.3281208330880545\n",
      "iteration:  57  cost:  0.14962391483399567\n",
      "iteration:  58  cost:  0.16824964017934213\n",
      "iteration:  59  cost:  0.17991088987685142\n",
      "[0.556, 0.878, 0.948, 0.952, 0.962, 0.96, 0.968]\n",
      "iteration:  60  cost:  0.1892197674979403\n",
      "iteration:  61  cost:  0.16223762789555407\n",
      "iteration:  62  cost:  0.11122963013869983\n",
      "iteration:  63  cost:  0.1700536742149544\n",
      "iteration:  64  cost:  0.19166030401954476\n",
      "iteration:  65  cost:  0.28123651307763103\n",
      "iteration:  66  cost:  0.1653424393491279\n",
      "iteration:  67  cost:  0.192631741592045\n",
      "iteration:  68  cost:  0.12044253846158127\n",
      "iteration:  69  cost:  0.1792265491127007\n",
      "[0.556, 0.878, 0.948, 0.952, 0.962, 0.96, 0.968, 0.966]\n",
      "iteration:  70  cost:  0.11647328494281678\n",
      "iteration:  71  cost:  0.3010064736930381\n",
      "iteration:  72  cost:  0.1400736266819218\n",
      "iteration:  73  cost:  0.11159658616067784\n",
      "iteration:  74  cost:  0.14236356871790184\n",
      "iteration:  75  cost:  0.11816089850978599\n",
      "iteration:  76  cost:  0.15588782002938636\n",
      "iteration:  77  cost:  0.14042302255674666\n",
      "iteration:  78  cost:  0.15143043121560099\n",
      "iteration:  79  cost:  0.14104224247795435\n",
      "[0.556, 0.878, 0.948, 0.952, 0.962, 0.96, 0.968, 0.966, 0.97]\n",
      "iteration:  80  cost:  0.1039719596011892\n",
      "iteration:  81  cost:  0.17551234291980208\n",
      "iteration:  82  cost:  0.28440320811528125\n",
      "iteration:  83  cost:  0.2101215427155831\n",
      "iteration:  84  cost:  0.11003081346133191\n",
      "iteration:  85  cost:  0.10704151028055381\n",
      "iteration:  86  cost:  0.21794874950295648\n",
      "iteration:  87  cost:  0.23941676846909096\n",
      "iteration:  88  cost:  0.11643825158653766\n",
      "iteration:  89  cost:  0.2317413160074418\n",
      "[0.556, 0.878, 0.948, 0.952, 0.962, 0.96, 0.968, 0.966, 0.97, 0.968]\n",
      "iteration:  90  cost:  0.12306848522704122\n",
      "iteration:  91  cost:  0.15543607357569264\n",
      "iteration:  92  cost:  0.27520250374465527\n",
      "iteration:  93  cost:  0.17808522776986532\n",
      "iteration:  94  cost:  0.0941799115133941\n",
      "iteration:  95  cost:  0.09287281312714557\n",
      "iteration:  96  cost:  0.25577432694084007\n",
      "iteration:  97  cost:  0.2907137877541265\n",
      "iteration:  98  cost:  0.24425885484222618\n",
      "iteration:  99  cost:  0.14751802890839585\n",
      "[0.556, 0.878, 0.948, 0.952, 0.962, 0.96, 0.968, 0.966, 0.97, 0.968, 0.962]\n",
      "Accuracy for U_5 pca8 :0.9839243498817967\n",
      "\n",
      "\n",
      "Loss History for QCNN circuits, U_5 pca16\n",
      "[0.552]\n",
      "iteration:  0  cost:  0.9814106625450867\n",
      "iteration:  1  cost:  0.9392253235173662\n",
      "iteration:  2  cost:  0.941404118751797\n",
      "iteration:  3  cost:  0.9131122210791733\n",
      "iteration:  4  cost:  0.9306088289729745\n",
      "iteration:  5  cost:  0.9486729104566923\n",
      "iteration:  6  cost:  0.9134303883119176\n",
      "iteration:  7  cost:  0.9294625144337069\n",
      "iteration:  8  cost:  0.9026701564587957\n",
      "iteration:  9  cost:  0.9033251591869843\n",
      "[0.552, 0.91]\n",
      "iteration:  10  cost:  0.8644332035180647\n",
      "iteration:  11  cost:  0.8511967552794094\n",
      "iteration:  12  cost:  0.8806401577444535\n",
      "iteration:  13  cost:  0.8929668073691643\n",
      "iteration:  14  cost:  0.8916995339145356\n",
      "iteration:  15  cost:  0.8762252659203117\n",
      "iteration:  16  cost:  0.8523427680577507\n",
      "iteration:  17  cost:  0.8748553086080169\n",
      "iteration:  18  cost:  0.8694060100033612\n",
      "iteration:  19  cost:  0.8243023898881867\n",
      "[0.552, 0.91, 0.872]\n",
      "iteration:  20  cost:  0.8621480862345859\n",
      "iteration:  21  cost:  0.8869077124855326\n",
      "iteration:  22  cost:  0.8087834973862031\n",
      "iteration:  23  cost:  0.796516531056997\n",
      "iteration:  24  cost:  0.826254676088376\n",
      "iteration:  25  cost:  0.7580771247206625\n",
      "iteration:  26  cost:  0.8215172334778873\n",
      "iteration:  27  cost:  0.825942109905855\n",
      "iteration:  28  cost:  0.8045789647657534\n",
      "iteration:  29  cost:  0.7651984324345937\n",
      "[0.552, 0.91, 0.872, 0.852]\n",
      "iteration:  30  cost:  0.7490247548910438\n",
      "iteration:  31  cost:  0.765013198583132\n",
      "iteration:  32  cost:  0.8046054990129845\n",
      "iteration:  33  cost:  0.6866849207409502\n",
      "iteration:  34  cost:  0.7965615642339503\n",
      "iteration:  35  cost:  0.6613260398149089\n",
      "iteration:  36  cost:  0.6738178109970069\n",
      "iteration:  37  cost:  0.7476851867415374\n",
      "iteration:  38  cost:  0.7475621397397102\n",
      "iteration:  39  cost:  0.692705283809833\n",
      "[0.552, 0.91, 0.872, 0.852, 0.798]\n",
      "Accuracy for U_5 pca16 :0.8118203309692671\n",
      "Epoch 1/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.1085 - val_loss: 0.0383\n",
      "Epoch 2/10\n",
      "396/396 [==============================] - 1s 1ms/step - loss: 0.0335 - val_loss: 0.0264\n",
      "Epoch 3/10\n",
      "396/396 [==============================] - 1s 1ms/step - loss: 0.0260 - val_loss: 0.0241\n",
      "Epoch 4/10\n",
      "396/396 [==============================] - 1s 1ms/step - loss: 0.0238 - val_loss: 0.0220\n",
      "Epoch 5/10\n",
      "396/396 [==============================] - 1s 1ms/step - loss: 0.0220 - val_loss: 0.0208\n",
      "Epoch 6/10\n",
      "396/396 [==============================] - 1s 1ms/step - loss: 0.0207 - val_loss: 0.0200\n",
      "Epoch 7/10\n",
      "396/396 [==============================] - 1s 1ms/step - loss: 0.0200 - val_loss: 0.0194\n",
      "Epoch 8/10\n",
      "396/396 [==============================] - 1s 1ms/step - loss: 0.0194 - val_loss: 0.0190\n",
      "Epoch 9/10\n",
      "396/396 [==============================] - 1s 1ms/step - loss: 0.0193 - val_loss: 0.0186\n",
      "Epoch 10/10\n",
      "396/396 [==============================] - 1s 1ms/step - loss: 0.0185 - val_loss: 0.0184\n",
      "\n",
      "\n",
      "Loss History for QCNN circuits, U_5 autoencoder8\n",
      "[0.498]\n",
      "iteration:  0  cost:  0.8843494701957292\n",
      "iteration:  1  cost:  0.875883016865055\n",
      "iteration:  2  cost:  1.0007955867387488\n",
      "iteration:  3  cost:  1.2549091722105057\n",
      "iteration:  4  cost:  1.0184091661677732\n",
      "iteration:  5  cost:  0.9748017158682893\n",
      "iteration:  6  cost:  0.9585749421430486\n",
      "iteration:  7  cost:  0.8628601428260201\n",
      "iteration:  8  cost:  0.8053108314658113\n",
      "iteration:  9  cost:  0.8644320673303227\n",
      "[0.498, 0.716]\n",
      "iteration:  10  cost:  0.8013494705544943\n",
      "iteration:  11  cost:  0.8771645471624118\n",
      "iteration:  12  cost:  0.9910220997270248\n",
      "iteration:  13  cost:  0.9978312209965061\n",
      "iteration:  14  cost:  0.7167587721676394\n",
      "iteration:  15  cost:  0.908959821484829\n",
      "iteration:  16  cost:  0.6731532851315463\n",
      "iteration:  17  cost:  0.8962391127788807\n",
      "iteration:  18  cost:  0.6873826959635543\n",
      "iteration:  19  cost:  0.8726921387990185\n",
      "[0.498, 0.716, 0.75]\n",
      "iteration:  20  cost:  0.7866906122660873\n",
      "iteration:  21  cost:  0.69560561149538\n",
      "iteration:  22  cost:  0.7065944096446997\n",
      "iteration:  23  cost:  0.7204030570831021\n",
      "iteration:  24  cost:  0.7301355224103567\n",
      "iteration:  25  cost:  0.6665476929221832\n",
      "iteration:  26  cost:  0.8744756743690014\n",
      "iteration:  27  cost:  0.5138526199828114\n",
      "iteration:  28  cost:  0.6915767743418365\n",
      "iteration:  29  cost:  0.6676013659650378\n",
      "[0.498, 0.716, 0.75, 0.808]\n",
      "iteration:  30  cost:  0.7888446777142377\n",
      "iteration:  31  cost:  0.7107925124309254\n",
      "iteration:  32  cost:  0.6188062985143791\n",
      "iteration:  33  cost:  0.8101479399755313\n",
      "iteration:  34  cost:  0.6089968965162246\n",
      "iteration:  35  cost:  0.5947121499974162\n",
      "iteration:  36  cost:  0.6972467877056462\n",
      "iteration:  37  cost:  0.697709519895431\n",
      "iteration:  38  cost:  0.7035006077833456\n",
      "iteration:  39  cost:  0.6817994039425548\n",
      "[0.498, 0.716, 0.75, 0.808, 0.858]\n",
      "iteration:  40  cost:  0.7391285904964898\n",
      "iteration:  41  cost:  0.5476772992168739\n",
      "iteration:  42  cost:  0.7790094870774874\n",
      "iteration:  43  cost:  0.5275842077729171\n",
      "iteration:  44  cost:  0.6821676085735074\n",
      "iteration:  45  cost:  0.7005939126258746\n",
      "iteration:  46  cost:  0.5609462586674359\n",
      "iteration:  47  cost:  0.5555484679659338\n",
      "iteration:  48  cost:  0.617644938771003\n",
      "iteration:  49  cost:  0.5764394474020011\n",
      "[0.498, 0.716, 0.75, 0.808, 0.858, 0.902]\n",
      "iteration:  50  cost:  0.6101541954575193\n",
      "iteration:  51  cost:  0.5929865260210009\n",
      "iteration:  52  cost:  0.5543987558936074\n",
      "iteration:  53  cost:  0.5735694030980069\n",
      "iteration:  54  cost:  0.6368648023586264\n",
      "iteration:  55  cost:  0.5235569086055673\n",
      "iteration:  56  cost:  0.5675007194273166\n",
      "iteration:  57  cost:  0.6648046907706214\n",
      "iteration:  58  cost:  0.5699321058853283\n",
      "iteration:  59  cost:  0.6955203958206877\n",
      "[0.498, 0.716, 0.75, 0.808, 0.858, 0.902, 0.834]\n",
      "iteration:  60  cost:  0.5106489174416954\n",
      "iteration:  61  cost:  0.5759232098541684\n",
      "iteration:  62  cost:  0.5801779259092119\n",
      "iteration:  63  cost:  0.6100339702278265\n",
      "iteration:  64  cost:  0.5682052950530103\n",
      "iteration:  65  cost:  0.5827635084749976\n",
      "iteration:  66  cost:  0.44153643520445196\n",
      "iteration:  67  cost:  0.5784585526360554\n",
      "iteration:  68  cost:  0.53791378957952\n",
      "iteration:  69  cost:  0.728587027885334\n",
      "[0.498, 0.716, 0.75, 0.808, 0.858, 0.902, 0.834, 0.904]\n",
      "iteration:  70  cost:  0.5281862354587499\n",
      "iteration:  71  cost:  0.5996338176205831\n",
      "iteration:  72  cost:  0.6106616763869984\n",
      "iteration:  73  cost:  0.5319952334990997\n",
      "iteration:  74  cost:  0.6024070544310657\n",
      "iteration:  75  cost:  0.628393874915375\n",
      "iteration:  76  cost:  0.6084857863693967\n",
      "iteration:  77  cost:  0.5736841017981998\n",
      "iteration:  78  cost:  0.6465343719196214\n",
      "iteration:  79  cost:  0.6087924435454413\n"
     ]
    }
   ],
   "source": [
    "Benchmarking(Unitaries, U_num_params, Encodings, circuit, binary = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = [0.9163120567375886, 0.8912529550827423, 0.9853427895981087, 0.9167848699763593, 0.9806146572104019, 0.9858156028368794, 0.9858156028368794, 0.8695035460992908, 0.9843971631205674, 0.9238770685579196, 0.975886524822695, 0.9163120567375886, 0.9702127659574468, 0.9290780141843972, 0.9867612293144208, 0.9442080378250591, 0.900709219858156, 0.7598108747044917, 0.9886524822695035, 0.9040189125295508, 0.9829787234042553, 0.908274231678487, 0.5617021276595745, 0.8921985815602836, 0.9858156028368794, 0.9210401891252955, 0.9706855791962175, 0.9219858156028369, 0.9801418439716312, 0.8969267139479905, 0.9810874704491725, 0.9626477541371158, 0.8704491725768322, 0.9588652482269504, 0.9891252955082742, 0.8713947990543736, 0.9853427895981087, 0.9536643026004729, 0.9224586288416076, 0.9286052009456265, 0.9853427895981087, 0.9640661938534278, 0.9858156028368794, 0.9366430260047282, 0.9829787234042553, 0.9442080378250591, 0.9843971631205674, 0.8832151300236407, 0.9517730496453901, 0.9215130023640662, 0.9560283687943263, 0.9437352245862884, 0.9872340425531915, 0.9484633569739953, 0.9735224586288416, 0.8458628841607565, 0.9796690307328605, 0.9541371158392435, 0.9825059101654846, 0.8940898345153664, 0.9820330969267139, 0.9361702127659575, 0.9782505910165484, 0.9475177304964539, 0.9309692671394799, 0.915839243498818, 0.9820330969267139, 0.9427895981087471, 0.9787234042553191, 0.9687943262411347, 0.7990543735224587, 0.7550827423167848, 0.9820330969267139, 0.9352245862884161, 0.9773049645390071, 0.9560283687943263, 0.9825059101654846, 0.9139479905437352, 0.9853427895981087, 0.9304964539007092]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "80"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_list = []\n",
    "for i in range(16):\n",
    "    #print(results[i], results[i+21], results[i+2*21], results[i+3*21], results[i+4*21])\n",
    "    results_list.append([results[i], results[i+16], results[i+2*16], results[i+3*16], results[i+4*16]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statistics as st"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for QNN with Compact Embedding (Rx-Ry) with 5 random initializations\n",
      "\n",
      "U_TTN pca16 Mean : 0.9140425531914894 U_TTN pca16 Variance : 0.0009483538163182047\n",
      "U_TTN Autoencoding16 Mean : 0.8894562647754137 U_TTN Autoencoding16 Variance : 0.005838114559406247\n",
      "U_5 pca16 Mean : 0.9802364066193854 U_5 pca16 Variance : 0.00019129375338821465\n",
      "U_5 Autoencoding16 Mean : 0.9157446808510639 U_5 Autoencoding16 Variance : 0.0009050964348987589\n",
      "U_6 pca16 Mean : 0.9829787234042553 U_6 pca16 Variance : 1.1848275014111777e-05\n",
      "U_6 Autoencoding16 Mean : 0.9530023640661939 U_6 Autoencoding16 Variance : 0.0008369353207138023\n",
      "U_9 pca16 Mean : 0.8485106382978723 U_9 pca16 Variance : 0.031163489428767826\n",
      "U_9 Autoencoding16 Mean : 0.8582505910165484 U_9 Autoencoding16 Variance : 0.004256481621201707\n",
      "U_13 pca16 Mean : 0.983451536643026 U_13 pca16 Variance : 6.594794583326366e-06\n",
      "U_13 Autoencoding16 Mean : 0.9396690307328606 U_13 Autoencoding16 Variance : 0.0003551799875928438\n",
      "U_14 pca16 Mean : 0.9784397163120567 U_14 pca16 Variance : 3.471768131493507e-05\n",
      "U_14 Autoencoding16 Mean : 0.9250118203309693 U_14 Autoencoding16 Variance : 0.000534580755495198\n",
      "U_15 pca16 Mean : 0.9795744680851064 U_15 pca16 Variance : 2.8547636213246676e-05\n",
      "U_15 Autoencoding16 Mean : 0.9240661938534279 U_15 Autoencoding16 Variance : 0.00035406222579906097\n",
      "SO(4) pca16 Mean : 0.9831678486997636 SO(4) pca16 Variance : 1.1915340721738824e-05\n",
      "SO(4) Autoencoding16 Mean : 0.9336170212765957 SO(4) Autoencoding16 Variance : 0.0009245678453464765\n"
     ]
    }
   ],
   "source": [
    "print(\"Results for QNN with Compact Embedding (Rx-Ry) with 5 random initializations\")\n",
    "print(\"\")\n",
    "for i in range(16):\n",
    "    if i < 2:\n",
    "        it = \"U_TTN\"\n",
    "    elif 1<i<4:\n",
    "        it = 'U_5'\n",
    "    elif 3<i<6:\n",
    "        it = 'U_6'\n",
    "    elif 5<i<8:\n",
    "        it = 'U_9'\n",
    "    elif 7<i<10:\n",
    "        it = 'U_13'\n",
    "    elif 9<i<12:\n",
    "        it = 'U_14'\n",
    "    elif 11<i<14:\n",
    "        it = 'U_15'\n",
    "    else:\n",
    "        it = 'SO(4)'\n",
    "    \n",
    "    if i % 2 == 0:\n",
    "        emb = \"pca16\"\n",
    "    else:\n",
    "        emb = \"Autoencoding16\"\n",
    "        \n",
    "    print(it + \" \" + emb + \" Mean : \" + str(st.mean(results_list[i])),  it + \" \" + emb + \" Variance : \" + str(st.variance(results_list[i])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2 One Class Classification with labels 0,1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Unitaries = ['U_TTN', 'U_5', 'U_6', 'U_9', 'U_13', 'U_14', 'U_15', 'U_SO4']\n",
    "U_num_params = [2, 10, 10, 4, 6, 6, 4, 6]\n",
    "Encodings = ['resize256', 'pca8', 'autoencoder8']\n",
    "classes = [0,1]\n",
    "circuit = 'QCNN'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Benchmarking(Unitaries, U_num_params, Encodings, circuit, binary = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.3 Binary Classification with 1, -1 labels with only Compact Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "Unitaries = ['U_TTN', 'U_5', 'U_6', 'U_9', 'U_13', 'U_14', 'U_15', 'U_SO4']\n",
    "U_num_params = [2, 10, 10, 4, 6, 6, 4, 6]\n",
    "Encodings = ['pca16', 'autoencoder16']\n",
    "classes = [0,1]\n",
    "circuit = 'QCNN'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0th step : \n",
      "\n",
      "\n",
      "Loss History for QCNN circuits, U_TTN pca16\n",
      "iteration:  0  cost:  1.02462241418309\n",
      "iteration:  10  cost:  0.939968561705772\n",
      "iteration:  20  cost:  0.8299348593435605\n",
      "iteration:  30  cost:  0.7669434726408423\n",
      "iteration:  40  cost:  0.8238425968585373\n",
      "iteration:  50  cost:  0.7961637973948912\n",
      "iteration:  60  cost:  0.8097759590534136\n",
      "iteration:  70  cost:  0.8776352478438227\n",
      "iteration:  80  cost:  0.8070919063647426\n",
      "iteration:  90  cost:  0.7960136488087349\n",
      "iteration:  100  cost:  0.8509849107052945\n",
      "iteration:  110  cost:  0.7750847670170908\n",
      "iteration:  120  cost:  0.8205368143322392\n",
      "iteration:  130  cost:  0.8482052776051655\n",
      "iteration:  140  cost:  0.8277574343654966\n",
      "Accuracy for U_TTN pca16 :0.9380614657210402\n",
      "Epoch 1/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.0944 - val_loss: 0.0289\n",
      "Epoch 2/10\n",
      "396/396 [==============================] - 1s 1ms/step - loss: 0.0276 - val_loss: 0.0228\n",
      "Epoch 3/10\n",
      "396/396 [==============================] - 1s 1ms/step - loss: 0.0219 - val_loss: 0.0190\n",
      "Epoch 4/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.0182 - val_loss: 0.0158\n",
      "Epoch 5/10\n",
      "396/396 [==============================] - 1s 1ms/step - loss: 0.0154 - val_loss: 0.0138\n",
      "Epoch 6/10\n",
      "396/396 [==============================] - 1s 1ms/step - loss: 0.0138 - val_loss: 0.0127\n",
      "Epoch 7/10\n",
      "396/396 [==============================] - 1s 1ms/step - loss: 0.0126 - val_loss: 0.0119\n",
      "Epoch 8/10\n",
      "396/396 [==============================] - 1s 1ms/step - loss: 0.0118 - val_loss: 0.0114\n",
      "Epoch 9/10\n",
      "396/396 [==============================] - 1s 1ms/step - loss: 0.0115 - val_loss: 0.0110\n",
      "Epoch 10/10\n",
      "396/396 [==============================] - 1s 1ms/step - loss: 0.0110 - val_loss: 0.0107\n",
      "\n",
      "\n",
      "Loss History for QCNN circuits, U_TTN autoencoder16\n",
      "iteration:  0  cost:  0.9479831632736095\n",
      "iteration:  10  cost:  0.9913473073101318\n",
      "iteration:  20  cost:  0.8929374833151349\n",
      "iteration:  30  cost:  0.8491035681015815\n",
      "iteration:  40  cost:  0.8021433416808125\n",
      "iteration:  50  cost:  0.8812635055256379\n",
      "iteration:  60  cost:  0.8030093392536475\n",
      "iteration:  70  cost:  0.889417427108802\n",
      "iteration:  80  cost:  0.6969578159725416\n",
      "iteration:  90  cost:  0.7777569102264025\n",
      "iteration:  100  cost:  0.7621509688998305\n",
      "iteration:  110  cost:  0.830544567709921\n",
      "iteration:  120  cost:  0.7426995507603142\n",
      "iteration:  130  cost:  0.7940125227166956\n",
      "iteration:  140  cost:  0.7828326115409106\n",
      "Accuracy for U_TTN autoencoder16 :0.7711583924349882\n",
      "\n",
      "\n",
      "Loss History for QCNN circuits, U_5 pca16\n",
      "iteration:  0  cost:  0.8609030558906566\n",
      "iteration:  10  cost:  1.0187762005174366\n",
      "iteration:  20  cost:  0.9893893758985257\n",
      "iteration:  30  cost:  0.8095641905762669\n",
      "iteration:  40  cost:  0.4519263960248654\n",
      "iteration:  50  cost:  0.16879512621708045\n",
      "iteration:  60  cost:  0.1975203292441434\n",
      "iteration:  70  cost:  0.16132160515823787\n",
      "iteration:  80  cost:  0.18348204672193813\n",
      "iteration:  90  cost:  0.14833707056936973\n",
      "iteration:  100  cost:  0.11019137166175477\n",
      "iteration:  110  cost:  0.22643850838867008\n",
      "iteration:  120  cost:  0.09523993657929943\n",
      "iteration:  130  cost:  0.08675069868543589\n",
      "iteration:  140  cost:  0.23446550258433307\n",
      "Accuracy for U_5 pca16 :0.984869976359338\n",
      "Epoch 1/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.0930 - val_loss: 0.0285\n",
      "Epoch 2/10\n",
      "396/396 [==============================] - 1s 1ms/step - loss: 0.0273 - val_loss: 0.0225\n",
      "Epoch 3/10\n",
      "396/396 [==============================] - 1s 1ms/step - loss: 0.0218 - val_loss: 0.0183\n",
      "Epoch 4/10\n",
      "396/396 [==============================] - 1s 1ms/step - loss: 0.0178 - val_loss: 0.0154\n",
      "Epoch 5/10\n",
      "396/396 [==============================] - 1s 1ms/step - loss: 0.0152 - val_loss: 0.0136\n",
      "Epoch 6/10\n",
      "396/396 [==============================] - 1s 1ms/step - loss: 0.0138 - val_loss: 0.0126\n",
      "Epoch 7/10\n",
      "396/396 [==============================] - 1s 1ms/step - loss: 0.0127 - val_loss: 0.0118\n",
      "Epoch 8/10\n",
      "396/396 [==============================] - 1s 1ms/step - loss: 0.0120 - val_loss: 0.0113\n",
      "Epoch 9/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.0113 - val_loss: 0.0110\n",
      "Epoch 10/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.0110 - val_loss: 0.0105\n",
      "\n",
      "\n",
      "Loss History for QCNN circuits, U_5 autoencoder16\n",
      "iteration:  0  cost:  2.0885778652576845\n",
      "iteration:  10  cost:  0.931149476461647\n",
      "iteration:  20  cost:  0.6480969080662169\n",
      "iteration:  30  cost:  0.46978205353909386\n",
      "iteration:  40  cost:  0.44126165036197335\n",
      "iteration:  50  cost:  0.3901775429348472\n",
      "iteration:  60  cost:  0.40733909918240196\n",
      "iteration:  70  cost:  0.41655894232873\n",
      "iteration:  80  cost:  0.3682471611580576\n",
      "iteration:  90  cost:  0.4489751239663361\n",
      "iteration:  100  cost:  0.4737202259113466\n",
      "iteration:  110  cost:  0.27338336586236023\n",
      "iteration:  120  cost:  0.3368940271601677\n",
      "iteration:  130  cost:  0.39298541743193044\n",
      "iteration:  140  cost:  0.3589140006652996\n",
      "Accuracy for U_5 autoencoder16 :0.9163120567375886\n",
      "\n",
      "\n",
      "Loss History for QCNN circuits, U_6 pca16\n",
      "iteration:  0  cost:  1.0673391043358706\n",
      "iteration:  10  cost:  1.0087676056198693\n",
      "iteration:  20  cost:  0.8451467122325121\n",
      "iteration:  30  cost:  0.7111826796996891\n",
      "iteration:  40  cost:  0.5819386648272218\n",
      "iteration:  50  cost:  0.39933438054845477\n",
      "iteration:  60  cost:  0.33727767154975247\n",
      "iteration:  70  cost:  0.19556396920691144\n",
      "iteration:  80  cost:  0.1969862092171447\n",
      "iteration:  90  cost:  0.0957822776744645\n",
      "iteration:  100  cost:  0.08617734872290278\n",
      "iteration:  110  cost:  0.11128333149821348\n",
      "iteration:  120  cost:  0.1816104232456834\n",
      "iteration:  130  cost:  0.03973150472214931\n",
      "iteration:  140  cost:  0.16767634864109618\n",
      "Accuracy for U_6 pca16 :0.9853427895981087\n",
      "Epoch 1/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.0960 - val_loss: 0.0300\n",
      "Epoch 2/10\n",
      "396/396 [==============================] - 1s 1ms/step - loss: 0.0284 - val_loss: 0.0236\n",
      "Epoch 3/10\n",
      "396/396 [==============================] - 1s 1ms/step - loss: 0.0226 - val_loss: 0.0192\n",
      "Epoch 4/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.0186 - val_loss: 0.0164\n",
      "Epoch 5/10\n",
      "396/396 [==============================] - 1s 1ms/step - loss: 0.0162 - val_loss: 0.0148\n",
      "Epoch 6/10\n",
      "396/396 [==============================] - 1s 1ms/step - loss: 0.0148 - val_loss: 0.0138\n",
      "Epoch 7/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.0137 - val_loss: 0.0130\n",
      "Epoch 8/10\n",
      "396/396 [==============================] - 1s 1ms/step - loss: 0.0131 - val_loss: 0.0119\n",
      "Epoch 9/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.0120 - val_loss: 0.0114\n",
      "Epoch 10/10\n",
      "396/396 [==============================] - 1s 1ms/step - loss: 0.0116 - val_loss: 0.0110\n",
      "\n",
      "\n",
      "Loss History for QCNN circuits, U_6 autoencoder16\n",
      "iteration:  0  cost:  1.0760978689379697\n",
      "iteration:  10  cost:  0.6133881288395133\n",
      "iteration:  20  cost:  0.5068750453065993\n",
      "iteration:  30  cost:  0.49292195438804837\n",
      "iteration:  40  cost:  0.4004253625946717\n",
      "iteration:  50  cost:  0.3608582607101777\n",
      "iteration:  60  cost:  0.48871569300637985\n",
      "iteration:  70  cost:  0.5421518333962978\n",
      "iteration:  80  cost:  0.39064453695032675\n",
      "iteration:  90  cost:  0.4191247910218287\n",
      "iteration:  100  cost:  0.39537303718209466\n",
      "iteration:  110  cost:  0.3852026254841473\n",
      "iteration:  120  cost:  0.2454681545310557\n",
      "iteration:  130  cost:  0.3370433936326476\n",
      "iteration:  140  cost:  0.3344894756668271\n",
      "Accuracy for U_6 autoencoder16 :0.966903073286052\n",
      "\n",
      "\n",
      "Loss History for QCNN circuits, U_9 pca16\n",
      "iteration:  0  cost:  1.059077500210866\n",
      "iteration:  10  cost:  0.9741577077067575\n",
      "iteration:  20  cost:  0.9518695958565984\n",
      "iteration:  30  cost:  0.9357264636362881\n",
      "iteration:  40  cost:  0.8721308000505924\n",
      "iteration:  50  cost:  0.9262158528694586\n",
      "iteration:  60  cost:  0.846947736630518\n",
      "iteration:  70  cost:  0.6865717838041807\n",
      "iteration:  80  cost:  0.22900404679904318\n",
      "iteration:  90  cost:  0.18039662039419815\n",
      "iteration:  100  cost:  0.23038663699317113\n",
      "iteration:  110  cost:  0.1753785816918829\n",
      "iteration:  120  cost:  0.18965666272317538\n",
      "iteration:  130  cost:  0.10090253964924538\n",
      "iteration:  140  cost:  0.14988148303797144\n",
      "Accuracy for U_9 pca16 :0.9796690307328605\n",
      "Epoch 1/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.0948 - val_loss: 0.0290\n",
      "Epoch 2/10\n",
      "396/396 [==============================] - 1s 1ms/step - loss: 0.0272 - val_loss: 0.0225\n",
      "Epoch 3/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.0217 - val_loss: 0.0189\n",
      "Epoch 4/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.0184 - val_loss: 0.0160\n",
      "Epoch 5/10\n",
      "396/396 [==============================] - 1s 1ms/step - loss: 0.0160 - val_loss: 0.0143\n",
      "Epoch 6/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.0144 - val_loss: 0.0133\n",
      "Epoch 7/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.0134 - val_loss: 0.0126\n",
      "Epoch 8/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.0126 - val_loss: 0.0121\n",
      "Epoch 9/10\n",
      "396/396 [==============================] - 1s 1ms/step - loss: 0.0122 - val_loss: 0.0117\n",
      "Epoch 10/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.0117 - val_loss: 0.0113\n",
      "\n",
      "\n",
      "Loss History for QCNN circuits, U_9 autoencoder16\n",
      "iteration:  0  cost:  1.014217577856479\n",
      "iteration:  10  cost:  0.9396910829493528\n",
      "iteration:  20  cost:  0.9401877121206986\n",
      "iteration:  30  cost:  0.8489818851089798\n",
      "iteration:  40  cost:  0.9023551557845201\n",
      "iteration:  50  cost:  0.8738179166174004\n",
      "iteration:  60  cost:  0.8943628951120786\n",
      "iteration:  70  cost:  0.8765490628084721\n",
      "iteration:  80  cost:  0.9109907074217217\n",
      "iteration:  90  cost:  0.8234788339301818\n",
      "iteration:  100  cost:  0.8501505764299558\n",
      "iteration:  110  cost:  0.8662379040524668\n",
      "iteration:  120  cost:  0.8458015060045638\n",
      "iteration:  130  cost:  0.8568105539606417\n",
      "iteration:  140  cost:  0.8812136650623087\n",
      "Accuracy for U_9 autoencoder16 :0.8212765957446808\n",
      "\n",
      "\n",
      "Loss History for QCNN circuits, U_13 pca16\n",
      "iteration:  0  cost:  1.108134553525761\n",
      "iteration:  10  cost:  1.1772883312513331\n",
      "iteration:  20  cost:  0.9527801445890252\n",
      "iteration:  30  cost:  0.895879520397651\n",
      "iteration:  40  cost:  0.8320969718971817\n",
      "iteration:  50  cost:  0.7966176286936993\n",
      "iteration:  60  cost:  0.6998661985342558\n",
      "iteration:  70  cost:  0.5517384733070907\n",
      "iteration:  80  cost:  0.46443026947779764\n",
      "iteration:  90  cost:  0.5379948734634219\n",
      "iteration:  100  cost:  0.39801092597011006\n",
      "iteration:  110  cost:  0.3753423665038773\n",
      "iteration:  120  cost:  0.27510038651887236\n",
      "iteration:  130  cost:  0.3299313830445787\n",
      "iteration:  140  cost:  0.3652078686491629\n",
      "Accuracy for U_13 pca16 :0.9825059101654846\n",
      "Epoch 1/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.0942 - val_loss: 0.0284\n",
      "Epoch 2/10\n",
      "396/396 [==============================] - 1s 1ms/step - loss: 0.0271 - val_loss: 0.0224\n",
      "Epoch 3/10\n",
      "396/396 [==============================] - 1s 1ms/step - loss: 0.0217 - val_loss: 0.0183\n",
      "Epoch 4/10\n",
      "396/396 [==============================] - 1s 1ms/step - loss: 0.0178 - val_loss: 0.0154\n",
      "Epoch 5/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.0154 - val_loss: 0.0138\n",
      "Epoch 6/10\n",
      "396/396 [==============================] - 1s 1ms/step - loss: 0.0137 - val_loss: 0.0126\n",
      "Epoch 7/10\n",
      "396/396 [==============================] - 1s 1ms/step - loss: 0.0126 - val_loss: 0.0118\n",
      "Epoch 8/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.0121 - val_loss: 0.0113\n",
      "Epoch 9/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.0114 - val_loss: 0.0109\n",
      "Epoch 10/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.0109 - val_loss: 0.0106\n",
      "\n",
      "\n",
      "Loss History for QCNN circuits, U_13 autoencoder16\n",
      "iteration:  0  cost:  0.7620652039439093\n",
      "iteration:  10  cost:  0.9571589034718774\n",
      "iteration:  20  cost:  0.6930520051384492\n",
      "iteration:  30  cost:  0.593241732727697\n",
      "iteration:  40  cost:  0.5993899511385966\n",
      "iteration:  50  cost:  0.5972819106839388\n",
      "iteration:  60  cost:  0.5996978190192273\n",
      "iteration:  70  cost:  0.5920890513998619\n",
      "iteration:  80  cost:  0.5910676227733955\n",
      "iteration:  90  cost:  0.53327234326541\n",
      "iteration:  100  cost:  0.5932080588451918\n",
      "iteration:  110  cost:  0.6132860906568284\n",
      "iteration:  120  cost:  0.594629602898931\n",
      "iteration:  130  cost:  0.4906014070793265\n",
      "iteration:  140  cost:  0.5175176499615951\n",
      "Accuracy for U_13 autoencoder16 :0.9451536643026005\n",
      "\n",
      "\n",
      "Loss History for QCNN circuits, U_14 pca16\n",
      "iteration:  0  cost:  0.8542115081395455\n",
      "iteration:  10  cost:  0.6590647270408939\n",
      "iteration:  20  cost:  0.542301810138268\n",
      "iteration:  30  cost:  0.4894942039877197\n",
      "iteration:  40  cost:  0.4966645487720806\n",
      "iteration:  50  cost:  0.46304273380370753\n",
      "iteration:  60  cost:  0.430969231350975\n",
      "iteration:  70  cost:  0.45504554912608325\n",
      "iteration:  80  cost:  0.32324875238010625\n",
      "iteration:  90  cost:  0.3997649022707116\n",
      "iteration:  100  cost:  0.35358806829154416\n",
      "iteration:  110  cost:  0.2716798134656303\n",
      "iteration:  120  cost:  0.33445073254109803\n",
      "iteration:  130  cost:  0.386092843781621\n",
      "iteration:  140  cost:  0.28120197123891083\n",
      "Accuracy for U_14 pca16 :0.9820330969267139\n",
      "Epoch 1/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.0971 - val_loss: 0.0279\n",
      "Epoch 2/10\n",
      "396/396 [==============================] - 0s 982us/step - loss: 0.0268 - val_loss: 0.0228\n",
      "Epoch 3/10\n",
      "396/396 [==============================] - 1s 1ms/step - loss: 0.0220 - val_loss: 0.0186\n",
      "Epoch 4/10\n",
      "396/396 [==============================] - 0s 963us/step - loss: 0.0181 - val_loss: 0.0158\n",
      "Epoch 5/10\n",
      "396/396 [==============================] - 0s 752us/step - loss: 0.0159 - val_loss: 0.0143\n",
      "Epoch 6/10\n",
      "396/396 [==============================] - 0s 755us/step - loss: 0.0142 - val_loss: 0.0134\n",
      "Epoch 7/10\n",
      "396/396 [==============================] - 0s 815us/step - loss: 0.0135 - val_loss: 0.0127\n",
      "Epoch 8/10\n",
      "396/396 [==============================] - 0s 1ms/step - loss: 0.0127 - val_loss: 0.0122\n",
      "Epoch 9/10\n",
      "396/396 [==============================] - 1s 1ms/step - loss: 0.0123 - val_loss: 0.0117\n",
      "Epoch 10/10\n",
      "396/396 [==============================] - 1s 1ms/step - loss: 0.0119 - val_loss: 0.0114\n",
      "\n",
      "\n",
      "Loss History for QCNN circuits, U_14 autoencoder16\n",
      "iteration:  0  cost:  1.3831500859101695\n",
      "iteration:  10  cost:  0.5688022399218784\n",
      "iteration:  20  cost:  0.39279997605760925\n",
      "iteration:  30  cost:  0.48716106372100904\n",
      "iteration:  40  cost:  0.2670973226415578\n",
      "iteration:  50  cost:  0.43464269298908076\n",
      "iteration:  60  cost:  0.25750553840659324\n",
      "iteration:  70  cost:  0.2799048676183529\n",
      "iteration:  80  cost:  0.3729524248555595\n",
      "iteration:  90  cost:  0.34574849280848907\n",
      "iteration:  100  cost:  0.2178356539194537\n",
      "iteration:  110  cost:  0.2664555013013366\n",
      "iteration:  120  cost:  0.32493892908795724\n",
      "iteration:  130  cost:  0.25529531551947765\n",
      "iteration:  140  cost:  0.5079444360636244\n",
      "Accuracy for U_14 autoencoder16 :0.9810874704491725\n",
      "\n",
      "\n",
      "Loss History for QCNN circuits, U_15 pca16\n",
      "iteration:  0  cost:  1.1695231692441537\n",
      "iteration:  10  cost:  0.9536033040532077\n",
      "iteration:  20  cost:  0.9952123717294556\n",
      "iteration:  30  cost:  0.7613810554671092\n",
      "iteration:  40  cost:  0.6569562685053368\n",
      "iteration:  50  cost:  0.5032000375143302\n",
      "iteration:  60  cost:  0.1666688473940448\n",
      "iteration:  70  cost:  0.09134513420716814\n",
      "iteration:  80  cost:  0.36929291993678853\n",
      "iteration:  90  cost:  0.07181058577329379\n",
      "iteration:  100  cost:  0.14113405405018023\n",
      "iteration:  110  cost:  0.23169070270387201\n",
      "iteration:  120  cost:  0.12549801875916886\n",
      "iteration:  130  cost:  0.042363799283380826\n",
      "iteration:  140  cost:  0.04602597104030809\n",
      "Accuracy for U_15 pca16 :0.9796690307328605\n",
      "Epoch 1/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.0935 - val_loss: 0.0282\n",
      "Epoch 2/10\n",
      "396/396 [==============================] - 1s 1ms/step - loss: 0.0269 - val_loss: 0.0222\n",
      "Epoch 3/10\n",
      "396/396 [==============================] - 0s 1ms/step - loss: 0.0214 - val_loss: 0.0181\n",
      "Epoch 4/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.0175 - val_loss: 0.0154\n",
      "Epoch 5/10\n",
      "396/396 [==============================] - 1s 1ms/step - loss: 0.0153 - val_loss: 0.0138\n",
      "Epoch 6/10\n",
      "396/396 [==============================] - 1s 1ms/step - loss: 0.0137 - val_loss: 0.0129\n",
      "Epoch 7/10\n",
      "396/396 [==============================] - 1s 1ms/step - loss: 0.0128 - val_loss: 0.0120\n",
      "Epoch 8/10\n",
      "396/396 [==============================] - 1s 1ms/step - loss: 0.0120 - val_loss: 0.0115\n",
      "Epoch 9/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.0116 - val_loss: 0.0110\n",
      "Epoch 10/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.0110 - val_loss: 0.0107\n",
      "\n",
      "\n",
      "Loss History for QCNN circuits, U_15 autoencoder16\n",
      "iteration:  0  cost:  0.9887752413369326\n",
      "iteration:  10  cost:  0.7777387813358387\n",
      "iteration:  20  cost:  0.5854650587222109\n",
      "iteration:  30  cost:  0.5532612114191353\n",
      "iteration:  40  cost:  0.6230326913125941\n",
      "iteration:  50  cost:  0.5039338248287044\n",
      "iteration:  60  cost:  0.6261483804212525\n",
      "iteration:  70  cost:  0.501721857809307\n",
      "iteration:  80  cost:  0.5849241565186637\n",
      "iteration:  90  cost:  0.6648515185282845\n",
      "iteration:  100  cost:  0.5928537352978275\n",
      "iteration:  110  cost:  0.6443820665997195\n",
      "iteration:  120  cost:  0.5566481175799382\n",
      "iteration:  130  cost:  0.47696006253756834\n",
      "iteration:  140  cost:  0.5993324073825518\n",
      "Accuracy for U_15 autoencoder16 :0.9106382978723404\n",
      "\n",
      "\n",
      "Loss History for QCNN circuits, U_SO4 pca16\n",
      "iteration:  0  cost:  1.0613689629282888\n",
      "iteration:  10  cost:  0.9424825827615544\n",
      "iteration:  20  cost:  0.928844912023482\n",
      "iteration:  30  cost:  0.888490424240301\n",
      "iteration:  40  cost:  0.7255688094153321\n",
      "iteration:  50  cost:  0.7105494251518674\n",
      "iteration:  60  cost:  0.6743713408714959\n",
      "iteration:  70  cost:  0.5842816499171265\n",
      "iteration:  80  cost:  0.5390556182740914\n",
      "iteration:  90  cost:  0.6048468286479987\n",
      "iteration:  100  cost:  0.5964152654304358\n",
      "iteration:  110  cost:  0.50245028608149\n",
      "iteration:  120  cost:  0.535470847871559\n",
      "iteration:  130  cost:  0.5731962957013547\n",
      "iteration:  140  cost:  0.5754457830914689\n",
      "Accuracy for U_SO4 pca16 :0.9810874704491725\n",
      "Epoch 1/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.0979 - val_loss: 0.0280\n",
      "Epoch 2/10\n",
      "396/396 [==============================] - 1s 1ms/step - loss: 0.0265 - val_loss: 0.0222\n",
      "Epoch 3/10\n",
      "396/396 [==============================] - 1s 1ms/step - loss: 0.0217 - val_loss: 0.0186\n",
      "Epoch 4/10\n",
      "396/396 [==============================] - 1s 1ms/step - loss: 0.0184 - val_loss: 0.0159\n",
      "Epoch 5/10\n",
      "396/396 [==============================] - 1s 1ms/step - loss: 0.0157 - val_loss: 0.0142\n",
      "Epoch 6/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.0143 - val_loss: 0.0131\n",
      "Epoch 7/10\n",
      "396/396 [==============================] - 1s 1ms/step - loss: 0.0130 - val_loss: 0.0123\n",
      "Epoch 8/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.0124 - val_loss: 0.0118\n",
      "Epoch 9/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.0117 - val_loss: 0.0113\n",
      "Epoch 10/10\n",
      "396/396 [==============================] - 1s 1ms/step - loss: 0.0114 - val_loss: 0.0108\n",
      "\n",
      "\n",
      "Loss History for QCNN circuits, U_SO4 autoencoder16\n",
      "iteration:  0  cost:  1.0200132364834318\n",
      "iteration:  10  cost:  0.4369061801066864\n",
      "iteration:  20  cost:  0.5095140309488735\n",
      "iteration:  30  cost:  0.4198848703415943\n",
      "iteration:  40  cost:  0.4689252398525312\n",
      "iteration:  50  cost:  0.5510651376712697\n",
      "iteration:  60  cost:  0.37295614042332376\n",
      "iteration:  70  cost:  0.34709244924258426\n",
      "iteration:  80  cost:  0.2820045923214501\n",
      "iteration:  90  cost:  0.25334812695459147\n",
      "iteration:  100  cost:  0.3494714259238336\n",
      "iteration:  110  cost:  0.27614977928651624\n",
      "iteration:  120  cost:  0.346358849291582\n",
      "iteration:  130  cost:  0.3835431665752909\n",
      "iteration:  140  cost:  0.37707699720122506\n",
      "Accuracy for U_SO4 autoencoder16 :0.9687943262411347\n",
      "1th step : \n",
      "\n",
      "\n",
      "Loss History for QCNN circuits, U_TTN pca16\n",
      "iteration:  0  cost:  0.9822415290318212\n",
      "iteration:  10  cost:  0.9838325245989425\n",
      "iteration:  20  cost:  0.9562808111828506\n",
      "iteration:  30  cost:  0.9475056184147584\n",
      "iteration:  40  cost:  0.949899100191729\n",
      "iteration:  50  cost:  0.9441140247374525\n",
      "iteration:  60  cost:  0.9431035222170473\n",
      "iteration:  70  cost:  0.9314530964661586\n",
      "iteration:  80  cost:  0.9592513706791671\n",
      "iteration:  90  cost:  0.9320372870682383\n",
      "iteration:  100  cost:  0.9194928353732758\n",
      "iteration:  110  cost:  0.9507182265652159\n",
      "iteration:  120  cost:  0.9159804951955002\n",
      "iteration:  130  cost:  0.8927531153490851\n",
      "iteration:  140  cost:  0.8805273323380569\n",
      "Accuracy for U_TTN pca16 :0.7905437352245863\n",
      "Epoch 1/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.0942 - val_loss: 0.0285\n",
      "Epoch 2/10\n",
      "396/396 [==============================] - 1s 1ms/step - loss: 0.0272 - val_loss: 0.0232\n",
      "Epoch 3/10\n",
      "396/396 [==============================] - 1s 1ms/step - loss: 0.0221 - val_loss: 0.0186\n",
      "Epoch 4/10\n",
      "396/396 [==============================] - 1s 1ms/step - loss: 0.0180 - val_loss: 0.0153\n",
      "Epoch 5/10\n",
      "396/396 [==============================] - 1s 1ms/step - loss: 0.0149 - val_loss: 0.0138\n",
      "Epoch 6/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.0137 - val_loss: 0.0127\n",
      "Epoch 7/10\n",
      "396/396 [==============================] - 1s 1ms/step - loss: 0.0128 - val_loss: 0.0120\n",
      "Epoch 8/10\n",
      "396/396 [==============================] - 1s 1ms/step - loss: 0.0121 - val_loss: 0.0114\n",
      "Epoch 9/10\n",
      "396/396 [==============================] - 1s 1ms/step - loss: 0.0116 - val_loss: 0.0110\n",
      "Epoch 10/10\n",
      "396/396 [==============================] - 1s 1ms/step - loss: 0.0111 - val_loss: 0.0108\n",
      "\n",
      "\n",
      "Loss History for QCNN circuits, U_TTN autoencoder16\n",
      "iteration:  0  cost:  0.9444600474295438\n",
      "iteration:  10  cost:  0.6865746287184769\n",
      "iteration:  20  cost:  0.6986273114691067\n",
      "iteration:  30  cost:  0.5991153160055737\n",
      "iteration:  40  cost:  0.6672638596423905\n",
      "iteration:  50  cost:  0.7136112789049796\n",
      "iteration:  60  cost:  0.8284851411295091\n",
      "iteration:  70  cost:  0.6084971894203328\n",
      "iteration:  80  cost:  0.661529051152168\n",
      "iteration:  90  cost:  0.7582033743499937\n",
      "iteration:  100  cost:  0.6360491134146316\n",
      "iteration:  110  cost:  0.5168545984539494\n",
      "iteration:  120  cost:  0.5455885747922129\n",
      "iteration:  130  cost:  0.7797386950054711\n",
      "iteration:  140  cost:  0.6284015002134699\n",
      "Accuracy for U_TTN autoencoder16 :0.6567375886524822\n",
      "\n",
      "\n",
      "Loss History for QCNN circuits, U_5 pca16\n",
      "iteration:  0  cost:  0.9327913380274221\n",
      "iteration:  10  cost:  0.8650531691715261\n",
      "iteration:  20  cost:  0.7827216214128088\n",
      "iteration:  30  cost:  0.8132889096383041\n",
      "iteration:  40  cost:  0.7348448191952517\n",
      "iteration:  50  cost:  0.5887945564917958\n",
      "iteration:  60  cost:  0.6084937057020694\n",
      "iteration:  70  cost:  0.4075880789392709\n",
      "iteration:  80  cost:  0.38448507313728414\n",
      "iteration:  90  cost:  0.372036985428412\n",
      "iteration:  100  cost:  0.2778906025365875\n",
      "iteration:  110  cost:  0.22862651614573629\n",
      "iteration:  120  cost:  0.33193617454942087\n",
      "iteration:  130  cost:  0.2534416631525422\n",
      "iteration:  140  cost:  0.22340283176006717\n",
      "Accuracy for U_5 pca16 :0.9867612293144208\n",
      "Epoch 1/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.0986 - val_loss: 0.0292\n",
      "Epoch 2/10\n",
      "396/396 [==============================] - 1s 1ms/step - loss: 0.0275 - val_loss: 0.0215\n",
      "Epoch 3/10\n",
      "396/396 [==============================] - 1s 1ms/step - loss: 0.0209 - val_loss: 0.0177\n",
      "Epoch 4/10\n",
      "396/396 [==============================] - 1s 1ms/step - loss: 0.0173 - val_loss: 0.0155\n",
      "Epoch 5/10\n",
      "396/396 [==============================] - 1s 1ms/step - loss: 0.0155 - val_loss: 0.0140\n",
      "Epoch 6/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.0140 - val_loss: 0.0129\n",
      "Epoch 7/10\n",
      "396/396 [==============================] - 1s 1ms/step - loss: 0.0130 - val_loss: 0.0121\n",
      "Epoch 8/10\n",
      "396/396 [==============================] - 1s 1ms/step - loss: 0.0122 - val_loss: 0.0115\n",
      "Epoch 9/10\n",
      "396/396 [==============================] - 1s 1ms/step - loss: 0.0114 - val_loss: 0.0111\n",
      "Epoch 10/10\n",
      "396/396 [==============================] - 1s 1ms/step - loss: 0.0112 - val_loss: 0.0108\n",
      "\n",
      "\n",
      "Loss History for QCNN circuits, U_5 autoencoder16\n",
      "iteration:  0  cost:  1.1161055298355949\n",
      "iteration:  10  cost:  0.517698876396527\n",
      "iteration:  20  cost:  0.3962593664215028\n",
      "iteration:  30  cost:  0.4812875428300053\n",
      "iteration:  40  cost:  0.41300375925792165\n",
      "iteration:  50  cost:  0.32946680753364516\n",
      "iteration:  60  cost:  0.38565141308450845\n",
      "iteration:  70  cost:  0.3250621270638615\n",
      "iteration:  80  cost:  0.40295159985852075\n",
      "iteration:  90  cost:  0.4408701807835814\n",
      "iteration:  100  cost:  0.39230607435442494\n",
      "iteration:  110  cost:  0.335008673341378\n",
      "iteration:  120  cost:  0.351487710649096\n",
      "iteration:  130  cost:  0.41559605118732246\n",
      "iteration:  140  cost:  0.35933562491269627\n",
      "Accuracy for U_5 autoencoder16 :0.9418439716312057\n",
      "\n",
      "\n",
      "Loss History for QCNN circuits, U_6 pca16\n",
      "iteration:  0  cost:  1.0103209627898229\n",
      "iteration:  10  cost:  1.0009361346375805\n",
      "iteration:  20  cost:  0.8463242978232915\n",
      "iteration:  30  cost:  0.7116800351651799\n",
      "iteration:  40  cost:  0.4765163704306158\n",
      "iteration:  50  cost:  0.3320478161314469\n",
      "iteration:  60  cost:  0.29464462923436313\n",
      "iteration:  70  cost:  0.36960142650425093\n",
      "iteration:  80  cost:  0.2129686757814639\n",
      "iteration:  90  cost:  0.15223137869206615\n",
      "iteration:  100  cost:  0.12150925298555279\n",
      "iteration:  110  cost:  0.19301878935676342\n",
      "iteration:  120  cost:  0.14934787827620816\n",
      "iteration:  130  cost:  0.18087266384013084\n",
      "iteration:  140  cost:  0.2360203857482381\n",
      "Accuracy for U_6 pca16 :0.9900709219858156\n",
      "Epoch 1/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.0951 - val_loss: 0.0289\n",
      "Epoch 2/10\n",
      "396/396 [==============================] - 1s 1ms/step - loss: 0.0272 - val_loss: 0.0218\n",
      "Epoch 3/10\n",
      "396/396 [==============================] - 1s 1ms/step - loss: 0.0209 - val_loss: 0.0176\n",
      "Epoch 4/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.0173 - val_loss: 0.0152\n",
      "Epoch 5/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.0150 - val_loss: 0.0137\n",
      "Epoch 6/10\n",
      "396/396 [==============================] - 1s 1ms/step - loss: 0.0135 - val_loss: 0.0126\n",
      "Epoch 7/10\n",
      "396/396 [==============================] - 1s 1ms/step - loss: 0.0126 - val_loss: 0.0118\n",
      "Epoch 8/10\n",
      "396/396 [==============================] - 1s 1ms/step - loss: 0.0119 - val_loss: 0.0112\n",
      "Epoch 9/10\n",
      "396/396 [==============================] - 1s 1ms/step - loss: 0.0112 - val_loss: 0.0108\n",
      "Epoch 10/10\n",
      "396/396 [==============================] - 1s 1ms/step - loss: 0.0110 - val_loss: 0.0104\n",
      "\n",
      "\n",
      "Loss History for QCNN circuits, U_6 autoencoder16\n",
      "iteration:  0  cost:  1.1946220103168086\n",
      "iteration:  10  cost:  0.8634352442360026\n",
      "iteration:  20  cost:  0.5687022451893284\n",
      "iteration:  30  cost:  0.48110143254869725\n",
      "iteration:  40  cost:  0.5475561452783592\n",
      "iteration:  50  cost:  0.4394530401546873\n",
      "iteration:  60  cost:  0.3863194483009411\n",
      "iteration:  70  cost:  0.49825266486065056\n",
      "iteration:  80  cost:  0.41530432471919226\n",
      "iteration:  90  cost:  0.45336454299582035\n",
      "iteration:  100  cost:  0.4162534813872644\n",
      "iteration:  110  cost:  0.2898827865606176\n",
      "iteration:  120  cost:  0.4064873105541251\n",
      "iteration:  130  cost:  0.5727557814540382\n",
      "iteration:  140  cost:  0.4339247529780913\n",
      "Accuracy for U_6 autoencoder16 :0.8624113475177305\n",
      "\n",
      "\n",
      "Loss History for QCNN circuits, U_9 pca16\n",
      "iteration:  0  cost:  0.8859060259664912\n",
      "iteration:  10  cost:  0.6302947850028207\n",
      "iteration:  20  cost:  0.5556044315718444\n",
      "iteration:  30  cost:  0.5812650559376082\n",
      "iteration:  40  cost:  0.47342736044932615\n",
      "iteration:  50  cost:  0.512077420970424\n",
      "iteration:  60  cost:  0.47292822460557665\n",
      "iteration:  70  cost:  0.5171430084648841\n",
      "iteration:  80  cost:  0.5630783737455857\n",
      "iteration:  90  cost:  0.47178518784270695\n",
      "iteration:  100  cost:  0.4862317085365017\n",
      "iteration:  110  cost:  0.49397445389696765\n",
      "iteration:  120  cost:  0.5356111006447908\n",
      "iteration:  130  cost:  0.6586306548804367\n",
      "iteration:  140  cost:  0.5000298109037425\n",
      "Accuracy for U_9 pca16 :0.9782505910165484\n",
      "Epoch 1/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.0932 - val_loss: 0.0285\n",
      "Epoch 2/10\n",
      "396/396 [==============================] - 1s 1ms/step - loss: 0.0275 - val_loss: 0.0227\n",
      "Epoch 3/10\n",
      "396/396 [==============================] - 1s 1ms/step - loss: 0.0217 - val_loss: 0.0182\n",
      "Epoch 4/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.0175 - val_loss: 0.0153\n",
      "Epoch 5/10\n",
      "396/396 [==============================] - 1s 1ms/step - loss: 0.0151 - val_loss: 0.0137\n",
      "Epoch 6/10\n",
      "396/396 [==============================] - 1s 1ms/step - loss: 0.0138 - val_loss: 0.0127\n",
      "Epoch 7/10\n",
      "396/396 [==============================] - 1s 1ms/step - loss: 0.0127 - val_loss: 0.0120\n",
      "Epoch 8/10\n",
      "396/396 [==============================] - 1s 1ms/step - loss: 0.0122 - val_loss: 0.0116\n",
      "Epoch 9/10\n",
      "396/396 [==============================] - 1s 1ms/step - loss: 0.0116 - val_loss: 0.0111\n",
      "Epoch 10/10\n",
      "396/396 [==============================] - 1s 1ms/step - loss: 0.0112 - val_loss: 0.0109\n",
      "\n",
      "\n",
      "Loss History for QCNN circuits, U_9 autoencoder16\n",
      "iteration:  0  cost:  1.0222547130734267\n",
      "iteration:  10  cost:  1.0121317508699041\n",
      "iteration:  20  cost:  0.9652912958168862\n",
      "iteration:  30  cost:  0.9295307040820212\n",
      "iteration:  40  cost:  0.8738847363565827\n",
      "iteration:  50  cost:  0.8369323308568961\n",
      "iteration:  60  cost:  0.8346182138081921\n",
      "iteration:  70  cost:  0.8411193253915644\n",
      "iteration:  80  cost:  0.841097151603378\n",
      "iteration:  90  cost:  0.8425197964304785\n",
      "iteration:  100  cost:  0.8127872682243238\n",
      "iteration:  110  cost:  0.8651512220329954\n",
      "iteration:  120  cost:  0.8487189071151104\n",
      "iteration:  130  cost:  0.8385557244769675\n",
      "iteration:  140  cost:  0.842071237480308\n",
      "Accuracy for U_9 autoencoder16 :0.9271867612293144\n",
      "\n",
      "\n",
      "Loss History for QCNN circuits, U_13 pca16\n",
      "iteration:  0  cost:  1.0356613966221124\n",
      "iteration:  10  cost:  1.0312150787018486\n",
      "iteration:  20  cost:  0.5964586810799346\n",
      "iteration:  30  cost:  0.3195721510612608\n",
      "iteration:  40  cost:  0.1931273451851901\n",
      "iteration:  50  cost:  0.16754443803427002\n",
      "iteration:  60  cost:  0.19193198900404532\n",
      "iteration:  70  cost:  0.15214342821423957\n",
      "iteration:  80  cost:  0.17366871284106497\n",
      "iteration:  90  cost:  0.20309251597031672\n",
      "iteration:  100  cost:  0.2221231855625889\n",
      "iteration:  110  cost:  0.21323682312075065\n",
      "iteration:  120  cost:  0.16078954467541096\n",
      "iteration:  130  cost:  0.14482007470524505\n",
      "iteration:  140  cost:  0.28481793991546767\n",
      "Accuracy for U_13 pca16 :0.984869976359338\n",
      "Epoch 1/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.0942 - val_loss: 0.0286\n",
      "Epoch 2/10\n",
      "396/396 [==============================] - 1s 1ms/step - loss: 0.0271 - val_loss: 0.0222\n",
      "Epoch 3/10\n",
      "396/396 [==============================] - 1s 1ms/step - loss: 0.0216 - val_loss: 0.0185\n",
      "Epoch 4/10\n",
      "396/396 [==============================] - 1s 1ms/step - loss: 0.0181 - val_loss: 0.0157\n",
      "Epoch 5/10\n",
      "396/396 [==============================] - 1s 1ms/step - loss: 0.0154 - val_loss: 0.0138\n",
      "Epoch 6/10\n",
      "396/396 [==============================] - 1s 1ms/step - loss: 0.0138 - val_loss: 0.0126\n",
      "Epoch 7/10\n",
      "396/396 [==============================] - 1s 1ms/step - loss: 0.0126 - val_loss: 0.0119\n",
      "Epoch 8/10\n",
      "396/396 [==============================] - 1s 1ms/step - loss: 0.0118 - val_loss: 0.0114\n",
      "Epoch 9/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.0114 - val_loss: 0.0109\n",
      "Epoch 10/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.0109 - val_loss: 0.0106\n",
      "\n",
      "\n",
      "Loss History for QCNN circuits, U_13 autoencoder16\n",
      "iteration:  0  cost:  1.2590450205145256\n",
      "iteration:  10  cost:  0.8972439106523272\n",
      "iteration:  20  cost:  0.5423259402766376\n",
      "iteration:  30  cost:  0.5734772392471236\n",
      "iteration:  40  cost:  0.5364046604575075\n",
      "iteration:  50  cost:  0.46806846914068656\n",
      "iteration:  60  cost:  0.5303042582892054\n",
      "iteration:  70  cost:  0.525067597326827\n",
      "iteration:  80  cost:  0.4190235833825869\n",
      "iteration:  90  cost:  0.48930776515971786\n",
      "iteration:  100  cost:  0.5139642406349149\n",
      "iteration:  110  cost:  0.45999758786622935\n",
      "iteration:  120  cost:  0.4263689396495214\n",
      "iteration:  130  cost:  0.41488835942115876\n",
      "iteration:  140  cost:  0.4184379035428848\n",
      "Accuracy for U_13 autoencoder16 :0.941371158392435\n",
      "\n",
      "\n",
      "Loss History for QCNN circuits, U_14 pca16\n",
      "iteration:  0  cost:  1.4333530159548535\n",
      "iteration:  10  cost:  0.8677604795327176\n",
      "iteration:  20  cost:  0.5519219167057531\n",
      "iteration:  30  cost:  0.48124082719154615\n",
      "iteration:  40  cost:  0.48804121198861294\n",
      "iteration:  50  cost:  0.5182206987689323\n",
      "iteration:  60  cost:  0.5104399323522905\n",
      "iteration:  70  cost:  0.5152303527570952\n",
      "iteration:  80  cost:  0.4575089920960862\n",
      "iteration:  90  cost:  0.5222284117215522\n",
      "iteration:  100  cost:  0.40188500198158067\n",
      "iteration:  110  cost:  0.42673115330155087\n",
      "iteration:  120  cost:  0.4361556617449811\n",
      "iteration:  130  cost:  0.42425506248838263\n",
      "iteration:  140  cost:  0.3853672370306327\n",
      "Accuracy for U_14 pca16 :0.983451536643026\n",
      "Epoch 1/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.0935 - val_loss: 0.0277\n",
      "Epoch 2/10\n",
      "396/396 [==============================] - 1s 1ms/step - loss: 0.0262 - val_loss: 0.0216\n",
      "Epoch 3/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.0211 - val_loss: 0.0176\n",
      "Epoch 4/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.0170 - val_loss: 0.0151\n",
      "Epoch 5/10\n",
      "396/396 [==============================] - 1s 1ms/step - loss: 0.0149 - val_loss: 0.0135\n",
      "Epoch 6/10\n",
      "396/396 [==============================] - 1s 1ms/step - loss: 0.0133 - val_loss: 0.0125\n",
      "Epoch 7/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.0124 - val_loss: 0.0118\n",
      "Epoch 8/10\n",
      "396/396 [==============================] - 1s 1ms/step - loss: 0.0119 - val_loss: 0.0113\n",
      "Epoch 9/10\n",
      "396/396 [==============================] - 1s 1ms/step - loss: 0.0114 - val_loss: 0.0108\n",
      "Epoch 10/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.0108 - val_loss: 0.0106\n",
      "\n",
      "\n",
      "Loss History for QCNN circuits, U_14 autoencoder16\n",
      "iteration:  0  cost:  1.6846308572281732\n",
      "iteration:  10  cost:  0.7048973638450897\n",
      "iteration:  20  cost:  0.6087791874730428\n",
      "iteration:  30  cost:  0.5262094956086828\n",
      "iteration:  40  cost:  0.4094229654339238\n",
      "iteration:  50  cost:  0.4212935867231138\n",
      "iteration:  60  cost:  0.4801873566961218\n",
      "iteration:  70  cost:  0.45410670600412517\n",
      "iteration:  80  cost:  0.6092022420362183\n",
      "iteration:  90  cost:  0.4602695692102366\n",
      "iteration:  100  cost:  0.5139757288143335\n",
      "iteration:  110  cost:  0.47611344699467756\n",
      "iteration:  120  cost:  0.4050593022976345\n",
      "iteration:  130  cost:  0.49334276817299794\n",
      "iteration:  140  cost:  0.5642604378924333\n",
      "Accuracy for U_14 autoencoder16 :0.950354609929078\n",
      "\n",
      "\n",
      "Loss History for QCNN circuits, U_15 pca16\n",
      "iteration:  0  cost:  1.2861090278251748\n",
      "iteration:  10  cost:  0.8815327225240925\n",
      "iteration:  20  cost:  0.6209898161120833\n",
      "iteration:  30  cost:  0.30157378592773726\n",
      "iteration:  40  cost:  0.29250653198089105\n",
      "iteration:  50  cost:  0.4568479683705592\n",
      "iteration:  60  cost:  0.2755201028416217\n",
      "iteration:  70  cost:  0.31873461034988354\n",
      "iteration:  80  cost:  0.19743027231319665\n",
      "iteration:  90  cost:  0.19871765340663494\n",
      "iteration:  100  cost:  0.29626100807057926\n",
      "iteration:  110  cost:  0.20908975405038874\n",
      "iteration:  120  cost:  0.2418906666143462\n",
      "iteration:  130  cost:  0.24178475868842297\n",
      "iteration:  140  cost:  0.16785225460605602\n",
      "Accuracy for U_15 pca16 :0.9791962174940898\n",
      "Epoch 1/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.0964 - val_loss: 0.0285\n",
      "Epoch 2/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.0270 - val_loss: 0.0223\n",
      "Epoch 3/10\n",
      "396/396 [==============================] - 1s 1ms/step - loss: 0.0217 - val_loss: 0.0188\n",
      "Epoch 4/10\n",
      "396/396 [==============================] - 1s 1ms/step - loss: 0.0183 - val_loss: 0.0158\n",
      "Epoch 5/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.0156 - val_loss: 0.0136\n",
      "Epoch 6/10\n",
      "396/396 [==============================] - 1s 1ms/step - loss: 0.0134 - val_loss: 0.0125\n",
      "Epoch 7/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.0125 - val_loss: 0.0117\n",
      "Epoch 8/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.0118 - val_loss: 0.0113\n",
      "Epoch 9/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.0113 - val_loss: 0.0109\n",
      "Epoch 10/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.0111 - val_loss: 0.0107\n",
      "\n",
      "\n",
      "Loss History for QCNN circuits, U_15 autoencoder16\n",
      "iteration:  0  cost:  1.0733183886903743\n",
      "iteration:  10  cost:  0.8071082041662179\n",
      "iteration:  20  cost:  0.7909440338825705\n",
      "iteration:  30  cost:  0.7635619310735593\n",
      "iteration:  40  cost:  0.7112548323168855\n",
      "iteration:  50  cost:  0.6772103365418215\n",
      "iteration:  60  cost:  0.6237243596171074\n",
      "iteration:  70  cost:  0.48543565728009663\n",
      "iteration:  80  cost:  0.46595898142594805\n",
      "iteration:  90  cost:  0.5573964883870645\n",
      "iteration:  100  cost:  0.6521662654817423\n",
      "iteration:  110  cost:  0.48972535098074543\n",
      "iteration:  120  cost:  0.40368609781394477\n",
      "iteration:  130  cost:  0.40701595529662155\n",
      "iteration:  140  cost:  0.5264289065036821\n",
      "Accuracy for U_15 autoencoder16 :0.9295508274231679\n",
      "\n",
      "\n",
      "Loss History for QCNN circuits, U_SO4 pca16\n",
      "iteration:  0  cost:  1.0231395156390894\n",
      "iteration:  10  cost:  0.6187906398038493\n",
      "iteration:  20  cost:  0.16399755245964953\n",
      "iteration:  30  cost:  0.10965863393082376\n",
      "iteration:  40  cost:  0.07147922533961347\n",
      "iteration:  50  cost:  0.0969624332873949\n",
      "iteration:  60  cost:  0.31430086358826625\n",
      "iteration:  70  cost:  0.21896476465764103\n",
      "iteration:  80  cost:  0.17746189113830144\n",
      "iteration:  90  cost:  0.25941624801186636\n",
      "iteration:  100  cost:  0.06143160049378547\n",
      "iteration:  110  cost:  0.2175572253638061\n",
      "iteration:  120  cost:  0.17580871063034753\n",
      "iteration:  130  cost:  0.1226487663737097\n",
      "iteration:  140  cost:  0.12873111680344637\n"
     ]
    }
   ],
   "source": [
    "Benchmarking(Unitaries, U_num_params, Encodings, circuit, binary = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.4 Binary Classification with 1, -1 labels with only Compact Encoding (3 rotation gates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "Unitaries = ['U_TTN', 'U_5', 'U_6', 'U_9', 'U_13', 'U_14', 'U_15', 'U_SO4']\n",
    "U_num_params = [2, 10, 10, 4, 6, 6, 4, 6]\n",
    "Encodings = ['pca24', 'autoencoder24']\n",
    "classes = [0,1]\n",
    "circuit = 'QCNN'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0th step : \n",
      "\n",
      "\n",
      "Loss History for QCNN circuits, U_TTN pca24\n",
      "iteration:  0  cost:  1.0414752772910194\n",
      "iteration:  10  cost:  0.9900446631079973\n",
      "iteration:  20  cost:  0.9748188462021049\n",
      "iteration:  30  cost:  1.009169692711398\n",
      "iteration:  40  cost:  0.9338012602156016\n",
      "iteration:  50  cost:  1.002172471825047\n",
      "iteration:  60  cost:  1.1654684796407944\n",
      "iteration:  70  cost:  1.0093460558984744\n",
      "iteration:  80  cost:  0.9860236106060475\n",
      "iteration:  90  cost:  0.971159250392691\n",
      "iteration:  100  cost:  0.9459460183732817\n",
      "iteration:  110  cost:  0.92605720696656\n",
      "iteration:  120  cost:  1.0199485848766627\n",
      "iteration:  130  cost:  1.0000236129919007\n",
      "iteration:  140  cost:  0.9992319724280523\n",
      "Accuracy for U_TTN pca24 :0.5385342789598109\n",
      "Epoch 1/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.0867 - val_loss: 0.0254\n",
      "Epoch 2/10\n",
      "396/396 [==============================] - 0s 815us/step - loss: 0.0239 - val_loss: 0.0187\n",
      "Epoch 3/10\n",
      "396/396 [==============================] - 0s 784us/step - loss: 0.0179 - val_loss: 0.0147\n",
      "Epoch 4/10\n",
      "396/396 [==============================] - 0s 796us/step - loss: 0.0142 - val_loss: 0.0123\n",
      "Epoch 5/10\n",
      "396/396 [==============================] - 0s 788us/step - loss: 0.0122 - val_loss: 0.0109\n",
      "Epoch 6/10\n",
      "396/396 [==============================] - 0s 801us/step - loss: 0.0106 - val_loss: 0.0098\n",
      "Epoch 7/10\n",
      "396/396 [==============================] - 0s 934us/step - loss: 0.0098 - val_loss: 0.0089\n",
      "Epoch 8/10\n",
      "396/396 [==============================] - 0s 800us/step - loss: 0.0089 - val_loss: 0.0084\n",
      "Epoch 9/10\n",
      "396/396 [==============================] - 0s 821us/step - loss: 0.0082 - val_loss: 0.0079\n",
      "Epoch 10/10\n",
      "396/396 [==============================] - 0s 805us/step - loss: 0.0079 - val_loss: 0.0075\n",
      "\n",
      "\n",
      "Loss History for QCNN circuits, U_TTN autoencoder24\n",
      "iteration:  0  cost:  1.1857285496994414\n",
      "iteration:  10  cost:  1.0352684165393256\n",
      "iteration:  20  cost:  1.000045904779478\n",
      "iteration:  30  cost:  0.8286454814093979\n",
      "iteration:  40  cost:  0.8081928828815472\n",
      "iteration:  50  cost:  0.7737596005342398\n",
      "iteration:  60  cost:  0.7794659674192714\n",
      "iteration:  70  cost:  0.7419372332552076\n",
      "iteration:  80  cost:  0.761967253137579\n",
      "iteration:  90  cost:  0.7141653058183727\n",
      "iteration:  100  cost:  0.7710391307622534\n",
      "iteration:  110  cost:  0.8029804547814224\n",
      "iteration:  120  cost:  0.7516199608098205\n",
      "iteration:  130  cost:  0.8074787139035249\n",
      "iteration:  140  cost:  0.733485595001836\n",
      "Accuracy for U_TTN autoencoder24 :0.9016548463356974\n",
      "\n",
      "\n",
      "Loss History for QCNN circuits, U_5 pca24\n",
      "iteration:  0  cost:  0.8402330023158799\n",
      "iteration:  10  cost:  1.1010368940302555\n",
      "iteration:  20  cost:  0.9888001184998362\n",
      "iteration:  30  cost:  1.0058020392894633\n",
      "iteration:  40  cost:  0.9984901277682644\n",
      "iteration:  50  cost:  1.0465807633340944\n",
      "iteration:  60  cost:  0.9826581259275876\n",
      "iteration:  70  cost:  1.0765109442530727\n",
      "iteration:  80  cost:  0.9863057887066132\n",
      "iteration:  90  cost:  0.9989876575456624\n",
      "iteration:  100  cost:  0.9829640527075146\n",
      "iteration:  110  cost:  0.9969372226335297\n",
      "iteration:  120  cost:  1.0028258881628351\n",
      "iteration:  130  cost:  0.9921491139540027\n",
      "iteration:  140  cost:  0.9783839062523573\n",
      "Accuracy for U_5 pca24 :0.5399527186761229\n",
      "Epoch 1/10\n",
      "396/396 [==============================] - 1s 1ms/step - loss: 0.0870 - val_loss: 0.0270\n",
      "Epoch 2/10\n",
      "396/396 [==============================] - 0s 821us/step - loss: 0.0255 - val_loss: 0.0198\n",
      "Epoch 3/10\n",
      "396/396 [==============================] - 0s 798us/step - loss: 0.0187 - val_loss: 0.0151\n",
      "Epoch 4/10\n",
      "396/396 [==============================] - 0s 804us/step - loss: 0.0147 - val_loss: 0.0126\n",
      "Epoch 5/10\n",
      "396/396 [==============================] - 0s 832us/step - loss: 0.0124 - val_loss: 0.0110\n",
      "Epoch 6/10\n",
      "396/396 [==============================] - 0s 817us/step - loss: 0.0108 - val_loss: 0.0099\n",
      "Epoch 7/10\n",
      "396/396 [==============================] - 0s 810us/step - loss: 0.0099 - val_loss: 0.0091\n",
      "Epoch 8/10\n",
      "396/396 [==============================] - 0s 824us/step - loss: 0.0091 - val_loss: 0.0084\n",
      "Epoch 9/10\n",
      "396/396 [==============================] - 0s 977us/step - loss: 0.0084 - val_loss: 0.0079\n",
      "Epoch 10/10\n",
      "396/396 [==============================] - 0s 819us/step - loss: 0.0080 - val_loss: 0.0075\n",
      "\n",
      "\n",
      "Loss History for QCNN circuits, U_5 autoencoder24\n",
      "iteration:  0  cost:  0.9102363100870433\n",
      "iteration:  10  cost:  0.6400524674675679\n",
      "iteration:  20  cost:  0.6024621506347467\n",
      "iteration:  30  cost:  0.5001131492267111\n",
      "iteration:  40  cost:  0.5026897290999187\n",
      "iteration:  50  cost:  0.48371797422445334\n",
      "iteration:  60  cost:  0.4880465951040295\n",
      "iteration:  70  cost:  0.5304740198233945\n",
      "iteration:  80  cost:  0.5878119704640278\n",
      "iteration:  90  cost:  0.46860021061266627\n",
      "iteration:  100  cost:  0.8966117058890493\n",
      "iteration:  110  cost:  0.5264427160388679\n",
      "iteration:  120  cost:  0.5510403598992886\n",
      "iteration:  130  cost:  0.4141112091631715\n",
      "iteration:  140  cost:  0.5264364013451837\n",
      "Accuracy for U_5 autoencoder24 :0.9011820330969267\n",
      "\n",
      "\n",
      "Loss History for QCNN circuits, U_6 pca24\n",
      "iteration:  0  cost:  1.0259243309602244\n",
      "iteration:  10  cost:  1.0214306811124643\n",
      "iteration:  20  cost:  1.0343560185391962\n",
      "iteration:  30  cost:  1.0244543361919884\n",
      "iteration:  40  cost:  1.0032509136206857\n",
      "iteration:  50  cost:  1.0101237457978436\n",
      "iteration:  60  cost:  1.0216611728464058\n",
      "iteration:  70  cost:  0.9971845840351027\n",
      "iteration:  80  cost:  1.0540561779013202\n",
      "iteration:  90  cost:  0.9927791692407409\n",
      "iteration:  100  cost:  0.9934583376320962\n",
      "iteration:  110  cost:  1.0036909169927468\n",
      "iteration:  120  cost:  0.9534729965784566\n",
      "iteration:  130  cost:  0.9147101656293489\n",
      "iteration:  140  cost:  1.0255024052983956\n",
      "Accuracy for U_6 pca24 :0.49598108747044917\n",
      "Epoch 1/10\n",
      "396/396 [==============================] - 1s 1ms/step - loss: 0.0889 - val_loss: 0.0267\n",
      "Epoch 2/10\n",
      "396/396 [==============================] - 0s 824us/step - loss: 0.0251 - val_loss: 0.0189\n",
      "Epoch 3/10\n",
      "396/396 [==============================] - 0s 841us/step - loss: 0.0179 - val_loss: 0.0149\n",
      "Epoch 4/10\n",
      "396/396 [==============================] - 0s 865us/step - loss: 0.0142 - val_loss: 0.0125\n",
      "Epoch 5/10\n",
      "396/396 [==============================] - 0s 1ms/step - loss: 0.0121 - val_loss: 0.0106\n",
      "Epoch 6/10\n",
      "396/396 [==============================] - 0s 850us/step - loss: 0.0107 - val_loss: 0.0095\n",
      "Epoch 7/10\n",
      "396/396 [==============================] - 0s 862us/step - loss: 0.0094 - val_loss: 0.0088\n",
      "Epoch 8/10\n",
      "396/396 [==============================] - 0s 853us/step - loss: 0.0087 - val_loss: 0.0082\n",
      "Epoch 9/10\n",
      "396/396 [==============================] - 0s 864us/step - loss: 0.0082 - val_loss: 0.0078\n",
      "Epoch 10/10\n",
      "396/396 [==============================] - 0s 847us/step - loss: 0.0076 - val_loss: 0.0075\n",
      "\n",
      "\n",
      "Loss History for QCNN circuits, U_6 autoencoder24\n",
      "iteration:  0  cost:  0.9987251972977027\n",
      "iteration:  10  cost:  0.760807219734705\n",
      "iteration:  20  cost:  0.6222247099510774\n",
      "iteration:  30  cost:  0.6424402993969516\n",
      "iteration:  40  cost:  0.6212451459128778\n",
      "iteration:  50  cost:  0.633179421821181\n",
      "iteration:  60  cost:  0.547451765333603\n",
      "iteration:  70  cost:  0.8087694063548809\n",
      "iteration:  80  cost:  0.957377412140437\n",
      "iteration:  90  cost:  0.6746392316594144\n",
      "iteration:  100  cost:  0.579075432459565\n",
      "iteration:  110  cost:  0.6993118449568319\n",
      "iteration:  120  cost:  0.48384574152717497\n",
      "iteration:  130  cost:  0.7079685851318263\n",
      "iteration:  140  cost:  0.590861132992432\n",
      "Accuracy for U_6 autoencoder24 :0.8543735224586289\n",
      "\n",
      "\n",
      "Loss History for QCNN circuits, U_9 pca24\n",
      "iteration:  0  cost:  0.9975052806511949\n",
      "iteration:  10  cost:  0.9977246828381894\n",
      "iteration:  20  cost:  0.9973363887451535\n",
      "iteration:  30  cost:  1.0025793881455474\n",
      "iteration:  40  cost:  0.9919859578300454\n",
      "iteration:  50  cost:  1.0136800928123497\n",
      "iteration:  60  cost:  0.9911805342141848\n",
      "iteration:  70  cost:  0.9908176457118069\n",
      "iteration:  80  cost:  0.9958495423965741\n",
      "iteration:  90  cost:  0.9876460265426094\n",
      "iteration:  100  cost:  0.9858693821039419\n",
      "iteration:  110  cost:  1.038013177937756\n",
      "iteration:  120  cost:  0.963578895045082\n",
      "iteration:  130  cost:  1.0257690552543397\n",
      "iteration:  140  cost:  0.9976144184431199\n",
      "Accuracy for U_9 pca24 :0.5366430260047281\n",
      "Epoch 1/10\n",
      "396/396 [==============================] - 1s 1ms/step - loss: 0.0886 - val_loss: 0.0260\n",
      "Epoch 2/10\n",
      "396/396 [==============================] - 0s 961us/step - loss: 0.0244 - val_loss: 0.0191\n",
      "Epoch 3/10\n",
      "396/396 [==============================] - 0s 927us/step - loss: 0.0182 - val_loss: 0.0148\n",
      "Epoch 4/10\n",
      "396/396 [==============================] - 0s 854us/step - loss: 0.0144 - val_loss: 0.0123\n",
      "Epoch 5/10\n",
      "396/396 [==============================] - 0s 963us/step - loss: 0.0120 - val_loss: 0.0107\n",
      "Epoch 6/10\n",
      "396/396 [==============================] - 0s 923us/step - loss: 0.0105 - val_loss: 0.0096\n",
      "Epoch 7/10\n",
      "396/396 [==============================] - 0s 849us/step - loss: 0.0096 - val_loss: 0.0087\n",
      "Epoch 8/10\n",
      "396/396 [==============================] - 0s 852us/step - loss: 0.0086 - val_loss: 0.0082\n",
      "Epoch 9/10\n",
      "396/396 [==============================] - 0s 857us/step - loss: 0.0081 - val_loss: 0.0077\n",
      "Epoch 10/10\n",
      "396/396 [==============================] - 0s 1ms/step - loss: 0.0077 - val_loss: 0.0074\n",
      "\n",
      "\n",
      "Loss History for QCNN circuits, U_9 autoencoder24\n",
      "iteration:  0  cost:  0.9877661183724296\n",
      "iteration:  10  cost:  0.9869794798510709\n",
      "iteration:  20  cost:  0.9861220138654414\n",
      "iteration:  30  cost:  0.973104056711749\n",
      "iteration:  40  cost:  0.9714788349478283\n",
      "iteration:  50  cost:  0.9519068697323645\n",
      "iteration:  60  cost:  0.8837369687447549\n",
      "iteration:  70  cost:  0.8353595125438781\n",
      "iteration:  80  cost:  0.940933035343054\n",
      "iteration:  90  cost:  0.8569746625313114\n",
      "iteration:  100  cost:  0.8948717268670094\n",
      "iteration:  110  cost:  0.8413328372685789\n",
      "iteration:  120  cost:  0.9032919681016806\n",
      "iteration:  130  cost:  0.8434880625752484\n",
      "iteration:  140  cost:  0.8683200679644217\n",
      "Accuracy for U_9 autoencoder24 :0.7924349881796691\n",
      "\n",
      "\n",
      "Loss History for QCNN circuits, U_13 pca24\n",
      "iteration:  0  cost:  0.995098840200669\n",
      "iteration:  10  cost:  1.0361150046875616\n",
      "iteration:  20  cost:  1.0600459602344992\n",
      "iteration:  30  cost:  0.9974549386588082\n",
      "iteration:  40  cost:  0.9690705994522263\n",
      "iteration:  50  cost:  0.9791166036341259\n",
      "iteration:  60  cost:  1.0195609825336458\n",
      "iteration:  70  cost:  0.9853415006559179\n",
      "iteration:  80  cost:  0.9920774734679544\n",
      "iteration:  90  cost:  0.9771182463287664\n",
      "iteration:  100  cost:  0.9650685067244348\n",
      "iteration:  110  cost:  1.0078846416017138\n",
      "iteration:  120  cost:  0.9570106517684365\n",
      "iteration:  130  cost:  0.9723069415217321\n",
      "iteration:  140  cost:  0.965419642935435\n",
      "Accuracy for U_13 pca24 :0.5810874704491725\n",
      "Epoch 1/10\n",
      "396/396 [==============================] - 1s 1ms/step - loss: 0.0863 - val_loss: 0.0262\n",
      "Epoch 2/10\n",
      "396/396 [==============================] - 0s 812us/step - loss: 0.0247 - val_loss: 0.0193\n",
      "Epoch 3/10\n",
      "396/396 [==============================] - 0s 829us/step - loss: 0.0183 - val_loss: 0.0146\n",
      "Epoch 4/10\n",
      "396/396 [==============================] - 0s 834us/step - loss: 0.0142 - val_loss: 0.0122\n",
      "Epoch 5/10\n",
      "396/396 [==============================] - 0s 965us/step - loss: 0.0122 - val_loss: 0.0108\n",
      "Epoch 6/10\n",
      "396/396 [==============================] - 0s 850us/step - loss: 0.0107 - val_loss: 0.0097\n",
      "Epoch 7/10\n",
      "396/396 [==============================] - 0s 827us/step - loss: 0.0097 - val_loss: 0.0088\n",
      "Epoch 8/10\n",
      "396/396 [==============================] - 0s 860us/step - loss: 0.0088 - val_loss: 0.0082\n",
      "Epoch 9/10\n",
      "396/396 [==============================] - 0s 872us/step - loss: 0.0081 - val_loss: 0.0077\n",
      "Epoch 10/10\n",
      "396/396 [==============================] - 0s 893us/step - loss: 0.0078 - val_loss: 0.0073\n",
      "\n",
      "\n",
      "Loss History for QCNN circuits, U_13 autoencoder24\n",
      "iteration:  0  cost:  1.472635300132126\n",
      "iteration:  10  cost:  0.8235578399871167\n",
      "iteration:  20  cost:  0.680462063220704\n",
      "iteration:  30  cost:  0.7917567196905351\n",
      "iteration:  40  cost:  0.5476120793526623\n",
      "iteration:  50  cost:  0.6999728180487363\n",
      "iteration:  60  cost:  0.5809918369982433\n",
      "iteration:  70  cost:  0.6121292226739485\n",
      "iteration:  80  cost:  0.5252831999198404\n",
      "iteration:  90  cost:  0.6685377832169914\n",
      "iteration:  100  cost:  0.630320914254702\n",
      "iteration:  110  cost:  0.5822704960212954\n",
      "iteration:  120  cost:  0.6816555309881868\n",
      "iteration:  130  cost:  0.5554577757162186\n",
      "iteration:  140  cost:  0.6290778964099678\n",
      "Accuracy for U_13 autoencoder24 :0.8761229314420804\n",
      "\n",
      "\n",
      "Loss History for QCNN circuits, U_14 pca24\n",
      "iteration:  0  cost:  1.1911266948442383\n",
      "iteration:  10  cost:  1.0875236881915464\n",
      "iteration:  20  cost:  0.9925964674523904\n",
      "iteration:  30  cost:  0.9744775598833221\n",
      "iteration:  40  cost:  1.0174815057316848\n",
      "iteration:  50  cost:  1.021525533685901\n",
      "iteration:  60  cost:  0.9817832139173629\n",
      "iteration:  70  cost:  1.0051946711168207\n",
      "iteration:  80  cost:  1.0028436077963527\n",
      "iteration:  90  cost:  1.0127123588542049\n",
      "iteration:  100  cost:  0.9489516790698697\n",
      "iteration:  110  cost:  1.027588283442394\n",
      "iteration:  120  cost:  0.9874458692242482\n",
      "iteration:  130  cost:  0.9348714010307247\n",
      "iteration:  140  cost:  0.9939621294091414\n",
      "Accuracy for U_14 pca24 :0.56548463356974\n",
      "Epoch 1/10\n",
      "396/396 [==============================] - 1s 1ms/step - loss: 0.0867 - val_loss: 0.0260\n",
      "Epoch 2/10\n",
      "396/396 [==============================] - 0s 813us/step - loss: 0.0246 - val_loss: 0.0193\n",
      "Epoch 3/10\n",
      "396/396 [==============================] - 0s 835us/step - loss: 0.0181 - val_loss: 0.0146\n",
      "Epoch 4/10\n",
      "396/396 [==============================] - 0s 813us/step - loss: 0.0142 - val_loss: 0.0122\n",
      "Epoch 5/10\n",
      "396/396 [==============================] - 0s 843us/step - loss: 0.0121 - val_loss: 0.0107\n",
      "Epoch 6/10\n",
      "396/396 [==============================] - 0s 799us/step - loss: 0.0105 - val_loss: 0.0097\n",
      "Epoch 7/10\n",
      "396/396 [==============================] - 0s 806us/step - loss: 0.0096 - val_loss: 0.0088\n",
      "Epoch 8/10\n",
      "396/396 [==============================] - 0s 802us/step - loss: 0.0088 - val_loss: 0.0082\n",
      "Epoch 9/10\n",
      "396/396 [==============================] - 0s 823us/step - loss: 0.0081 - val_loss: 0.0078\n",
      "Epoch 10/10\n",
      "396/396 [==============================] - 0s 959us/step - loss: 0.0077 - val_loss: 0.0074\n",
      "\n",
      "\n",
      "Loss History for QCNN circuits, U_14 autoencoder24\n",
      "iteration:  0  cost:  0.8889524704350974\n",
      "iteration:  10  cost:  0.5447172211778059\n",
      "iteration:  20  cost:  0.6344391558632666\n",
      "iteration:  30  cost:  0.6910489746441136\n",
      "iteration:  40  cost:  0.5229530874016793\n",
      "iteration:  50  cost:  0.5948723047220998\n",
      "iteration:  60  cost:  0.5603643231657156\n",
      "iteration:  70  cost:  0.4252622168694882\n",
      "iteration:  80  cost:  0.5947207016424035\n",
      "iteration:  90  cost:  0.6617702174172116\n",
      "iteration:  100  cost:  0.6358655839464183\n",
      "iteration:  110  cost:  0.46283218597088277\n",
      "iteration:  120  cost:  0.5213977608717788\n",
      "iteration:  130  cost:  0.5010896892473831\n",
      "iteration:  140  cost:  0.5807852657934575\n",
      "Accuracy for U_14 autoencoder24 :0.858628841607565\n",
      "\n",
      "\n",
      "Loss History for QCNN circuits, U_15 pca24\n",
      "iteration:  0  cost:  1.0011034428016379\n",
      "iteration:  10  cost:  1.052526133073235\n",
      "iteration:  20  cost:  0.9389784618822398\n",
      "iteration:  30  cost:  0.9953448580206655\n",
      "iteration:  40  cost:  1.0075336106568669\n",
      "iteration:  50  cost:  0.9810126160060773\n",
      "iteration:  60  cost:  1.0124171427642787\n",
      "iteration:  70  cost:  0.9812798388515459\n",
      "iteration:  80  cost:  1.008912695431768\n",
      "iteration:  90  cost:  1.0153097501948196\n",
      "iteration:  100  cost:  1.016185018511927\n",
      "iteration:  110  cost:  0.9903870436692942\n",
      "iteration:  120  cost:  0.9730390912895455\n",
      "iteration:  130  cost:  0.952925126099287\n",
      "iteration:  140  cost:  1.0328938864353454\n",
      "Accuracy for U_15 pca24 :0.5432624113475177\n",
      "Epoch 1/10\n",
      "396/396 [==============================] - 1s 1ms/step - loss: 0.0882 - val_loss: 0.0247\n",
      "Epoch 2/10\n",
      "396/396 [==============================] - 0s 801us/step - loss: 0.0234 - val_loss: 0.0186\n",
      "Epoch 3/10\n",
      "396/396 [==============================] - 0s 824us/step - loss: 0.0178 - val_loss: 0.0145\n",
      "Epoch 4/10\n",
      "396/396 [==============================] - 0s 822us/step - loss: 0.0139 - val_loss: 0.0122\n",
      "Epoch 5/10\n",
      "396/396 [==============================] - 0s 899us/step - loss: 0.0119 - val_loss: 0.0107\n",
      "Epoch 6/10\n",
      "396/396 [==============================] - 0s 864us/step - loss: 0.0105 - val_loss: 0.0096\n",
      "Epoch 7/10\n",
      "396/396 [==============================] - 0s 922us/step - loss: 0.0095 - val_loss: 0.0089\n",
      "Epoch 8/10\n",
      "396/396 [==============================] - 0s 924us/step - loss: 0.0088 - val_loss: 0.0081\n",
      "Epoch 9/10\n",
      "396/396 [==============================] - 0s 1ms/step - loss: 0.0081 - val_loss: 0.0077\n",
      "Epoch 10/10\n",
      "396/396 [==============================] - 0s 846us/step - loss: 0.0075 - val_loss: 0.0073\n",
      "\n",
      "\n",
      "Loss History for QCNN circuits, U_15 autoencoder24\n",
      "iteration:  0  cost:  1.0909985308499126\n",
      "iteration:  10  cost:  0.8451218558318441\n",
      "iteration:  20  cost:  0.8415447557099737\n",
      "iteration:  30  cost:  0.6728770647528863\n",
      "iteration:  40  cost:  0.7075526964189481\n",
      "iteration:  50  cost:  0.8219758620097779\n",
      "iteration:  60  cost:  0.692879551849075\n",
      "iteration:  70  cost:  0.7191278379807943\n",
      "iteration:  80  cost:  0.6186539136412119\n",
      "iteration:  90  cost:  0.7511463956063517\n",
      "iteration:  100  cost:  0.8013852614718854\n",
      "iteration:  110  cost:  0.8826028527846869\n",
      "iteration:  120  cost:  0.7480665406795733\n",
      "iteration:  130  cost:  0.7241900526820778\n",
      "iteration:  140  cost:  0.6500743713664686\n",
      "Accuracy for U_15 autoencoder24 :0.8591016548463357\n",
      "\n",
      "\n",
      "Loss History for QCNN circuits, U_SO4 pca24\n",
      "iteration:  0  cost:  1.0539646411258854\n",
      "iteration:  10  cost:  1.053988954293449\n",
      "iteration:  20  cost:  0.8349591222717899\n",
      "iteration:  30  cost:  0.9466725977406374\n",
      "iteration:  40  cost:  0.9933112466767056\n",
      "iteration:  50  cost:  0.9928982733297463\n",
      "iteration:  60  cost:  0.9877141969862409\n",
      "iteration:  70  cost:  0.9835323947957901\n",
      "iteration:  80  cost:  1.0284909079209081\n",
      "iteration:  90  cost:  1.0309903003767458\n",
      "iteration:  100  cost:  1.0022604588996271\n",
      "iteration:  110  cost:  1.004318783555736\n",
      "iteration:  120  cost:  1.0466567545040455\n",
      "iteration:  130  cost:  0.9986196551199868\n",
      "iteration:  140  cost:  1.026921020472535\n",
      "Accuracy for U_SO4 pca24 :0.5366430260047281\n",
      "Epoch 1/10\n",
      "396/396 [==============================] - 1s 1ms/step - loss: 0.0869 - val_loss: 0.0258\n",
      "Epoch 2/10\n",
      "396/396 [==============================] - 0s 777us/step - loss: 0.0244 - val_loss: 0.0190\n",
      "Epoch 3/10\n",
      "396/396 [==============================] - 0s 794us/step - loss: 0.0178 - val_loss: 0.0146\n",
      "Epoch 4/10\n",
      "396/396 [==============================] - 0s 776us/step - loss: 0.0141 - val_loss: 0.0123\n",
      "Epoch 5/10\n",
      "396/396 [==============================] - 0s 812us/step - loss: 0.0121 - val_loss: 0.0107\n",
      "Epoch 6/10\n",
      "396/396 [==============================] - 0s 789us/step - loss: 0.0106 - val_loss: 0.0097\n",
      "Epoch 7/10\n",
      "396/396 [==============================] - 0s 810us/step - loss: 0.0096 - val_loss: 0.0089\n",
      "Epoch 8/10\n",
      "396/396 [==============================] - 0s 801us/step - loss: 0.0090 - val_loss: 0.0084\n",
      "Epoch 9/10\n",
      "396/396 [==============================] - 0s 788us/step - loss: 0.0084 - val_loss: 0.0079\n",
      "Epoch 10/10\n",
      "396/396 [==============================] - 0s 799us/step - loss: 0.0080 - val_loss: 0.0076\n",
      "\n",
      "\n",
      "Loss History for QCNN circuits, U_SO4 autoencoder24\n",
      "iteration:  0  cost:  0.95458108130832\n",
      "iteration:  10  cost:  0.7315187888788145\n",
      "iteration:  20  cost:  0.6951884965599606\n",
      "iteration:  30  cost:  0.47176076290626895\n",
      "iteration:  40  cost:  0.637540196205872\n",
      "iteration:  50  cost:  0.6265557378916662\n",
      "iteration:  60  cost:  0.7448505615768503\n",
      "iteration:  70  cost:  0.5061060480508761\n",
      "iteration:  80  cost:  0.7851566463646374\n",
      "iteration:  90  cost:  0.6356745763417451\n",
      "iteration:  100  cost:  0.9111104750638526\n",
      "iteration:  110  cost:  0.5995943991172442\n",
      "iteration:  120  cost:  0.5394353083931438\n",
      "iteration:  130  cost:  0.7171846920406375\n",
      "iteration:  140  cost:  0.781561562039448\n",
      "Accuracy for U_SO4 autoencoder24 :0.7858156028368795\n",
      "1th step : \n",
      "\n",
      "\n",
      "Loss History for QCNN circuits, U_TTN pca24\n",
      "iteration:  0  cost:  1.0084683367433565\n",
      "iteration:  10  cost:  0.9997989402317364\n",
      "iteration:  20  cost:  1.0023169208531824\n",
      "iteration:  30  cost:  1.008367736313212\n",
      "iteration:  40  cost:  1.019205364422217\n",
      "iteration:  50  cost:  0.9928430645750501\n",
      "iteration:  60  cost:  1.0178442614925265\n",
      "iteration:  70  cost:  0.9852661394948238\n",
      "iteration:  80  cost:  1.0035436678900633\n",
      "iteration:  90  cost:  0.9946448574705784\n",
      "iteration:  100  cost:  1.0050355320762288\n",
      "iteration:  110  cost:  0.9907246812345342\n",
      "iteration:  120  cost:  0.9758340160673004\n",
      "iteration:  130  cost:  0.9670026138516967\n",
      "iteration:  140  cost:  1.0087121203157374\n",
      "Accuracy for U_TTN pca24 :0.5366430260047281\n",
      "Epoch 1/10\n",
      "396/396 [==============================] - 1s 1ms/step - loss: 0.0878 - val_loss: 0.0265\n",
      "Epoch 2/10\n",
      "396/396 [==============================] - 0s 788us/step - loss: 0.0244 - val_loss: 0.0189\n",
      "Epoch 3/10\n",
      "396/396 [==============================] - 0s 778us/step - loss: 0.0181 - val_loss: 0.0149\n",
      "Epoch 4/10\n",
      "396/396 [==============================] - 0s 811us/step - loss: 0.0146 - val_loss: 0.0125\n",
      "Epoch 5/10\n",
      "396/396 [==============================] - 0s 786us/step - loss: 0.0123 - val_loss: 0.0110\n",
      "Epoch 6/10\n",
      "396/396 [==============================] - 0s 795us/step - loss: 0.0109 - val_loss: 0.0099\n",
      "Epoch 7/10\n",
      "396/396 [==============================] - 0s 791us/step - loss: 0.0097 - val_loss: 0.0090\n",
      "Epoch 8/10\n",
      "396/396 [==============================] - 0s 923us/step - loss: 0.0090 - val_loss: 0.0084\n",
      "Epoch 9/10\n",
      "396/396 [==============================] - 0s 785us/step - loss: 0.0083 - val_loss: 0.0079\n",
      "Epoch 10/10\n",
      "396/396 [==============================] - 0s 785us/step - loss: 0.0080 - val_loss: 0.0074\n",
      "\n",
      "\n",
      "Loss History for QCNN circuits, U_TTN autoencoder24\n",
      "iteration:  0  cost:  0.9793096775057515\n",
      "iteration:  10  cost:  0.898502473016443\n",
      "iteration:  20  cost:  0.8382634726321929\n",
      "iteration:  30  cost:  0.9450468037204349\n",
      "iteration:  40  cost:  0.9059231900290861\n",
      "iteration:  50  cost:  0.8736479201735783\n",
      "iteration:  60  cost:  0.7875161024010571\n",
      "iteration:  70  cost:  0.7967959835265926\n",
      "iteration:  80  cost:  0.8712914556818359\n",
      "iteration:  90  cost:  0.8550282826858921\n",
      "iteration:  100  cost:  0.8162446606948857\n",
      "iteration:  110  cost:  0.7944694605421212\n",
      "iteration:  120  cost:  0.9558440461024129\n",
      "iteration:  130  cost:  0.832322035842717\n",
      "iteration:  140  cost:  0.7362491293625487\n",
      "Accuracy for U_TTN autoencoder24 :0.7319148936170212\n",
      "\n",
      "\n",
      "Loss History for QCNN circuits, U_5 pca24\n",
      "iteration:  0  cost:  1.1553607267459727\n",
      "iteration:  10  cost:  1.1259448227346607\n",
      "iteration:  20  cost:  0.9904965360785647\n",
      "iteration:  30  cost:  0.9830511984512758\n",
      "iteration:  40  cost:  1.2454561848655792\n",
      "iteration:  50  cost:  0.9991513569102763\n",
      "iteration:  60  cost:  0.9546754940206538\n",
      "iteration:  70  cost:  0.9984750704856515\n",
      "iteration:  80  cost:  0.9880290669708239\n",
      "iteration:  90  cost:  0.9822710837319716\n",
      "iteration:  100  cost:  0.9309024803534399\n",
      "iteration:  110  cost:  1.0250039263871722\n",
      "iteration:  120  cost:  0.9575864177154959\n",
      "iteration:  130  cost:  1.0551251311092784\n",
      "iteration:  140  cost:  1.0020861811119692\n",
      "Accuracy for U_5 pca24 :0.5366430260047281\n",
      "Epoch 1/10\n",
      "396/396 [==============================] - 1s 1ms/step - loss: 0.0883 - val_loss: 0.0254\n",
      "Epoch 2/10\n",
      "396/396 [==============================] - 0s 774us/step - loss: 0.0240 - val_loss: 0.0188\n",
      "Epoch 3/10\n",
      "396/396 [==============================] - 0s 794us/step - loss: 0.0177 - val_loss: 0.0143\n",
      "Epoch 4/10\n",
      "396/396 [==============================] - 0s 810us/step - loss: 0.0138 - val_loss: 0.0122\n",
      "Epoch 5/10\n",
      "396/396 [==============================] - 0s 815us/step - loss: 0.0119 - val_loss: 0.0107\n",
      "Epoch 6/10\n",
      "396/396 [==============================] - 0s 787us/step - loss: 0.0105 - val_loss: 0.0097\n",
      "Epoch 7/10\n",
      "396/396 [==============================] - 0s 926us/step - loss: 0.0095 - val_loss: 0.0088\n",
      "Epoch 8/10\n",
      "396/396 [==============================] - 0s 800us/step - loss: 0.0087 - val_loss: 0.0083\n",
      "Epoch 9/10\n",
      "396/396 [==============================] - 0s 793us/step - loss: 0.0083 - val_loss: 0.0080\n",
      "Epoch 10/10\n",
      "396/396 [==============================] - 0s 780us/step - loss: 0.0077 - val_loss: 0.0075\n",
      "\n",
      "\n",
      "Loss History for QCNN circuits, U_5 autoencoder24\n",
      "iteration:  0  cost:  0.9327617725309052\n",
      "iteration:  10  cost:  0.8458732814792441\n",
      "iteration:  20  cost:  0.6922318621760973\n",
      "iteration:  30  cost:  0.5987246756185808\n",
      "iteration:  40  cost:  0.6810323042955667\n",
      "iteration:  50  cost:  0.6495123215097461\n",
      "iteration:  60  cost:  0.5790149086700329\n",
      "iteration:  70  cost:  0.7985432951733791\n",
      "iteration:  80  cost:  0.6084267210350426\n",
      "iteration:  90  cost:  0.6214117930357609\n",
      "iteration:  100  cost:  0.8996466708927144\n",
      "iteration:  110  cost:  0.6275321415964575\n",
      "iteration:  120  cost:  0.7591661932615934\n",
      "iteration:  130  cost:  0.6839762147577393\n",
      "iteration:  140  cost:  0.8406859431720928\n",
      "Accuracy for U_5 autoencoder24 :0.8775413711583925\n",
      "\n",
      "\n",
      "Loss History for QCNN circuits, U_6 pca24\n",
      "iteration:  0  cost:  1.4542962154002606\n",
      "iteration:  10  cost:  1.0135365023627612\n",
      "iteration:  20  cost:  1.0090827261135533\n",
      "iteration:  30  cost:  0.9988973003005693\n",
      "iteration:  40  cost:  0.9993258256870162\n",
      "iteration:  50  cost:  0.9998630398746136\n",
      "iteration:  60  cost:  0.9943872042104728\n",
      "iteration:  70  cost:  0.9359152993480585\n",
      "iteration:  80  cost:  1.0097005693948795\n",
      "iteration:  90  cost:  0.9942477556657701\n",
      "iteration:  100  cost:  0.9678431707357155\n",
      "iteration:  110  cost:  0.9802989288553714\n",
      "iteration:  120  cost:  0.9419568635513811\n",
      "iteration:  130  cost:  1.002093401589246\n",
      "iteration:  140  cost:  0.9987213370534955\n",
      "Accuracy for U_6 pca24 :0.5366430260047281\n",
      "Epoch 1/10\n",
      "396/396 [==============================] - 1s 981us/step - loss: 0.0853 - val_loss: 0.0257\n",
      "Epoch 2/10\n",
      "396/396 [==============================] - 0s 792us/step - loss: 0.0241 - val_loss: 0.0193\n",
      "Epoch 3/10\n",
      "396/396 [==============================] - 0s 910us/step - loss: 0.0184 - val_loss: 0.0152\n",
      "Epoch 4/10\n",
      "396/396 [==============================] - 0s 784us/step - loss: 0.0147 - val_loss: 0.0124\n",
      "Epoch 5/10\n",
      "396/396 [==============================] - 0s 785us/step - loss: 0.0120 - val_loss: 0.0107\n",
      "Epoch 6/10\n",
      "396/396 [==============================] - 0s 793us/step - loss: 0.0106 - val_loss: 0.0096\n",
      "Epoch 7/10\n",
      "396/396 [==============================] - 0s 785us/step - loss: 0.0096 - val_loss: 0.0087\n",
      "Epoch 8/10\n",
      "396/396 [==============================] - 0s 788us/step - loss: 0.0088 - val_loss: 0.0081\n",
      "Epoch 9/10\n",
      "396/396 [==============================] - 0s 788us/step - loss: 0.0081 - val_loss: 0.0077\n",
      "Epoch 10/10\n",
      "396/396 [==============================] - 0s 924us/step - loss: 0.0077 - val_loss: 0.0074\n",
      "\n",
      "\n",
      "Loss History for QCNN circuits, U_6 autoencoder24\n",
      "iteration:  0  cost:  1.0056673995026735\n",
      "iteration:  10  cost:  0.6959778367143048\n",
      "iteration:  20  cost:  0.552827464657448\n",
      "iteration:  30  cost:  0.6716703986841033\n",
      "iteration:  40  cost:  0.5500280964039973\n",
      "iteration:  50  cost:  0.4122488000586166\n",
      "iteration:  60  cost:  0.5379987029671893\n",
      "iteration:  70  cost:  0.599931326110616\n",
      "iteration:  80  cost:  0.6106861442607672\n",
      "iteration:  90  cost:  0.4706081067682596\n",
      "iteration:  100  cost:  0.4820854346514607\n",
      "iteration:  110  cost:  0.3751901232059378\n",
      "iteration:  120  cost:  0.4019738400519455\n",
      "iteration:  130  cost:  0.4975046650438304\n",
      "iteration:  140  cost:  0.4844365247000579\n",
      "Accuracy for U_6 autoencoder24 :0.8860520094562647\n",
      "\n",
      "\n",
      "Loss History for QCNN circuits, U_9 pca24\n",
      "iteration:  0  cost:  1.0337935834229075\n",
      "iteration:  10  cost:  0.999042447859295\n",
      "iteration:  20  cost:  0.9959166270534345\n",
      "iteration:  30  cost:  1.0072547921693233\n",
      "iteration:  40  cost:  0.9901967966435055\n",
      "iteration:  50  cost:  0.996078705493594\n",
      "iteration:  60  cost:  0.9958746242396096\n",
      "iteration:  70  cost:  0.9840514672031466\n",
      "iteration:  80  cost:  0.9704734884375555\n",
      "iteration:  90  cost:  0.9634839037086995\n",
      "iteration:  100  cost:  0.970637963926266\n",
      "iteration:  110  cost:  1.0392989917443591\n",
      "iteration:  120  cost:  1.0116371017092305\n",
      "iteration:  130  cost:  1.013427373673977\n",
      "iteration:  140  cost:  0.9825093069992634\n",
      "Accuracy for U_9 pca24 :0.5631205673758866\n",
      "Epoch 1/10\n",
      "396/396 [==============================] - 1s 987us/step - loss: 0.0864 - val_loss: 0.0257\n",
      "Epoch 2/10\n",
      "396/396 [==============================] - 0s 904us/step - loss: 0.0242 - val_loss: 0.0191\n",
      "Epoch 3/10\n",
      "396/396 [==============================] - 0s 771us/step - loss: 0.0183 - val_loss: 0.0144\n",
      "Epoch 4/10\n",
      "396/396 [==============================] - 0s 776us/step - loss: 0.0139 - val_loss: 0.0119\n",
      "Epoch 5/10\n",
      "396/396 [==============================] - 0s 784us/step - loss: 0.0117 - val_loss: 0.0104\n",
      "Epoch 6/10\n",
      "396/396 [==============================] - 0s 785us/step - loss: 0.0102 - val_loss: 0.0094\n",
      "Epoch 7/10\n",
      "396/396 [==============================] - 0s 785us/step - loss: 0.0093 - val_loss: 0.0086\n",
      "Epoch 8/10\n",
      "396/396 [==============================] - 0s 781us/step - loss: 0.0085 - val_loss: 0.0080\n",
      "Epoch 9/10\n",
      "396/396 [==============================] - 0s 926us/step - loss: 0.0079 - val_loss: 0.0075\n",
      "Epoch 10/10\n",
      "396/396 [==============================] - 0s 784us/step - loss: 0.0076 - val_loss: 0.0072\n",
      "\n",
      "\n",
      "Loss History for QCNN circuits, U_9 autoencoder24\n",
      "iteration:  0  cost:  0.9901949123085758\n",
      "iteration:  10  cost:  0.9890747530416911\n",
      "iteration:  20  cost:  0.9694729524964413\n",
      "iteration:  30  cost:  0.9706857374024048\n",
      "iteration:  40  cost:  1.0018556783039982\n",
      "iteration:  50  cost:  0.9938334471151583\n",
      "iteration:  60  cost:  0.9868563042697699\n",
      "iteration:  70  cost:  0.9409571248872782\n",
      "iteration:  80  cost:  0.9016044376314789\n",
      "iteration:  90  cost:  0.936166265259661\n",
      "iteration:  100  cost:  0.8986521239041798\n",
      "iteration:  110  cost:  0.7953854124516839\n",
      "iteration:  120  cost:  0.7245468261260558\n",
      "iteration:  130  cost:  0.7952045641057874\n",
      "iteration:  140  cost:  0.8215383062916949\n",
      "Accuracy for U_9 autoencoder24 :0.8756501182033097\n",
      "\n",
      "\n",
      "Loss History for QCNN circuits, U_13 pca24\n",
      "iteration:  0  cost:  1.2531037034879227\n",
      "iteration:  10  cost:  0.9761885940751206\n",
      "iteration:  20  cost:  1.1360161836634657\n",
      "iteration:  30  cost:  0.979506885509643\n",
      "iteration:  40  cost:  0.9569655193069475\n",
      "iteration:  50  cost:  1.0072794991958802\n",
      "iteration:  60  cost:  0.9873078107400766\n",
      "iteration:  70  cost:  1.0096329047043588\n",
      "iteration:  80  cost:  1.0283506143895462\n",
      "iteration:  90  cost:  0.9544275084985848\n",
      "iteration:  100  cost:  1.0076422815722923\n",
      "iteration:  110  cost:  1.015888958525975\n",
      "iteration:  120  cost:  0.9678073969403991\n",
      "iteration:  130  cost:  1.0246873663319782\n",
      "iteration:  140  cost:  0.9984400635194262\n",
      "Accuracy for U_13 pca24 :0.5385342789598109\n",
      "Epoch 1/10\n",
      "396/396 [==============================] - 1s 979us/step - loss: 0.0867 - val_loss: 0.0250\n",
      "Epoch 2/10\n",
      "396/396 [==============================] - 0s 775us/step - loss: 0.0234 - val_loss: 0.0185\n",
      "Epoch 3/10\n",
      "396/396 [==============================] - 0s 787us/step - loss: 0.0176 - val_loss: 0.0146\n",
      "Epoch 4/10\n",
      "396/396 [==============================] - 0s 785us/step - loss: 0.0143 - val_loss: 0.0123\n",
      "Epoch 5/10\n",
      "396/396 [==============================] - 0s 926us/step - loss: 0.0120 - val_loss: 0.0108\n",
      "Epoch 6/10\n",
      "396/396 [==============================] - 0s 795us/step - loss: 0.0106 - val_loss: 0.0096\n",
      "Epoch 7/10\n",
      "396/396 [==============================] - 0s 788us/step - loss: 0.0095 - val_loss: 0.0088\n",
      "Epoch 8/10\n",
      "396/396 [==============================] - 0s 792us/step - loss: 0.0087 - val_loss: 0.0082\n",
      "Epoch 9/10\n",
      "396/396 [==============================] - 0s 794us/step - loss: 0.0083 - val_loss: 0.0077\n",
      "Epoch 10/10\n",
      "396/396 [==============================] - 0s 802us/step - loss: 0.0076 - val_loss: 0.0074\n",
      "\n",
      "\n",
      "Loss History for QCNN circuits, U_13 autoencoder24\n",
      "iteration:  0  cost:  2.075820144088611\n",
      "iteration:  10  cost:  0.5292397536873937\n",
      "iteration:  20  cost:  0.4627077259440177\n",
      "iteration:  30  cost:  0.5886192022835568\n",
      "iteration:  40  cost:  0.42857760942237677\n",
      "iteration:  50  cost:  0.40698969735098184\n",
      "iteration:  60  cost:  0.4765206043647426\n",
      "iteration:  70  cost:  0.5837353373309755\n",
      "iteration:  80  cost:  0.4740702315228298\n",
      "iteration:  90  cost:  0.6313499055242341\n",
      "iteration:  100  cost:  0.5437554850518846\n",
      "iteration:  110  cost:  0.4858235494677278\n",
      "iteration:  120  cost:  0.6850427773766541\n",
      "iteration:  130  cost:  0.3784262766489568\n",
      "iteration:  140  cost:  0.5731331640302435\n",
      "Accuracy for U_13 autoencoder24 :0.9134751773049645\n",
      "\n",
      "\n",
      "Loss History for QCNN circuits, U_14 pca24\n",
      "iteration:  0  cost:  0.9365761862786947\n",
      "iteration:  10  cost:  1.035934634324866\n",
      "iteration:  20  cost:  0.8390570084518726\n",
      "iteration:  30  cost:  1.029725034990051\n",
      "iteration:  40  cost:  1.0022925830174838\n",
      "iteration:  50  cost:  0.9760824353391915\n",
      "iteration:  60  cost:  0.99287161340166\n",
      "iteration:  70  cost:  1.092193872334812\n",
      "iteration:  80  cost:  0.8617891031286135\n",
      "iteration:  90  cost:  1.1196768126555892\n",
      "iteration:  100  cost:  1.0051661616861935\n",
      "iteration:  110  cost:  0.9734090636489302\n",
      "iteration:  120  cost:  0.9970875004410334\n",
      "iteration:  130  cost:  1.0234846901836385\n",
      "iteration:  140  cost:  0.9818862842174731\n",
      "Accuracy for U_14 pca24 :0.5394799054373522\n",
      "Epoch 1/10\n",
      "396/396 [==============================] - 1s 1ms/step - loss: 0.0885 - val_loss: 0.0262\n",
      "Epoch 2/10\n",
      "396/396 [==============================] - 0s 783us/step - loss: 0.0244 - val_loss: 0.0192\n",
      "Epoch 3/10\n",
      "396/396 [==============================] - 0s 780us/step - loss: 0.0183 - val_loss: 0.0147\n",
      "Epoch 4/10\n",
      "396/396 [==============================] - 0s 795us/step - loss: 0.0142 - val_loss: 0.0123\n",
      "Epoch 5/10\n",
      "396/396 [==============================] - 0s 789us/step - loss: 0.0123 - val_loss: 0.0108\n",
      "Epoch 6/10\n",
      "396/396 [==============================] - 0s 790us/step - loss: 0.0107 - val_loss: 0.0098\n",
      "Epoch 7/10\n",
      "396/396 [==============================] - 0s 949us/step - loss: 0.0097 - val_loss: 0.0091\n",
      "Epoch 8/10\n",
      "396/396 [==============================] - 0s 809us/step - loss: 0.0089 - val_loss: 0.0084\n",
      "Epoch 9/10\n",
      "396/396 [==============================] - 0s 796us/step - loss: 0.0083 - val_loss: 0.0080\n",
      "Epoch 10/10\n",
      "396/396 [==============================] - 0s 800us/step - loss: 0.0080 - val_loss: 0.0076\n",
      "\n",
      "\n",
      "Loss History for QCNN circuits, U_14 autoencoder24\n",
      "iteration:  0  cost:  0.9226133582835235\n",
      "iteration:  10  cost:  0.8842389749675879\n",
      "iteration:  20  cost:  0.7972601349954489\n",
      "iteration:  30  cost:  0.7341502096667747\n",
      "iteration:  40  cost:  0.6671352825810933\n",
      "iteration:  50  cost:  0.744131453857517\n",
      "iteration:  60  cost:  0.6973961335323152\n",
      "iteration:  70  cost:  0.7227039345841287\n",
      "iteration:  80  cost:  0.7523700043318458\n",
      "iteration:  90  cost:  0.5962469753380488\n",
      "iteration:  100  cost:  0.626178778488192\n",
      "iteration:  110  cost:  0.6810507815670996\n",
      "iteration:  120  cost:  0.6108948094565787\n",
      "iteration:  130  cost:  0.6202082238475007\n",
      "iteration:  140  cost:  0.6132480471309686\n",
      "Accuracy for U_14 autoencoder24 :0.8879432624113475\n",
      "\n",
      "\n",
      "Loss History for QCNN circuits, U_15 pca24\n",
      "iteration:  0  cost:  1.0475730681081115\n",
      "iteration:  10  cost:  0.9789908479078313\n",
      "iteration:  20  cost:  1.0926529472837891\n",
      "iteration:  30  cost:  0.969847441247063\n",
      "iteration:  40  cost:  1.0172319130456622\n",
      "iteration:  50  cost:  0.9479179655581738\n",
      "iteration:  60  cost:  1.0024027423879176\n",
      "iteration:  70  cost:  1.0021948623908918\n",
      "iteration:  80  cost:  1.0058386097830483\n",
      "iteration:  90  cost:  1.000006585985668\n",
      "iteration:  100  cost:  0.9643577740496386\n",
      "iteration:  110  cost:  1.0218879577372826\n",
      "iteration:  120  cost:  0.9917628120390082\n",
      "iteration:  130  cost:  1.0051467285053717\n",
      "iteration:  140  cost:  0.9722343820345991\n",
      "Accuracy for U_15 pca24 :0.5366430260047281\n",
      "Epoch 1/10\n",
      "396/396 [==============================] - 1s 1ms/step - loss: 0.0857 - val_loss: 0.0270\n",
      "Epoch 2/10\n",
      "396/396 [==============================] - 0s 784us/step - loss: 0.0253 - val_loss: 0.0198\n",
      "Epoch 3/10\n",
      "396/396 [==============================] - 0s 813us/step - loss: 0.0187 - val_loss: 0.0151\n",
      "Epoch 4/10\n",
      "396/396 [==============================] - 0s 774us/step - loss: 0.0144 - val_loss: 0.0124\n",
      "Epoch 5/10\n",
      "396/396 [==============================] - 0s 800us/step - loss: 0.0121 - val_loss: 0.0111\n",
      "Epoch 6/10\n",
      "396/396 [==============================] - 0s 809us/step - loss: 0.0106 - val_loss: 0.0098\n",
      "Epoch 7/10\n",
      "396/396 [==============================] - 0s 823us/step - loss: 0.0097 - val_loss: 0.0090\n",
      "Epoch 8/10\n",
      "396/396 [==============================] - 0s 795us/step - loss: 0.0089 - val_loss: 0.0084\n",
      "Epoch 9/10\n",
      "396/396 [==============================] - 0s 942us/step - loss: 0.0084 - val_loss: 0.0079\n",
      "Epoch 10/10\n",
      "396/396 [==============================] - 0s 791us/step - loss: 0.0080 - val_loss: 0.0075\n",
      "\n",
      "\n",
      "Loss History for QCNN circuits, U_15 autoencoder24\n",
      "iteration:  0  cost:  1.054666961358556\n",
      "iteration:  10  cost:  0.9821040663675518\n",
      "iteration:  20  cost:  0.9094833291558583\n",
      "iteration:  30  cost:  0.8918620272503209\n",
      "iteration:  40  cost:  0.8793683028376654\n",
      "iteration:  50  cost:  0.913806762470022\n",
      "iteration:  60  cost:  0.9496311341953646\n",
      "iteration:  70  cost:  0.9776152588112959\n",
      "iteration:  80  cost:  0.8927209048077664\n",
      "iteration:  90  cost:  0.8200657935227744\n",
      "iteration:  100  cost:  0.8980923333933021\n",
      "iteration:  110  cost:  0.892652736876064\n",
      "iteration:  120  cost:  0.9260757449798936\n",
      "iteration:  130  cost:  0.8499848986022619\n",
      "iteration:  140  cost:  0.8560881751607642\n",
      "Accuracy for U_15 autoencoder24 :0.699290780141844\n",
      "\n",
      "\n",
      "Loss History for QCNN circuits, U_SO4 pca24\n",
      "iteration:  0  cost:  1.0908805263070278\n",
      "iteration:  10  cost:  1.0222467180320587\n",
      "iteration:  20  cost:  1.007049848813112\n",
      "iteration:  30  cost:  1.0234778900194805\n",
      "iteration:  40  cost:  0.9654698369525591\n",
      "iteration:  50  cost:  0.9974388830869988\n",
      "iteration:  60  cost:  0.996743646418263\n",
      "iteration:  70  cost:  0.9938209964003462\n",
      "iteration:  80  cost:  0.9962849190991085\n",
      "iteration:  90  cost:  1.0257732950316338\n",
      "iteration:  100  cost:  0.9825281433143839\n",
      "iteration:  110  cost:  1.0082659246941268\n",
      "iteration:  120  cost:  0.9338374344142248\n",
      "iteration:  130  cost:  0.9640699595708271\n",
      "iteration:  140  cost:  0.9612997183067934\n",
      "Accuracy for U_SO4 pca24 :0.5910165484633569\n",
      "Epoch 1/10\n",
      "396/396 [==============================] - 1s 1ms/step - loss: 0.0860 - val_loss: 0.0261\n",
      "Epoch 2/10\n",
      "396/396 [==============================] - 0s 790us/step - loss: 0.0245 - val_loss: 0.0194\n",
      "Epoch 3/10\n",
      "396/396 [==============================] - 0s 770us/step - loss: 0.0183 - val_loss: 0.0150\n",
      "Epoch 4/10\n",
      "396/396 [==============================] - 0s 778us/step - loss: 0.0145 - val_loss: 0.0124\n",
      "Epoch 5/10\n",
      "396/396 [==============================] - 0s 783us/step - loss: 0.0121 - val_loss: 0.0108\n",
      "Epoch 6/10\n",
      "396/396 [==============================] - 0s 786us/step - loss: 0.0107 - val_loss: 0.0096\n",
      "Epoch 7/10\n",
      "396/396 [==============================] - 0s 788us/step - loss: 0.0097 - val_loss: 0.0089\n",
      "Epoch 8/10\n",
      "396/396 [==============================] - 0s 785us/step - loss: 0.0088 - val_loss: 0.0082\n",
      "Epoch 9/10\n",
      "396/396 [==============================] - 0s 793us/step - loss: 0.0082 - val_loss: 0.0078\n",
      "Epoch 10/10\n",
      "396/396 [==============================] - 0s 786us/step - loss: 0.0077 - val_loss: 0.0074\n",
      "\n",
      "\n",
      "Loss History for QCNN circuits, U_SO4 autoencoder24\n",
      "iteration:  0  cost:  1.0827752560548851\n",
      "iteration:  10  cost:  0.9629830639522606\n",
      "iteration:  20  cost:  0.9634898998599519\n",
      "iteration:  30  cost:  0.717391741913594\n",
      "iteration:  40  cost:  0.917714160899838\n",
      "iteration:  50  cost:  0.7096226207964864\n",
      "iteration:  60  cost:  0.7709380270718128\n",
      "iteration:  70  cost:  0.6984671529781024\n",
      "iteration:  80  cost:  0.737760049704899\n",
      "iteration:  90  cost:  0.6988759150667161\n",
      "iteration:  100  cost:  0.7424497003489604\n",
      "iteration:  110  cost:  0.767658054944623\n",
      "iteration:  120  cost:  0.6698391106061763\n",
      "iteration:  130  cost:  0.6849155611154493\n",
      "iteration:  140  cost:  0.7116639584905111\n",
      "Accuracy for U_SO4 autoencoder24 :0.8671394799054374\n",
      "2th step : \n",
      "\n",
      "\n",
      "Loss History for QCNN circuits, U_TTN pca24\n",
      "iteration:  0  cost:  0.9981670074780452\n",
      "iteration:  10  cost:  1.004247674152688\n",
      "iteration:  20  cost:  1.0018628218157901\n",
      "iteration:  30  cost:  1.0015155429597686\n",
      "iteration:  40  cost:  0.9988586874045164\n",
      "iteration:  50  cost:  1.0014413871260337\n",
      "iteration:  60  cost:  1.0010826513382634\n",
      "iteration:  70  cost:  0.9939801276903624\n",
      "iteration:  80  cost:  1.0023272969541885\n",
      "iteration:  90  cost:  1.0000531627172058\n",
      "iteration:  100  cost:  1.0154874510282845\n",
      "iteration:  110  cost:  0.9928257655368365\n",
      "iteration:  120  cost:  0.9665761928250085\n",
      "iteration:  130  cost:  0.9730148032305741\n",
      "iteration:  140  cost:  0.9762342396206937\n",
      "Accuracy for U_TTN pca24 :0.5366430260047281\n",
      "Epoch 1/10\n",
      "396/396 [==============================] - 1s 1ms/step - loss: 0.0884 - val_loss: 0.0261\n",
      "Epoch 2/10\n",
      "396/396 [==============================] - 0s 792us/step - loss: 0.0241 - val_loss: 0.0185\n",
      "Epoch 3/10\n",
      "396/396 [==============================] - 0s 786us/step - loss: 0.0177 - val_loss: 0.0144\n",
      "Epoch 4/10\n",
      "396/396 [==============================] - 0s 787us/step - loss: 0.0140 - val_loss: 0.0122\n",
      "Epoch 5/10\n",
      "396/396 [==============================] - 0s 802us/step - loss: 0.0121 - val_loss: 0.0109\n",
      "Epoch 6/10\n",
      "396/396 [==============================] - 0s 786us/step - loss: 0.0107 - val_loss: 0.0098\n",
      "Epoch 7/10\n",
      "396/396 [==============================] - 0s 792us/step - loss: 0.0099 - val_loss: 0.0089\n",
      "Epoch 8/10\n",
      "396/396 [==============================] - 0s 928us/step - loss: 0.0091 - val_loss: 0.0083\n",
      "Epoch 9/10\n",
      "396/396 [==============================] - 0s 794us/step - loss: 0.0083 - val_loss: 0.0078\n",
      "Epoch 10/10\n",
      "396/396 [==============================] - 0s 788us/step - loss: 0.0078 - val_loss: 0.0075\n",
      "\n",
      "\n",
      "Loss History for QCNN circuits, U_TTN autoencoder24\n",
      "iteration:  0  cost:  1.0812563046851658\n",
      "iteration:  10  cost:  0.9270220224040119\n",
      "iteration:  20  cost:  0.920375939999257\n",
      "iteration:  30  cost:  0.7256844052182272\n",
      "iteration:  40  cost:  0.950107468307069\n",
      "iteration:  50  cost:  0.8312469022595187\n",
      "iteration:  60  cost:  0.8579879838792438\n",
      "iteration:  70  cost:  0.6238778485881609\n",
      "iteration:  80  cost:  0.9394121469475885\n",
      "iteration:  90  cost:  1.1894676376457807\n",
      "iteration:  100  cost:  0.9094683060590448\n",
      "iteration:  110  cost:  0.8503047932960277\n",
      "iteration:  120  cost:  0.8293218361878857\n",
      "iteration:  130  cost:  0.63762094352913\n",
      "iteration:  140  cost:  0.7633880537947292\n",
      "Accuracy for U_TTN autoencoder24 :0.631678486997636\n",
      "\n",
      "\n",
      "Loss History for QCNN circuits, U_5 pca24\n",
      "iteration:  0  cost:  1.334604391453461\n",
      "iteration:  10  cost:  0.92722223076388\n",
      "iteration:  20  cost:  0.9950162908482176\n",
      "iteration:  30  cost:  0.926271687092751\n",
      "iteration:  40  cost:  0.9938230110705878\n",
      "iteration:  50  cost:  0.9178159381777039\n",
      "iteration:  60  cost:  1.1690656570996383\n",
      "iteration:  70  cost:  1.0672558149980917\n",
      "iteration:  80  cost:  0.9911661473554929\n",
      "iteration:  90  cost:  1.0451959305142338\n",
      "iteration:  100  cost:  1.0326371293393297\n",
      "iteration:  110  cost:  0.9721483595506661\n",
      "iteration:  120  cost:  0.9919890023529612\n",
      "iteration:  130  cost:  0.9847113805804639\n",
      "iteration:  140  cost:  1.0130504934032907\n",
      "Accuracy for U_5 pca24 :0.5366430260047281\n",
      "Epoch 1/10\n",
      "396/396 [==============================] - 1s 1ms/step - loss: 0.0871 - val_loss: 0.0265\n",
      "Epoch 2/10\n",
      "396/396 [==============================] - 0s 777us/step - loss: 0.0247 - val_loss: 0.0190\n",
      "Epoch 3/10\n",
      "396/396 [==============================] - 0s 775us/step - loss: 0.0178 - val_loss: 0.0146\n",
      "Epoch 4/10\n",
      "396/396 [==============================] - 0s 792us/step - loss: 0.0140 - val_loss: 0.0122\n",
      "Epoch 5/10\n",
      "396/396 [==============================] - 0s 779us/step - loss: 0.0118 - val_loss: 0.0107\n",
      "Epoch 6/10\n",
      "396/396 [==============================] - 0s 778us/step - loss: 0.0105 - val_loss: 0.0095\n",
      "Epoch 7/10\n",
      "396/396 [==============================] - 0s 788us/step - loss: 0.0096 - val_loss: 0.0088\n",
      "Epoch 8/10\n",
      "396/396 [==============================] - 0s 917us/step - loss: 0.0089 - val_loss: 0.0082\n",
      "Epoch 9/10\n",
      "396/396 [==============================] - 0s 781us/step - loss: 0.0082 - val_loss: 0.0078\n",
      "Epoch 10/10\n",
      "396/396 [==============================] - 0s 784us/step - loss: 0.0078 - val_loss: 0.0074\n",
      "\n",
      "\n",
      "Loss History for QCNN circuits, U_5 autoencoder24\n",
      "iteration:  0  cost:  1.070649626590501\n",
      "iteration:  10  cost:  0.7156480344261634\n",
      "iteration:  20  cost:  0.61935013327933\n",
      "iteration:  30  cost:  0.8231022877283172\n",
      "iteration:  40  cost:  0.6855908129329481\n",
      "iteration:  50  cost:  0.6965345866998508\n",
      "iteration:  60  cost:  0.6818406855365192\n",
      "iteration:  70  cost:  0.5618438777776537\n",
      "iteration:  80  cost:  0.6204415202019631\n",
      "iteration:  90  cost:  0.6759482425840612\n",
      "iteration:  100  cost:  0.7021578498983899\n",
      "iteration:  110  cost:  0.5832010369105474\n",
      "iteration:  120  cost:  0.5804673728354678\n",
      "iteration:  130  cost:  0.9247805508589169\n",
      "iteration:  140  cost:  0.493574295462852\n",
      "Accuracy for U_5 autoencoder24 :0.9106382978723404\n",
      "\n",
      "\n",
      "Loss History for QCNN circuits, U_6 pca24\n",
      "iteration:  0  cost:  1.4844810094414567\n",
      "iteration:  10  cost:  1.013900844909882\n",
      "iteration:  20  cost:  1.0001293860810756\n",
      "iteration:  30  cost:  0.9065225664540852\n",
      "iteration:  40  cost:  1.027304781610831\n",
      "iteration:  50  cost:  0.9952093682684542\n",
      "iteration:  60  cost:  0.9074923904208299\n",
      "iteration:  70  cost:  0.9345659600416084\n",
      "iteration:  80  cost:  0.998838261744481\n",
      "iteration:  90  cost:  0.9912954777895416\n",
      "iteration:  100  cost:  0.9800546837544921\n",
      "iteration:  110  cost:  1.0120707475503516\n",
      "iteration:  120  cost:  0.9963482101962607\n",
      "iteration:  130  cost:  0.9690237734216542\n",
      "iteration:  140  cost:  0.990219352355857\n",
      "Accuracy for U_6 pca24 :0.5366430260047281\n",
      "Epoch 1/10\n",
      "396/396 [==============================] - 1s 964us/step - loss: 0.0881 - val_loss: 0.0252\n",
      "Epoch 2/10\n",
      "396/396 [==============================] - 0s 773us/step - loss: 0.0240 - val_loss: 0.0189\n",
      "Epoch 3/10\n",
      "396/396 [==============================] - 0s 910us/step - loss: 0.0181 - val_loss: 0.0145\n",
      "Epoch 4/10\n",
      "396/396 [==============================] - 0s 796us/step - loss: 0.0142 - val_loss: 0.0121\n",
      "Epoch 5/10\n",
      "396/396 [==============================] - 0s 778us/step - loss: 0.0118 - val_loss: 0.0105\n",
      "Epoch 6/10\n",
      "396/396 [==============================] - 0s 779us/step - loss: 0.0103 - val_loss: 0.0094\n",
      "Epoch 7/10\n",
      "396/396 [==============================] - 0s 801us/step - loss: 0.0094 - val_loss: 0.0086\n",
      "Epoch 8/10\n",
      "396/396 [==============================] - 0s 781us/step - loss: 0.0085 - val_loss: 0.0080\n",
      "Epoch 9/10\n",
      "396/396 [==============================] - 0s 790us/step - loss: 0.0079 - val_loss: 0.0076\n",
      "Epoch 10/10\n",
      "396/396 [==============================] - 0s 926us/step - loss: 0.0075 - val_loss: 0.0073\n",
      "\n",
      "\n",
      "Loss History for QCNN circuits, U_6 autoencoder24\n",
      "iteration:  0  cost:  0.9047373282797976\n",
      "iteration:  10  cost:  0.6522800433670172\n",
      "iteration:  20  cost:  0.6451452507600846\n",
      "iteration:  30  cost:  0.568930444826782\n",
      "iteration:  40  cost:  0.777972402715242\n",
      "iteration:  50  cost:  0.5882642327252694\n",
      "iteration:  60  cost:  0.6057618917822072\n",
      "iteration:  70  cost:  0.5051248618944674\n",
      "iteration:  80  cost:  0.6095573111771633\n",
      "iteration:  90  cost:  0.5988132914635793\n",
      "iteration:  100  cost:  0.705893957995746\n",
      "iteration:  110  cost:  0.7080847832651783\n",
      "iteration:  120  cost:  0.6027638880382487\n",
      "iteration:  130  cost:  0.5436366820590126\n",
      "iteration:  140  cost:  0.4611762855645256\n",
      "Accuracy for U_6 autoencoder24 :0.840661938534279\n",
      "\n",
      "\n",
      "Loss History for QCNN circuits, U_9 pca24\n",
      "iteration:  0  cost:  1.003395950812543\n",
      "iteration:  10  cost:  0.9989879336905227\n",
      "iteration:  20  cost:  1.0018385864021018\n",
      "iteration:  30  cost:  1.0023048129452305\n",
      "iteration:  40  cost:  1.0018203670071981\n",
      "iteration:  50  cost:  0.9891776791255303\n",
      "iteration:  60  cost:  1.0326503310072628\n",
      "iteration:  70  cost:  0.9962560706077348\n",
      "iteration:  80  cost:  0.9922519910531024\n",
      "iteration:  90  cost:  0.9967473611723139\n",
      "iteration:  100  cost:  0.9778998324346446\n",
      "iteration:  110  cost:  0.9643625413649164\n",
      "iteration:  120  cost:  0.9848329538366852\n",
      "iteration:  130  cost:  1.0025133514705429\n",
      "iteration:  140  cost:  0.9981412397644814\n",
      "Accuracy for U_9 pca24 :0.4335697399527187\n",
      "Epoch 1/10\n",
      "396/396 [==============================] - 1s 986us/step - loss: 0.0895 - val_loss: 0.0259\n",
      "Epoch 2/10\n",
      "396/396 [==============================] - 0s 908us/step - loss: 0.0236 - val_loss: 0.0182\n",
      "Epoch 3/10\n",
      "396/396 [==============================] - 0s 805us/step - loss: 0.0174 - val_loss: 0.0144\n",
      "Epoch 4/10\n",
      "396/396 [==============================] - 0s 803us/step - loss: 0.0142 - val_loss: 0.0121\n",
      "Epoch 5/10\n",
      "396/396 [==============================] - 0s 790us/step - loss: 0.0119 - val_loss: 0.0105\n",
      "Epoch 6/10\n",
      "396/396 [==============================] - 0s 794us/step - loss: 0.0103 - val_loss: 0.0094\n",
      "Epoch 7/10\n",
      "396/396 [==============================] - 0s 795us/step - loss: 0.0093 - val_loss: 0.0087\n",
      "Epoch 8/10\n",
      "396/396 [==============================] - 0s 808us/step - loss: 0.0086 - val_loss: 0.0081\n",
      "Epoch 9/10\n",
      "396/396 [==============================] - 0s 927us/step - loss: 0.0080 - val_loss: 0.0077\n",
      "Epoch 10/10\n",
      "396/396 [==============================] - 0s 789us/step - loss: 0.0077 - val_loss: 0.0073\n",
      "\n",
      "\n",
      "Loss History for QCNN circuits, U_9 autoencoder24\n",
      "iteration:  0  cost:  0.9947370176823358\n",
      "iteration:  10  cost:  1.0307186418826049\n",
      "iteration:  20  cost:  1.016195726526336\n",
      "iteration:  30  cost:  0.9759045826182902\n",
      "iteration:  40  cost:  0.9188025003923912\n",
      "iteration:  50  cost:  0.8986004812663526\n",
      "iteration:  60  cost:  0.8635447046521014\n",
      "iteration:  70  cost:  0.892620944091549\n",
      "iteration:  80  cost:  0.8364761685895415\n",
      "iteration:  90  cost:  0.8331478691282621\n",
      "iteration:  100  cost:  0.916348430676204\n",
      "iteration:  110  cost:  0.83576044905974\n",
      "iteration:  120  cost:  0.9041656657749639\n",
      "iteration:  130  cost:  0.8606203592415328\n",
      "iteration:  140  cost:  0.8838821753299031\n",
      "Accuracy for U_9 autoencoder24 :0.8401891252955083\n",
      "\n",
      "\n",
      "Loss History for QCNN circuits, U_13 pca24\n",
      "iteration:  0  cost:  1.0823769456805057\n",
      "iteration:  10  cost:  1.0063912488791498\n",
      "iteration:  20  cost:  1.0301767353528362\n",
      "iteration:  30  cost:  1.0018677106677274\n",
      "iteration:  40  cost:  1.0002421360389746\n",
      "iteration:  50  cost:  1.0547134704619738\n",
      "iteration:  60  cost:  1.0627893485413071\n",
      "iteration:  70  cost:  0.9687432829768678\n",
      "iteration:  80  cost:  0.9655561204564712\n",
      "iteration:  90  cost:  1.0231718703582677\n",
      "iteration:  100  cost:  1.0603683988726043\n",
      "iteration:  110  cost:  0.9840475463719024\n",
      "iteration:  120  cost:  0.9967748191670788\n",
      "iteration:  130  cost:  1.003140345450754\n",
      "iteration:  140  cost:  1.0061365985045363\n",
      "Accuracy for U_13 pca24 :0.5366430260047281\n",
      "Epoch 1/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.0871 - val_loss: 0.0263\n",
      "Epoch 2/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.0245 - val_loss: 0.0187\n",
      "Epoch 3/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.0176 - val_loss: 0.0142\n",
      "Epoch 4/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.0139 - val_loss: 0.0120\n",
      "Epoch 5/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.0118 - val_loss: 0.0106\n",
      "Epoch 6/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.0105 - val_loss: 0.0095\n",
      "Epoch 7/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.0093 - val_loss: 0.0087\n",
      "Epoch 8/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.0087 - val_loss: 0.0082\n",
      "Epoch 9/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.0081 - val_loss: 0.0078\n",
      "Epoch 10/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.0078 - val_loss: 0.0075\n",
      "\n",
      "\n",
      "Loss History for QCNN circuits, U_13 autoencoder24\n",
      "iteration:  0  cost:  1.139935512089643\n",
      "iteration:  10  cost:  0.9221337539776235\n",
      "iteration:  20  cost:  0.7665810634318078\n",
      "iteration:  30  cost:  0.7681368964308704\n",
      "iteration:  40  cost:  0.8691395178553134\n",
      "iteration:  50  cost:  0.7838605130600537\n",
      "iteration:  60  cost:  0.9115681408871298\n",
      "iteration:  70  cost:  0.7766374842363757\n",
      "iteration:  80  cost:  0.8364317080957333\n",
      "iteration:  90  cost:  0.8260537748144483\n",
      "iteration:  100  cost:  0.7673067031372577\n",
      "iteration:  110  cost:  0.8257567163174909\n",
      "iteration:  120  cost:  0.7863716804829781\n",
      "iteration:  130  cost:  0.7781932989116649\n",
      "iteration:  140  cost:  0.7530045162723417\n",
      "Accuracy for U_13 autoencoder24 :0.8713947990543736\n",
      "\n",
      "\n",
      "Loss History for QCNN circuits, U_14 pca24\n",
      "iteration:  0  cost:  1.0558810528403175\n",
      "iteration:  10  cost:  1.081481853682809\n",
      "iteration:  20  cost:  1.0146333651300747\n",
      "iteration:  30  cost:  1.033639406849882\n",
      "iteration:  40  cost:  0.9904761602537677\n",
      "iteration:  50  cost:  1.0037071424596566\n",
      "iteration:  60  cost:  1.011500874514286\n",
      "iteration:  70  cost:  0.981484190609597\n",
      "iteration:  80  cost:  1.0111818193959043\n",
      "iteration:  90  cost:  0.9849173800047591\n",
      "iteration:  100  cost:  0.993898948681134\n",
      "iteration:  110  cost:  1.001578903572174\n",
      "iteration:  120  cost:  0.9840378946017989\n",
      "iteration:  130  cost:  1.0099260811137725\n",
      "iteration:  140  cost:  1.012315128251022\n",
      "Accuracy for U_14 pca24 :0.5645390070921986\n",
      "Epoch 1/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.0875 - val_loss: 0.0268\n",
      "Epoch 2/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.0247 - val_loss: 0.0191\n",
      "Epoch 3/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.0180 - val_loss: 0.0146\n",
      "Epoch 4/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.0141 - val_loss: 0.0120\n",
      "Epoch 5/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.0117 - val_loss: 0.0105\n",
      "Epoch 6/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.0105 - val_loss: 0.0095\n",
      "Epoch 7/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.0094 - val_loss: 0.0087\n",
      "Epoch 8/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.0087 - val_loss: 0.0081\n",
      "Epoch 9/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.0083 - val_loss: 0.0077\n",
      "Epoch 10/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.0078 - val_loss: 0.0074\n",
      "\n",
      "\n",
      "Loss History for QCNN circuits, U_14 autoencoder24\n",
      "iteration:  0  cost:  1.1582800984717239\n",
      "iteration:  10  cost:  0.7838873630660135\n",
      "iteration:  20  cost:  0.901187644715896\n",
      "iteration:  30  cost:  0.9675156798050427\n",
      "iteration:  40  cost:  0.741272808621032\n",
      "iteration:  50  cost:  0.7646578297173164\n",
      "iteration:  60  cost:  0.7430996318320274\n",
      "iteration:  70  cost:  0.7575085295801359\n",
      "iteration:  80  cost:  0.655098933427631\n",
      "iteration:  90  cost:  0.7722626774746072\n",
      "iteration:  100  cost:  0.7121955189773922\n",
      "iteration:  110  cost:  0.6798877187275773\n",
      "iteration:  120  cost:  0.6981522027584743\n",
      "iteration:  130  cost:  0.730227374998889\n",
      "iteration:  140  cost:  0.7493401922425099\n",
      "Accuracy for U_14 autoencoder24 :0.7390070921985815\n",
      "\n",
      "\n",
      "Loss History for QCNN circuits, U_15 pca24\n",
      "iteration:  0  cost:  0.9732477056912476\n",
      "iteration:  10  cost:  0.9971700387744977\n",
      "iteration:  20  cost:  0.9957904825259482\n",
      "iteration:  30  cost:  0.9877207725942247\n",
      "iteration:  40  cost:  1.0177845101659813\n",
      "iteration:  50  cost:  1.0205720250772183\n",
      "iteration:  60  cost:  0.9567086677382991\n",
      "iteration:  70  cost:  1.0273108352675115\n",
      "iteration:  80  cost:  0.9775540460048913\n",
      "iteration:  90  cost:  0.9851969737962544\n",
      "iteration:  100  cost:  1.0104663306884651\n",
      "iteration:  110  cost:  0.956508629684993\n",
      "iteration:  120  cost:  1.0688824745714358\n",
      "iteration:  130  cost:  0.9671554739311717\n",
      "iteration:  140  cost:  0.9145232246879705\n",
      "Accuracy for U_15 pca24 :0.5366430260047281\n",
      "Epoch 1/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.0848 - val_loss: 0.0266\n",
      "Epoch 2/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.0249 - val_loss: 0.0194\n",
      "Epoch 3/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.0184 - val_loss: 0.0149\n",
      "Epoch 4/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.0143 - val_loss: 0.0123\n",
      "Epoch 5/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.0121 - val_loss: 0.0109\n",
      "Epoch 6/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.0107 - val_loss: 0.0099\n",
      "Epoch 7/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.0098 - val_loss: 0.0091\n",
      "Epoch 8/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.0089 - val_loss: 0.0084\n",
      "Epoch 9/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.0085 - val_loss: 0.0080\n",
      "Epoch 10/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.0078 - val_loss: 0.0075\n",
      "\n",
      "\n",
      "Loss History for QCNN circuits, U_15 autoencoder24\n",
      "iteration:  0  cost:  1.0137981514739676\n",
      "iteration:  10  cost:  0.9680563895673437\n",
      "iteration:  20  cost:  0.8046694645123503\n",
      "iteration:  30  cost:  0.8708510759513532\n",
      "iteration:  40  cost:  0.7211309464510697\n",
      "iteration:  50  cost:  0.8535768902455296\n",
      "iteration:  60  cost:  0.8182496606766175\n",
      "iteration:  70  cost:  0.6797220507779258\n",
      "iteration:  80  cost:  0.7550310455010723\n",
      "iteration:  90  cost:  0.7898438583112217\n",
      "iteration:  100  cost:  0.7908030706471423\n",
      "iteration:  110  cost:  0.7606462205544318\n",
      "iteration:  120  cost:  0.7634276967451225\n",
      "iteration:  130  cost:  0.7784614654372044\n",
      "iteration:  140  cost:  0.7416685878284991\n",
      "Accuracy for U_15 autoencoder24 :0.8997635933806146\n",
      "\n",
      "\n",
      "Loss History for QCNN circuits, U_SO4 pca24\n",
      "iteration:  0  cost:  0.986056114959037\n",
      "iteration:  10  cost:  1.034265929462214\n",
      "iteration:  20  cost:  1.0218861020785683\n",
      "iteration:  30  cost:  0.9878610841312266\n",
      "iteration:  40  cost:  1.0045098055112986\n",
      "iteration:  50  cost:  1.0092348550249868\n",
      "iteration:  60  cost:  1.0088158566994625\n",
      "iteration:  70  cost:  1.006732273665399\n",
      "iteration:  80  cost:  0.9928281808988524\n",
      "iteration:  90  cost:  0.9974863952027426\n",
      "iteration:  100  cost:  0.9512235101324122\n",
      "iteration:  110  cost:  1.0343493026014547\n",
      "iteration:  120  cost:  0.9262484216317637\n",
      "iteration:  130  cost:  0.9533767899924146\n",
      "iteration:  140  cost:  0.9687236533966167\n",
      "Accuracy for U_SO4 pca24 :0.5371158392434988\n",
      "Epoch 1/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.0869 - val_loss: 0.0260\n",
      "Epoch 2/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.0245 - val_loss: 0.0192\n",
      "Epoch 3/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.0183 - val_loss: 0.0148\n",
      "Epoch 4/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.0144 - val_loss: 0.0122\n",
      "Epoch 5/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.0120 - val_loss: 0.0107\n",
      "Epoch 6/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.0105 - val_loss: 0.0096\n",
      "Epoch 7/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.0095 - val_loss: 0.0088\n",
      "Epoch 8/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.0088 - val_loss: 0.0083\n",
      "Epoch 9/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.0082 - val_loss: 0.0078\n",
      "Epoch 10/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.0078 - val_loss: 0.0074\n",
      "\n",
      "\n",
      "Loss History for QCNN circuits, U_SO4 autoencoder24\n",
      "iteration:  0  cost:  0.8683897954049403\n",
      "iteration:  10  cost:  0.7806485882116797\n",
      "iteration:  20  cost:  0.6611224002750109\n",
      "iteration:  30  cost:  0.7470161976217533\n",
      "iteration:  40  cost:  0.682204407560001\n",
      "iteration:  50  cost:  0.6013903647588803\n",
      "iteration:  60  cost:  0.5335418601906429\n",
      "iteration:  70  cost:  0.5632353260193232\n",
      "iteration:  80  cost:  0.562751406034529\n",
      "iteration:  90  cost:  0.5139846398854206\n",
      "iteration:  100  cost:  0.5273624606596132\n",
      "iteration:  110  cost:  0.4200529219694551\n",
      "iteration:  120  cost:  0.5135955501039188\n",
      "iteration:  130  cost:  0.7589774601283414\n",
      "iteration:  140  cost:  0.43307746038071193\n",
      "Accuracy for U_SO4 autoencoder24 :0.9219858156028369\n",
      "3th step : \n",
      "\n",
      "\n",
      "Loss History for QCNN circuits, U_TTN pca24\n",
      "iteration:  0  cost:  1.0572009216050813\n",
      "iteration:  10  cost:  0.9910302954708942\n",
      "iteration:  20  cost:  1.0032407169549067\n",
      "iteration:  30  cost:  0.9735649513735802\n",
      "iteration:  40  cost:  1.0191971965380828\n",
      "iteration:  50  cost:  0.980402220663509\n",
      "iteration:  60  cost:  0.9292067201933741\n",
      "iteration:  70  cost:  0.9781809043307171\n",
      "iteration:  80  cost:  0.9488105634849462\n",
      "iteration:  90  cost:  0.9687377694896298\n",
      "iteration:  100  cost:  0.9703243361895078\n",
      "iteration:  110  cost:  0.9734362718778172\n",
      "iteration:  120  cost:  0.9843662378320562\n",
      "iteration:  130  cost:  0.9865473865379965\n",
      "iteration:  140  cost:  0.9935953968360727\n",
      "Accuracy for U_TTN pca24 :0.5371158392434988\n",
      "Epoch 1/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.0868 - val_loss: 0.0266\n",
      "Epoch 2/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.0251 - val_loss: 0.0194\n",
      "Epoch 3/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.0184 - val_loss: 0.0148\n",
      "Epoch 4/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.0144 - val_loss: 0.0124\n",
      "Epoch 5/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.0121 - val_loss: 0.0109\n",
      "Epoch 6/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.0107 - val_loss: 0.0100\n",
      "Epoch 7/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.0099 - val_loss: 0.0092\n",
      "Epoch 8/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.0091 - val_loss: 0.0085\n",
      "Epoch 9/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.0084 - val_loss: 0.0080\n",
      "Epoch 10/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.0080 - val_loss: 0.0076\n",
      "\n",
      "\n",
      "Loss History for QCNN circuits, U_TTN autoencoder24\n",
      "iteration:  0  cost:  1.1321697800021229\n",
      "iteration:  10  cost:  0.9714149812249415\n",
      "iteration:  20  cost:  0.9757273326579738\n",
      "iteration:  30  cost:  0.8611835709413852\n",
      "iteration:  40  cost:  0.8562637238959955\n",
      "iteration:  50  cost:  0.7354109967545014\n",
      "iteration:  60  cost:  0.7995905497115592\n",
      "iteration:  70  cost:  0.7458270135551557\n",
      "iteration:  80  cost:  0.7889621542256501\n",
      "iteration:  90  cost:  0.8462116739594898\n",
      "iteration:  100  cost:  0.8413956240761701\n",
      "iteration:  110  cost:  0.8750633684431364\n",
      "iteration:  120  cost:  0.7815348831382208\n",
      "iteration:  130  cost:  1.0248299882457566\n",
      "iteration:  140  cost:  0.7775607331070191\n",
      "Accuracy for U_TTN autoencoder24 :0.7271867612293145\n",
      "\n",
      "\n",
      "Loss History for QCNN circuits, U_5 pca24\n",
      "iteration:  0  cost:  0.8945422129761452\n",
      "iteration:  10  cost:  0.9993926742382135\n",
      "iteration:  20  cost:  0.996327290054358\n",
      "iteration:  30  cost:  0.9867117073965771\n",
      "iteration:  40  cost:  0.9730715215478505\n",
      "iteration:  50  cost:  0.9527827402487477\n",
      "iteration:  60  cost:  0.9965252199478455\n",
      "iteration:  70  cost:  0.9661963504573572\n",
      "iteration:  80  cost:  1.030183375281948\n",
      "iteration:  90  cost:  0.9931662643248959\n",
      "iteration:  100  cost:  1.0034412547870657\n",
      "iteration:  110  cost:  1.0363087846626693\n",
      "iteration:  120  cost:  1.008644614769875\n",
      "iteration:  130  cost:  1.0746315421093917\n",
      "iteration:  140  cost:  0.9841639639191823\n",
      "Accuracy for U_5 pca24 :0.5366430260047281\n",
      "Epoch 1/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.0872 - val_loss: 0.0260\n",
      "Epoch 2/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.0241 - val_loss: 0.0193\n",
      "Epoch 3/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.0181 - val_loss: 0.0143\n",
      "Epoch 4/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.0139 - val_loss: 0.0120\n",
      "Epoch 5/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.0116 - val_loss: 0.0104\n",
      "Epoch 6/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.0102 - val_loss: 0.0093\n",
      "Epoch 7/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.0094 - val_loss: 0.0085\n",
      "Epoch 8/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.0084 - val_loss: 0.0079\n",
      "Epoch 9/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.0080 - val_loss: 0.0075\n",
      "Epoch 10/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.0077 - val_loss: 0.0073\n",
      "\n",
      "\n",
      "Loss History for QCNN circuits, U_5 autoencoder24\n",
      "iteration:  0  cost:  1.2147563159402563\n",
      "iteration:  10  cost:  0.8924202913549942\n",
      "iteration:  20  cost:  0.6050482610189664\n",
      "iteration:  30  cost:  0.608012062917036\n",
      "iteration:  40  cost:  0.638052148912386\n",
      "iteration:  50  cost:  0.5040964652530288\n",
      "iteration:  60  cost:  0.443349536738062\n",
      "iteration:  70  cost:  0.5530857394989716\n",
      "iteration:  80  cost:  0.45840429051301557\n",
      "iteration:  90  cost:  0.4248302774544357\n",
      "iteration:  100  cost:  0.47811165389250326\n",
      "iteration:  110  cost:  0.6692641176023537\n",
      "iteration:  120  cost:  0.553887950460824\n",
      "iteration:  130  cost:  0.4533031785123541\n",
      "iteration:  140  cost:  0.6043188780135036\n",
      "Accuracy for U_5 autoencoder24 :0.9148936170212766\n",
      "\n",
      "\n",
      "Loss History for QCNN circuits, U_6 pca24\n",
      "iteration:  0  cost:  1.3123731563106056\n",
      "iteration:  10  cost:  1.025164215459198\n",
      "iteration:  20  cost:  0.8678223680031282\n",
      "iteration:  30  cost:  0.9175932678376135\n",
      "iteration:  40  cost:  0.9574901457837841\n",
      "iteration:  50  cost:  1.2287744946018315\n",
      "iteration:  60  cost:  1.0256723762023734\n",
      "iteration:  70  cost:  1.005896114508579\n",
      "iteration:  80  cost:  0.970595552506644\n",
      "iteration:  90  cost:  1.0379718037519208\n",
      "iteration:  100  cost:  0.9748716048678978\n",
      "iteration:  110  cost:  0.9861093129346465\n",
      "iteration:  120  cost:  0.9961728994684733\n",
      "iteration:  130  cost:  0.9706858880353281\n",
      "iteration:  140  cost:  1.0543231393131032\n",
      "Accuracy for U_6 pca24 :0.5366430260047281\n",
      "Epoch 1/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.0891 - val_loss: 0.0251\n",
      "Epoch 2/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.0233 - val_loss: 0.0181\n",
      "Epoch 3/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.0172 - val_loss: 0.0143\n",
      "Epoch 4/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.0141 - val_loss: 0.0123\n",
      "Epoch 5/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.0121 - val_loss: 0.0109\n",
      "Epoch 6/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.0109 - val_loss: 0.0099\n",
      "Epoch 7/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.0098 - val_loss: 0.0091\n",
      "Epoch 8/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.0090 - val_loss: 0.0085\n",
      "Epoch 9/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.0085 - val_loss: 0.0080\n",
      "Epoch 10/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.0081 - val_loss: 0.0076\n",
      "\n",
      "\n",
      "Loss History for QCNN circuits, U_6 autoencoder24\n",
      "iteration:  0  cost:  1.185942101597229\n",
      "iteration:  10  cost:  0.9293566818178243\n",
      "iteration:  20  cost:  0.8569682751775933\n",
      "iteration:  30  cost:  0.798878567426371\n",
      "iteration:  40  cost:  0.7840960062131246\n",
      "iteration:  50  cost:  0.8448025129754332\n",
      "iteration:  60  cost:  0.9399234490141023\n",
      "iteration:  70  cost:  0.6720763212264016\n",
      "iteration:  80  cost:  0.7716842677778065\n",
      "iteration:  90  cost:  0.8259472039325005\n",
      "iteration:  100  cost:  0.6429667954029162\n",
      "iteration:  110  cost:  0.774641571375964\n",
      "iteration:  120  cost:  0.8198822116632387\n",
      "iteration:  130  cost:  0.7910345838920679\n",
      "iteration:  140  cost:  0.7658403750162901\n",
      "Accuracy for U_6 autoencoder24 :0.8085106382978723\n",
      "\n",
      "\n",
      "Loss History for QCNN circuits, U_9 pca24\n",
      "iteration:  0  cost:  1.0039971526112503\n",
      "iteration:  10  cost:  0.9866699056090793\n",
      "iteration:  20  cost:  0.9850713797737936\n",
      "iteration:  30  cost:  1.0094338665497185\n",
      "iteration:  40  cost:  1.0037409075674073\n",
      "iteration:  50  cost:  1.0036190822541473\n",
      "iteration:  60  cost:  0.9661400808505752\n",
      "iteration:  70  cost:  0.9529291244474782\n",
      "iteration:  80  cost:  0.9686959972154474\n",
      "iteration:  90  cost:  0.9556747496505106\n",
      "iteration:  100  cost:  1.0013760978863682\n",
      "iteration:  110  cost:  0.9946342070380914\n",
      "iteration:  120  cost:  1.0166587349912053\n",
      "iteration:  130  cost:  0.9994116134514526\n",
      "iteration:  140  cost:  0.9511375229286568\n",
      "Accuracy for U_9 pca24 :0.5366430260047281\n",
      "Epoch 1/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.0881 - val_loss: 0.0268\n",
      "Epoch 2/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.0251 - val_loss: 0.0198\n",
      "Epoch 3/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.0189 - val_loss: 0.0155\n",
      "Epoch 4/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.0150 - val_loss: 0.0130\n",
      "Epoch 5/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.0129 - val_loss: 0.0115\n",
      "Epoch 6/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.0113 - val_loss: 0.0104\n",
      "Epoch 7/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.0105 - val_loss: 0.0096\n",
      "Epoch 8/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.0096 - val_loss: 0.0090\n",
      "Epoch 9/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.0089 - val_loss: 0.0085\n",
      "Epoch 10/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.0086 - val_loss: 0.0082\n",
      "\n",
      "\n",
      "Loss History for QCNN circuits, U_9 autoencoder24\n",
      "iteration:  0  cost:  0.9777463809741331\n",
      "iteration:  10  cost:  0.9540006006540201\n",
      "iteration:  20  cost:  0.9087610385535096\n",
      "iteration:  30  cost:  0.8530136438463434\n",
      "iteration:  40  cost:  0.8723502231172504\n",
      "iteration:  50  cost:  0.9727086281345197\n",
      "iteration:  60  cost:  0.8597936901073236\n",
      "iteration:  70  cost:  0.965726364554628\n",
      "iteration:  80  cost:  0.8650894498969034\n",
      "iteration:  90  cost:  0.8735666944872773\n",
      "iteration:  100  cost:  0.8614634381275252\n",
      "iteration:  110  cost:  0.859329898656094\n",
      "iteration:  120  cost:  0.9081617823833735\n",
      "iteration:  130  cost:  0.9250053410951865\n",
      "iteration:  140  cost:  0.8648909119371485\n",
      "Accuracy for U_9 autoencoder24 :0.6312056737588653\n",
      "\n",
      "\n",
      "Loss History for QCNN circuits, U_13 pca24\n",
      "iteration:  0  cost:  1.0317656674991627\n",
      "iteration:  10  cost:  1.007033868332116\n",
      "iteration:  20  cost:  0.9776090447993844\n",
      "iteration:  30  cost:  1.0618387660329724\n",
      "iteration:  40  cost:  1.002530385071126\n",
      "iteration:  50  cost:  1.0158702566367115\n",
      "iteration:  60  cost:  1.007931610359475\n",
      "iteration:  70  cost:  0.9856182729238653\n",
      "iteration:  80  cost:  1.0072998614918012\n",
      "iteration:  90  cost:  0.9671648443451352\n",
      "iteration:  100  cost:  1.100556449568573\n",
      "iteration:  110  cost:  0.980498729817722\n",
      "iteration:  120  cost:  1.0281756799775168\n",
      "iteration:  130  cost:  0.9848327948864377\n",
      "iteration:  140  cost:  0.9851039388054214\n",
      "Accuracy for U_13 pca24 :0.5380614657210402\n",
      "Epoch 1/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.0859 - val_loss: 0.0265\n",
      "Epoch 2/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.0248 - val_loss: 0.0195\n",
      "Epoch 3/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.0184 - val_loss: 0.0149\n",
      "Epoch 4/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.0145 - val_loss: 0.0123\n",
      "Epoch 5/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.0121 - val_loss: 0.0108\n",
      "Epoch 6/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.0107 - val_loss: 0.0098\n",
      "Epoch 7/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.0096 - val_loss: 0.0090\n",
      "Epoch 8/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.0090 - val_loss: 0.0085\n",
      "Epoch 9/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.0083 - val_loss: 0.0080\n",
      "Epoch 10/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.0079 - val_loss: 0.0078\n",
      "\n",
      "\n",
      "Loss History for QCNN circuits, U_13 autoencoder24\n",
      "iteration:  0  cost:  0.9607334927271346\n",
      "iteration:  10  cost:  0.6274704890983231\n",
      "iteration:  20  cost:  0.7056785319480747\n",
      "iteration:  30  cost:  0.6693928555111939\n",
      "iteration:  40  cost:  0.5957664372836726\n",
      "iteration:  50  cost:  0.619391799106807\n",
      "iteration:  60  cost:  0.5679908857719522\n",
      "iteration:  70  cost:  0.5927913082053116\n",
      "iteration:  80  cost:  0.6435541256439176\n",
      "iteration:  90  cost:  0.5841384934748245\n",
      "iteration:  100  cost:  0.45616607682712945\n",
      "iteration:  110  cost:  0.7148758701209676\n",
      "iteration:  120  cost:  0.6528673564670195\n",
      "iteration:  130  cost:  0.5465881239508336\n",
      "iteration:  140  cost:  0.5822384769062522\n",
      "Accuracy for U_13 autoencoder24 :0.9073286052009456\n",
      "\n",
      "\n",
      "Loss History for QCNN circuits, U_14 pca24\n",
      "iteration:  0  cost:  1.5470327235649048\n",
      "iteration:  10  cost:  0.9856787359047934\n",
      "iteration:  20  cost:  0.9850601624108051\n",
      "iteration:  30  cost:  1.0750538061455952\n",
      "iteration:  40  cost:  1.0797472950714253\n",
      "iteration:  50  cost:  1.0013795736403168\n",
      "iteration:  60  cost:  0.9930297690721634\n",
      "iteration:  70  cost:  0.9176515121330533\n",
      "iteration:  80  cost:  1.0147475085899527\n",
      "iteration:  90  cost:  1.0109685251691338\n",
      "iteration:  100  cost:  1.0009003318039595\n",
      "iteration:  110  cost:  0.9555046521362172\n",
      "iteration:  120  cost:  0.9995110141710479\n",
      "iteration:  130  cost:  0.9971187974488543\n",
      "iteration:  140  cost:  0.9878586623440134\n",
      "Accuracy for U_14 pca24 :0.5366430260047281\n",
      "Epoch 1/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.0854 - val_loss: 0.0263\n",
      "Epoch 2/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.0246 - val_loss: 0.0195\n",
      "Epoch 3/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.0186 - val_loss: 0.0144\n",
      "Epoch 4/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.0137 - val_loss: 0.0120\n",
      "Epoch 5/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.0117 - val_loss: 0.0105\n",
      "Epoch 6/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.0104 - val_loss: 0.0096\n",
      "Epoch 7/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.0094 - val_loss: 0.0088\n",
      "Epoch 8/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.0086 - val_loss: 0.0082\n",
      "Epoch 9/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.0081 - val_loss: 0.0078\n",
      "Epoch 10/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.0077 - val_loss: 0.0074\n",
      "\n",
      "\n",
      "Loss History for QCNN circuits, U_14 autoencoder24\n",
      "iteration:  0  cost:  1.1380105670214222\n",
      "iteration:  10  cost:  0.8745924011735314\n",
      "iteration:  20  cost:  0.6911033338675103\n",
      "iteration:  30  cost:  0.6582629460412002\n",
      "iteration:  40  cost:  0.5606620037187783\n",
      "iteration:  50  cost:  0.5123787028726431\n",
      "iteration:  60  cost:  0.6025201001372579\n",
      "iteration:  70  cost:  0.6866626527802646\n",
      "iteration:  80  cost:  0.483175433193612\n",
      "iteration:  90  cost:  0.7044104202715405\n",
      "iteration:  100  cost:  0.6372671397984626\n",
      "iteration:  110  cost:  0.631588678704369\n",
      "iteration:  120  cost:  0.5313689225445123\n",
      "iteration:  130  cost:  0.6517592050691501\n",
      "iteration:  140  cost:  0.5781769596766931\n",
      "Accuracy for U_14 autoencoder24 :0.9238770685579196\n",
      "\n",
      "\n",
      "Loss History for QCNN circuits, U_15 pca24\n",
      "iteration:  0  cost:  0.959399282608063\n",
      "iteration:  10  cost:  1.0980683807999425\n",
      "iteration:  20  cost:  0.9701850673138331\n",
      "iteration:  30  cost:  0.9858911559927533\n",
      "iteration:  40  cost:  0.9437237604357287\n",
      "iteration:  50  cost:  0.9989894727708143\n",
      "iteration:  60  cost:  0.9849572960245303\n",
      "iteration:  70  cost:  1.0544195747229748\n",
      "iteration:  80  cost:  1.0037753937516505\n",
      "iteration:  90  cost:  1.005710781317632\n",
      "iteration:  100  cost:  1.0675572389575345\n",
      "iteration:  110  cost:  0.9935758176774315\n",
      "iteration:  120  cost:  1.0012746426206085\n",
      "iteration:  130  cost:  0.9814392930723875\n",
      "iteration:  140  cost:  1.0179729801400113\n",
      "Accuracy for U_15 pca24 :0.5375886524822695\n",
      "Epoch 1/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.0860 - val_loss: 0.0269\n",
      "Epoch 2/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.0249 - val_loss: 0.0193\n",
      "Epoch 3/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.0182 - val_loss: 0.0145\n",
      "Epoch 4/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.0139 - val_loss: 0.0120\n",
      "Epoch 5/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.0119 - val_loss: 0.0106\n",
      "Epoch 6/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.0104 - val_loss: 0.0094\n",
      "Epoch 7/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.0093 - val_loss: 0.0087\n",
      "Epoch 8/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.0087 - val_loss: 0.0082\n",
      "Epoch 9/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.0081 - val_loss: 0.0078\n",
      "Epoch 10/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.0079 - val_loss: 0.0075\n",
      "\n",
      "\n",
      "Loss History for QCNN circuits, U_15 autoencoder24\n",
      "iteration:  0  cost:  1.0037633172479032\n",
      "iteration:  10  cost:  0.6870167651623613\n",
      "iteration:  20  cost:  0.7651109062775916\n",
      "iteration:  30  cost:  0.5442879852488799\n",
      "iteration:  40  cost:  0.7845239663664979\n",
      "iteration:  50  cost:  0.7295604969883223\n",
      "iteration:  60  cost:  0.6999334093209726\n",
      "iteration:  70  cost:  0.5860311861411208\n",
      "iteration:  80  cost:  0.7130214369549032\n",
      "iteration:  90  cost:  0.736530381072594\n",
      "iteration:  100  cost:  0.7307804291518365\n",
      "iteration:  110  cost:  0.7757169992229906\n",
      "iteration:  120  cost:  0.8319408273610843\n",
      "iteration:  130  cost:  0.6747239217251927\n",
      "iteration:  140  cost:  0.9134196886013832\n",
      "Accuracy for U_15 autoencoder24 :0.8401891252955083\n",
      "\n",
      "\n",
      "Loss History for QCNN circuits, U_SO4 pca24\n",
      "iteration:  0  cost:  0.9733683014365181\n",
      "iteration:  10  cost:  0.975833906544337\n",
      "iteration:  20  cost:  1.008455578272657\n",
      "iteration:  30  cost:  1.037246312709054\n",
      "iteration:  40  cost:  0.9831877308755638\n",
      "iteration:  50  cost:  0.9911118864408844\n",
      "iteration:  60  cost:  0.9864556490509089\n",
      "iteration:  70  cost:  0.9132832105195291\n",
      "iteration:  80  cost:  0.9934069379164734\n",
      "iteration:  90  cost:  1.0131940522464455\n",
      "iteration:  100  cost:  1.0120829901682258\n",
      "iteration:  110  cost:  0.999482725753132\n",
      "iteration:  120  cost:  1.0699214993458082\n",
      "iteration:  130  cost:  0.9723273848998717\n",
      "iteration:  140  cost:  1.010006003213639\n",
      "Accuracy for U_SO4 pca24 :0.577304964539007\n",
      "Epoch 1/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.0873 - val_loss: 0.0265\n",
      "Epoch 2/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.0248 - val_loss: 0.0185\n",
      "Epoch 3/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.0175 - val_loss: 0.0143\n",
      "Epoch 4/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.0139 - val_loss: 0.0122\n",
      "Epoch 5/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.0118 - val_loss: 0.0106\n",
      "Epoch 6/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.0105 - val_loss: 0.0095\n",
      "Epoch 7/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.0096 - val_loss: 0.0088\n",
      "Epoch 8/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.0088 - val_loss: 0.0082\n",
      "Epoch 9/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.0083 - val_loss: 0.0076\n",
      "Epoch 10/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.0077 - val_loss: 0.0073\n",
      "\n",
      "\n",
      "Loss History for QCNN circuits, U_SO4 autoencoder24\n",
      "iteration:  0  cost:  1.202127247910218\n",
      "iteration:  10  cost:  0.8722587111807791\n",
      "iteration:  20  cost:  0.7739438222859161\n",
      "iteration:  30  cost:  0.7430038413523218\n",
      "iteration:  40  cost:  0.659793424516748\n",
      "iteration:  50  cost:  0.6671579282633653\n",
      "iteration:  60  cost:  0.6399840674334536\n",
      "iteration:  70  cost:  0.4790277878821842\n",
      "iteration:  80  cost:  0.6386523022306428\n",
      "iteration:  90  cost:  0.5193959900686916\n",
      "iteration:  100  cost:  0.7762175307881151\n",
      "iteration:  110  cost:  0.5801875553821877\n",
      "iteration:  120  cost:  0.4224277432918271\n",
      "iteration:  130  cost:  0.6362056530848333\n",
      "iteration:  140  cost:  0.5564312971348317\n",
      "Accuracy for U_SO4 autoencoder24 :0.8548463356973995\n",
      "4th step : \n",
      "\n",
      "\n",
      "Loss History for QCNN circuits, U_TTN pca24\n",
      "iteration:  0  cost:  1.0007773026417266\n",
      "iteration:  10  cost:  1.0005722660530327\n",
      "iteration:  20  cost:  0.995597468161542\n",
      "iteration:  30  cost:  1.001764936968803\n",
      "iteration:  40  cost:  0.9960954366291341\n",
      "iteration:  50  cost:  0.9875689947974046\n",
      "iteration:  60  cost:  1.0131458719787991\n",
      "iteration:  70  cost:  0.9790907728182683\n",
      "iteration:  80  cost:  1.0584090449095696\n",
      "iteration:  90  cost:  1.0097714824733526\n",
      "iteration:  100  cost:  0.9827564001834246\n",
      "iteration:  110  cost:  0.9938729279497764\n",
      "iteration:  120  cost:  0.9463671311333668\n",
      "iteration:  130  cost:  1.0513968112400929\n",
      "iteration:  140  cost:  1.0035436650072018\n",
      "Accuracy for U_TTN pca24 :0.5366430260047281\n",
      "Epoch 1/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.0862 - val_loss: 0.0266\n",
      "Epoch 2/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.0249 - val_loss: 0.0198\n",
      "Epoch 3/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.0187 - val_loss: 0.0154\n",
      "Epoch 4/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.0147 - val_loss: 0.0130\n",
      "Epoch 5/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.0125 - val_loss: 0.0111\n",
      "Epoch 6/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.0107 - val_loss: 0.0098\n",
      "Epoch 7/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.0096 - val_loss: 0.0090\n",
      "Epoch 8/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.0089 - val_loss: 0.0084\n",
      "Epoch 9/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.0083 - val_loss: 0.0081\n",
      "Epoch 10/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.0081 - val_loss: 0.0076\n",
      "\n",
      "\n",
      "Loss History for QCNN circuits, U_TTN autoencoder24\n",
      "iteration:  0  cost:  1.0217915394968415\n",
      "iteration:  10  cost:  0.7697831472056343\n",
      "iteration:  20  cost:  0.7388418636504192\n",
      "iteration:  30  cost:  0.7482733292974136\n",
      "iteration:  40  cost:  0.6703503423624185\n",
      "iteration:  50  cost:  0.6532595628053897\n",
      "iteration:  60  cost:  0.6740013747912913\n",
      "iteration:  70  cost:  0.7454067606715555\n",
      "iteration:  80  cost:  0.843584104190882\n",
      "iteration:  90  cost:  0.7158325293892297\n",
      "iteration:  100  cost:  0.669122727219592\n",
      "iteration:  110  cost:  0.6385571019951826\n",
      "iteration:  120  cost:  0.7700340852379433\n",
      "iteration:  130  cost:  0.5927468476517338\n",
      "iteration:  140  cost:  0.7017126911890879\n",
      "Accuracy for U_TTN autoencoder24 :0.8278959810874704\n",
      "\n",
      "\n",
      "Loss History for QCNN circuits, U_5 pca24\n",
      "iteration:  0  cost:  1.1114297482275028\n",
      "iteration:  10  cost:  0.9439044195546126\n",
      "iteration:  20  cost:  1.0148356056383958\n",
      "iteration:  30  cost:  1.0273436926156794\n",
      "iteration:  40  cost:  0.9836527346742262\n",
      "iteration:  50  cost:  1.0010044827509732\n",
      "iteration:  60  cost:  0.997652738241666\n",
      "iteration:  70  cost:  1.0028892301673153\n",
      "iteration:  80  cost:  1.005617394662897\n",
      "iteration:  90  cost:  1.1260742877415217\n",
      "iteration:  100  cost:  0.9858641488652563\n",
      "iteration:  110  cost:  1.0041994878263074\n",
      "iteration:  120  cost:  1.0104947207490655\n",
      "iteration:  130  cost:  0.9668254871160954\n",
      "iteration:  140  cost:  0.9995486315261823\n",
      "Accuracy for U_5 pca24 :0.46004728132387707\n",
      "Epoch 1/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.0875 - val_loss: 0.0265\n",
      "Epoch 2/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.0246 - val_loss: 0.0191\n",
      "Epoch 3/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.0179 - val_loss: 0.0150\n",
      "Epoch 4/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.0144 - val_loss: 0.0125\n",
      "Epoch 5/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.0121 - val_loss: 0.0109\n",
      "Epoch 6/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.0108 - val_loss: 0.0099\n",
      "Epoch 7/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.0098 - val_loss: 0.0092\n",
      "Epoch 8/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.0091 - val_loss: 0.0086\n",
      "Epoch 9/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.0085 - val_loss: 0.0081\n",
      "Epoch 10/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.0080 - val_loss: 0.0077\n",
      "\n",
      "\n",
      "Loss History for QCNN circuits, U_5 autoencoder24\n",
      "iteration:  0  cost:  1.0331313172050411\n",
      "iteration:  10  cost:  0.7789308863247387\n",
      "iteration:  20  cost:  0.6631587813287073\n",
      "iteration:  30  cost:  0.6108388619798092\n",
      "iteration:  40  cost:  0.6589245402036127\n",
      "iteration:  50  cost:  0.5916623354104057\n",
      "iteration:  60  cost:  0.5264873228741761\n",
      "iteration:  70  cost:  0.5186278828435767\n",
      "iteration:  80  cost:  0.6618413729116784\n",
      "iteration:  90  cost:  0.6479150855328158\n",
      "iteration:  100  cost:  0.5759825371920323\n",
      "iteration:  110  cost:  0.5033223499010862\n",
      "iteration:  120  cost:  0.6714280382441262\n",
      "iteration:  130  cost:  0.5354586641218386\n",
      "iteration:  140  cost:  0.5281233192351088\n",
      "Accuracy for U_5 autoencoder24 :0.9120567375886525\n",
      "\n",
      "\n",
      "Loss History for QCNN circuits, U_6 pca24\n",
      "iteration:  0  cost:  1.0048907801101736\n",
      "iteration:  10  cost:  0.9465701194550185\n",
      "iteration:  20  cost:  1.0189611065699584\n",
      "iteration:  30  cost:  1.0268337729002364\n",
      "iteration:  40  cost:  0.9887086737704507\n",
      "iteration:  50  cost:  0.9853814480471088\n",
      "iteration:  60  cost:  0.9601464909152051\n",
      "iteration:  70  cost:  0.9897922587532135\n",
      "iteration:  80  cost:  0.9947125612643911\n",
      "iteration:  90  cost:  0.963725811475489\n",
      "iteration:  100  cost:  1.0208884488208476\n",
      "iteration:  110  cost:  0.9772294737289421\n",
      "iteration:  120  cost:  1.068137023178511\n",
      "iteration:  130  cost:  1.0055295261727868\n",
      "iteration:  140  cost:  0.98532150104309\n",
      "Accuracy for U_6 pca24 :0.5366430260047281\n",
      "Epoch 1/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.0871 - val_loss: 0.0253\n",
      "Epoch 2/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.0241 - val_loss: 0.0189\n",
      "Epoch 3/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.0181 - val_loss: 0.0150\n",
      "Epoch 4/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.0146 - val_loss: 0.0127\n",
      "Epoch 5/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.0127 - val_loss: 0.0112\n",
      "Epoch 6/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.0110 - val_loss: 0.0100\n",
      "Epoch 7/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.0099 - val_loss: 0.0092\n",
      "Epoch 8/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.0091 - val_loss: 0.0086\n",
      "Epoch 9/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.0086 - val_loss: 0.0081\n",
      "Epoch 10/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.0081 - val_loss: 0.0077\n",
      "\n",
      "\n",
      "Loss History for QCNN circuits, U_6 autoencoder24\n",
      "iteration:  0  cost:  1.1340476695315886\n",
      "iteration:  10  cost:  0.9373915951425095\n",
      "iteration:  20  cost:  0.886027862563752\n",
      "iteration:  30  cost:  0.7233822359547069\n",
      "iteration:  40  cost:  0.8058556977725735\n",
      "iteration:  50  cost:  0.6616544511899862\n",
      "iteration:  60  cost:  0.7640299269795194\n",
      "iteration:  70  cost:  0.7773512409493334\n",
      "iteration:  80  cost:  0.7341913278303883\n",
      "iteration:  90  cost:  1.0258952979465819\n",
      "iteration:  100  cost:  0.5990022731805662\n",
      "iteration:  110  cost:  0.5823387568191223\n",
      "iteration:  120  cost:  0.5447676084462834\n",
      "iteration:  130  cost:  0.7741180588416217\n",
      "iteration:  140  cost:  0.6381110935393823\n",
      "Accuracy for U_6 autoencoder24 :0.8761229314420804\n",
      "\n",
      "\n",
      "Loss History for QCNN circuits, U_9 pca24\n",
      "iteration:  0  cost:  1.1767135866127802\n",
      "iteration:  10  cost:  1.0441915524857754\n",
      "iteration:  20  cost:  1.0004759155701821\n",
      "iteration:  30  cost:  0.9953715952041416\n",
      "iteration:  40  cost:  0.9741491787497327\n",
      "iteration:  50  cost:  0.977848093662554\n",
      "iteration:  60  cost:  0.9899377573824047\n",
      "iteration:  70  cost:  1.0088859091344557\n",
      "iteration:  80  cost:  1.008068924248985\n",
      "iteration:  90  cost:  1.0340185186084034\n",
      "iteration:  100  cost:  0.9888383046740341\n",
      "iteration:  110  cost:  0.9884265457242906\n",
      "iteration:  120  cost:  0.9784699071057031\n",
      "iteration:  130  cost:  0.9818947227752589\n",
      "iteration:  140  cost:  0.9973224038856336\n",
      "Accuracy for U_9 pca24 :0.5366430260047281\n",
      "Epoch 1/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.0857 - val_loss: 0.0255\n",
      "Epoch 2/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.0239 - val_loss: 0.0183\n",
      "Epoch 3/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.0173 - val_loss: 0.0142\n",
      "Epoch 4/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.0140 - val_loss: 0.0120\n",
      "Epoch 5/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.0117 - val_loss: 0.0105\n",
      "Epoch 6/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.0103 - val_loss: 0.0095\n",
      "Epoch 7/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.0095 - val_loss: 0.0087\n",
      "Epoch 8/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.0086 - val_loss: 0.0082\n",
      "Epoch 9/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.0081 - val_loss: 0.0078\n",
      "Epoch 10/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.0076 - val_loss: 0.0074\n",
      "\n",
      "\n",
      "Loss History for QCNN circuits, U_9 autoencoder24\n",
      "iteration:  0  cost:  0.9965699407746276\n",
      "iteration:  10  cost:  0.9892029344141992\n",
      "iteration:  20  cost:  0.9888667532050074\n",
      "iteration:  30  cost:  0.9821467024359112\n",
      "iteration:  40  cost:  0.9624682789015838\n",
      "iteration:  50  cost:  0.9638351199615944\n",
      "iteration:  60  cost:  0.9583247595531887\n",
      "iteration:  70  cost:  0.9532065147459785\n",
      "iteration:  80  cost:  0.9506790937721452\n",
      "iteration:  90  cost:  0.9637567360060914\n",
      "iteration:  100  cost:  0.9615431130267355\n",
      "iteration:  110  cost:  0.9571130810711133\n",
      "iteration:  120  cost:  0.9656701371265836\n",
      "iteration:  130  cost:  0.9631584282023493\n",
      "iteration:  140  cost:  0.9342077950679842\n",
      "Accuracy for U_9 autoencoder24 :0.8170212765957446\n",
      "\n",
      "\n",
      "Loss History for QCNN circuits, U_13 pca24\n",
      "iteration:  0  cost:  1.001363311058747\n",
      "iteration:  10  cost:  0.9981992642890936\n",
      "iteration:  20  cost:  0.9947020887015023\n",
      "iteration:  30  cost:  0.9993539059899978\n",
      "iteration:  40  cost:  1.0209405413880104\n",
      "iteration:  50  cost:  1.0156563732636634\n",
      "iteration:  60  cost:  0.9619028601282054\n",
      "iteration:  70  cost:  1.0347573775187164\n",
      "iteration:  80  cost:  0.9891151498063929\n",
      "iteration:  90  cost:  1.0154081903951373\n",
      "iteration:  100  cost:  0.9157466800628425\n",
      "iteration:  110  cost:  1.00052181765487\n",
      "iteration:  120  cost:  1.0050057733288467\n",
      "iteration:  130  cost:  1.0480059770753511\n",
      "iteration:  140  cost:  0.9844107065919725\n",
      "Accuracy for U_13 pca24 :0.5366430260047281\n",
      "Epoch 1/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.0883 - val_loss: 0.0253\n",
      "Epoch 2/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.0236 - val_loss: 0.0189\n",
      "Epoch 3/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.0177 - val_loss: 0.0146\n",
      "Epoch 4/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.0142 - val_loss: 0.0124\n",
      "Epoch 5/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.0123 - val_loss: 0.0110\n",
      "Epoch 6/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.0109 - val_loss: 0.0099\n",
      "Epoch 7/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.0097 - val_loss: 0.0091\n",
      "Epoch 8/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.0089 - val_loss: 0.0084\n",
      "Epoch 9/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.0083 - val_loss: 0.0080\n",
      "Epoch 10/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.0078 - val_loss: 0.0075\n",
      "\n",
      "\n",
      "Loss History for QCNN circuits, U_13 autoencoder24\n",
      "iteration:  0  cost:  1.0203974956400812\n",
      "iteration:  10  cost:  0.6762214136344821\n",
      "iteration:  20  cost:  0.5821801523258736\n",
      "iteration:  30  cost:  0.6235717349740856\n",
      "iteration:  40  cost:  0.496123842247874\n",
      "iteration:  50  cost:  0.5890445043372005\n",
      "iteration:  60  cost:  0.523099225969805\n",
      "iteration:  70  cost:  0.5294483881239748\n",
      "iteration:  80  cost:  0.4604733472250363\n",
      "iteration:  90  cost:  0.46745807078509133\n",
      "iteration:  100  cost:  0.5140369748101177\n",
      "iteration:  110  cost:  0.46986645360689644\n",
      "iteration:  120  cost:  0.3647157937087338\n",
      "iteration:  130  cost:  0.37203099403500567\n",
      "iteration:  140  cost:  0.5075671650541503\n",
      "Accuracy for U_13 autoencoder24 :0.9328605200945627\n",
      "\n",
      "\n",
      "Loss History for QCNN circuits, U_14 pca24\n",
      "iteration:  0  cost:  1.210217350257359\n",
      "iteration:  10  cost:  0.8726789068223293\n",
      "iteration:  20  cost:  0.9965144754481776\n",
      "iteration:  30  cost:  1.012249474886663\n",
      "iteration:  40  cost:  0.986633723289281\n",
      "iteration:  50  cost:  1.0500713337105672\n",
      "iteration:  60  cost:  1.0011600904775098\n",
      "iteration:  70  cost:  1.0003765873426889\n",
      "iteration:  80  cost:  0.9268712293206097\n",
      "iteration:  90  cost:  1.0092571380303428\n",
      "iteration:  100  cost:  0.9980060802037795\n",
      "iteration:  110  cost:  0.9478947344372409\n",
      "iteration:  120  cost:  0.9812152112680905\n",
      "iteration:  130  cost:  0.970806520236349\n",
      "iteration:  140  cost:  1.0862238319210233\n",
      "Accuracy for U_14 pca24 :0.5366430260047281\n",
      "Epoch 1/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.0861 - val_loss: 0.0251\n",
      "Epoch 2/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.0236 - val_loss: 0.0189\n",
      "Epoch 3/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.0179 - val_loss: 0.0147\n",
      "Epoch 4/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.0143 - val_loss: 0.0122\n",
      "Epoch 5/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.0121 - val_loss: 0.0108\n",
      "Epoch 6/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.0105 - val_loss: 0.0097\n",
      "Epoch 7/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.0098 - val_loss: 0.0090\n",
      "Epoch 8/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.0090 - val_loss: 0.0085\n",
      "Epoch 9/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.0086 - val_loss: 0.0081\n",
      "Epoch 10/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.0080 - val_loss: 0.0077\n",
      "\n",
      "\n",
      "Loss History for QCNN circuits, U_14 autoencoder24\n",
      "iteration:  0  cost:  0.8561642545994046\n",
      "iteration:  10  cost:  0.8981922362176467\n",
      "iteration:  20  cost:  0.88098967719505\n",
      "iteration:  30  cost:  0.7856771903554393\n",
      "iteration:  40  cost:  0.8674017532573933\n",
      "iteration:  50  cost:  0.7750996173209347\n",
      "iteration:  60  cost:  0.6872314301822771\n",
      "iteration:  70  cost:  0.6904505528873075\n",
      "iteration:  80  cost:  0.673609342391082\n",
      "iteration:  90  cost:  0.7783145230130813\n",
      "iteration:  100  cost:  0.850814679411543\n",
      "iteration:  110  cost:  0.7241920905614271\n",
      "iteration:  120  cost:  0.6953984800911341\n",
      "iteration:  130  cost:  0.7978898560964922\n",
      "iteration:  140  cost:  0.6828074736388569\n",
      "Accuracy for U_14 autoencoder24 :0.8713947990543736\n",
      "\n",
      "\n",
      "Loss History for QCNN circuits, U_15 pca24\n",
      "iteration:  0  cost:  1.0266955978173689\n",
      "iteration:  10  cost:  0.9657090777584056\n",
      "iteration:  20  cost:  1.1376692609236407\n",
      "iteration:  30  cost:  0.9035039407243056\n",
      "iteration:  40  cost:  0.9830178094057545\n",
      "iteration:  50  cost:  0.984834581375339\n",
      "iteration:  60  cost:  1.0084924926877208\n",
      "iteration:  70  cost:  1.0236051168498101\n",
      "iteration:  80  cost:  0.9812170425338362\n",
      "iteration:  90  cost:  0.9422788842189885\n",
      "iteration:  100  cost:  1.0167080741137522\n",
      "iteration:  110  cost:  1.0339300890510938\n",
      "iteration:  120  cost:  0.977880022735244\n",
      "iteration:  130  cost:  1.0021629032124002\n",
      "iteration:  140  cost:  0.9882228898707092\n",
      "Accuracy for U_15 pca24 :0.5375886524822695\n",
      "Epoch 1/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.0877 - val_loss: 0.0249\n",
      "Epoch 2/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.0231 - val_loss: 0.0182\n",
      "Epoch 3/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.0176 - val_loss: 0.0144\n",
      "Epoch 4/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.0141 - val_loss: 0.0123\n",
      "Epoch 5/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.0120 - val_loss: 0.0107\n",
      "Epoch 6/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.0107 - val_loss: 0.0096\n",
      "Epoch 7/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.0094 - val_loss: 0.0087\n",
      "Epoch 8/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.0086 - val_loss: 0.0081\n",
      "Epoch 9/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.0080 - val_loss: 0.0077\n",
      "Epoch 10/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.0077 - val_loss: 0.0073\n",
      "\n",
      "\n",
      "Loss History for QCNN circuits, U_15 autoencoder24\n",
      "iteration:  0  cost:  1.0926968914505562\n",
      "iteration:  10  cost:  0.9398171499072134\n",
      "iteration:  20  cost:  0.8134690630577138\n",
      "iteration:  30  cost:  0.7323068797704987\n",
      "iteration:  40  cost:  0.7531643190537894\n",
      "iteration:  50  cost:  0.5381318354385486\n",
      "iteration:  60  cost:  0.5641177068448294\n",
      "iteration:  70  cost:  0.5826575880981771\n",
      "iteration:  80  cost:  0.6487091888388231\n",
      "iteration:  90  cost:  0.531703677534841\n",
      "iteration:  100  cost:  0.551865562677198\n",
      "iteration:  110  cost:  0.5575105776975784\n",
      "iteration:  120  cost:  0.6519965278882751\n",
      "iteration:  130  cost:  0.5914272461752665\n",
      "iteration:  140  cost:  0.5416674893585277\n",
      "Accuracy for U_15 autoencoder24 :0.8945626477541371\n",
      "\n",
      "\n",
      "Loss History for QCNN circuits, U_SO4 pca24\n",
      "iteration:  0  cost:  1.0168377211741804\n",
      "iteration:  10  cost:  1.0805997092405528\n",
      "iteration:  20  cost:  0.9895370542728295\n",
      "iteration:  30  cost:  1.0209311182031304\n",
      "iteration:  40  cost:  1.007567897957352\n",
      "iteration:  50  cost:  1.0109357346553625\n",
      "iteration:  60  cost:  0.9575939210717762\n",
      "iteration:  70  cost:  1.0227527404389192\n",
      "iteration:  80  cost:  1.0159107110939067\n",
      "iteration:  90  cost:  1.0582760288608761\n",
      "iteration:  100  cost:  0.98925917538204\n",
      "iteration:  110  cost:  1.0078896417951326\n",
      "iteration:  120  cost:  0.9787765731792177\n",
      "iteration:  130  cost:  0.9873459306841821\n",
      "iteration:  140  cost:  0.9982353607769674\n",
      "Accuracy for U_SO4 pca24 :0.5366430260047281\n",
      "Epoch 1/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.0859 - val_loss: 0.0258\n",
      "Epoch 2/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.0244 - val_loss: 0.0193\n",
      "Epoch 3/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.0182 - val_loss: 0.0150\n",
      "Epoch 4/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.0145 - val_loss: 0.0125\n",
      "Epoch 5/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.0124 - val_loss: 0.0109\n",
      "Epoch 6/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.0109 - val_loss: 0.0097\n",
      "Epoch 7/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.0096 - val_loss: 0.0089\n",
      "Epoch 8/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.0088 - val_loss: 0.0083\n",
      "Epoch 9/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.0082 - val_loss: 0.0079\n",
      "Epoch 10/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.0078 - val_loss: 0.0075\n",
      "\n",
      "\n",
      "Loss History for QCNN circuits, U_SO4 autoencoder24\n",
      "iteration:  0  cost:  1.08876490803663\n",
      "iteration:  10  cost:  0.9473577601539352\n",
      "iteration:  20  cost:  0.9285180555002904\n",
      "iteration:  30  cost:  0.8132595925993452\n",
      "iteration:  40  cost:  0.8527290670308868\n",
      "iteration:  50  cost:  0.8161516702408932\n",
      "iteration:  60  cost:  0.7464570728999697\n",
      "iteration:  70  cost:  0.7359215246861222\n",
      "iteration:  80  cost:  0.8616413186954947\n",
      "iteration:  90  cost:  0.8057652244703541\n",
      "iteration:  100  cost:  0.7776622918337801\n",
      "iteration:  110  cost:  0.8447544465839069\n",
      "iteration:  120  cost:  0.774126973960616\n",
      "iteration:  130  cost:  0.9177090265305229\n",
      "iteration:  140  cost:  0.6561036954122761\n",
      "Accuracy for U_SO4 autoencoder24 :0.8288416075650118\n",
      "[0.5385342789598109, 0.9016548463356974, 0.5399527186761229, 0.9011820330969267, 0.49598108747044917, 0.8543735224586289, 0.5366430260047281, 0.7924349881796691, 0.5810874704491725, 0.8761229314420804, 0.56548463356974, 0.858628841607565, 0.5432624113475177, 0.8591016548463357, 0.5366430260047281, 0.7858156028368795, 0.5366430260047281, 0.7319148936170212, 0.5366430260047281, 0.8775413711583925, 0.5366430260047281, 0.8860520094562647, 0.5631205673758866, 0.8756501182033097, 0.5385342789598109, 0.9134751773049645, 0.5394799054373522, 0.8879432624113475, 0.5366430260047281, 0.699290780141844, 0.5910165484633569, 0.8671394799054374, 0.5366430260047281, 0.631678486997636, 0.5366430260047281, 0.9106382978723404, 0.5366430260047281, 0.840661938534279, 0.4335697399527187, 0.8401891252955083, 0.5366430260047281, 0.8713947990543736, 0.5645390070921986, 0.7390070921985815, 0.5366430260047281, 0.8997635933806146, 0.5371158392434988, 0.9219858156028369, 0.5371158392434988, 0.7271867612293145, 0.5366430260047281, 0.9148936170212766, 0.5366430260047281, 0.8085106382978723, 0.5366430260047281, 0.6312056737588653, 0.5380614657210402, 0.9073286052009456, 0.5366430260047281, 0.9238770685579196, 0.5375886524822695, 0.8401891252955083, 0.577304964539007, 0.8548463356973995, 0.5366430260047281, 0.8278959810874704, 0.46004728132387707, 0.9120567375886525, 0.5366430260047281, 0.8761229314420804, 0.5366430260047281, 0.8170212765957446, 0.5366430260047281, 0.9328605200945627, 0.5366430260047281, 0.8713947990543736, 0.5375886524822695, 0.8945626477541371, 0.5366430260047281, 0.8288416075650118]\n"
     ]
    }
   ],
   "source": [
    "Benchmarking(Unitaries, U_num_params, Encodings, circuit, binary = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = [0.5385342789598109, 0.9016548463356974, 0.5399527186761229, 0.9011820330969267, 0.49598108747044917, 0.8543735224586289, 0.5366430260047281, 0.7924349881796691, 0.5810874704491725, 0.8761229314420804, 0.56548463356974, 0.858628841607565, 0.5432624113475177, 0.8591016548463357, 0.5366430260047281, 0.7858156028368795, 0.5366430260047281, 0.7319148936170212, 0.5366430260047281, 0.8775413711583925, 0.5366430260047281, 0.8860520094562647, 0.5631205673758866, 0.8756501182033097, 0.5385342789598109, 0.9134751773049645, 0.5394799054373522, 0.8879432624113475, 0.5366430260047281, 0.699290780141844, 0.5910165484633569, 0.8671394799054374, 0.5366430260047281, 0.631678486997636, 0.5366430260047281, 0.9106382978723404, 0.5366430260047281, 0.840661938534279, 0.4335697399527187, 0.8401891252955083, 0.5366430260047281, 0.8713947990543736, 0.5645390070921986, 0.7390070921985815, 0.5366430260047281, 0.8997635933806146, 0.5371158392434988, 0.9219858156028369, 0.5371158392434988, 0.7271867612293145, 0.5366430260047281, 0.9148936170212766, 0.5366430260047281, 0.8085106382978723, 0.5366430260047281, 0.6312056737588653, 0.5380614657210402, 0.9073286052009456, 0.5366430260047281, 0.9238770685579196, 0.5375886524822695, 0.8401891252955083, 0.577304964539007, 0.8548463356973995, 0.5366430260047281, 0.8278959810874704, 0.46004728132387707, 0.9120567375886525, 0.5366430260047281, 0.8761229314420804, 0.5366430260047281, 0.8170212765957446, 0.5366430260047281, 0.9328605200945627, 0.5366430260047281, 0.8713947990543736, 0.5375886524822695, 0.8945626477541371, 0.5366430260047281, 0.8288416075650118]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_list = []\n",
    "for i in range(16):\n",
    "    #print(results[i], results[i+21], results[i+2*21], results[i+3*21], results[i+4*21])\n",
    "    results_list.append([results[i], results[i+16], results[i+2*16], results[i+3*16], results[i+4*16]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statistics as st"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for QNN with Compact-Compact Embedding (Ry-Rz-Ry) with 5 random initializations\n",
      "\n",
      "U_TTN pca24 Mean : 0.5371158392434988 U_TTN pca24 Variance : 6.706570762704779e-07\n",
      "U_TTN Autoencoding24 Mean : 0.7640661938534279 U_TTN Autoencoding24 Variance : 0.01073129565358326\n",
      "U_5 pca24 Mean : 0.5219858156028369 U_5 pca24 Variance : 0.0012009232712416659\n",
      "U_5 Autoencoding24 Mean : 0.9032624113475177 U_5 Autoencoding24 Variance : 0.00023323217589099512\n",
      "U_6 pca24 Mean : 0.5285106382978724 U_6 pca24 Variance : 0.0003306786490730961\n",
      "U_6 Autoencoding24 Mean : 0.8531442080378251 U_6 Autoencoding24 Variance : 0.0009401047342800785\n",
      "U_9 pca24 Mean : 0.521323877068558 U_9 pca24 Variance : 0.0025379452184944866\n",
      "U_9 Autoencoding24 Mean : 0.7913002364066194 U_9 Autoencoding24 Variance : 0.008949538643819616\n",
      "U_13 pca24 Mean : 0.546193853427896 U_13 pca24 Variance : 0.0003812014821521377\n",
      "U_13 Autoencoding24 Mean : 0.9002364066193853 U_13 Autoencoding24 Variance : 0.000675798780521882\n",
      "U_14 pca24 Mean : 0.5485579196217494 U_14 pca24 Variance : 0.00022706213078930814\n",
      "U_14 Autoencoding24 Mean : 0.8561702127659574 U_14 Autoencoding24 Variance : 0.004889693677380416\n",
      "U_15 pca24 Mean : 0.5383451536643026 U_15 pca24 Variance : 7.779622084737545e-06\n",
      "U_15 Autoencoding24 Mean : 0.8385815602836879 U_15 Autoencoding24 Variance : 0.006675675826724564\n",
      "SO(4) pca24 Mean : 0.5557446808510638 SO(4) pca24 Variance : 0.0006964326632351368\n",
      "SO(4) Autoencoding24 Mean : 0.851725768321513 SO(4) Autoencoding24 Variance : 0.002512907354313722\n"
     ]
    }
   ],
   "source": [
    "print(\"Results for QNN with Compact-Compact Embedding (Ry-Rz-Ry) with 5 random initializations\")\n",
    "print(\"\")\n",
    "for i in range(16):\n",
    "    if i < 2:\n",
    "        it = \"U_TTN\"\n",
    "    elif 1<i<4:\n",
    "        it = 'U_5'\n",
    "    elif 3<i<6:\n",
    "        it = 'U_6'\n",
    "    elif 5<i<8:\n",
    "        it = 'U_9'\n",
    "    elif 7<i<10:\n",
    "        it = 'U_13'\n",
    "    elif 9<i<12:\n",
    "        it = 'U_14'\n",
    "    elif 11<i<14:\n",
    "        it = 'U_15'\n",
    "    else:\n",
    "        it = 'SO(4)'\n",
    "    \n",
    "    if i % 2 == 0:\n",
    "        emb = \"pca24\"\n",
    "    else:\n",
    "        emb = \"Autoencoding24\"\n",
    "        \n",
    "    print(it + \" \" + emb + \" Mean : \" + str(st.mean(results_list[i])),  it + \" \" + emb + \" Variance : \" + str(st.variance(results_list[i])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.5 Binary Classification with 1, -1 labels with U+P in the end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Results for Hierarchical Classifier circuit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1 Binary Classification with 1, -1 labeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "Unitaries = ['U_TTN', 'U_5', 'U_6', 'U_13', 'U_14', 'U_15', 'U_SO4'] \n",
    "U_num_params = [2, 10, 10, 6, 6, 4, 6]\n",
    "Encodings = ['resize256', 'pca8', 'autoencoder8']\n",
    "classes = [0,1]\n",
    "circuit = 'Hierarchical'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0th step : \n",
      "\n",
      "\n",
      "Loss History for Hierarchical circuits, U_TTN resize256\n",
      "iteration:  0  cost:  1.193148450071449\n",
      "iteration:  10  cost:  0.8290276834444283\n",
      "iteration:  20  cost:  0.9302363433562466\n",
      "iteration:  30  cost:  0.986788512497954\n",
      "iteration:  40  cost:  0.7107467410916322\n",
      "iteration:  50  cost:  0.3353836269622367\n",
      "iteration:  60  cost:  0.3645465184221521\n",
      "iteration:  70  cost:  0.363218958892557\n",
      "iteration:  80  cost:  0.28779898668935633\n",
      "iteration:  90  cost:  0.34890035371694156\n",
      "iteration:  100  cost:  0.37018830567516725\n",
      "iteration:  110  cost:  0.22881955636152912\n",
      "iteration:  120  cost:  0.3663425052375745\n",
      "iteration:  130  cost:  0.34140589541114663\n",
      "iteration:  140  cost:  0.32650150031342906\n",
      "Accuracy for U_TTN resize256 :0.9725768321513002\n",
      "\n",
      "\n",
      "Loss History for Hierarchical circuits, U_TTN pca8\n",
      "iteration:  0  cost:  1.192942287160597\n",
      "iteration:  10  cost:  0.9397208746087911\n",
      "iteration:  20  cost:  0.9340626649607722\n",
      "iteration:  30  cost:  0.6464723823486593\n",
      "iteration:  40  cost:  0.5917567081321288\n",
      "iteration:  50  cost:  0.3968893376531317\n",
      "iteration:  60  cost:  0.5002122333101406\n",
      "iteration:  70  cost:  0.2843849400138483\n",
      "iteration:  80  cost:  0.5154374879806238\n",
      "iteration:  90  cost:  0.35587643607743885\n",
      "iteration:  100  cost:  0.3712263027119317\n",
      "iteration:  110  cost:  0.4092402627625657\n",
      "iteration:  120  cost:  0.43829771624852415\n",
      "iteration:  130  cost:  0.3811871238556319\n",
      "iteration:  140  cost:  0.18692573083671588\n",
      "Accuracy for U_TTN pca8 :0.9626477541371158\n",
      "Epoch 1/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.1043 - val_loss: 0.0359\n",
      "Epoch 2/10\n",
      "396/396 [==============================] - 1s 1ms/step - loss: 0.0327 - val_loss: 0.0269\n",
      "Epoch 3/10\n",
      "396/396 [==============================] - 1s 1ms/step - loss: 0.0262 - val_loss: 0.0239\n",
      "Epoch 4/10\n",
      "396/396 [==============================] - 1s 1ms/step - loss: 0.0235 - val_loss: 0.0218\n",
      "Epoch 5/10\n",
      "396/396 [==============================] - 1s 1ms/step - loss: 0.0214 - val_loss: 0.0204\n",
      "Epoch 6/10\n",
      "396/396 [==============================] - 1s 1ms/step - loss: 0.0207 - val_loss: 0.0196\n",
      "Epoch 7/10\n",
      "396/396 [==============================] - 1s 1ms/step - loss: 0.0197 - val_loss: 0.0191\n",
      "Epoch 8/10\n",
      "396/396 [==============================] - 0s 1ms/step - loss: 0.0191 - val_loss: 0.0185\n",
      "Epoch 9/10\n",
      "396/396 [==============================] - 1s 1ms/step - loss: 0.0187 - val_loss: 0.0181\n",
      "Epoch 10/10\n",
      "396/396 [==============================] - 1s 1ms/step - loss: 0.0185 - val_loss: 0.0178\n",
      "\n",
      "\n",
      "Loss History for Hierarchical circuits, U_TTN autoencoder8\n",
      "iteration:  0  cost:  1.0481457617218775\n",
      "iteration:  10  cost:  0.9826899487347945\n",
      "iteration:  20  cost:  0.7632935361819193\n",
      "iteration:  30  cost:  0.8891064095060851\n",
      "iteration:  40  cost:  0.9344643449803174\n",
      "iteration:  50  cost:  0.8384282202540818\n",
      "iteration:  60  cost:  0.5740680570870086\n",
      "iteration:  70  cost:  0.7166730226576916\n",
      "iteration:  80  cost:  0.7550022268178822\n",
      "iteration:  90  cost:  0.6495169537290313\n",
      "iteration:  100  cost:  0.8034847383490997\n",
      "iteration:  110  cost:  0.7543023264643182\n",
      "iteration:  120  cost:  0.8617818502328034\n",
      "iteration:  130  cost:  0.8068524574930308\n",
      "iteration:  140  cost:  0.617285986409891\n",
      "Accuracy for U_TTN autoencoder8 :0.7881796690307329\n",
      "\n",
      "\n",
      "Loss History for Hierarchical circuits, U_5 resize256\n",
      "iteration:  0  cost:  1.3840053124742733\n",
      "iteration:  10  cost:  0.9349534399769507\n",
      "iteration:  20  cost:  0.9254440491820671\n",
      "iteration:  30  cost:  0.6723456144422723\n",
      "iteration:  40  cost:  0.387809017677337\n",
      "iteration:  50  cost:  0.4312770050953913\n",
      "iteration:  60  cost:  0.3727626382293364\n",
      "iteration:  70  cost:  0.26889908678607044\n",
      "iteration:  80  cost:  0.28907590672463246\n",
      "iteration:  90  cost:  0.25856840415264276\n",
      "iteration:  100  cost:  0.31345702051518226\n",
      "iteration:  110  cost:  0.35361975326837547\n",
      "iteration:  120  cost:  0.3589580982108283\n",
      "iteration:  130  cost:  0.3211170917737658\n",
      "iteration:  140  cost:  0.42346037213735677\n",
      "Accuracy for U_5 resize256 :0.9730496453900709\n",
      "\n",
      "\n",
      "Loss History for Hierarchical circuits, U_5 pca8\n",
      "iteration:  0  cost:  1.0859249039526675\n",
      "iteration:  10  cost:  1.049352259869498\n",
      "iteration:  20  cost:  1.013409168363585\n",
      "iteration:  30  cost:  1.0222296919553673\n",
      "iteration:  40  cost:  0.9583750763316935\n",
      "iteration:  50  cost:  0.9406975760458137\n",
      "iteration:  60  cost:  0.7458655785165175\n",
      "iteration:  70  cost:  0.40401228745600243\n",
      "iteration:  80  cost:  0.36590649130971903\n",
      "iteration:  90  cost:  0.446463772759873\n",
      "iteration:  100  cost:  0.35235385202696107\n",
      "iteration:  110  cost:  0.33731970838736286\n",
      "iteration:  120  cost:  0.25379547457948587\n",
      "iteration:  130  cost:  0.29955555364957187\n",
      "iteration:  140  cost:  0.34005572150317226\n",
      "Accuracy for U_5 pca8 :0.9531914893617022\n",
      "Epoch 1/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.1088 - val_loss: 0.0337\n",
      "Epoch 2/10\n",
      "396/396 [==============================] - 1s 1ms/step - loss: 0.0315 - val_loss: 0.0269\n",
      "Epoch 3/10\n",
      "396/396 [==============================] - 1s 1ms/step - loss: 0.0262 - val_loss: 0.0235\n",
      "Epoch 4/10\n",
      "396/396 [==============================] - 1s 1ms/step - loss: 0.0231 - val_loss: 0.0210\n",
      "Epoch 5/10\n",
      "396/396 [==============================] - 1s 1ms/step - loss: 0.0210 - val_loss: 0.0198\n",
      "Epoch 6/10\n",
      "396/396 [==============================] - 1s 1ms/step - loss: 0.0199 - val_loss: 0.0191\n",
      "Epoch 7/10\n",
      "396/396 [==============================] - 1s 1ms/step - loss: 0.0193 - val_loss: 0.0185\n",
      "Epoch 8/10\n",
      "396/396 [==============================] - 1s 1ms/step - loss: 0.0190 - val_loss: 0.0181\n",
      "Epoch 9/10\n",
      "396/396 [==============================] - 1s 1ms/step - loss: 0.0184 - val_loss: 0.0178\n",
      "Epoch 10/10\n",
      "396/396 [==============================] - 1s 1ms/step - loss: 0.0179 - val_loss: 0.0175\n",
      "\n",
      "\n",
      "Loss History for Hierarchical circuits, U_5 autoencoder8\n",
      "iteration:  0  cost:  1.3373971533697553\n",
      "iteration:  10  cost:  0.9570573149012074\n",
      "iteration:  20  cost:  0.7300390087913331\n",
      "iteration:  30  cost:  0.6781232610809775\n",
      "iteration:  40  cost:  0.7079739608422126\n",
      "iteration:  50  cost:  0.48558014543740513\n",
      "iteration:  60  cost:  0.5886652559478246\n",
      "iteration:  70  cost:  0.5603706890949587\n",
      "iteration:  80  cost:  0.6228046236972142\n",
      "iteration:  90  cost:  0.6169733366071084\n",
      "iteration:  100  cost:  0.5511409416140625\n",
      "iteration:  110  cost:  0.5081005336834111\n",
      "iteration:  120  cost:  0.527666201057366\n",
      "iteration:  130  cost:  0.6635661374463544\n",
      "iteration:  140  cost:  0.4957742545260075\n",
      "Accuracy for U_5 autoencoder8 :0.8373522458628841\n",
      "\n",
      "\n",
      "Loss History for Hierarchical circuits, U_6 resize256\n",
      "iteration:  0  cost:  0.92196787519642\n",
      "iteration:  10  cost:  0.5721220808769619\n",
      "iteration:  20  cost:  0.36082575142661566\n",
      "iteration:  30  cost:  0.3797124507684574\n",
      "iteration:  40  cost:  0.35816090142583057\n",
      "iteration:  50  cost:  0.3520637261875626\n",
      "iteration:  60  cost:  0.2259823220220105\n",
      "iteration:  70  cost:  0.22982863006802645\n",
      "iteration:  80  cost:  0.2601793710693884\n",
      "iteration:  90  cost:  0.15715004433730673\n",
      "iteration:  100  cost:  0.289316567447519\n",
      "iteration:  110  cost:  0.1897443764608438\n",
      "iteration:  120  cost:  0.1661826667724538\n",
      "iteration:  130  cost:  0.15796185916208078\n",
      "iteration:  140  cost:  0.3573414772057054\n",
      "Accuracy for U_6 resize256 :0.9858156028368794\n",
      "\n",
      "\n",
      "Loss History for Hierarchical circuits, U_6 pca8\n",
      "iteration:  0  cost:  1.3687771001189935\n",
      "iteration:  10  cost:  1.0016654683454878\n",
      "iteration:  20  cost:  0.9272889783255515\n",
      "iteration:  30  cost:  0.9578001203548535\n",
      "iteration:  40  cost:  1.1310404346656469\n",
      "iteration:  50  cost:  1.0411623710455364\n",
      "iteration:  60  cost:  0.9112117952491361\n",
      "iteration:  70  cost:  0.9876333833622546\n",
      "iteration:  80  cost:  0.8798385643516273\n",
      "iteration:  90  cost:  0.8122952145798336\n",
      "iteration:  100  cost:  0.4202801466584007\n",
      "iteration:  110  cost:  0.2369689366042186\n",
      "iteration:  120  cost:  0.1105509858699259\n",
      "iteration:  130  cost:  0.19868414948863125\n",
      "iteration:  140  cost:  0.14266961616211055\n",
      "Accuracy for U_6 pca8 :0.9777777777777777\n",
      "Epoch 1/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.1063 - val_loss: 0.0369\n",
      "Epoch 2/10\n",
      "396/396 [==============================] - 1s 1ms/step - loss: 0.0330 - val_loss: 0.0269\n",
      "Epoch 3/10\n",
      "396/396 [==============================] - 1s 1ms/step - loss: 0.0262 - val_loss: 0.0235\n",
      "Epoch 4/10\n",
      "396/396 [==============================] - 1s 1ms/step - loss: 0.0228 - val_loss: 0.0217\n",
      "Epoch 5/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.0216 - val_loss: 0.0207\n",
      "Epoch 6/10\n",
      "396/396 [==============================] - 1s 1ms/step - loss: 0.0208 - val_loss: 0.0200\n",
      "Epoch 7/10\n",
      "396/396 [==============================] - 1s 1ms/step - loss: 0.0201 - val_loss: 0.0195\n",
      "Epoch 8/10\n",
      "396/396 [==============================] - 1s 1ms/step - loss: 0.0196 - val_loss: 0.0189\n",
      "Epoch 9/10\n",
      "396/396 [==============================] - 1s 1ms/step - loss: 0.0191 - val_loss: 0.0185\n",
      "Epoch 10/10\n",
      "396/396 [==============================] - 1s 1ms/step - loss: 0.0188 - val_loss: 0.0181\n",
      "\n",
      "\n",
      "Loss History for Hierarchical circuits, U_6 autoencoder8\n",
      "iteration:  0  cost:  1.5021564827247682\n",
      "iteration:  10  cost:  0.6333631286326008\n",
      "iteration:  20  cost:  0.5282247929217246\n",
      "iteration:  30  cost:  0.5354190013429012\n",
      "iteration:  40  cost:  0.40843531244666403\n",
      "iteration:  50  cost:  0.39792131427303884\n",
      "iteration:  60  cost:  0.5715926043040823\n",
      "iteration:  70  cost:  0.3588568040319775\n",
      "iteration:  80  cost:  0.34619050071107393\n",
      "iteration:  90  cost:  0.4024959500171035\n",
      "iteration:  100  cost:  0.34541499151540545\n",
      "iteration:  110  cost:  0.30925287514617816\n",
      "iteration:  120  cost:  0.5094082823799222\n",
      "iteration:  130  cost:  0.36238073363453643\n",
      "iteration:  140  cost:  0.26985809619558443\n",
      "Accuracy for U_6 autoencoder8 :0.9498817966903074\n",
      "\n",
      "\n",
      "Loss History for Hierarchical circuits, U_13 resize256\n",
      "iteration:  0  cost:  1.125750143233931\n",
      "iteration:  10  cost:  0.8571043901730788\n",
      "iteration:  20  cost:  0.6316216811781991\n",
      "iteration:  30  cost:  0.4487759636571327\n",
      "iteration:  40  cost:  0.3691952197960047\n",
      "iteration:  50  cost:  0.30204103044650127\n",
      "iteration:  60  cost:  0.36200140125763824\n",
      "iteration:  70  cost:  0.3698578402835225\n",
      "iteration:  80  cost:  0.22644870199763006\n",
      "iteration:  90  cost:  0.28102310616880033\n",
      "iteration:  100  cost:  0.3918305857145812\n",
      "iteration:  110  cost:  0.2618811355708579\n",
      "iteration:  120  cost:  0.2586311954799687\n",
      "iteration:  130  cost:  0.33664533964020094\n",
      "iteration:  140  cost:  0.24341941264827593\n",
      "Accuracy for U_13 resize256 :0.9801418439716312\n",
      "\n",
      "\n",
      "Loss History for Hierarchical circuits, U_13 pca8\n",
      "iteration:  0  cost:  1.1114999792809965\n",
      "iteration:  10  cost:  0.9030831689797906\n",
      "iteration:  20  cost:  1.033794364593736\n",
      "iteration:  30  cost:  0.9717888835520285\n",
      "iteration:  40  cost:  0.9652073740626911\n",
      "iteration:  50  cost:  0.984775574702417\n",
      "iteration:  60  cost:  0.8745810311147346\n",
      "iteration:  70  cost:  1.13457384306451\n",
      "iteration:  80  cost:  1.1541299165863579\n",
      "iteration:  90  cost:  1.048444765731951\n",
      "iteration:  100  cost:  0.8694560941756242\n",
      "iteration:  110  cost:  0.8760449027666161\n",
      "iteration:  120  cost:  0.9267918482285614\n",
      "iteration:  130  cost:  0.8281204374118012\n",
      "iteration:  140  cost:  0.7594645484382356\n",
      "Accuracy for U_13 pca8 :0.6647754137115839\n",
      "Epoch 1/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.1103 - val_loss: 0.0369\n",
      "Epoch 2/10\n",
      "396/396 [==============================] - 1s 1ms/step - loss: 0.0341 - val_loss: 0.0268\n",
      "Epoch 3/10\n",
      "396/396 [==============================] - 1s 1ms/step - loss: 0.0261 - val_loss: 0.0234\n",
      "Epoch 4/10\n",
      "396/396 [==============================] - 1s 1ms/step - loss: 0.0230 - val_loss: 0.0216\n",
      "Epoch 5/10\n",
      "396/396 [==============================] - 1s 1ms/step - loss: 0.0215 - val_loss: 0.0203\n",
      "Epoch 6/10\n",
      "396/396 [==============================] - 1s 1ms/step - loss: 0.0206 - val_loss: 0.0195\n",
      "Epoch 7/10\n",
      "396/396 [==============================] - 1s 1ms/step - loss: 0.0198 - val_loss: 0.0189\n",
      "Epoch 8/10\n",
      "396/396 [==============================] - 1s 1ms/step - loss: 0.0192 - val_loss: 0.0184\n",
      "Epoch 9/10\n",
      "396/396 [==============================] - 1s 1ms/step - loss: 0.0187 - val_loss: 0.0180\n",
      "Epoch 10/10\n",
      "396/396 [==============================] - 1s 1ms/step - loss: 0.0185 - val_loss: 0.0178\n",
      "\n",
      "\n",
      "Loss History for Hierarchical circuits, U_13 autoencoder8\n",
      "iteration:  0  cost:  2.0696087787836457\n",
      "iteration:  10  cost:  0.4696326439339982\n",
      "iteration:  20  cost:  0.4941748660527384\n",
      "iteration:  30  cost:  0.3711413488849587\n",
      "iteration:  40  cost:  0.2257659453180033\n",
      "iteration:  50  cost:  0.34636066760748124\n",
      "iteration:  60  cost:  0.2658602257506379\n",
      "iteration:  70  cost:  0.3676642289050212\n",
      "iteration:  80  cost:  0.3570935548310149\n",
      "iteration:  90  cost:  0.24414304273592285\n",
      "iteration:  100  cost:  0.37813818491960055\n",
      "iteration:  110  cost:  0.3000785353971971\n",
      "iteration:  120  cost:  0.21322903963962844\n",
      "iteration:  130  cost:  0.36666866082285027\n",
      "iteration:  140  cost:  0.39512601912755696\n",
      "Accuracy for U_13 autoencoder8 :0.9640661938534278\n",
      "\n",
      "\n",
      "Loss History for Hierarchical circuits, U_14 resize256\n",
      "iteration:  0  cost:  1.0216845010937343\n",
      "iteration:  10  cost:  0.9647170267275285\n",
      "iteration:  20  cost:  0.6076522221816849\n",
      "iteration:  30  cost:  0.48185283679977936\n",
      "iteration:  40  cost:  0.47962785935148916\n",
      "iteration:  50  cost:  0.3481206691202891\n",
      "iteration:  60  cost:  0.44797573384491435\n",
      "iteration:  70  cost:  0.2147049157339651\n",
      "iteration:  80  cost:  0.320851886336526\n",
      "iteration:  90  cost:  0.23065724255151376\n",
      "iteration:  100  cost:  0.2821366946405583\n",
      "iteration:  110  cost:  0.22304724075149995\n",
      "iteration:  120  cost:  0.3708176018124973\n",
      "iteration:  130  cost:  0.17345567970450504\n",
      "iteration:  140  cost:  0.21995049233491934\n",
      "Accuracy for U_14 resize256 :0.9853427895981087\n",
      "\n",
      "\n",
      "Loss History for Hierarchical circuits, U_14 pca8\n",
      "iteration:  0  cost:  1.4073414314260624\n",
      "iteration:  10  cost:  1.0091779508683298\n",
      "iteration:  20  cost:  0.9897776388532167\n",
      "iteration:  30  cost:  0.9993962350821171\n",
      "iteration:  40  cost:  0.9996344308526927\n",
      "iteration:  50  cost:  0.9650482033247247\n",
      "iteration:  60  cost:  1.0009275235643582\n",
      "iteration:  70  cost:  0.9368233773996191\n",
      "iteration:  80  cost:  1.0101372049039792\n",
      "iteration:  90  cost:  0.9210952386502563\n",
      "iteration:  100  cost:  0.9759919344456338\n",
      "iteration:  110  cost:  0.9730684281857964\n",
      "iteration:  120  cost:  0.8769257103030631\n",
      "iteration:  130  cost:  0.8904545276589485\n",
      "iteration:  140  cost:  0.8524931232202266\n",
      "Accuracy for U_14 pca8 :0.6382978723404256\n",
      "Epoch 1/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.1109 - val_loss: 0.0394\n",
      "Epoch 2/10\n",
      "396/396 [==============================] - 1s 1ms/step - loss: 0.0355 - val_loss: 0.0275\n",
      "Epoch 3/10\n",
      "396/396 [==============================] - 1s 1ms/step - loss: 0.0267 - val_loss: 0.0246\n",
      "Epoch 4/10\n",
      "396/396 [==============================] - 1s 1ms/step - loss: 0.0245 - val_loss: 0.0228\n",
      "Epoch 5/10\n",
      "396/396 [==============================] - 1s 1ms/step - loss: 0.0230 - val_loss: 0.0218\n",
      "Epoch 6/10\n",
      "396/396 [==============================] - 1s 1ms/step - loss: 0.0216 - val_loss: 0.0209\n",
      "Epoch 7/10\n",
      "396/396 [==============================] - 1s 1ms/step - loss: 0.0210 - val_loss: 0.0204\n",
      "Epoch 8/10\n",
      "396/396 [==============================] - 1s 1ms/step - loss: 0.0205 - val_loss: 0.0200\n",
      "Epoch 9/10\n",
      "396/396 [==============================] - 1s 1ms/step - loss: 0.0202 - val_loss: 0.0197\n",
      "Epoch 10/10\n",
      "396/396 [==============================] - 1s 1ms/step - loss: 0.0197 - val_loss: 0.0195\n",
      "\n",
      "\n",
      "Loss History for Hierarchical circuits, U_14 autoencoder8\n",
      "iteration:  0  cost:  0.7814781914741918\n",
      "iteration:  10  cost:  0.8302667847849561\n",
      "iteration:  20  cost:  0.629824376991334\n",
      "iteration:  30  cost:  0.6248208766110833\n",
      "iteration:  40  cost:  0.3687680301078104\n",
      "iteration:  50  cost:  0.33942227219372934\n",
      "iteration:  60  cost:  0.31537620262458516\n",
      "iteration:  70  cost:  0.29827325159686097\n",
      "iteration:  80  cost:  0.22286970768403502\n",
      "iteration:  90  cost:  0.27993418895585864\n",
      "iteration:  100  cost:  0.3412419080970494\n",
      "iteration:  110  cost:  0.2715051931246069\n",
      "iteration:  120  cost:  0.2870635837809426\n",
      "iteration:  130  cost:  0.3259898020024212\n",
      "iteration:  140  cost:  0.2698390744132848\n",
      "Accuracy for U_14 autoencoder8 :0.9919621749408983\n",
      "\n",
      "\n",
      "Loss History for Hierarchical circuits, U_15 resize256\n",
      "iteration:  0  cost:  1.2304840058286777\n",
      "iteration:  10  cost:  0.21498916893381484\n",
      "iteration:  20  cost:  0.24906971469985728\n",
      "iteration:  30  cost:  0.22570916657131967\n",
      "iteration:  40  cost:  0.1804490624188677\n",
      "iteration:  50  cost:  0.2242920764269015\n",
      "iteration:  60  cost:  0.17622605799919877\n",
      "iteration:  70  cost:  0.1268153130144278\n",
      "iteration:  80  cost:  0.1839588205353372\n",
      "iteration:  90  cost:  0.15273518514551332\n",
      "iteration:  100  cost:  0.24033946209131588\n",
      "iteration:  110  cost:  0.14011034406823872\n",
      "iteration:  120  cost:  0.21080487922369007\n",
      "iteration:  130  cost:  0.15777608048053982\n",
      "iteration:  140  cost:  0.10636593473428584\n",
      "Accuracy for U_15 resize256 :0.9872340425531915\n",
      "\n",
      "\n",
      "Loss History for Hierarchical circuits, U_15 pca8\n",
      "iteration:  0  cost:  1.0335627454228316\n",
      "iteration:  10  cost:  0.10295159693064951\n",
      "iteration:  20  cost:  0.14696201783288493\n",
      "iteration:  30  cost:  0.17212219173795493\n",
      "iteration:  40  cost:  0.092536248351752\n",
      "iteration:  50  cost:  0.15183738340125624\n",
      "iteration:  60  cost:  0.08666197323816799\n",
      "iteration:  70  cost:  0.1295293167880771\n",
      "iteration:  80  cost:  0.09111309050139488\n",
      "iteration:  90  cost:  0.11997663221617377\n",
      "iteration:  100  cost:  0.10761569954919369\n",
      "iteration:  110  cost:  0.16330321084113109\n",
      "iteration:  120  cost:  0.08882557882447191\n",
      "iteration:  130  cost:  0.1566437524381236\n",
      "iteration:  140  cost:  0.10771234245003125\n",
      "Accuracy for U_15 pca8 :0.9858156028368794\n",
      "Epoch 1/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.1075 - val_loss: 0.0338\n",
      "Epoch 2/10\n",
      "396/396 [==============================] - 1s 1ms/step - loss: 0.0313 - val_loss: 0.0268\n",
      "Epoch 3/10\n",
      "396/396 [==============================] - 1s 1ms/step - loss: 0.0263 - val_loss: 0.0237\n",
      "Epoch 4/10\n",
      "396/396 [==============================] - 1s 1ms/step - loss: 0.0236 - val_loss: 0.0215\n",
      "Epoch 5/10\n",
      "396/396 [==============================] - 1s 1ms/step - loss: 0.0217 - val_loss: 0.0202\n",
      "Epoch 6/10\n",
      "396/396 [==============================] - 1s 1ms/step - loss: 0.0202 - val_loss: 0.0195\n",
      "Epoch 7/10\n",
      "396/396 [==============================] - 1s 1ms/step - loss: 0.0194 - val_loss: 0.0189\n",
      "Epoch 8/10\n",
      "396/396 [==============================] - 1s 1ms/step - loss: 0.0191 - val_loss: 0.0185\n",
      "Epoch 9/10\n",
      "396/396 [==============================] - 1s 1ms/step - loss: 0.0188 - val_loss: 0.0181\n",
      "Epoch 10/10\n",
      "396/396 [==============================] - 1s 1ms/step - loss: 0.0184 - val_loss: 0.0179\n",
      "\n",
      "\n",
      "Loss History for Hierarchical circuits, U_15 autoencoder8\n",
      "iteration:  0  cost:  1.2597760510181957\n",
      "iteration:  10  cost:  0.4311901618959943\n",
      "iteration:  20  cost:  0.34619691396436203\n",
      "iteration:  30  cost:  0.2767839418836902\n",
      "iteration:  40  cost:  0.2871244031486656\n",
      "iteration:  50  cost:  0.2470258512793959\n",
      "iteration:  60  cost:  0.2400721158969688\n",
      "iteration:  70  cost:  0.16010960252342574\n",
      "iteration:  80  cost:  0.21879704100840625\n",
      "iteration:  90  cost:  0.23736044172492338\n",
      "iteration:  100  cost:  0.13944693827081397\n",
      "iteration:  110  cost:  0.24144531219139131\n",
      "iteration:  120  cost:  0.21429059333729975\n",
      "iteration:  130  cost:  0.2165473824586805\n",
      "iteration:  140  cost:  0.20846900157125167\n",
      "Accuracy for U_15 autoencoder8 :0.9867612293144208\n",
      "\n",
      "\n",
      "Loss History for Hierarchical circuits, U_SO4 resize256\n",
      "iteration:  0  cost:  1.3752290421880842\n",
      "iteration:  10  cost:  0.44095527777912463\n",
      "iteration:  20  cost:  0.2865995606257854\n",
      "iteration:  30  cost:  0.42630819737985887\n",
      "iteration:  40  cost:  0.502887222304236\n",
      "iteration:  50  cost:  0.24607009854626172\n",
      "iteration:  60  cost:  0.18718957200129233\n",
      "iteration:  70  cost:  0.3323544184516145\n",
      "iteration:  80  cost:  0.2321603585391624\n",
      "iteration:  90  cost:  0.26938906393315637\n",
      "iteration:  100  cost:  0.41401193973206935\n",
      "iteration:  110  cost:  0.17439966682998878\n",
      "iteration:  120  cost:  0.3693203188592885\n",
      "iteration:  130  cost:  0.32778738614252734\n",
      "iteration:  140  cost:  0.32312382886746716\n",
      "Accuracy for U_SO4 resize256 :0.9380614657210402\n",
      "\n",
      "\n",
      "Loss History for Hierarchical circuits, U_SO4 pca8\n",
      "iteration:  0  cost:  0.8603640826675455\n",
      "iteration:  10  cost:  0.3102411821887518\n",
      "iteration:  20  cost:  0.1001718542478652\n",
      "iteration:  30  cost:  0.11912546211458615\n",
      "iteration:  40  cost:  0.2786370421668863\n",
      "iteration:  50  cost:  0.22265414187700308\n",
      "iteration:  60  cost:  0.11251306604363025\n",
      "iteration:  70  cost:  0.1293234027968378\n",
      "iteration:  80  cost:  0.114173564336874\n",
      "iteration:  90  cost:  0.18139640625918646\n",
      "iteration:  100  cost:  0.23805937184835355\n",
      "iteration:  110  cost:  0.13608991356402456\n",
      "iteration:  120  cost:  0.12899097800955045\n",
      "iteration:  130  cost:  0.28395524367675645\n",
      "iteration:  140  cost:  0.2664913663978173\n",
      "Accuracy for U_SO4 pca8 :0.983451536643026\n",
      "Epoch 1/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.1103 - val_loss: 0.0345\n",
      "Epoch 2/10\n",
      "396/396 [==============================] - 1s 1ms/step - loss: 0.0323 - val_loss: 0.0275\n",
      "Epoch 3/10\n",
      "396/396 [==============================] - 1s 1ms/step - loss: 0.0270 - val_loss: 0.0245\n",
      "Epoch 4/10\n",
      "396/396 [==============================] - 1s 1ms/step - loss: 0.0238 - val_loss: 0.0221\n",
      "Epoch 5/10\n",
      "396/396 [==============================] - 1s 1ms/step - loss: 0.0219 - val_loss: 0.0207\n",
      "Epoch 6/10\n",
      "396/396 [==============================] - 1s 1ms/step - loss: 0.0207 - val_loss: 0.0198\n",
      "Epoch 7/10\n",
      "396/396 [==============================] - 1s 1ms/step - loss: 0.0200 - val_loss: 0.0193\n",
      "Epoch 8/10\n",
      "396/396 [==============================] - 1s 1ms/step - loss: 0.0196 - val_loss: 0.0187\n",
      "Epoch 9/10\n",
      "396/396 [==============================] - 1s 1ms/step - loss: 0.0189 - val_loss: 0.0184\n",
      "Epoch 10/10\n",
      "396/396 [==============================] - 1s 1ms/step - loss: 0.0186 - val_loss: 0.0181\n",
      "\n",
      "\n",
      "Loss History for Hierarchical circuits, U_SO4 autoencoder8\n",
      "iteration:  0  cost:  0.7522573785608492\n",
      "iteration:  10  cost:  0.5735613049925671\n",
      "iteration:  20  cost:  0.23553740913536975\n",
      "iteration:  30  cost:  0.34967996549144914\n",
      "iteration:  40  cost:  0.23861658872669228\n",
      "iteration:  50  cost:  0.19694644079497706\n",
      "iteration:  60  cost:  0.25118096172311705\n",
      "iteration:  70  cost:  0.28519699185780584\n",
      "iteration:  80  cost:  0.3629850239937632\n",
      "iteration:  90  cost:  0.20643977234660127\n",
      "iteration:  100  cost:  0.24612677716177894\n",
      "iteration:  110  cost:  0.18453361428398707\n",
      "iteration:  120  cost:  0.1695152644925448\n",
      "iteration:  130  cost:  0.21943015201998115\n",
      "iteration:  140  cost:  0.19720557876791056\n",
      "Accuracy for U_SO4 autoencoder8 :0.9839243498817967\n",
      "1th step : \n",
      "\n",
      "\n",
      "Loss History for Hierarchical circuits, U_TTN resize256\n",
      "iteration:  0  cost:  1.036903898591478\n",
      "iteration:  10  cost:  0.6457070852405847\n",
      "iteration:  20  cost:  0.46745314311967895\n",
      "iteration:  30  cost:  0.5102120755334189\n",
      "iteration:  40  cost:  0.3076256062165281\n",
      "iteration:  50  cost:  0.5411279040476151\n",
      "iteration:  60  cost:  0.42863492909069356\n",
      "iteration:  70  cost:  0.5517072483272112\n",
      "iteration:  80  cost:  0.2641662446016389\n",
      "iteration:  90  cost:  0.40666119870050216\n",
      "iteration:  100  cost:  0.44246001560889586\n",
      "iteration:  110  cost:  0.34857834399388976\n",
      "iteration:  120  cost:  0.25359963644458433\n",
      "iteration:  130  cost:  0.25811239043036344\n",
      "iteration:  140  cost:  0.23758616779136074\n",
      "Accuracy for U_TTN resize256 :0.9706855791962175\n",
      "\n",
      "\n",
      "Loss History for Hierarchical circuits, U_TTN pca8\n",
      "iteration:  0  cost:  1.5366113978305833\n",
      "iteration:  10  cost:  0.4977942908717192\n",
      "iteration:  20  cost:  0.49677659122559525\n",
      "iteration:  30  cost:  0.4873333792998138\n",
      "iteration:  40  cost:  0.44151585329769966\n",
      "iteration:  50  cost:  0.31574942658014615\n",
      "iteration:  60  cost:  0.46355483984887236\n",
      "iteration:  70  cost:  0.43922471145446096\n",
      "iteration:  80  cost:  0.32887264176140896\n",
      "iteration:  90  cost:  0.3160106445109516\n",
      "iteration:  100  cost:  0.36156467736547704\n",
      "iteration:  110  cost:  0.31418054826927416\n",
      "iteration:  120  cost:  0.4628041541195238\n",
      "iteration:  130  cost:  0.3500928142296796\n",
      "iteration:  140  cost:  0.3513389618903574\n",
      "Accuracy for U_TTN pca8 :0.9692671394799054\n",
      "Epoch 1/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.1097 - val_loss: 0.0350\n",
      "Epoch 2/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.0323 - val_loss: 0.0271\n",
      "Epoch 3/10\n",
      "396/396 [==============================] - 1s 1ms/step - loss: 0.0265 - val_loss: 0.0238\n",
      "Epoch 4/10\n",
      "396/396 [==============================] - 1s 1ms/step - loss: 0.0234 - val_loss: 0.0219\n",
      "Epoch 5/10\n",
      "396/396 [==============================] - 1s 1ms/step - loss: 0.0219 - val_loss: 0.0208\n",
      "Epoch 6/10\n",
      "396/396 [==============================] - 1s 1ms/step - loss: 0.0208 - val_loss: 0.0199\n",
      "Epoch 7/10\n",
      "396/396 [==============================] - 1s 1ms/step - loss: 0.0198 - val_loss: 0.0192\n",
      "Epoch 8/10\n",
      "396/396 [==============================] - 1s 1ms/step - loss: 0.0191 - val_loss: 0.0187\n",
      "Epoch 9/10\n",
      "396/396 [==============================] - 1s 1ms/step - loss: 0.0187 - val_loss: 0.0183\n",
      "Epoch 10/10\n",
      "396/396 [==============================] - 1s 1ms/step - loss: 0.0182 - val_loss: 0.0181\n",
      "\n",
      "\n",
      "Loss History for Hierarchical circuits, U_TTN autoencoder8\n",
      "iteration:  0  cost:  1.122213985997284\n",
      "iteration:  10  cost:  0.8146120661183746\n",
      "iteration:  20  cost:  0.5311890548809829\n",
      "iteration:  30  cost:  0.484553714823773\n",
      "iteration:  40  cost:  0.4070669244888772\n",
      "iteration:  50  cost:  0.2880650743785607\n",
      "iteration:  60  cost:  0.4486622787549722\n",
      "iteration:  70  cost:  0.3151509728133901\n",
      "iteration:  80  cost:  0.3740892539085852\n",
      "iteration:  90  cost:  0.4965655473110384\n",
      "iteration:  100  cost:  0.31661835606949784\n",
      "iteration:  110  cost:  0.3282041145947296\n",
      "iteration:  120  cost:  0.3427572870682232\n",
      "iteration:  130  cost:  0.3397082358866357\n",
      "iteration:  140  cost:  0.42930363588384923\n",
      "Accuracy for U_TTN autoencoder8 :0.9749408983451536\n",
      "\n",
      "\n",
      "Loss History for Hierarchical circuits, U_5 resize256\n",
      "iteration:  0  cost:  1.5136195965271215\n",
      "iteration:  10  cost:  1.0207596516509077\n",
      "iteration:  20  cost:  1.0094780670895478\n",
      "iteration:  30  cost:  1.0093040673770268\n",
      "iteration:  40  cost:  1.0231452719897325\n",
      "iteration:  50  cost:  1.009006842487466\n",
      "iteration:  60  cost:  1.029208171912498\n",
      "iteration:  70  cost:  1.0116921453244856\n",
      "iteration:  80  cost:  0.9913745332764458\n",
      "iteration:  90  cost:  0.9796981010922198\n",
      "iteration:  100  cost:  0.9678188685191504\n",
      "iteration:  110  cost:  0.9442268109243159\n",
      "iteration:  120  cost:  0.9523720410487099\n",
      "iteration:  130  cost:  0.9357207209041819\n",
      "iteration:  140  cost:  0.9078333060134202\n",
      "Accuracy for U_5 resize256 :0.5947990543735224\n",
      "\n",
      "\n",
      "Loss History for Hierarchical circuits, U_5 pca8\n",
      "iteration:  0  cost:  1.0902788157724468\n",
      "iteration:  10  cost:  0.9749856678871499\n",
      "iteration:  20  cost:  1.0009406452097185\n",
      "iteration:  30  cost:  0.9885457198946643\n",
      "iteration:  40  cost:  1.0454594381879128\n",
      "iteration:  50  cost:  0.9672445082316327\n",
      "iteration:  60  cost:  1.0421729510224629\n",
      "iteration:  70  cost:  0.9351487240614814\n",
      "iteration:  80  cost:  0.999319805648486\n",
      "iteration:  90  cost:  0.9713385794413334\n",
      "iteration:  100  cost:  0.9416404570926283\n",
      "iteration:  110  cost:  0.9894645658319936\n",
      "iteration:  120  cost:  0.9397184979060021\n",
      "iteration:  130  cost:  0.9629482612084383\n",
      "iteration:  140  cost:  0.9735861296693135\n",
      "Accuracy for U_5 pca8 :0.6392434988179669\n",
      "Epoch 1/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.1094 - val_loss: 0.0325\n",
      "Epoch 2/10\n",
      "396/396 [==============================] - 1s 1ms/step - loss: 0.0305 - val_loss: 0.0268\n",
      "Epoch 3/10\n",
      "396/396 [==============================] - 1s 1ms/step - loss: 0.0264 - val_loss: 0.0241\n",
      "Epoch 4/10\n",
      "396/396 [==============================] - 1s 1ms/step - loss: 0.0239 - val_loss: 0.0221\n",
      "Epoch 5/10\n",
      "396/396 [==============================] - 1s 1ms/step - loss: 0.0223 - val_loss: 0.0206\n",
      "Epoch 6/10\n",
      "396/396 [==============================] - 1s 1ms/step - loss: 0.0206 - val_loss: 0.0196\n",
      "Epoch 7/10\n",
      "396/396 [==============================] - 1s 1ms/step - loss: 0.0196 - val_loss: 0.0186\n",
      "Epoch 8/10\n",
      "396/396 [==============================] - 1s 1ms/step - loss: 0.0190 - val_loss: 0.0180\n",
      "Epoch 9/10\n",
      "396/396 [==============================] - 1s 1ms/step - loss: 0.0185 - val_loss: 0.0177\n",
      "Epoch 10/10\n",
      "396/396 [==============================] - 1s 1ms/step - loss: 0.0179 - val_loss: 0.0173\n",
      "\n",
      "\n",
      "Loss History for Hierarchical circuits, U_5 autoencoder8\n",
      "iteration:  0  cost:  1.4625604026335273\n",
      "iteration:  10  cost:  0.3397889304629597\n",
      "iteration:  20  cost:  0.5620668865788925\n",
      "iteration:  30  cost:  0.34442806107515106\n",
      "iteration:  40  cost:  0.3699703456405672\n",
      "iteration:  50  cost:  0.30413805296551866\n",
      "iteration:  60  cost:  0.2902217532473359\n",
      "iteration:  70  cost:  0.3314304959475887\n",
      "iteration:  80  cost:  0.3395567696713463\n",
      "iteration:  90  cost:  0.4796761277813388\n",
      "iteration:  100  cost:  0.2634835902600321\n",
      "iteration:  110  cost:  0.2927604425135807\n",
      "iteration:  120  cost:  0.39452998589221644\n",
      "iteration:  130  cost:  0.4297653327964622\n",
      "iteration:  140  cost:  0.2721530964429339\n",
      "Accuracy for U_5 autoencoder8 :0.9631205673758865\n",
      "\n",
      "\n",
      "Loss History for Hierarchical circuits, U_6 resize256\n",
      "iteration:  0  cost:  0.88285875302379\n",
      "iteration:  10  cost:  1.0405100499464772\n",
      "iteration:  20  cost:  0.7853740026082572\n",
      "iteration:  30  cost:  0.48264431558923604\n",
      "iteration:  40  cost:  0.4503911671654048\n",
      "iteration:  50  cost:  0.31674700036037523\n",
      "iteration:  60  cost:  0.28557118726962055\n",
      "iteration:  70  cost:  0.2040383977298805\n",
      "iteration:  80  cost:  0.24587622025474964\n",
      "iteration:  90  cost:  0.2870520558896855\n",
      "iteration:  100  cost:  0.28030923086599246\n",
      "iteration:  110  cost:  0.21007771722395469\n",
      "iteration:  120  cost:  0.22471217742986632\n",
      "iteration:  130  cost:  0.24495792300696892\n",
      "iteration:  140  cost:  0.22525105070112394\n",
      "Accuracy for U_6 resize256 :0.9796690307328605\n",
      "\n",
      "\n",
      "Loss History for Hierarchical circuits, U_6 pca8\n",
      "iteration:  0  cost:  1.2311520415017068\n",
      "iteration:  10  cost:  1.0150973791864037\n",
      "iteration:  20  cost:  0.98222527317361\n",
      "iteration:  30  cost:  1.0136855233226627\n",
      "iteration:  40  cost:  0.8523204810280793\n",
      "iteration:  50  cost:  0.9000922005418276\n",
      "iteration:  60  cost:  0.9591279302093244\n",
      "iteration:  70  cost:  0.9552378611251371\n",
      "iteration:  80  cost:  0.8634612165184632\n",
      "iteration:  90  cost:  0.684602899018828\n",
      "iteration:  100  cost:  0.41119017652073436\n",
      "iteration:  110  cost:  0.4192626914698455\n",
      "iteration:  120  cost:  0.2885958902212697\n",
      "iteration:  130  cost:  0.21484701954505758\n",
      "iteration:  140  cost:  0.37700462661576933\n",
      "Accuracy for U_6 pca8 :0.9541371158392435\n",
      "Epoch 1/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.1068 - val_loss: 0.0347\n",
      "Epoch 2/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.0321 - val_loss: 0.0269\n",
      "Epoch 3/10\n",
      "396/396 [==============================] - 1s 1ms/step - loss: 0.0262 - val_loss: 0.0237\n",
      "Epoch 4/10\n",
      "396/396 [==============================] - 1s 1ms/step - loss: 0.0235 - val_loss: 0.0219\n",
      "Epoch 5/10\n",
      "396/396 [==============================] - 1s 1ms/step - loss: 0.0217 - val_loss: 0.0207\n",
      "Epoch 6/10\n",
      "396/396 [==============================] - 1s 1ms/step - loss: 0.0205 - val_loss: 0.0198\n",
      "Epoch 7/10\n",
      "396/396 [==============================] - 1s 1ms/step - loss: 0.0200 - val_loss: 0.0192\n",
      "Epoch 8/10\n",
      "396/396 [==============================] - 1s 1ms/step - loss: 0.0195 - val_loss: 0.0187\n",
      "Epoch 9/10\n",
      "396/396 [==============================] - 1s 1ms/step - loss: 0.0188 - val_loss: 0.0183\n",
      "Epoch 10/10\n",
      "396/396 [==============================] - 1s 1ms/step - loss: 0.0185 - val_loss: 0.0181\n",
      "\n",
      "\n",
      "Loss History for Hierarchical circuits, U_6 autoencoder8\n",
      "iteration:  0  cost:  1.1325946794581399\n",
      "iteration:  10  cost:  0.7291384612220368\n",
      "iteration:  20  cost:  0.3877574370853106\n",
      "iteration:  30  cost:  0.46111434970547704\n",
      "iteration:  40  cost:  0.502643073396895\n",
      "iteration:  50  cost:  0.4430659215059737\n",
      "iteration:  60  cost:  0.3209322199097451\n",
      "iteration:  70  cost:  0.35829387830962267\n",
      "iteration:  80  cost:  0.28680040439293697\n",
      "iteration:  90  cost:  0.2119508662618602\n",
      "iteration:  100  cost:  0.2879228187408731\n",
      "iteration:  110  cost:  0.1792957813255852\n",
      "iteration:  120  cost:  0.21461938571755035\n",
      "iteration:  130  cost:  0.23555222279855428\n",
      "iteration:  140  cost:  0.27487039144864533\n",
      "Accuracy for U_6 autoencoder8 :0.9952718676122931\n",
      "\n",
      "\n",
      "Loss History for Hierarchical circuits, U_13 resize256\n",
      "iteration:  0  cost:  1.1869029491649004\n",
      "iteration:  10  cost:  0.9037670825512639\n",
      "iteration:  20  cost:  0.9238278216515394\n",
      "iteration:  30  cost:  0.9155426392242555\n",
      "iteration:  40  cost:  0.8999345747040686\n",
      "iteration:  50  cost:  0.8890000228467722\n",
      "iteration:  60  cost:  0.6248886146262015\n",
      "iteration:  70  cost:  0.49033832377989556\n",
      "iteration:  80  cost:  0.47724422801167493\n",
      "iteration:  90  cost:  0.36871277886142445\n",
      "iteration:  100  cost:  0.34368273013849465\n",
      "iteration:  110  cost:  0.1966541932582776\n",
      "iteration:  120  cost:  0.37032224283592613\n",
      "iteration:  130  cost:  0.32052855193243845\n",
      "iteration:  140  cost:  0.31527175429547927\n",
      "Accuracy for U_13 resize256 :0.9791962174940898\n",
      "\n",
      "\n",
      "Loss History for Hierarchical circuits, U_13 pca8\n",
      "iteration:  0  cost:  1.0699870944888392\n",
      "iteration:  10  cost:  1.0702524082709657\n",
      "iteration:  20  cost:  0.9427298121092521\n",
      "iteration:  30  cost:  1.0396174856137501\n",
      "iteration:  40  cost:  0.9566925662046029\n",
      "iteration:  50  cost:  0.8990473563622724\n",
      "iteration:  60  cost:  0.9164374363639696\n",
      "iteration:  70  cost:  1.1006515709778293\n",
      "iteration:  80  cost:  0.8947055884641602\n",
      "iteration:  90  cost:  0.8923475390526896\n",
      "iteration:  100  cost:  0.7772598710782931\n",
      "iteration:  110  cost:  0.4085600522400908\n",
      "iteration:  120  cost:  0.44786885725464587\n",
      "iteration:  130  cost:  0.24408446603918932\n",
      "iteration:  140  cost:  0.34856835961879695\n",
      "Accuracy for U_13 pca8 :0.9569739952718677\n",
      "Epoch 1/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.1088 - val_loss: 0.0390\n",
      "Epoch 2/10\n",
      "396/396 [==============================] - 1s 1ms/step - loss: 0.0354 - val_loss: 0.0280\n",
      "Epoch 3/10\n",
      "396/396 [==============================] - 1s 1ms/step - loss: 0.0277 - val_loss: 0.0257\n",
      "Epoch 4/10\n",
      "396/396 [==============================] - 1s 1ms/step - loss: 0.0254 - val_loss: 0.0238\n",
      "Epoch 5/10\n",
      "396/396 [==============================] - 1s 1ms/step - loss: 0.0237 - val_loss: 0.0223\n",
      "Epoch 6/10\n",
      "396/396 [==============================] - 1s 1ms/step - loss: 0.0222 - val_loss: 0.0212\n",
      "Epoch 7/10\n",
      "396/396 [==============================] - 1s 1ms/step - loss: 0.0213 - val_loss: 0.0204\n",
      "Epoch 8/10\n",
      "396/396 [==============================] - 1s 1ms/step - loss: 0.0205 - val_loss: 0.0200\n",
      "Epoch 9/10\n",
      "396/396 [==============================] - 1s 1ms/step - loss: 0.0200 - val_loss: 0.0196\n",
      "Epoch 10/10\n",
      "396/396 [==============================] - 1s 1ms/step - loss: 0.0199 - val_loss: 0.0194\n",
      "\n",
      "\n",
      "Loss History for Hierarchical circuits, U_13 autoencoder8\n",
      "iteration:  0  cost:  1.8084737413243397\n",
      "iteration:  10  cost:  0.6656684226148382\n",
      "iteration:  20  cost:  0.6038395931542117\n",
      "iteration:  30  cost:  0.5495021847326794\n",
      "iteration:  40  cost:  0.6120706006273153\n",
      "iteration:  50  cost:  0.42025156667119307\n",
      "iteration:  60  cost:  0.4486246829417471\n",
      "iteration:  70  cost:  0.31267198808796876\n",
      "iteration:  80  cost:  0.32013409587865466\n",
      "iteration:  90  cost:  0.2945900430082001\n",
      "iteration:  100  cost:  0.37602049551204575\n",
      "iteration:  110  cost:  0.3764615627714909\n",
      "iteration:  120  cost:  0.43381338831724797\n",
      "iteration:  130  cost:  0.19597485186375585\n",
      "iteration:  140  cost:  0.2679393890829088\n",
      "Accuracy for U_13 autoencoder8 :0.9229314420803783\n",
      "\n",
      "\n",
      "Loss History for Hierarchical circuits, U_14 resize256\n",
      "iteration:  0  cost:  1.2015865223363555\n",
      "iteration:  10  cost:  0.6806690782493472\n",
      "iteration:  20  cost:  0.5443826441971302\n",
      "iteration:  30  cost:  0.6121219990751393\n",
      "iteration:  40  cost:  0.3901734316893078\n",
      "iteration:  50  cost:  0.3588297846948739\n",
      "iteration:  60  cost:  0.280020680383603\n",
      "iteration:  70  cost:  0.30669154842874236\n",
      "iteration:  80  cost:  0.3915518068357076\n",
      "iteration:  90  cost:  0.3490938782177343\n",
      "iteration:  100  cost:  0.3324162586351904\n",
      "iteration:  110  cost:  0.36383241127733074\n",
      "iteration:  120  cost:  0.2646745555865801\n",
      "iteration:  130  cost:  0.44114463456043196\n",
      "iteration:  140  cost:  0.22759175034308107\n",
      "Accuracy for U_14 resize256 :0.9475177304964539\n",
      "\n",
      "\n",
      "Loss History for Hierarchical circuits, U_14 pca8\n",
      "iteration:  0  cost:  1.1238816188350989\n",
      "iteration:  10  cost:  1.1677059704092005\n",
      "iteration:  20  cost:  1.058615265905905\n",
      "iteration:  30  cost:  1.0128999185546208\n",
      "iteration:  40  cost:  0.9977426539666616\n",
      "iteration:  50  cost:  1.0131120068980461\n",
      "iteration:  60  cost:  1.0289770619340541\n",
      "iteration:  70  cost:  0.898045092220266\n",
      "iteration:  80  cost:  0.9672695326876191\n",
      "iteration:  90  cost:  0.9540812405646893\n",
      "iteration:  100  cost:  1.008803615288943\n",
      "iteration:  110  cost:  0.9664295695180831\n",
      "iteration:  120  cost:  0.9451605104684573\n",
      "iteration:  130  cost:  0.8615577114814177\n",
      "iteration:  140  cost:  0.9146855275239293\n",
      "Accuracy for U_14 pca8 :0.7423167848699763\n",
      "Epoch 1/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.1066 - val_loss: 0.0350\n",
      "Epoch 2/10\n",
      "396/396 [==============================] - 1s 1ms/step - loss: 0.0326 - val_loss: 0.0269\n",
      "Epoch 3/10\n",
      "396/396 [==============================] - 1s 1ms/step - loss: 0.0265 - val_loss: 0.0238\n",
      "Epoch 4/10\n",
      "396/396 [==============================] - 1s 1ms/step - loss: 0.0234 - val_loss: 0.0220\n",
      "Epoch 5/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.0218 - val_loss: 0.0206\n",
      "Epoch 6/10\n",
      "396/396 [==============================] - 1s 1ms/step - loss: 0.0206 - val_loss: 0.0197\n",
      "Epoch 7/10\n",
      "396/396 [==============================] - 1s 1ms/step - loss: 0.0198 - val_loss: 0.0190\n",
      "Epoch 8/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.0191 - val_loss: 0.0185\n",
      "Epoch 9/10\n",
      "396/396 [==============================] - 1s 1ms/step - loss: 0.0186 - val_loss: 0.0182\n",
      "Epoch 10/10\n",
      "396/396 [==============================] - 1s 1ms/step - loss: 0.0182 - val_loss: 0.0178\n",
      "\n",
      "\n",
      "Loss History for Hierarchical circuits, U_14 autoencoder8\n",
      "iteration:  0  cost:  0.7685299457927068\n",
      "iteration:  10  cost:  0.32756300466760285\n",
      "iteration:  20  cost:  0.35264920949460404\n",
      "iteration:  30  cost:  0.2654065223100958\n",
      "iteration:  40  cost:  0.40912391876360343\n",
      "iteration:  50  cost:  0.2953324973050329\n",
      "iteration:  60  cost:  0.2745067991656784\n",
      "iteration:  70  cost:  0.20997756282615884\n",
      "iteration:  80  cost:  0.4279896865605549\n",
      "iteration:  90  cost:  0.27590549519933594\n",
      "iteration:  100  cost:  0.23167509331281824\n",
      "iteration:  110  cost:  0.28413124252273114\n",
      "iteration:  120  cost:  0.27575101078240233\n",
      "iteration:  130  cost:  0.24937398458952653\n",
      "iteration:  140  cost:  0.1778964105567925\n",
      "Accuracy for U_14 autoencoder8 :0.9498817966903074\n",
      "\n",
      "\n",
      "Loss History for Hierarchical circuits, U_15 resize256\n",
      "iteration:  0  cost:  1.168492552381699\n",
      "iteration:  10  cost:  0.3521573814306639\n",
      "iteration:  20  cost:  0.16337561030801162\n",
      "iteration:  30  cost:  0.1253124636667254\n",
      "iteration:  40  cost:  0.1667566520802879\n",
      "iteration:  50  cost:  0.316994966040075\n",
      "iteration:  60  cost:  0.16897976954716964\n",
      "iteration:  70  cost:  0.14102210117247563\n",
      "iteration:  80  cost:  0.2728363580307241\n",
      "iteration:  90  cost:  0.1803693697192311\n",
      "iteration:  100  cost:  0.23328238718596025\n",
      "iteration:  110  cost:  0.18717352576354418\n",
      "iteration:  120  cost:  0.12967292794124471\n",
      "iteration:  130  cost:  0.15303282068907387\n",
      "iteration:  140  cost:  0.19574723323382945\n",
      "Accuracy for U_15 resize256 :0.9895981087470449\n",
      "\n",
      "\n",
      "Loss History for Hierarchical circuits, U_15 pca8\n",
      "iteration:  0  cost:  1.3750738940171303\n",
      "iteration:  10  cost:  0.7269467965914737\n",
      "iteration:  20  cost:  0.24171094142320362\n",
      "iteration:  30  cost:  0.1305392190276851\n",
      "iteration:  40  cost:  0.16897856147476722\n",
      "iteration:  50  cost:  0.14567429635942974\n",
      "iteration:  60  cost:  0.2631729470713397\n",
      "iteration:  70  cost:  0.28417157025666484\n",
      "iteration:  80  cost:  0.11556019797486554\n",
      "iteration:  90  cost:  0.16966240988935713\n",
      "iteration:  100  cost:  0.12688227077430067\n",
      "iteration:  110  cost:  0.16600815778057018\n",
      "iteration:  120  cost:  0.1531385838041317\n",
      "iteration:  130  cost:  0.1260651941960365\n",
      "iteration:  140  cost:  0.15131779185563812\n",
      "Accuracy for U_15 pca8 :0.9843971631205674\n",
      "Epoch 1/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.1067 - val_loss: 0.0359\n",
      "Epoch 2/10\n",
      "396/396 [==============================] - 1s 1ms/step - loss: 0.0328 - val_loss: 0.0270\n",
      "Epoch 3/10\n",
      "396/396 [==============================] - 1s 1ms/step - loss: 0.0265 - val_loss: 0.0234\n",
      "Epoch 4/10\n",
      "396/396 [==============================] - 1s 1ms/step - loss: 0.0230 - val_loss: 0.0214\n",
      "Epoch 5/10\n",
      "396/396 [==============================] - 1s 1ms/step - loss: 0.0212 - val_loss: 0.0200\n",
      "Epoch 6/10\n",
      "396/396 [==============================] - 1s 1ms/step - loss: 0.0202 - val_loss: 0.0191\n",
      "Epoch 7/10\n",
      "396/396 [==============================] - 1s 1ms/step - loss: 0.0193 - val_loss: 0.0184\n",
      "Epoch 8/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.0186 - val_loss: 0.0180\n",
      "Epoch 9/10\n",
      "396/396 [==============================] - 1s 1ms/step - loss: 0.0181 - val_loss: 0.0177\n",
      "Epoch 10/10\n",
      "396/396 [==============================] - 1s 1ms/step - loss: 0.0179 - val_loss: 0.0175\n",
      "\n",
      "\n",
      "Loss History for Hierarchical circuits, U_15 autoencoder8\n",
      "iteration:  0  cost:  1.1494962329842766\n",
      "iteration:  10  cost:  0.4598293347635237\n",
      "iteration:  20  cost:  0.1564242734805757\n",
      "iteration:  30  cost:  0.23894567180290568\n",
      "iteration:  40  cost:  0.31755589019416314\n",
      "iteration:  50  cost:  0.2920626026509914\n",
      "iteration:  60  cost:  0.11467399853233591\n",
      "iteration:  70  cost:  0.1646447336874762\n",
      "iteration:  80  cost:  0.15554091371610912\n",
      "iteration:  90  cost:  0.17251757851413038\n",
      "iteration:  100  cost:  0.2194894121280827\n",
      "iteration:  110  cost:  0.1032705154588105\n",
      "iteration:  120  cost:  0.16277062093681238\n",
      "iteration:  130  cost:  0.25758387165215846\n",
      "iteration:  140  cost:  0.28415044212098145\n",
      "Accuracy for U_15 autoencoder8 :0.9654846335697399\n",
      "\n",
      "\n",
      "Loss History for Hierarchical circuits, U_SO4 resize256\n",
      "iteration:  0  cost:  1.0493726158189447\n",
      "iteration:  10  cost:  0.7917686224865119\n",
      "iteration:  20  cost:  0.5038975170547205\n",
      "iteration:  30  cost:  0.35987432175670875\n",
      "iteration:  40  cost:  0.19474453311353465\n",
      "iteration:  50  cost:  0.24312248859692517\n",
      "iteration:  60  cost:  0.22938786954007193\n",
      "iteration:  70  cost:  0.2416612157609919\n",
      "iteration:  80  cost:  0.2797858207653023\n",
      "iteration:  90  cost:  0.16869945340898723\n",
      "iteration:  100  cost:  0.30119754092847356\n",
      "iteration:  110  cost:  0.17014413389614244\n",
      "iteration:  120  cost:  0.16732331976417483\n",
      "iteration:  130  cost:  0.2669817737846262\n",
      "iteration:  140  cost:  0.14543132269970419\n",
      "Accuracy for U_SO4 resize256 :0.9886524822695035\n",
      "\n",
      "\n",
      "Loss History for Hierarchical circuits, U_SO4 pca8\n",
      "iteration:  0  cost:  1.0225463891580746\n",
      "iteration:  10  cost:  0.9386531008896495\n",
      "iteration:  20  cost:  0.18048238120682425\n",
      "iteration:  30  cost:  0.2509902386355291\n",
      "iteration:  40  cost:  0.1307201643800772\n",
      "iteration:  50  cost:  0.11359413914444223\n",
      "iteration:  60  cost:  0.12153203748164856\n",
      "iteration:  70  cost:  0.10110372549032506\n",
      "iteration:  80  cost:  0.13853338121067796\n",
      "iteration:  90  cost:  0.0791406324691554\n",
      "iteration:  100  cost:  0.24681141994899045\n",
      "iteration:  110  cost:  0.11449699689385337\n",
      "iteration:  120  cost:  0.12694695107651616\n",
      "iteration:  130  cost:  0.18014427767881902\n",
      "iteration:  140  cost:  0.05360535230784297\n",
      "Accuracy for U_SO4 pca8 :0.983451536643026\n",
      "Epoch 1/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.1069 - val_loss: 0.0347\n",
      "Epoch 2/10\n",
      "396/396 [==============================] - 1s 1ms/step - loss: 0.0317 - val_loss: 0.0269\n",
      "Epoch 3/10\n",
      "396/396 [==============================] - 1s 1ms/step - loss: 0.0259 - val_loss: 0.0237\n",
      "Epoch 4/10\n",
      "396/396 [==============================] - 1s 1ms/step - loss: 0.0233 - val_loss: 0.0217\n",
      "Epoch 5/10\n",
      "396/396 [==============================] - 1s 1ms/step - loss: 0.0217 - val_loss: 0.0204\n",
      "Epoch 6/10\n",
      "396/396 [==============================] - 1s 1ms/step - loss: 0.0204 - val_loss: 0.0195\n",
      "Epoch 7/10\n",
      "396/396 [==============================] - 1s 1ms/step - loss: 0.0197 - val_loss: 0.0189\n",
      "Epoch 8/10\n",
      "396/396 [==============================] - 1s 1ms/step - loss: 0.0193 - val_loss: 0.0185\n",
      "Epoch 9/10\n",
      "396/396 [==============================] - 1s 1ms/step - loss: 0.0187 - val_loss: 0.0182\n",
      "Epoch 10/10\n",
      "396/396 [==============================] - 1s 1ms/step - loss: 0.0188 - val_loss: 0.0179\n",
      "\n",
      "\n",
      "Loss History for Hierarchical circuits, U_SO4 autoencoder8\n",
      "iteration:  0  cost:  1.441061218944601\n",
      "iteration:  10  cost:  0.38872996722235437\n",
      "iteration:  20  cost:  0.27864956137188346\n",
      "iteration:  30  cost:  0.4721693568832647\n",
      "iteration:  40  cost:  0.4807036826421421\n",
      "iteration:  50  cost:  0.3279381273895721\n",
      "iteration:  60  cost:  0.24330580611350341\n",
      "iteration:  70  cost:  0.2387844206380674\n",
      "iteration:  80  cost:  0.34407211489069267\n",
      "iteration:  90  cost:  0.3670440377651751\n",
      "iteration:  100  cost:  0.22500590954405092\n",
      "iteration:  110  cost:  0.15719279900637326\n",
      "iteration:  120  cost:  0.23236404285752002\n",
      "iteration:  130  cost:  0.1737052859265109\n",
      "iteration:  140  cost:  0.2822077515460307\n",
      "Accuracy for U_SO4 autoencoder8 :0.9801418439716312\n",
      "2th step : \n",
      "\n",
      "\n",
      "Loss History for Hierarchical circuits, U_TTN resize256\n",
      "iteration:  0  cost:  0.7093063818234804\n",
      "iteration:  10  cost:  0.33526139071194955\n",
      "iteration:  20  cost:  0.30585848848478503\n",
      "iteration:  30  cost:  0.23611682348673285\n",
      "iteration:  40  cost:  0.31616844716727927\n",
      "iteration:  50  cost:  0.34657064165731044\n",
      "iteration:  60  cost:  0.2937288373185031\n",
      "iteration:  70  cost:  0.22315325464411792\n",
      "iteration:  80  cost:  0.2328975587697763\n",
      "iteration:  90  cost:  0.28802670763164134\n",
      "iteration:  100  cost:  0.33392850446838196\n",
      "iteration:  110  cost:  0.271044683973599\n",
      "iteration:  120  cost:  0.42801308789208015\n",
      "iteration:  130  cost:  0.25042719193332197\n",
      "iteration:  140  cost:  0.31207931047817533\n",
      "Accuracy for U_TTN resize256 :0.975886524822695\n",
      "\n",
      "\n",
      "Loss History for Hierarchical circuits, U_TTN pca8\n",
      "iteration:  0  cost:  1.3486030138367133\n",
      "iteration:  10  cost:  1.0881494382135883\n",
      "iteration:  20  cost:  0.9028193653078428\n",
      "iteration:  30  cost:  0.757522619965746\n",
      "iteration:  40  cost:  0.8182278579490216\n",
      "iteration:  50  cost:  0.6630582243031413\n",
      "iteration:  60  cost:  0.23815543032013398\n",
      "iteration:  70  cost:  0.2365724321589913\n",
      "iteration:  80  cost:  0.2678444093465177\n",
      "iteration:  90  cost:  0.3207102772176761\n",
      "iteration:  100  cost:  0.2855183271156813\n",
      "iteration:  110  cost:  0.2510027022845644\n",
      "iteration:  120  cost:  0.27602724494021297\n",
      "iteration:  130  cost:  0.3124629218014299\n",
      "iteration:  140  cost:  0.38300205863316356\n",
      "Accuracy for U_TTN pca8 :0.9801418439716312\n",
      "Epoch 1/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.1071 - val_loss: 0.0352\n",
      "Epoch 2/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.0324 - val_loss: 0.0276\n",
      "Epoch 3/10\n",
      "396/396 [==============================] - 1s 1ms/step - loss: 0.0272 - val_loss: 0.0245\n",
      "Epoch 4/10\n",
      "396/396 [==============================] - 1s 1ms/step - loss: 0.0242 - val_loss: 0.0221\n",
      "Epoch 5/10\n",
      "396/396 [==============================] - 1s 1ms/step - loss: 0.0221 - val_loss: 0.0209\n",
      "Epoch 6/10\n",
      "396/396 [==============================] - 1s 1ms/step - loss: 0.0210 - val_loss: 0.0200\n",
      "Epoch 7/10\n",
      "396/396 [==============================] - 1s 1ms/step - loss: 0.0203 - val_loss: 0.0193\n",
      "Epoch 8/10\n",
      "396/396 [==============================] - 1s 1ms/step - loss: 0.0194 - val_loss: 0.0187\n",
      "Epoch 9/10\n",
      "396/396 [==============================] - 1s 1ms/step - loss: 0.0192 - val_loss: 0.0183\n",
      "Epoch 10/10\n",
      "396/396 [==============================] - 1s 1ms/step - loss: 0.0186 - val_loss: 0.0181\n",
      "\n",
      "\n",
      "Loss History for Hierarchical circuits, U_TTN autoencoder8\n",
      "iteration:  0  cost:  1.265376518145025\n",
      "iteration:  10  cost:  0.5976254149356957\n",
      "iteration:  20  cost:  0.42827292758016483\n",
      "iteration:  30  cost:  0.38195816664681026\n",
      "iteration:  40  cost:  0.54705919230339\n",
      "iteration:  50  cost:  0.52740045809007\n",
      "iteration:  60  cost:  0.3535016417043557\n",
      "iteration:  70  cost:  0.4805257012529473\n",
      "iteration:  80  cost:  0.5726761716220732\n",
      "iteration:  90  cost:  0.4663737257925639\n",
      "iteration:  100  cost:  0.49736348669346947\n",
      "iteration:  110  cost:  0.4823600915568227\n",
      "iteration:  120  cost:  0.415700356543274\n",
      "iteration:  130  cost:  0.4934339607170084\n",
      "iteration:  140  cost:  0.5123697537724915\n",
      "Accuracy for U_TTN autoencoder8 :0.9167848699763593\n",
      "\n",
      "\n",
      "Loss History for Hierarchical circuits, U_5 resize256\n",
      "iteration:  0  cost:  1.0233449713559108\n",
      "iteration:  10  cost:  1.0101139800743715\n",
      "iteration:  20  cost:  1.026779300391393\n",
      "iteration:  30  cost:  0.9761922352838452\n",
      "iteration:  40  cost:  0.7455656304544089\n",
      "iteration:  50  cost:  0.8254897055995397\n",
      "iteration:  60  cost:  0.42420944264756827\n",
      "iteration:  70  cost:  0.286877064857319\n",
      "iteration:  80  cost:  0.32901143983236125\n",
      "iteration:  90  cost:  0.3432404315897588\n",
      "iteration:  100  cost:  0.26435445818500225\n",
      "iteration:  110  cost:  0.289929219886329\n",
      "iteration:  120  cost:  0.2902883834145215\n",
      "iteration:  130  cost:  0.3814669172962877\n",
      "iteration:  140  cost:  0.4454402295458527\n",
      "Accuracy for U_5 resize256 :0.968321513002364\n",
      "\n",
      "\n",
      "Loss History for Hierarchical circuits, U_5 pca8\n",
      "iteration:  0  cost:  1.113005867798754\n",
      "iteration:  10  cost:  0.9909758968773186\n",
      "iteration:  20  cost:  1.055941479252708\n",
      "iteration:  30  cost:  0.928062371170561\n",
      "iteration:  40  cost:  1.0668906523814556\n",
      "iteration:  50  cost:  0.9976011349656996\n",
      "iteration:  60  cost:  0.9623961276386511\n",
      "iteration:  70  cost:  0.9924786730406973\n",
      "iteration:  80  cost:  1.0308835055684447\n",
      "iteration:  90  cost:  0.9385927463330677\n",
      "iteration:  100  cost:  0.9790304338523594\n",
      "iteration:  110  cost:  0.9663569888973845\n",
      "iteration:  120  cost:  0.9625437529859502\n",
      "iteration:  130  cost:  0.9832366508543143\n",
      "iteration:  140  cost:  0.9751967119061438\n",
      "Accuracy for U_5 pca8 :0.6392434988179669\n",
      "Epoch 1/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.1100 - val_loss: 0.0341\n",
      "Epoch 2/10\n",
      "396/396 [==============================] - 1s 1ms/step - loss: 0.0320 - val_loss: 0.0269\n",
      "Epoch 3/10\n",
      "396/396 [==============================] - 1s 1ms/step - loss: 0.0265 - val_loss: 0.0238\n",
      "Epoch 4/10\n",
      "396/396 [==============================] - 1s 1ms/step - loss: 0.0238 - val_loss: 0.0217\n",
      "Epoch 5/10\n",
      "396/396 [==============================] - 1s 1ms/step - loss: 0.0217 - val_loss: 0.0202\n",
      "Epoch 6/10\n",
      "396/396 [==============================] - 1s 1ms/step - loss: 0.0203 - val_loss: 0.0194\n",
      "Epoch 7/10\n",
      "396/396 [==============================] - 1s 1ms/step - loss: 0.0198 - val_loss: 0.0187\n",
      "Epoch 8/10\n",
      "396/396 [==============================] - 1s 1ms/step - loss: 0.0193 - val_loss: 0.0183\n",
      "Epoch 9/10\n",
      "396/396 [==============================] - 1s 1ms/step - loss: 0.0187 - val_loss: 0.0180\n",
      "Epoch 10/10\n",
      "396/396 [==============================] - 1s 1ms/step - loss: 0.0185 - val_loss: 0.0177\n",
      "\n",
      "\n",
      "Loss History for Hierarchical circuits, U_5 autoencoder8\n",
      "iteration:  0  cost:  1.2339431350275607\n",
      "iteration:  10  cost:  0.5181544930675455\n",
      "iteration:  20  cost:  0.627296822535409\n",
      "iteration:  30  cost:  0.6080724121994295\n",
      "iteration:  40  cost:  0.6537923868951613\n",
      "iteration:  50  cost:  0.5863011828611903\n",
      "iteration:  60  cost:  0.7651729237034043\n",
      "iteration:  70  cost:  0.5870069934526745\n",
      "iteration:  80  cost:  0.5629732411610664\n",
      "iteration:  90  cost:  0.8186217543401691\n",
      "iteration:  100  cost:  0.870120209614969\n",
      "iteration:  110  cost:  0.534424580722029\n",
      "iteration:  120  cost:  0.4962946915082017\n",
      "iteration:  130  cost:  0.675384206064265\n",
      "iteration:  140  cost:  0.5886716671537694\n",
      "Accuracy for U_5 autoencoder8 :0.8936170212765957\n",
      "\n",
      "\n",
      "Loss History for Hierarchical circuits, U_6 resize256\n",
      "iteration:  0  cost:  1.3321916753874812\n",
      "iteration:  10  cost:  0.8970962610625624\n",
      "iteration:  20  cost:  0.6131213760893941\n",
      "iteration:  30  cost:  0.42392093608324616\n",
      "iteration:  40  cost:  0.19040813529768813\n",
      "iteration:  50  cost:  0.27665985883224725\n",
      "iteration:  60  cost:  0.23601295472931658\n",
      "iteration:  70  cost:  0.23514643121620174\n",
      "iteration:  80  cost:  0.19838540273570424\n",
      "iteration:  90  cost:  0.1940169127944658\n",
      "iteration:  100  cost:  0.17470030863818548\n",
      "iteration:  110  cost:  0.20083704530753846\n",
      "iteration:  120  cost:  0.15691869001960396\n",
      "iteration:  130  cost:  0.23121551425555092\n",
      "iteration:  140  cost:  0.11236012128993987\n",
      "Accuracy for U_6 resize256 :0.9891252955082742\n",
      "\n",
      "\n",
      "Loss History for Hierarchical circuits, U_6 pca8\n",
      "iteration:  0  cost:  1.1480234878657574\n",
      "iteration:  10  cost:  0.999928035911675\n",
      "iteration:  20  cost:  0.8199594761919289\n",
      "iteration:  30  cost:  0.3621770239119529\n",
      "iteration:  40  cost:  0.22347123731607244\n",
      "iteration:  50  cost:  0.4631296963853855\n",
      "iteration:  60  cost:  0.24007115586493208\n",
      "iteration:  70  cost:  0.17814973142807877\n",
      "iteration:  80  cost:  0.11784284777035181\n",
      "iteration:  90  cost:  0.15869263430515262\n",
      "iteration:  100  cost:  0.23496819907776445\n",
      "iteration:  110  cost:  0.20408430835310928\n",
      "iteration:  120  cost:  0.2016068731900019\n",
      "iteration:  130  cost:  0.18212852625776008\n",
      "iteration:  140  cost:  0.1400358031569453\n",
      "Accuracy for U_6 pca8 :0.9806146572104019\n",
      "Epoch 1/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.1072 - val_loss: 0.0362\n",
      "Epoch 2/10\n",
      "396/396 [==============================] - 1s 1ms/step - loss: 0.0330 - val_loss: 0.0272\n",
      "Epoch 3/10\n",
      "396/396 [==============================] - 1s 1ms/step - loss: 0.0267 - val_loss: 0.0245\n",
      "Epoch 4/10\n",
      "396/396 [==============================] - 1s 1ms/step - loss: 0.0241 - val_loss: 0.0222\n",
      "Epoch 5/10\n",
      "396/396 [==============================] - 1s 1ms/step - loss: 0.0220 - val_loss: 0.0207\n",
      "Epoch 6/10\n",
      "396/396 [==============================] - 1s 1ms/step - loss: 0.0207 - val_loss: 0.0197\n",
      "Epoch 7/10\n",
      "396/396 [==============================] - 1s 1ms/step - loss: 0.0198 - val_loss: 0.0190\n",
      "Epoch 8/10\n",
      "396/396 [==============================] - 1s 1ms/step - loss: 0.0192 - val_loss: 0.0184\n",
      "Epoch 9/10\n",
      "396/396 [==============================] - 1s 1ms/step - loss: 0.0186 - val_loss: 0.0180\n",
      "Epoch 10/10\n",
      "396/396 [==============================] - 1s 1ms/step - loss: 0.0181 - val_loss: 0.0178\n",
      "\n",
      "\n",
      "Loss History for Hierarchical circuits, U_6 autoencoder8\n",
      "iteration:  0  cost:  1.3294197681138744\n",
      "iteration:  10  cost:  0.3018063692392479\n",
      "iteration:  20  cost:  0.3452072669277238\n",
      "iteration:  30  cost:  0.21465400193769857\n",
      "iteration:  40  cost:  0.3377250912870352\n",
      "iteration:  50  cost:  0.21247522797549265\n",
      "iteration:  60  cost:  0.17147189827008621\n",
      "iteration:  70  cost:  0.19388839095394775\n",
      "iteration:  80  cost:  0.3037103372038288\n",
      "iteration:  90  cost:  0.2718125554463726\n",
      "iteration:  100  cost:  0.21033216581547723\n",
      "iteration:  110  cost:  0.24175791417668313\n",
      "iteration:  120  cost:  0.2833063474944235\n",
      "iteration:  130  cost:  0.2200394131512695\n",
      "iteration:  140  cost:  0.3240025288695431\n",
      "Accuracy for U_6 autoencoder8 :0.9550827423167849\n",
      "\n",
      "\n",
      "Loss History for Hierarchical circuits, U_13 resize256\n",
      "iteration:  0  cost:  1.8645621158909935\n",
      "iteration:  10  cost:  1.0003912118303147\n",
      "iteration:  20  cost:  1.3757478209302212\n",
      "iteration:  30  cost:  1.027229460865066\n",
      "iteration:  40  cost:  1.2299576566527635\n",
      "iteration:  50  cost:  1.2034109552257346\n",
      "iteration:  60  cost:  0.9723246073764666\n",
      "iteration:  70  cost:  0.8510321182843593\n",
      "iteration:  80  cost:  0.47480869346485555\n",
      "iteration:  90  cost:  0.42020679974540814\n",
      "iteration:  100  cost:  0.4547601964088902\n",
      "iteration:  110  cost:  0.3511704628529288\n",
      "iteration:  120  cost:  0.35986103612070686\n",
      "iteration:  130  cost:  0.3349334975716404\n",
      "iteration:  140  cost:  0.36107799660659173\n",
      "Accuracy for U_13 resize256 :0.9716312056737588\n",
      "\n",
      "\n",
      "Loss History for Hierarchical circuits, U_13 pca8\n",
      "iteration:  0  cost:  1.2246992637540766\n",
      "iteration:  10  cost:  0.8249554536271443\n",
      "iteration:  20  cost:  0.9649426345597643\n",
      "iteration:  30  cost:  0.9967285717068425\n",
      "iteration:  40  cost:  1.0314206770274483\n",
      "iteration:  50  cost:  0.9011515531046799\n",
      "iteration:  60  cost:  0.9820113367723351\n",
      "iteration:  70  cost:  0.9167585198307525\n",
      "iteration:  80  cost:  1.0419700248964152\n",
      "iteration:  90  cost:  1.0884454894560402\n",
      "iteration:  100  cost:  0.9187708689023129\n",
      "iteration:  110  cost:  0.9389563344989581\n",
      "iteration:  120  cost:  0.9849399257095377\n",
      "iteration:  130  cost:  1.0446891531798705\n",
      "iteration:  140  cost:  0.9858068619586391\n",
      "Accuracy for U_13 pca8 :0.6151300236406619\n",
      "Epoch 1/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.1055 - val_loss: 0.0341\n",
      "Epoch 2/10\n",
      "396/396 [==============================] - 1s 1ms/step - loss: 0.0314 - val_loss: 0.0269\n",
      "Epoch 3/10\n",
      "396/396 [==============================] - 1s 1ms/step - loss: 0.0263 - val_loss: 0.0235\n",
      "Epoch 4/10\n",
      "396/396 [==============================] - 1s 1ms/step - loss: 0.0232 - val_loss: 0.0214\n",
      "Epoch 5/10\n",
      "396/396 [==============================] - 1s 1ms/step - loss: 0.0217 - val_loss: 0.0202\n",
      "Epoch 6/10\n",
      "396/396 [==============================] - 1s 1ms/step - loss: 0.0204 - val_loss: 0.0193\n",
      "Epoch 7/10\n",
      "396/396 [==============================] - 1s 1ms/step - loss: 0.0200 - val_loss: 0.0186\n",
      "Epoch 8/10\n",
      "396/396 [==============================] - 1s 1ms/step - loss: 0.0190 - val_loss: 0.0182\n",
      "Epoch 9/10\n",
      "396/396 [==============================] - 1s 1ms/step - loss: 0.0185 - val_loss: 0.0179\n",
      "Epoch 10/10\n",
      "396/396 [==============================] - 1s 1ms/step - loss: 0.0185 - val_loss: 0.0176\n",
      "\n",
      "\n",
      "Loss History for Hierarchical circuits, U_13 autoencoder8\n",
      "iteration:  0  cost:  1.3147890989191242\n",
      "iteration:  10  cost:  0.6164860411621499\n",
      "iteration:  20  cost:  0.34017952317388\n",
      "iteration:  30  cost:  0.31302494489362975\n",
      "iteration:  40  cost:  0.2718573239043086\n",
      "iteration:  50  cost:  0.35824301615398463\n",
      "iteration:  60  cost:  0.2507483865799755\n",
      "iteration:  70  cost:  0.3831558354968206\n",
      "iteration:  80  cost:  0.21836869410773843\n",
      "iteration:  90  cost:  0.3588966060207391\n",
      "iteration:  100  cost:  0.18463454506258245\n",
      "iteration:  110  cost:  0.33686484792069554\n",
      "iteration:  120  cost:  0.24695130115032335\n",
      "iteration:  130  cost:  0.1877649526063171\n",
      "iteration:  140  cost:  0.4195124314790705\n",
      "Accuracy for U_13 autoencoder8 :0.9011820330969267\n",
      "\n",
      "\n",
      "Loss History for Hierarchical circuits, U_14 resize256\n",
      "iteration:  0  cost:  0.9806928253910059\n",
      "iteration:  10  cost:  0.8932799419127978\n",
      "iteration:  20  cost:  0.7028049527994371\n",
      "iteration:  30  cost:  0.7739861240646949\n",
      "iteration:  40  cost:  0.5511369491866517\n",
      "iteration:  50  cost:  0.5141399483605624\n",
      "iteration:  60  cost:  0.38883005429980466\n",
      "iteration:  70  cost:  0.28656428028554876\n",
      "iteration:  80  cost:  0.3344259908137793\n",
      "iteration:  90  cost:  0.2222527583457099\n",
      "iteration:  100  cost:  0.2938786915394901\n",
      "iteration:  110  cost:  0.3256084362442609\n",
      "iteration:  120  cost:  0.21909373527390183\n",
      "iteration:  130  cost:  0.32304473569162406\n",
      "iteration:  140  cost:  0.3597268386009319\n",
      "Accuracy for U_14 resize256 :0.9654846335697399\n",
      "\n",
      "\n",
      "Loss History for Hierarchical circuits, U_14 pca8\n",
      "iteration:  0  cost:  0.9689242485225159\n",
      "iteration:  10  cost:  0.9656199880330483\n",
      "iteration:  20  cost:  1.064154530035075\n",
      "iteration:  30  cost:  0.9033393222398537\n",
      "iteration:  40  cost:  0.45207222752900633\n",
      "iteration:  50  cost:  0.41427138359137267\n",
      "iteration:  60  cost:  0.27654708770700337\n",
      "iteration:  70  cost:  0.40535533543338625\n",
      "iteration:  80  cost:  0.2743882483169022\n",
      "iteration:  90  cost:  0.19302085654684206\n",
      "iteration:  100  cost:  0.41183700987743643\n",
      "iteration:  110  cost:  0.2708024755282781\n",
      "iteration:  120  cost:  0.2829671245041095\n",
      "iteration:  130  cost:  0.3105081608133587\n",
      "iteration:  140  cost:  0.3896192822018261\n",
      "Accuracy for U_14 pca8 :0.9744680851063829\n",
      "Epoch 1/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.1103 - val_loss: 0.0342\n",
      "Epoch 2/10\n",
      "396/396 [==============================] - 1s 1ms/step - loss: 0.0314 - val_loss: 0.0271\n",
      "Epoch 3/10\n",
      "396/396 [==============================] - 1s 1ms/step - loss: 0.0268 - val_loss: 0.0239\n",
      "Epoch 4/10\n",
      "396/396 [==============================] - 1s 1ms/step - loss: 0.0235 - val_loss: 0.0214\n",
      "Epoch 5/10\n",
      "396/396 [==============================] - 1s 1ms/step - loss: 0.0214 - val_loss: 0.0200\n",
      "Epoch 6/10\n",
      "396/396 [==============================] - 1s 1ms/step - loss: 0.0201 - val_loss: 0.0191\n",
      "Epoch 7/10\n",
      "396/396 [==============================] - 1s 1ms/step - loss: 0.0193 - val_loss: 0.0186\n",
      "Epoch 8/10\n",
      "396/396 [==============================] - 1s 1ms/step - loss: 0.0189 - val_loss: 0.0180\n",
      "Epoch 9/10\n",
      "396/396 [==============================] - 1s 1ms/step - loss: 0.0186 - val_loss: 0.0177\n",
      "Epoch 10/10\n",
      "396/396 [==============================] - 1s 1ms/step - loss: 0.0181 - val_loss: 0.0175\n",
      "\n",
      "\n",
      "Loss History for Hierarchical circuits, U_14 autoencoder8\n",
      "iteration:  0  cost:  1.025607217330971\n",
      "iteration:  10  cost:  0.5391381547686099\n",
      "iteration:  20  cost:  0.4360592283314588\n",
      "iteration:  30  cost:  0.3792450064423805\n",
      "iteration:  40  cost:  0.2619043657413824\n",
      "iteration:  50  cost:  0.35420832556694043\n",
      "iteration:  60  cost:  0.3444159367002327\n",
      "iteration:  70  cost:  0.3820092353175591\n",
      "iteration:  80  cost:  0.28456927636092627\n",
      "iteration:  90  cost:  0.2893870502124594\n",
      "iteration:  100  cost:  0.30779285782032434\n",
      "iteration:  110  cost:  0.3616660404132318\n",
      "iteration:  120  cost:  0.33228684462732294\n",
      "iteration:  130  cost:  0.14702524695088515\n",
      "iteration:  140  cost:  0.19396815214920768\n",
      "Accuracy for U_14 autoencoder8 :0.9380614657210402\n",
      "\n",
      "\n",
      "Loss History for Hierarchical circuits, U_15 resize256\n",
      "iteration:  0  cost:  0.6566116373710745\n",
      "iteration:  10  cost:  0.18066351508802586\n",
      "iteration:  20  cost:  0.15373617362954106\n",
      "iteration:  30  cost:  0.149567781018973\n",
      "iteration:  40  cost:  0.21270619473632776\n",
      "iteration:  50  cost:  0.1928488350470408\n",
      "iteration:  60  cost:  0.24275303764083048\n",
      "iteration:  70  cost:  0.22287894489488572\n",
      "iteration:  80  cost:  0.14827463956569117\n",
      "iteration:  90  cost:  0.21319712455911763\n",
      "iteration:  100  cost:  0.1851602918268341\n",
      "iteration:  110  cost:  0.18714762712536168\n",
      "iteration:  120  cost:  0.12274018223960477\n",
      "iteration:  130  cost:  0.18890551498229974\n",
      "iteration:  140  cost:  0.20153809634102263\n",
      "Accuracy for U_15 resize256 :0.9877068557919622\n",
      "\n",
      "\n",
      "Loss History for Hierarchical circuits, U_15 pca8\n",
      "iteration:  0  cost:  0.7382798688800691\n",
      "iteration:  10  cost:  0.9397922883792766\n",
      "iteration:  20  cost:  0.6760311494648151\n",
      "iteration:  30  cost:  0.22531538046710714\n",
      "iteration:  40  cost:  0.3193552688830467\n",
      "iteration:  50  cost:  0.2210903188344124\n",
      "iteration:  60  cost:  0.08257381645268579\n",
      "iteration:  70  cost:  0.06948271646144707\n",
      "iteration:  80  cost:  0.10804567429882535\n",
      "iteration:  90  cost:  0.10545974143393258\n",
      "iteration:  100  cost:  0.09773776507552168\n",
      "iteration:  110  cost:  0.1062488028894574\n",
      "iteration:  120  cost:  0.12354827656502042\n",
      "iteration:  130  cost:  0.07511902908810751\n",
      "iteration:  140  cost:  0.13700747261598298\n",
      "Accuracy for U_15 pca8 :0.9853427895981087\n",
      "Epoch 1/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.1059 - val_loss: 0.0366\n",
      "Epoch 2/10\n",
      "396/396 [==============================] - 1s 1ms/step - loss: 0.0330 - val_loss: 0.0276\n",
      "Epoch 3/10\n",
      "396/396 [==============================] - 1s 1ms/step - loss: 0.0270 - val_loss: 0.0247\n",
      "Epoch 4/10\n",
      "396/396 [==============================] - 1s 1ms/step - loss: 0.0243 - val_loss: 0.0229\n",
      "Epoch 5/10\n",
      "396/396 [==============================] - 1s 1ms/step - loss: 0.0227 - val_loss: 0.0217\n",
      "Epoch 6/10\n",
      "396/396 [==============================] - 1s 1ms/step - loss: 0.0214 - val_loss: 0.0207\n",
      "Epoch 7/10\n",
      "396/396 [==============================] - 1s 1ms/step - loss: 0.0206 - val_loss: 0.0199\n",
      "Epoch 8/10\n",
      "396/396 [==============================] - 1s 1ms/step - loss: 0.0202 - val_loss: 0.0194\n",
      "Epoch 9/10\n",
      "396/396 [==============================] - 1s 1ms/step - loss: 0.0194 - val_loss: 0.0188\n",
      "Epoch 10/10\n",
      "396/396 [==============================] - 1s 1ms/step - loss: 0.0186 - val_loss: 0.0183\n",
      "\n",
      "\n",
      "Loss History for Hierarchical circuits, U_15 autoencoder8\n",
      "iteration:  0  cost:  1.362282866130686\n",
      "iteration:  10  cost:  0.6140783174299361\n",
      "iteration:  20  cost:  0.3471174638751727\n",
      "iteration:  30  cost:  0.2788807728646615\n",
      "iteration:  40  cost:  0.21393274590270359\n",
      "iteration:  50  cost:  0.24635332259555692\n",
      "iteration:  60  cost:  0.24747013786725663\n",
      "iteration:  70  cost:  0.2887379221376845\n",
      "iteration:  80  cost:  0.14814223227130466\n",
      "iteration:  90  cost:  0.21411771631528478\n",
      "iteration:  100  cost:  0.22544871046278828\n",
      "iteration:  110  cost:  0.17192294408511408\n",
      "iteration:  120  cost:  0.23207788081177316\n",
      "iteration:  130  cost:  0.20718791307955545\n",
      "iteration:  140  cost:  0.2017170907367253\n",
      "Accuracy for U_15 autoencoder8 :0.991016548463357\n",
      "\n",
      "\n",
      "Loss History for Hierarchical circuits, U_SO4 resize256\n",
      "iteration:  0  cost:  1.346044648925884\n",
      "iteration:  10  cost:  1.0709332757727632\n",
      "iteration:  20  cost:  0.4064995122855858\n",
      "iteration:  30  cost:  0.5010833167925434\n",
      "iteration:  40  cost:  0.35793484841638806\n",
      "iteration:  50  cost:  0.3822233640368723\n",
      "iteration:  60  cost:  0.27222689033538816\n",
      "iteration:  70  cost:  0.26073839079208644\n",
      "iteration:  80  cost:  0.17690458333075917\n",
      "iteration:  90  cost:  0.17904867093777704\n",
      "iteration:  100  cost:  0.4162005322708143\n",
      "iteration:  110  cost:  0.25978068387239284\n",
      "iteration:  120  cost:  0.2943770699857638\n",
      "iteration:  130  cost:  0.3300176968610278\n",
      "iteration:  140  cost:  0.36884374553422133\n",
      "Accuracy for U_SO4 resize256 :0.9385342789598109\n",
      "\n",
      "\n",
      "Loss History for Hierarchical circuits, U_SO4 pca8\n",
      "iteration:  0  cost:  1.1552465966252996\n",
      "iteration:  10  cost:  0.29585090834014766\n",
      "iteration:  20  cost:  0.21288710241493422\n",
      "iteration:  30  cost:  0.127578452483023\n",
      "iteration:  40  cost:  0.29069149144320294\n",
      "iteration:  50  cost:  0.21713151770333405\n",
      "iteration:  60  cost:  0.13454825786038221\n",
      "iteration:  70  cost:  0.14891995502746122\n",
      "iteration:  80  cost:  0.1348381559723615\n",
      "iteration:  90  cost:  0.23396224975757104\n",
      "iteration:  100  cost:  0.1121833831422065\n",
      "iteration:  110  cost:  0.0931764680360309\n",
      "iteration:  120  cost:  0.12089490737233344\n",
      "iteration:  130  cost:  0.09816532694383338\n",
      "iteration:  140  cost:  0.1237500490609313\n",
      "Accuracy for U_SO4 pca8 :0.9872340425531915\n",
      "Epoch 1/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.1074 - val_loss: 0.0348\n",
      "Epoch 2/10\n",
      "396/396 [==============================] - 1s 1ms/step - loss: 0.0320 - val_loss: 0.0270\n",
      "Epoch 3/10\n",
      "396/396 [==============================] - 1s 1ms/step - loss: 0.0265 - val_loss: 0.0243\n",
      "Epoch 4/10\n",
      "396/396 [==============================] - 1s 1ms/step - loss: 0.0240 - val_loss: 0.0219\n",
      "Epoch 5/10\n",
      "396/396 [==============================] - 1s 1ms/step - loss: 0.0218 - val_loss: 0.0203\n",
      "Epoch 6/10\n",
      "396/396 [==============================] - 1s 1ms/step - loss: 0.0201 - val_loss: 0.0192\n",
      "Epoch 7/10\n",
      "396/396 [==============================] - 1s 1ms/step - loss: 0.0194 - val_loss: 0.0186\n",
      "Epoch 8/10\n",
      "396/396 [==============================] - 1s 1ms/step - loss: 0.0186 - val_loss: 0.0181\n",
      "Epoch 9/10\n",
      "396/396 [==============================] - 1s 1ms/step - loss: 0.0182 - val_loss: 0.0177\n",
      "Epoch 10/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.0178 - val_loss: 0.0175\n",
      "\n",
      "\n",
      "Loss History for Hierarchical circuits, U_SO4 autoencoder8\n",
      "iteration:  0  cost:  1.0504618309669747\n",
      "iteration:  10  cost:  0.38933773247735615\n",
      "iteration:  20  cost:  0.17640228207105937\n",
      "iteration:  30  cost:  0.34393418696794326\n",
      "iteration:  40  cost:  0.34096856199164194\n",
      "iteration:  50  cost:  0.2588236970720593\n",
      "iteration:  60  cost:  0.4250900066444808\n",
      "iteration:  70  cost:  0.24131221650745835\n",
      "iteration:  80  cost:  0.21438518109502083\n",
      "iteration:  90  cost:  0.1781053862986511\n",
      "iteration:  100  cost:  0.2824727918247614\n",
      "iteration:  110  cost:  0.16230820304117777\n",
      "iteration:  120  cost:  0.20885695677277508\n",
      "iteration:  130  cost:  0.22362440750628734\n",
      "iteration:  140  cost:  0.19466957319497286\n",
      "Accuracy for U_SO4 autoencoder8 :0.9872340425531915\n",
      "3th step : \n",
      "\n",
      "\n",
      "Loss History for Hierarchical circuits, U_TTN resize256\n",
      "iteration:  0  cost:  0.8252978326534555\n",
      "iteration:  10  cost:  0.4758630195007998\n",
      "iteration:  20  cost:  0.42556147416900736\n",
      "iteration:  30  cost:  0.3544075264554502\n",
      "iteration:  40  cost:  0.5021939583210316\n",
      "iteration:  50  cost:  0.44830448586275135\n",
      "iteration:  60  cost:  0.30022005453883877\n",
      "iteration:  70  cost:  0.23333234399929917\n",
      "iteration:  80  cost:  0.40947472275118535\n",
      "iteration:  90  cost:  0.3495392963934072\n",
      "iteration:  100  cost:  0.3585776330031463\n",
      "iteration:  110  cost:  0.24996667485493407\n",
      "iteration:  120  cost:  0.21003567922885796\n",
      "iteration:  130  cost:  0.19482586376351263\n",
      "iteration:  140  cost:  0.27136606353850046\n",
      "Accuracy for U_TTN resize256 :0.9739952718676123\n",
      "\n",
      "\n",
      "Loss History for Hierarchical circuits, U_TTN pca8\n",
      "iteration:  0  cost:  1.0060746877831637\n",
      "iteration:  10  cost:  1.0043236925806163\n",
      "iteration:  20  cost:  1.0368647960493176\n",
      "iteration:  30  cost:  0.8954741397930639\n",
      "iteration:  40  cost:  0.37247722763112684\n",
      "iteration:  50  cost:  0.3930052118389425\n",
      "iteration:  60  cost:  0.30614674675085946\n",
      "iteration:  70  cost:  0.42146954571343415\n",
      "iteration:  80  cost:  0.29815091723490705\n",
      "iteration:  90  cost:  0.48474298328854415\n",
      "iteration:  100  cost:  0.3388562987124233\n",
      "iteration:  110  cost:  0.2601012077310701\n",
      "iteration:  120  cost:  0.3327465497178064\n",
      "iteration:  130  cost:  0.4042725225766021\n",
      "iteration:  140  cost:  0.30982102168846715\n",
      "Accuracy for U_TTN pca8 :0.9456264775413712\n",
      "Epoch 1/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.1053 - val_loss: 0.0365\n",
      "Epoch 2/10\n",
      "396/396 [==============================] - 1s 1ms/step - loss: 0.0334 - val_loss: 0.0277\n",
      "Epoch 3/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.0273 - val_loss: 0.0249\n",
      "Epoch 4/10\n",
      "396/396 [==============================] - 1s 1ms/step - loss: 0.0243 - val_loss: 0.0227\n",
      "Epoch 5/10\n",
      "396/396 [==============================] - 1s 1ms/step - loss: 0.0227 - val_loss: 0.0213\n",
      "Epoch 6/10\n",
      "396/396 [==============================] - 1s 1ms/step - loss: 0.0215 - val_loss: 0.0204\n",
      "Epoch 7/10\n",
      "396/396 [==============================] - 1s 1ms/step - loss: 0.0205 - val_loss: 0.0198\n",
      "Epoch 8/10\n",
      "396/396 [==============================] - 1s 1ms/step - loss: 0.0201 - val_loss: 0.0191\n",
      "Epoch 9/10\n",
      "396/396 [==============================] - 1s 1ms/step - loss: 0.0193 - val_loss: 0.0185\n",
      "Epoch 10/10\n",
      "396/396 [==============================] - 1s 1ms/step - loss: 0.0189 - val_loss: 0.0181\n",
      "\n",
      "\n",
      "Loss History for Hierarchical circuits, U_TTN autoencoder8\n",
      "iteration:  0  cost:  1.2443047994022423\n",
      "iteration:  10  cost:  0.7377051092026542\n",
      "iteration:  20  cost:  0.7694770896363559\n",
      "iteration:  30  cost:  0.7570153832553025\n",
      "iteration:  40  cost:  0.7367502612931197\n",
      "iteration:  50  cost:  0.6228086248799322\n",
      "iteration:  60  cost:  0.6169411015305711\n",
      "iteration:  70  cost:  0.6009133647695475\n",
      "iteration:  80  cost:  0.7056194202772726\n",
      "iteration:  90  cost:  0.8428760899358967\n",
      "iteration:  100  cost:  0.6823552079320249\n",
      "iteration:  110  cost:  0.7811868485520361\n",
      "iteration:  120  cost:  0.6564016296223812\n",
      "iteration:  130  cost:  0.6450722314545456\n",
      "iteration:  140  cost:  0.586670759113196\n",
      "Accuracy for U_TTN autoencoder8 :0.9546099290780142\n",
      "\n",
      "\n",
      "Loss History for Hierarchical circuits, U_5 resize256\n",
      "iteration:  0  cost:  0.9987182960049608\n",
      "iteration:  10  cost:  0.9986664437735441\n",
      "iteration:  20  cost:  1.0391313070863977\n",
      "iteration:  30  cost:  0.48779683687342507\n",
      "iteration:  40  cost:  0.41570504549058923\n",
      "iteration:  50  cost:  0.2835519464988529\n",
      "iteration:  60  cost:  0.28405738786562695\n",
      "iteration:  70  cost:  0.2713005596194895\n",
      "iteration:  80  cost:  0.21978354616172985\n",
      "iteration:  90  cost:  0.362322612417869\n",
      "iteration:  100  cost:  0.256316115154559\n",
      "iteration:  110  cost:  0.2679441206969882\n",
      "iteration:  120  cost:  0.20220512864366458\n",
      "iteration:  130  cost:  0.28935251184715316\n",
      "iteration:  140  cost:  0.2558174186340535\n",
      "Accuracy for U_5 resize256 :0.9735224586288416\n",
      "\n",
      "\n",
      "Loss History for Hierarchical circuits, U_5 pca8\n",
      "iteration:  0  cost:  1.0791599400452245\n",
      "iteration:  10  cost:  1.0733781226633161\n",
      "iteration:  20  cost:  1.0082651846644821\n",
      "iteration:  30  cost:  0.9739741596640507\n",
      "iteration:  40  cost:  0.9430318229708035\n",
      "iteration:  50  cost:  0.9802634518135126\n",
      "iteration:  60  cost:  0.9823205015532714\n",
      "iteration:  70  cost:  1.017145028450418\n",
      "iteration:  80  cost:  1.0060960447781704\n",
      "iteration:  90  cost:  0.9834741313281933\n",
      "iteration:  100  cost:  0.9152148041339746\n",
      "iteration:  110  cost:  0.9601924858206489\n",
      "iteration:  120  cost:  0.9148131025515205\n",
      "iteration:  130  cost:  0.9629235691778224\n",
      "iteration:  140  cost:  0.8368584179070937\n",
      "Accuracy for U_5 pca8 :0.6042553191489362\n",
      "Epoch 1/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.1084 - val_loss: 0.0360\n",
      "Epoch 2/10\n",
      "396/396 [==============================] - 1s 1ms/step - loss: 0.0329 - val_loss: 0.0269\n",
      "Epoch 3/10\n",
      "396/396 [==============================] - 1s 1ms/step - loss: 0.0264 - val_loss: 0.0238\n",
      "Epoch 4/10\n",
      "396/396 [==============================] - 1s 1ms/step - loss: 0.0232 - val_loss: 0.0216\n",
      "Epoch 5/10\n",
      "396/396 [==============================] - 1s 1ms/step - loss: 0.0215 - val_loss: 0.0204\n",
      "Epoch 6/10\n",
      "396/396 [==============================] - 1s 1ms/step - loss: 0.0204 - val_loss: 0.0196\n",
      "Epoch 7/10\n",
      "396/396 [==============================] - 1s 1ms/step - loss: 0.0198 - val_loss: 0.0190\n",
      "Epoch 8/10\n",
      "396/396 [==============================] - 1s 1ms/step - loss: 0.0192 - val_loss: 0.0185\n",
      "Epoch 9/10\n",
      "396/396 [==============================] - 1s 1ms/step - loss: 0.0188 - val_loss: 0.0181\n",
      "Epoch 10/10\n",
      "396/396 [==============================] - 1s 1ms/step - loss: 0.0185 - val_loss: 0.0178\n",
      "\n",
      "\n",
      "Loss History for Hierarchical circuits, U_5 autoencoder8\n",
      "iteration:  0  cost:  0.8047518971741852\n",
      "iteration:  10  cost:  0.5279411683643329\n",
      "iteration:  20  cost:  0.5770908061717098\n",
      "iteration:  30  cost:  0.5124061379886693\n",
      "iteration:  40  cost:  0.5317334297812829\n",
      "iteration:  50  cost:  0.3872164483353903\n",
      "iteration:  60  cost:  0.369946467152281\n",
      "iteration:  70  cost:  0.38089863582625283\n",
      "iteration:  80  cost:  0.3884302687195989\n",
      "iteration:  90  cost:  0.3047645400754451\n",
      "iteration:  100  cost:  0.30642983700990906\n",
      "iteration:  110  cost:  0.42633814535732106\n",
      "iteration:  120  cost:  0.3636566745348197\n",
      "iteration:  130  cost:  0.25440284503564004\n",
      "iteration:  140  cost:  0.36145190157103335\n",
      "Accuracy for U_5 autoencoder8 :0.950354609929078\n",
      "\n",
      "\n",
      "Loss History for Hierarchical circuits, U_6 resize256\n",
      "iteration:  0  cost:  1.218839209586501\n",
      "iteration:  10  cost:  0.9093973970030038\n",
      "iteration:  20  cost:  0.631953716049138\n",
      "iteration:  30  cost:  0.5692707551842615\n",
      "iteration:  40  cost:  0.433898753544685\n",
      "iteration:  50  cost:  0.4577545462325384\n",
      "iteration:  60  cost:  0.3154951009674561\n",
      "iteration:  70  cost:  0.35578490465249296\n",
      "iteration:  80  cost:  0.2456409391875075\n",
      "iteration:  90  cost:  0.34933667720853884\n",
      "iteration:  100  cost:  0.23241604759549786\n",
      "iteration:  110  cost:  0.19125756408361574\n",
      "iteration:  120  cost:  0.12938687116689143\n",
      "iteration:  130  cost:  0.1841575026019313\n",
      "iteration:  140  cost:  0.14599080988719906\n",
      "Accuracy for U_6 resize256 :0.9881796690307328\n",
      "\n",
      "\n",
      "Loss History for Hierarchical circuits, U_6 pca8\n",
      "iteration:  0  cost:  0.9740489438139349\n",
      "iteration:  10  cost:  1.0133361228422115\n",
      "iteration:  20  cost:  0.7774511447810042\n",
      "iteration:  30  cost:  0.6989708560023314\n",
      "iteration:  40  cost:  0.35225968270623226\n",
      "iteration:  50  cost:  0.19402941456665612\n",
      "iteration:  60  cost:  0.3281476182713621\n",
      "iteration:  70  cost:  0.18071730834047398\n",
      "iteration:  80  cost:  0.0805564731077349\n",
      "iteration:  90  cost:  0.24439682085966744\n",
      "iteration:  100  cost:  0.23240404174538454\n",
      "iteration:  110  cost:  0.1548851081723118\n",
      "iteration:  120  cost:  0.12000494352042067\n",
      "iteration:  130  cost:  0.07662824705557632\n",
      "iteration:  140  cost:  0.14084352894732274\n",
      "Accuracy for U_6 pca8 :0.9810874704491725\n",
      "Epoch 1/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.1105 - val_loss: 0.0358\n",
      "Epoch 2/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.0329 - val_loss: 0.0274\n",
      "Epoch 3/10\n",
      "396/396 [==============================] - 1s 1ms/step - loss: 0.0270 - val_loss: 0.0239\n",
      "Epoch 4/10\n",
      "396/396 [==============================] - 1s 1ms/step - loss: 0.0234 - val_loss: 0.0215\n",
      "Epoch 5/10\n",
      "396/396 [==============================] - 1s 1ms/step - loss: 0.0213 - val_loss: 0.0199\n",
      "Epoch 6/10\n",
      "396/396 [==============================] - 1s 1ms/step - loss: 0.0200 - val_loss: 0.0191\n",
      "Epoch 7/10\n",
      "396/396 [==============================] - 1s 1ms/step - loss: 0.0192 - val_loss: 0.0186\n",
      "Epoch 8/10\n",
      "396/396 [==============================] - 1s 1ms/step - loss: 0.0188 - val_loss: 0.0183\n",
      "Epoch 9/10\n",
      "396/396 [==============================] - 1s 1ms/step - loss: 0.0185 - val_loss: 0.0180\n",
      "Epoch 10/10\n",
      "396/396 [==============================] - 1s 1ms/step - loss: 0.0182 - val_loss: 0.0178\n",
      "\n",
      "\n",
      "Loss History for Hierarchical circuits, U_6 autoencoder8\n",
      "iteration:  0  cost:  1.319039713892376\n",
      "iteration:  10  cost:  0.6967120752807006\n",
      "iteration:  20  cost:  0.3756303653795564\n",
      "iteration:  30  cost:  0.35979692496397986\n",
      "iteration:  40  cost:  0.270986032717836\n",
      "iteration:  50  cost:  0.23255191024128657\n",
      "iteration:  60  cost:  0.2969364320083747\n",
      "iteration:  70  cost:  0.2074650913523024\n",
      "iteration:  80  cost:  0.27321484655890693\n",
      "iteration:  90  cost:  0.2121834827855085\n",
      "iteration:  100  cost:  0.2646231469647822\n",
      "iteration:  110  cost:  0.24846458877261735\n",
      "iteration:  120  cost:  0.23853361811765642\n",
      "iteration:  130  cost:  0.24770827186931918\n",
      "iteration:  140  cost:  0.29836118271056516\n",
      "Accuracy for U_6 autoencoder8 :0.9862884160756501\n",
      "\n",
      "\n",
      "Loss History for Hierarchical circuits, U_13 resize256\n",
      "iteration:  0  cost:  1.1027640619991168\n",
      "iteration:  10  cost:  0.9224074685696582\n",
      "iteration:  20  cost:  1.014784544957678\n",
      "iteration:  30  cost:  1.015025935161555\n",
      "iteration:  40  cost:  1.0007446305427634\n",
      "iteration:  50  cost:  0.9609466827798638\n",
      "iteration:  60  cost:  0.9688281847160323\n",
      "iteration:  70  cost:  0.9946341755531384\n",
      "iteration:  80  cost:  0.9259972313932674\n",
      "iteration:  90  cost:  0.9744864980656461\n",
      "iteration:  100  cost:  0.9309420575104203\n",
      "iteration:  110  cost:  0.9193366140726448\n",
      "iteration:  120  cost:  0.9451877601063015\n",
      "iteration:  130  cost:  0.6076024462446405\n",
      "iteration:  140  cost:  0.4264471844610448\n",
      "Accuracy for U_13 resize256 :0.957919621749409\n",
      "\n",
      "\n",
      "Loss History for Hierarchical circuits, U_13 pca8\n",
      "iteration:  0  cost:  1.3121698848211931\n",
      "iteration:  10  cost:  0.9799118287816008\n",
      "iteration:  20  cost:  0.8895693341579181\n",
      "iteration:  30  cost:  0.8856190592574342\n",
      "iteration:  40  cost:  0.6621999364873475\n",
      "iteration:  50  cost:  0.3517563229010493\n",
      "iteration:  60  cost:  0.1861819180224829\n",
      "iteration:  70  cost:  0.2497652451442355\n",
      "iteration:  80  cost:  0.21243796142268156\n",
      "iteration:  90  cost:  0.23832347026300899\n",
      "iteration:  100  cost:  0.1443946236360673\n",
      "iteration:  110  cost:  0.26632609841619503\n",
      "iteration:  120  cost:  0.1867850495344966\n",
      "iteration:  130  cost:  0.2563765095367656\n",
      "iteration:  140  cost:  0.33877426514482467\n",
      "Accuracy for U_13 pca8 :0.9810874704491725\n",
      "Epoch 1/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.1094 - val_loss: 0.0373\n",
      "Epoch 2/10\n",
      "396/396 [==============================] - 1s 1ms/step - loss: 0.0326 - val_loss: 0.0266\n",
      "Epoch 3/10\n",
      "396/396 [==============================] - 1s 1ms/step - loss: 0.0263 - val_loss: 0.0239\n",
      "Epoch 4/10\n",
      "396/396 [==============================] - 1s 1ms/step - loss: 0.0238 - val_loss: 0.0221\n",
      "Epoch 5/10\n",
      "396/396 [==============================] - 1s 1ms/step - loss: 0.0219 - val_loss: 0.0209\n",
      "Epoch 6/10\n",
      "396/396 [==============================] - 1s 1ms/step - loss: 0.0208 - val_loss: 0.0200\n",
      "Epoch 7/10\n",
      "396/396 [==============================] - 1s 1ms/step - loss: 0.0199 - val_loss: 0.0193\n",
      "Epoch 8/10\n",
      "396/396 [==============================] - 1s 1ms/step - loss: 0.0194 - val_loss: 0.0187\n",
      "Epoch 9/10\n",
      "396/396 [==============================] - 1s 1ms/step - loss: 0.0190 - val_loss: 0.0182\n",
      "Epoch 10/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.0185 - val_loss: 0.0179\n",
      "\n",
      "\n",
      "Loss History for Hierarchical circuits, U_13 autoencoder8\n",
      "iteration:  0  cost:  0.6345333980329291\n",
      "iteration:  10  cost:  0.6183242679215385\n",
      "iteration:  20  cost:  0.5283440025028324\n",
      "iteration:  30  cost:  0.5799897142012695\n",
      "iteration:  40  cost:  0.5230818819638577\n",
      "iteration:  50  cost:  0.5247893794796044\n",
      "iteration:  60  cost:  0.5315738325886216\n",
      "iteration:  70  cost:  0.5476455155243628\n",
      "iteration:  80  cost:  0.4501890115614369\n",
      "iteration:  90  cost:  0.41649692651650105\n",
      "iteration:  100  cost:  0.47741966670033464\n",
      "iteration:  110  cost:  0.34094658195460736\n",
      "iteration:  120  cost:  0.3437118514699376\n",
      "iteration:  130  cost:  0.42175445692159985\n",
      "iteration:  140  cost:  0.3643217694999138\n",
      "Accuracy for U_13 autoencoder8 :0.9617021276595744\n",
      "\n",
      "\n",
      "Loss History for Hierarchical circuits, U_14 resize256\n",
      "iteration:  0  cost:  1.0346752408291169\n",
      "iteration:  10  cost:  0.8287842875835153\n",
      "iteration:  20  cost:  0.5912024830722775\n",
      "iteration:  30  cost:  0.38441229097320695\n",
      "iteration:  40  cost:  0.2043028917089427\n",
      "iteration:  50  cost:  0.4504653111468416\n",
      "iteration:  60  cost:  0.28388943628448504\n",
      "iteration:  70  cost:  0.30024098341791644\n",
      "iteration:  80  cost:  0.21110607667040113\n",
      "iteration:  90  cost:  0.2922743005471862\n",
      "iteration:  100  cost:  0.2198591136360263\n",
      "iteration:  110  cost:  0.20888882080951265\n",
      "iteration:  120  cost:  0.3078197244150366\n",
      "iteration:  130  cost:  0.3311087387053139\n",
      "iteration:  140  cost:  0.24896128195598466\n",
      "Accuracy for U_14 resize256 :0.9858156028368794\n",
      "\n",
      "\n",
      "Loss History for Hierarchical circuits, U_14 pca8\n",
      "iteration:  0  cost:  1.7137701707189203\n",
      "iteration:  10  cost:  1.0010195714763253\n",
      "iteration:  20  cost:  0.9382777264132613\n",
      "iteration:  30  cost:  0.8325944759492507\n",
      "iteration:  40  cost:  0.9295429371239646\n",
      "iteration:  50  cost:  0.9705571070943289\n",
      "iteration:  60  cost:  0.7375202198025466\n",
      "iteration:  70  cost:  0.3390153766076985\n",
      "iteration:  80  cost:  0.29291324980197797\n",
      "iteration:  90  cost:  0.29879250908807586\n",
      "iteration:  100  cost:  0.3933400828196567\n",
      "iteration:  110  cost:  0.47185488586526914\n",
      "iteration:  120  cost:  0.3402639639418183\n",
      "iteration:  130  cost:  0.20761217435766405\n",
      "iteration:  140  cost:  0.32323878702425046\n",
      "Accuracy for U_14 pca8 :0.9588652482269504\n",
      "Epoch 1/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.1094 - val_loss: 0.0335\n",
      "Epoch 2/10\n",
      "396/396 [==============================] - 1s 1ms/step - loss: 0.0318 - val_loss: 0.0275\n",
      "Epoch 3/10\n",
      "396/396 [==============================] - 1s 1ms/step - loss: 0.0270 - val_loss: 0.0245\n",
      "Epoch 4/10\n",
      "396/396 [==============================] - 1s 1ms/step - loss: 0.0240 - val_loss: 0.0216\n",
      "Epoch 5/10\n",
      "396/396 [==============================] - 1s 1ms/step - loss: 0.0216 - val_loss: 0.0201\n",
      "Epoch 6/10\n",
      "396/396 [==============================] - 1s 1ms/step - loss: 0.0201 - val_loss: 0.0191\n",
      "Epoch 7/10\n",
      "396/396 [==============================] - 1s 1ms/step - loss: 0.0191 - val_loss: 0.0186\n",
      "Epoch 8/10\n",
      "396/396 [==============================] - 1s 1ms/step - loss: 0.0189 - val_loss: 0.0182\n",
      "Epoch 9/10\n",
      "396/396 [==============================] - 1s 1ms/step - loss: 0.0185 - val_loss: 0.0179\n",
      "Epoch 10/10\n",
      "396/396 [==============================] - 1s 1ms/step - loss: 0.0181 - val_loss: 0.0176\n",
      "\n",
      "\n",
      "Loss History for Hierarchical circuits, U_14 autoencoder8\n",
      "iteration:  0  cost:  2.1538333878288514\n",
      "iteration:  10  cost:  0.21451824272254288\n",
      "iteration:  20  cost:  0.32358052846927765\n",
      "iteration:  30  cost:  0.28857812307012576\n",
      "iteration:  40  cost:  0.24824339155595102\n",
      "iteration:  50  cost:  0.29143093703363215\n",
      "iteration:  60  cost:  0.18487065548913903\n",
      "iteration:  70  cost:  0.17915872070665015\n",
      "iteration:  80  cost:  0.2216548623445828\n",
      "iteration:  90  cost:  0.27413933171043603\n",
      "iteration:  100  cost:  0.1648644540883434\n",
      "iteration:  110  cost:  0.4354824001773377\n",
      "iteration:  120  cost:  0.28978923231242915\n",
      "iteration:  130  cost:  0.2575965108993393\n",
      "iteration:  140  cost:  0.20703462083998908\n",
      "Accuracy for U_14 autoencoder8 :0.9749408983451536\n",
      "\n",
      "\n",
      "Loss History for Hierarchical circuits, U_15 resize256\n",
      "iteration:  0  cost:  0.937753013264274\n",
      "iteration:  10  cost:  0.44462944337924887\n",
      "iteration:  20  cost:  0.2936507998408514\n",
      "iteration:  30  cost:  0.13682038855404416\n",
      "iteration:  40  cost:  0.1887397853507083\n",
      "iteration:  50  cost:  0.23433019663977753\n",
      "iteration:  60  cost:  0.10711163366912295\n",
      "iteration:  70  cost:  0.17014350277702772\n",
      "iteration:  80  cost:  0.1641762340276363\n",
      "iteration:  90  cost:  0.16455594422434047\n",
      "iteration:  100  cost:  0.2284813580708072\n",
      "iteration:  110  cost:  0.18444064190630155\n",
      "iteration:  120  cost:  0.12947467621547895\n",
      "iteration:  130  cost:  0.15224728439783505\n",
      "iteration:  140  cost:  0.12576826514303874\n",
      "Accuracy for U_15 resize256 :0.9886524822695035\n",
      "\n",
      "\n",
      "Loss History for Hierarchical circuits, U_15 pca8\n",
      "iteration:  0  cost:  0.9876175375809079\n",
      "iteration:  10  cost:  0.8712079102856914\n",
      "iteration:  20  cost:  0.15598528828640487\n",
      "iteration:  30  cost:  0.1896050646421225\n",
      "iteration:  40  cost:  0.13384321632011395\n",
      "iteration:  50  cost:  0.14547761308471852\n",
      "iteration:  60  cost:  0.0481856857193128\n",
      "iteration:  70  cost:  0.31079950674145673\n",
      "iteration:  80  cost:  0.06327663013435597\n",
      "iteration:  90  cost:  0.16384131641838678\n",
      "iteration:  100  cost:  0.18490476736437209\n",
      "iteration:  110  cost:  0.13764211759796122\n",
      "iteration:  120  cost:  0.08210327538155698\n",
      "iteration:  130  cost:  0.13299364019932725\n",
      "iteration:  140  cost:  0.0923660057450124\n",
      "Accuracy for U_15 pca8 :0.9862884160756501\n",
      "Epoch 1/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.1072 - val_loss: 0.0346\n",
      "Epoch 2/10\n",
      "396/396 [==============================] - 1s 1ms/step - loss: 0.0319 - val_loss: 0.0273\n",
      "Epoch 3/10\n",
      "396/396 [==============================] - 1s 1ms/step - loss: 0.0268 - val_loss: 0.0243\n",
      "Epoch 4/10\n",
      "396/396 [==============================] - 1s 1ms/step - loss: 0.0240 - val_loss: 0.0217\n",
      "Epoch 5/10\n",
      "396/396 [==============================] - 1s 1ms/step - loss: 0.0216 - val_loss: 0.0203\n",
      "Epoch 6/10\n",
      "396/396 [==============================] - 1s 1ms/step - loss: 0.0204 - val_loss: 0.0195\n",
      "Epoch 7/10\n",
      "396/396 [==============================] - 1s 1ms/step - loss: 0.0196 - val_loss: 0.0189\n",
      "Epoch 8/10\n",
      "396/396 [==============================] - 1s 1ms/step - loss: 0.0192 - val_loss: 0.0184\n",
      "Epoch 9/10\n",
      "396/396 [==============================] - 1s 1ms/step - loss: 0.0188 - val_loss: 0.0181\n",
      "Epoch 10/10\n",
      "396/396 [==============================] - 1s 1ms/step - loss: 0.0183 - val_loss: 0.0178\n",
      "\n",
      "\n",
      "Loss History for Hierarchical circuits, U_15 autoencoder8\n",
      "iteration:  0  cost:  0.8209852521769185\n",
      "iteration:  10  cost:  0.448337475338597\n",
      "iteration:  20  cost:  0.4244688682435559\n",
      "iteration:  30  cost:  0.380097889262496\n",
      "iteration:  40  cost:  0.1466754751194353\n",
      "iteration:  50  cost:  0.2009619316460856\n",
      "iteration:  60  cost:  0.38773296778175415\n",
      "iteration:  70  cost:  0.3049802101822073\n",
      "iteration:  80  cost:  0.29469472534143654\n",
      "iteration:  90  cost:  0.29758518737957873\n",
      "iteration:  100  cost:  0.277874436218119\n",
      "iteration:  110  cost:  0.23215458448235585\n",
      "iteration:  120  cost:  0.3277848324470413\n",
      "iteration:  130  cost:  0.2802321679072304\n",
      "iteration:  140  cost:  0.20793168029144352\n",
      "Accuracy for U_15 autoencoder8 :0.9678486997635933\n",
      "\n",
      "\n",
      "Loss History for Hierarchical circuits, U_SO4 resize256\n",
      "iteration:  0  cost:  1.0876492994401596\n",
      "iteration:  10  cost:  0.875031444661837\n",
      "iteration:  20  cost:  0.3492993456888202\n",
      "iteration:  30  cost:  0.35187035372731545\n",
      "iteration:  40  cost:  0.3244851681807592\n",
      "iteration:  50  cost:  0.3304827986649241\n",
      "iteration:  60  cost:  0.28491539499911694\n",
      "iteration:  70  cost:  0.17098100252565807\n",
      "iteration:  80  cost:  0.2023459010622861\n",
      "iteration:  90  cost:  0.1604522298657404\n",
      "iteration:  100  cost:  0.38219200320817104\n",
      "iteration:  110  cost:  0.14674944668857434\n",
      "iteration:  120  cost:  0.2319085551733336\n",
      "iteration:  130  cost:  0.1717003224461861\n",
      "iteration:  140  cost:  0.14467363997309132\n",
      "Accuracy for U_SO4 resize256 :0.9891252955082742\n",
      "\n",
      "\n",
      "Loss History for Hierarchical circuits, U_SO4 pca8\n",
      "iteration:  0  cost:  1.139460352032038\n",
      "iteration:  10  cost:  0.8787675610685872\n",
      "iteration:  20  cost:  0.3818110733032691\n",
      "iteration:  30  cost:  0.25645924212291726\n",
      "iteration:  40  cost:  0.1669334381241178\n",
      "iteration:  50  cost:  0.2501777404395046\n",
      "iteration:  60  cost:  0.16909293302390016\n",
      "iteration:  70  cost:  0.10453180754727188\n",
      "iteration:  80  cost:  0.16146199641647402\n",
      "iteration:  90  cost:  0.14109568100880898\n",
      "iteration:  100  cost:  0.15911165846563888\n",
      "iteration:  110  cost:  0.0984156485952162\n",
      "iteration:  120  cost:  0.16788227554487747\n",
      "iteration:  130  cost:  0.35473679228609284\n",
      "iteration:  140  cost:  0.12402732584353006\n",
      "Accuracy for U_SO4 pca8 :0.9810874704491725\n",
      "Epoch 1/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.1079 - val_loss: 0.0348\n",
      "Epoch 2/10\n",
      "396/396 [==============================] - 1s 1ms/step - loss: 0.0323 - val_loss: 0.0271\n",
      "Epoch 3/10\n",
      "396/396 [==============================] - 1s 1ms/step - loss: 0.0265 - val_loss: 0.0247\n",
      "Epoch 4/10\n",
      "396/396 [==============================] - 1s 1ms/step - loss: 0.0243 - val_loss: 0.0219\n",
      "Epoch 5/10\n",
      "396/396 [==============================] - 1s 1ms/step - loss: 0.0215 - val_loss: 0.0202\n",
      "Epoch 6/10\n",
      "396/396 [==============================] - 1s 1ms/step - loss: 0.0202 - val_loss: 0.0193\n",
      "Epoch 7/10\n",
      "396/396 [==============================] - 1s 1ms/step - loss: 0.0198 - val_loss: 0.0188\n",
      "Epoch 8/10\n",
      "396/396 [==============================] - 1s 1ms/step - loss: 0.0191 - val_loss: 0.0184\n",
      "Epoch 9/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.0186 - val_loss: 0.0181\n",
      "Epoch 10/10\n",
      "396/396 [==============================] - 1s 1ms/step - loss: 0.0184 - val_loss: 0.0178\n",
      "\n",
      "\n",
      "Loss History for Hierarchical circuits, U_SO4 autoencoder8\n",
      "iteration:  0  cost:  1.1064518303313409\n",
      "iteration:  10  cost:  0.4441195198894281\n",
      "iteration:  20  cost:  0.317731337039604\n",
      "iteration:  30  cost:  0.33123630124136677\n",
      "iteration:  40  cost:  0.2900615363980574\n",
      "iteration:  50  cost:  0.21030204317404583\n",
      "iteration:  60  cost:  0.23992628748947314\n",
      "iteration:  70  cost:  0.24287535994679094\n",
      "iteration:  80  cost:  0.2950511530333979\n",
      "iteration:  90  cost:  0.23328339912379295\n",
      "iteration:  100  cost:  0.28534976040631344\n",
      "iteration:  110  cost:  0.15944635381915495\n",
      "iteration:  120  cost:  0.30863654288939846\n",
      "iteration:  130  cost:  0.2536501471576918\n",
      "iteration:  140  cost:  0.33530161159777305\n",
      "Accuracy for U_SO4 autoencoder8 :0.9697399527186761\n",
      "4th step : \n",
      "\n",
      "\n",
      "Loss History for Hierarchical circuits, U_TTN resize256\n",
      "iteration:  0  cost:  1.0333989805309347\n",
      "iteration:  10  cost:  0.8016274934808298\n",
      "iteration:  20  cost:  0.4892875161982498\n",
      "iteration:  30  cost:  0.47861103100867164\n",
      "iteration:  40  cost:  0.45424943631672954\n",
      "iteration:  50  cost:  0.380744435711756\n",
      "iteration:  60  cost:  0.4193469437175832\n",
      "iteration:  70  cost:  0.3067869997335482\n",
      "iteration:  80  cost:  0.3202169999671907\n",
      "iteration:  90  cost:  0.24815324761116592\n",
      "iteration:  100  cost:  0.28547336539651336\n",
      "iteration:  110  cost:  0.24076389390596112\n",
      "iteration:  120  cost:  0.28915815020250457\n",
      "iteration:  130  cost:  0.2839226142613323\n",
      "iteration:  140  cost:  0.39343337348888974\n",
      "Accuracy for U_TTN resize256 :0.9777777777777777\n",
      "\n",
      "\n",
      "Loss History for Hierarchical circuits, U_TTN pca8\n",
      "iteration:  0  cost:  1.1348758084610648\n",
      "iteration:  10  cost:  0.997608043930894\n",
      "iteration:  20  cost:  0.8742751057707031\n",
      "iteration:  30  cost:  0.6342478960310871\n",
      "iteration:  40  cost:  0.3697749441017346\n",
      "iteration:  50  cost:  0.3390803137542278\n",
      "iteration:  60  cost:  0.33109668895702404\n",
      "iteration:  70  cost:  0.37879809366177647\n",
      "iteration:  80  cost:  0.31087016438049\n",
      "iteration:  90  cost:  0.3424005352173903\n",
      "iteration:  100  cost:  0.359543354062355\n",
      "iteration:  110  cost:  0.3118636539538193\n",
      "iteration:  120  cost:  0.5045297977828784\n",
      "iteration:  130  cost:  0.2874067642596213\n",
      "iteration:  140  cost:  0.3053664365235673\n",
      "Accuracy for U_TTN pca8 :0.9527186761229315\n",
      "Epoch 1/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.1075 - val_loss: 0.0357\n",
      "Epoch 2/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.0325 - val_loss: 0.0267\n",
      "Epoch 3/10\n",
      "396/396 [==============================] - 1s 1ms/step - loss: 0.0261 - val_loss: 0.0235\n",
      "Epoch 4/10\n",
      "396/396 [==============================] - 1s 1ms/step - loss: 0.0233 - val_loss: 0.0216\n",
      "Epoch 5/10\n",
      "396/396 [==============================] - 1s 1ms/step - loss: 0.0216 - val_loss: 0.0205\n",
      "Epoch 6/10\n",
      "396/396 [==============================] - 1s 1ms/step - loss: 0.0205 - val_loss: 0.0197\n",
      "Epoch 7/10\n",
      "396/396 [==============================] - 1s 1ms/step - loss: 0.0197 - val_loss: 0.0190\n",
      "Epoch 8/10\n",
      "396/396 [==============================] - 1s 1ms/step - loss: 0.0191 - val_loss: 0.0185\n",
      "Epoch 9/10\n",
      "396/396 [==============================] - 1s 1ms/step - loss: 0.0187 - val_loss: 0.0180\n",
      "Epoch 10/10\n",
      "396/396 [==============================] - 1s 1ms/step - loss: 0.0184 - val_loss: 0.0178\n",
      "\n",
      "\n",
      "Loss History for Hierarchical circuits, U_TTN autoencoder8\n",
      "iteration:  0  cost:  1.0681564619897517\n",
      "iteration:  10  cost:  0.8983578915359351\n",
      "iteration:  20  cost:  0.3170215473176095\n",
      "iteration:  30  cost:  0.2956688037418884\n",
      "iteration:  40  cost:  0.3384464772016906\n",
      "iteration:  50  cost:  0.21655589826287527\n",
      "iteration:  60  cost:  0.18503764396876984\n",
      "iteration:  70  cost:  0.26604013344665\n",
      "iteration:  80  cost:  0.32835921477260455\n",
      "iteration:  90  cost:  0.303658431383049\n",
      "iteration:  100  cost:  0.3370900985454036\n",
      "iteration:  110  cost:  0.18965876516813956\n",
      "iteration:  120  cost:  0.24883700702357014\n",
      "iteration:  130  cost:  0.22917742694393275\n",
      "iteration:  140  cost:  0.25784073384100137\n",
      "Accuracy for U_TTN autoencoder8 :0.9602836879432625\n",
      "\n",
      "\n",
      "Loss History for Hierarchical circuits, U_5 resize256\n",
      "iteration:  0  cost:  0.9837595068593804\n",
      "iteration:  10  cost:  1.0764900785066103\n",
      "iteration:  20  cost:  1.196087822704741\n",
      "iteration:  30  cost:  1.0073502312878408\n",
      "iteration:  40  cost:  0.9729464164505879\n",
      "iteration:  50  cost:  0.9652720810556262\n",
      "iteration:  60  cost:  1.0276844377914325\n",
      "iteration:  70  cost:  0.9900263326101135\n",
      "iteration:  80  cost:  0.9958383770620539\n",
      "iteration:  90  cost:  0.9986087420269772\n",
      "iteration:  100  cost:  1.0024643364251482\n",
      "iteration:  110  cost:  1.0006035207065935\n",
      "iteration:  120  cost:  0.9784021256065867\n",
      "iteration:  130  cost:  0.9871701481303045\n",
      "iteration:  140  cost:  0.938854356771986\n",
      "Accuracy for U_5 resize256 :0.5366430260047281\n",
      "\n",
      "\n",
      "Loss History for Hierarchical circuits, U_5 pca8\n",
      "iteration:  0  cost:  1.0090108358960757\n",
      "iteration:  10  cost:  0.9567944615836862\n",
      "iteration:  20  cost:  0.9014496925475918\n",
      "iteration:  30  cost:  0.9640341331837492\n",
      "iteration:  40  cost:  0.9912049123845301\n",
      "iteration:  50  cost:  0.8857223786213928\n",
      "iteration:  60  cost:  0.9655739284245233\n",
      "iteration:  70  cost:  0.9943568113398797\n",
      "iteration:  80  cost:  1.004796883912791\n",
      "iteration:  90  cost:  0.9959118465691928\n",
      "iteration:  100  cost:  0.9668671892734451\n",
      "iteration:  110  cost:  0.9848757899645073\n",
      "iteration:  120  cost:  1.0149273257571687\n",
      "iteration:  130  cost:  1.0080891734790776\n",
      "iteration:  140  cost:  0.9480733140169686\n",
      "Accuracy for U_5 pca8 :0.5583924349881797\n",
      "Epoch 1/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.1071 - val_loss: 0.0346\n",
      "Epoch 2/10\n",
      "396/396 [==============================] - 1s 1ms/step - loss: 0.0328 - val_loss: 0.0277\n",
      "Epoch 3/10\n",
      "396/396 [==============================] - 1s 1ms/step - loss: 0.0265 - val_loss: 0.0234\n",
      "Epoch 4/10\n",
      "396/396 [==============================] - 1s 1ms/step - loss: 0.0230 - val_loss: 0.0209\n",
      "Epoch 5/10\n",
      "396/396 [==============================] - 1s 1ms/step - loss: 0.0210 - val_loss: 0.0196\n",
      "Epoch 6/10\n",
      "396/396 [==============================] - 1s 1ms/step - loss: 0.0198 - val_loss: 0.0188\n",
      "Epoch 7/10\n",
      "396/396 [==============================] - 1s 1ms/step - loss: 0.0190 - val_loss: 0.0183\n",
      "Epoch 8/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.0184 - val_loss: 0.0179\n",
      "Epoch 9/10\n",
      "396/396 [==============================] - 1s 1ms/step - loss: 0.0181 - val_loss: 0.0176\n",
      "Epoch 10/10\n",
      "396/396 [==============================] - 1s 1ms/step - loss: 0.0180 - val_loss: 0.0173\n",
      "\n",
      "\n",
      "Loss History for Hierarchical circuits, U_5 autoencoder8\n",
      "iteration:  0  cost:  1.1976477614338057\n",
      "iteration:  10  cost:  0.840150557858384\n",
      "iteration:  20  cost:  0.6087918285560574\n",
      "iteration:  30  cost:  0.5060285698180911\n",
      "iteration:  40  cost:  0.31446008761333\n",
      "iteration:  50  cost:  0.3917753144215812\n",
      "iteration:  60  cost:  0.26658810925151605\n",
      "iteration:  70  cost:  0.36335928320940647\n",
      "iteration:  80  cost:  0.247256231872199\n",
      "iteration:  90  cost:  0.26832894349150743\n",
      "iteration:  100  cost:  0.34848539108572196\n",
      "iteration:  110  cost:  0.323625242054759\n",
      "iteration:  120  cost:  0.28620845867712247\n",
      "iteration:  130  cost:  0.24502502439213877\n",
      "iteration:  140  cost:  0.3635679934928354\n",
      "Accuracy for U_5 autoencoder8 :0.9947990543735225\n",
      "\n",
      "\n",
      "Loss History for Hierarchical circuits, U_6 resize256\n",
      "iteration:  0  cost:  1.2898839570568938\n",
      "iteration:  10  cost:  1.0834140552303295\n",
      "iteration:  20  cost:  0.3101099858854839\n",
      "iteration:  30  cost:  0.2261832477959348\n",
      "iteration:  40  cost:  0.25942751212081006\n",
      "iteration:  50  cost:  0.1506361170040996\n",
      "iteration:  60  cost:  0.23692449491892206\n",
      "iteration:  70  cost:  0.17554784515012312\n",
      "iteration:  80  cost:  0.23300697327509337\n",
      "iteration:  90  cost:  0.10852327259184916\n",
      "iteration:  100  cost:  0.20797960336989552\n",
      "iteration:  110  cost:  0.21646422559673692\n",
      "iteration:  120  cost:  0.14777664886680625\n",
      "iteration:  130  cost:  0.22722911075910474\n",
      "iteration:  140  cost:  0.19364934773344014\n",
      "Accuracy for U_6 resize256 :0.9886524822695035\n",
      "\n",
      "\n",
      "Loss History for Hierarchical circuits, U_6 pca8\n",
      "iteration:  0  cost:  1.0779984542484764\n",
      "iteration:  10  cost:  0.9811841747216896\n",
      "iteration:  20  cost:  0.9712498173068795\n",
      "iteration:  30  cost:  0.821450148069525\n",
      "iteration:  40  cost:  0.9600849592282336\n",
      "iteration:  50  cost:  1.0094069450051608\n",
      "iteration:  60  cost:  1.0180470115864662\n",
      "iteration:  70  cost:  0.9906766170179009\n",
      "iteration:  80  cost:  0.9020194326295065\n",
      "iteration:  90  cost:  0.9187848455902373\n",
      "iteration:  100  cost:  1.1476953547070645\n",
      "iteration:  110  cost:  0.8072168189243536\n",
      "iteration:  120  cost:  0.9302108536297555\n",
      "iteration:  130  cost:  0.9702817376671841\n",
      "iteration:  140  cost:  0.8016130346639203\n",
      "Accuracy for U_6 pca8 :0.6548463356973995\n",
      "Epoch 1/10\n",
      "396/396 [==============================] - 1s 1ms/step - loss: 0.1077 - val_loss: 0.0363\n",
      "Epoch 2/10\n",
      "396/396 [==============================] - 1s 1ms/step - loss: 0.0334 - val_loss: 0.0276\n",
      "Epoch 3/10\n",
      "396/396 [==============================] - 1s 1ms/step - loss: 0.0270 - val_loss: 0.0244\n",
      "Epoch 4/10\n",
      "396/396 [==============================] - 1s 1ms/step - loss: 0.0239 - val_loss: 0.0226\n",
      "Epoch 5/10\n",
      "396/396 [==============================] - 1s 1ms/step - loss: 0.0225 - val_loss: 0.0215\n",
      "Epoch 6/10\n",
      "396/396 [==============================] - 1s 1ms/step - loss: 0.0215 - val_loss: 0.0208\n",
      "Epoch 7/10\n",
      "396/396 [==============================] - 1s 1ms/step - loss: 0.0210 - val_loss: 0.0201\n",
      "Epoch 8/10\n",
      "396/396 [==============================] - 1s 1ms/step - loss: 0.0200 - val_loss: 0.0196\n",
      "Epoch 9/10\n",
      "396/396 [==============================] - 1s 1ms/step - loss: 0.0196 - val_loss: 0.0190\n",
      "Epoch 10/10\n",
      "396/396 [==============================] - 1s 1ms/step - loss: 0.0191 - val_loss: 0.0185\n",
      "\n",
      "\n",
      "Loss History for Hierarchical circuits, U_6 autoencoder8\n",
      "iteration:  0  cost:  0.6936968121885557\n",
      "iteration:  10  cost:  0.5190003798456274\n",
      "iteration:  20  cost:  0.44967195038403523\n",
      "iteration:  30  cost:  0.40817233438128087\n",
      "iteration:  40  cost:  0.4269765493215069\n",
      "iteration:  50  cost:  0.34189770406754383\n",
      "iteration:  60  cost:  0.39996921581463946\n",
      "iteration:  70  cost:  0.2888581414926923\n",
      "iteration:  80  cost:  0.4008830921091869\n",
      "iteration:  90  cost:  0.38881724580650784\n",
      "iteration:  100  cost:  0.3748025348744559\n",
      "iteration:  110  cost:  0.2613932613965229\n",
      "iteration:  120  cost:  0.3713277324443428\n",
      "iteration:  130  cost:  0.33325722721067413\n",
      "iteration:  140  cost:  0.3264350062004759\n",
      "Accuracy for U_6 autoencoder8 :0.9900709219858156\n",
      "\n",
      "\n",
      "Loss History for Hierarchical circuits, U_13 resize256\n",
      "iteration:  0  cost:  0.9921212858635297\n",
      "iteration:  10  cost:  1.02633970278689\n",
      "iteration:  20  cost:  0.9782000899400595\n",
      "iteration:  30  cost:  0.8552057003698589\n",
      "iteration:  40  cost:  0.5060251643835494\n",
      "iteration:  50  cost:  0.3918614264251648\n",
      "iteration:  60  cost:  0.4353062205080696\n",
      "iteration:  70  cost:  0.32145924961439776\n",
      "iteration:  80  cost:  0.36513730019582036\n",
      "iteration:  90  cost:  0.2906595112787491\n",
      "iteration:  100  cost:  0.35045786351031716\n",
      "iteration:  110  cost:  0.2588338374071501\n",
      "iteration:  120  cost:  0.287256194833861\n",
      "iteration:  130  cost:  0.31167699599652937\n",
      "iteration:  140  cost:  0.25888565002047836\n",
      "Accuracy for U_13 resize256 :0.9796690307328605\n",
      "\n",
      "\n",
      "Loss History for Hierarchical circuits, U_13 pca8\n",
      "iteration:  0  cost:  0.9977658443264938\n",
      "iteration:  10  cost:  0.9894436372484897\n",
      "iteration:  20  cost:  1.0516218453388704\n",
      "iteration:  30  cost:  0.9328335628644946\n",
      "iteration:  40  cost:  1.260925959937506\n",
      "iteration:  50  cost:  0.9640467532133621\n",
      "iteration:  60  cost:  0.9642231701739612\n",
      "iteration:  70  cost:  0.931738130195106\n",
      "iteration:  80  cost:  0.9643501581806386\n",
      "iteration:  90  cost:  1.0109397884240088\n",
      "iteration:  100  cost:  0.997340969845787\n",
      "iteration:  110  cost:  0.9813066517201164\n",
      "iteration:  120  cost:  0.8284211769003754\n",
      "iteration:  130  cost:  0.8686284358505353\n",
      "iteration:  140  cost:  0.8424704975710259\n",
      "Accuracy for U_13 pca8 :0.6033096926713948\n",
      "Epoch 1/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.1073 - val_loss: 0.0343\n",
      "Epoch 2/10\n",
      "396/396 [==============================] - 1s 1ms/step - loss: 0.0317 - val_loss: 0.0271\n",
      "Epoch 3/10\n",
      "396/396 [==============================] - 1s 1ms/step - loss: 0.0267 - val_loss: 0.0240\n",
      "Epoch 4/10\n",
      "396/396 [==============================] - 1s 1ms/step - loss: 0.0240 - val_loss: 0.0219\n",
      "Epoch 5/10\n",
      "396/396 [==============================] - 1s 1ms/step - loss: 0.0220 - val_loss: 0.0202\n",
      "Epoch 6/10\n",
      "396/396 [==============================] - 1s 1ms/step - loss: 0.0202 - val_loss: 0.0192\n",
      "Epoch 7/10\n",
      "396/396 [==============================] - 1s 1ms/step - loss: 0.0193 - val_loss: 0.0185\n",
      "Epoch 8/10\n",
      "396/396 [==============================] - 1s 1ms/step - loss: 0.0189 - val_loss: 0.0181\n",
      "Epoch 9/10\n",
      "396/396 [==============================] - 1s 1ms/step - loss: 0.0182 - val_loss: 0.0178\n",
      "Epoch 10/10\n",
      "396/396 [==============================] - 1s 1ms/step - loss: 0.0179 - val_loss: 0.0175\n",
      "\n",
      "\n",
      "Loss History for Hierarchical circuits, U_13 autoencoder8\n",
      "iteration:  0  cost:  1.3200062698228938\n",
      "iteration:  10  cost:  0.5363495072615561\n",
      "iteration:  20  cost:  0.3575859210273303\n",
      "iteration:  30  cost:  0.3686452765393359\n",
      "iteration:  40  cost:  0.20667769430227373\n",
      "iteration:  50  cost:  0.24642945559355872\n",
      "iteration:  60  cost:  0.33028267031637637\n",
      "iteration:  70  cost:  0.23219159398921219\n",
      "iteration:  80  cost:  0.39217203941831696\n",
      "iteration:  90  cost:  0.268997958756871\n",
      "iteration:  100  cost:  0.31143910867171504\n",
      "iteration:  110  cost:  0.35750780976337404\n",
      "iteration:  120  cost:  0.30254288666522416\n",
      "iteration:  130  cost:  0.25541562257837713\n",
      "iteration:  140  cost:  0.4495030779421876\n",
      "Accuracy for U_13 autoencoder8 :0.9513002364066194\n",
      "\n",
      "\n",
      "Loss History for Hierarchical circuits, U_14 resize256\n",
      "iteration:  0  cost:  1.503721947110501\n",
      "iteration:  10  cost:  0.9711892176620632\n",
      "iteration:  20  cost:  0.7073498036619611\n",
      "iteration:  30  cost:  0.5703823064887058\n",
      "iteration:  40  cost:  0.4489571970242423\n",
      "iteration:  50  cost:  0.32664847173257533\n",
      "iteration:  60  cost:  0.263280748739262\n",
      "iteration:  70  cost:  0.36690079253929603\n",
      "iteration:  80  cost:  0.4139021657032725\n",
      "iteration:  90  cost:  0.2673608720351998\n",
      "iteration:  100  cost:  0.26853529763784034\n",
      "iteration:  110  cost:  0.3613645245404184\n",
      "iteration:  120  cost:  0.28520378212738595\n",
      "iteration:  130  cost:  0.1848139166221327\n",
      "iteration:  140  cost:  0.37123338412181595\n",
      "Accuracy for U_14 resize256 :0.9881796690307328\n",
      "\n",
      "\n",
      "Loss History for Hierarchical circuits, U_14 pca8\n",
      "iteration:  0  cost:  1.4593318677381786\n",
      "iteration:  10  cost:  0.9622945291703185\n",
      "iteration:  20  cost:  0.9444490348961265\n",
      "iteration:  30  cost:  0.8440120195898896\n",
      "iteration:  40  cost:  0.8248541947115362\n",
      "iteration:  50  cost:  0.945393499673592\n",
      "iteration:  60  cost:  0.9260070997620532\n",
      "iteration:  70  cost:  0.9871810497530794\n",
      "iteration:  80  cost:  0.7319647091504471\n",
      "iteration:  90  cost:  0.5020234856257324\n",
      "iteration:  100  cost:  0.4371624565479002\n",
      "iteration:  110  cost:  0.42905735330185446\n",
      "iteration:  120  cost:  0.21931406405712842\n",
      "iteration:  130  cost:  0.2431004206302407\n",
      "iteration:  140  cost:  0.29199824193122526\n",
      "Accuracy for U_14 pca8 :0.9815602836879432\n",
      "Epoch 1/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.1089 - val_loss: 0.0335\n",
      "Epoch 2/10\n",
      "396/396 [==============================] - 1s 1ms/step - loss: 0.0312 - val_loss: 0.0272\n",
      "Epoch 3/10\n",
      "396/396 [==============================] - 1s 1ms/step - loss: 0.0270 - val_loss: 0.0244\n",
      "Epoch 4/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.0240 - val_loss: 0.0223\n",
      "Epoch 5/10\n",
      "396/396 [==============================] - 1s 1ms/step - loss: 0.0221 - val_loss: 0.0211\n",
      "Epoch 6/10\n",
      "396/396 [==============================] - 1s 1ms/step - loss: 0.0208 - val_loss: 0.0202\n",
      "Epoch 7/10\n",
      "396/396 [==============================] - 1s 1ms/step - loss: 0.0204 - val_loss: 0.0192\n",
      "Epoch 8/10\n",
      "396/396 [==============================] - 1s 1ms/step - loss: 0.0195 - val_loss: 0.0187\n",
      "Epoch 9/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.0190 - val_loss: 0.0183\n",
      "Epoch 10/10\n",
      "396/396 [==============================] - 1s 1ms/step - loss: 0.0185 - val_loss: 0.0179\n",
      "\n",
      "\n",
      "Loss History for Hierarchical circuits, U_14 autoencoder8\n",
      "iteration:  0  cost:  1.646836181199927\n",
      "iteration:  10  cost:  0.7170786147537271\n",
      "iteration:  20  cost:  0.6342481306859706\n",
      "iteration:  30  cost:  0.6552068002077069\n",
      "iteration:  40  cost:  0.6169602757672061\n",
      "iteration:  50  cost:  0.49741637561683083\n",
      "iteration:  60  cost:  0.6726309231150566\n",
      "iteration:  70  cost:  0.6287730037516238\n",
      "iteration:  80  cost:  0.4957255450691882\n",
      "iteration:  90  cost:  0.49169253638426824\n",
      "iteration:  100  cost:  0.47570564365013257\n",
      "iteration:  110  cost:  0.42463286388674304\n",
      "iteration:  120  cost:  0.4302372746605311\n",
      "iteration:  130  cost:  0.43832233388406555\n",
      "iteration:  140  cost:  0.49649506039633023\n",
      "Accuracy for U_14 autoencoder8 :0.9513002364066194\n",
      "\n",
      "\n",
      "Loss History for Hierarchical circuits, U_15 resize256\n",
      "iteration:  0  cost:  1.6454396806298264\n",
      "iteration:  10  cost:  0.5985421172363973\n",
      "iteration:  20  cost:  0.3438318452715708\n",
      "iteration:  30  cost:  0.215134121860677\n",
      "iteration:  40  cost:  0.11637351618660688\n",
      "iteration:  50  cost:  0.3041831545722989\n",
      "iteration:  60  cost:  0.30277489974822236\n",
      "iteration:  70  cost:  0.20065014537411194\n",
      "iteration:  80  cost:  0.17828015217821203\n",
      "iteration:  90  cost:  0.18081559504225286\n",
      "iteration:  100  cost:  0.16522145687319437\n",
      "iteration:  110  cost:  0.2248289826862503\n",
      "iteration:  120  cost:  0.10450911224682967\n",
      "iteration:  130  cost:  0.14936777301917212\n",
      "iteration:  140  cost:  0.13515728512987343\n",
      "Accuracy for U_15 resize256 :0.9891252955082742\n",
      "\n",
      "\n",
      "Loss History for Hierarchical circuits, U_15 pca8\n",
      "iteration:  0  cost:  1.1095420589910157\n",
      "iteration:  10  cost:  0.8816660457588971\n",
      "iteration:  20  cost:  0.3298638201447694\n",
      "iteration:  30  cost:  0.2607883833883246\n",
      "iteration:  40  cost:  0.3493099157788596\n",
      "iteration:  50  cost:  0.3631847680565459\n",
      "iteration:  60  cost:  0.41653657036449465\n",
      "iteration:  70  cost:  0.26119626024956055\n",
      "iteration:  80  cost:  0.08093681527046886\n",
      "iteration:  90  cost:  0.07977616546631078\n",
      "iteration:  100  cost:  0.14654474598918182\n",
      "iteration:  110  cost:  0.1615120026738532\n",
      "iteration:  120  cost:  0.08863752726592651\n",
      "iteration:  130  cost:  0.11044915839253376\n",
      "iteration:  140  cost:  0.08096807630454465\n",
      "Accuracy for U_15 pca8 :0.9839243498817967\n",
      "Epoch 1/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.1096 - val_loss: 0.0350\n",
      "Epoch 2/10\n",
      "396/396 [==============================] - 1s 1ms/step - loss: 0.0318 - val_loss: 0.0266\n",
      "Epoch 3/10\n",
      "396/396 [==============================] - 1s 1ms/step - loss: 0.0263 - val_loss: 0.0238\n",
      "Epoch 4/10\n",
      "396/396 [==============================] - 1s 1ms/step - loss: 0.0235 - val_loss: 0.0218\n",
      "Epoch 5/10\n",
      "396/396 [==============================] - 1s 1ms/step - loss: 0.0218 - val_loss: 0.0205\n",
      "Epoch 6/10\n",
      "396/396 [==============================] - 1s 1ms/step - loss: 0.0208 - val_loss: 0.0195\n",
      "Epoch 7/10\n",
      "396/396 [==============================] - 1s 1ms/step - loss: 0.0195 - val_loss: 0.0187\n",
      "Epoch 8/10\n",
      "396/396 [==============================] - 1s 1ms/step - loss: 0.0189 - val_loss: 0.0181\n",
      "Epoch 9/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.0185 - val_loss: 0.0178\n",
      "Epoch 10/10\n",
      "396/396 [==============================] - 1s 1ms/step - loss: 0.0181 - val_loss: 0.0175\n",
      "\n",
      "\n",
      "Loss History for Hierarchical circuits, U_15 autoencoder8\n",
      "iteration:  0  cost:  1.0480125832520268\n",
      "iteration:  10  cost:  0.4290177732454233\n",
      "iteration:  20  cost:  0.33567675394589097\n",
      "iteration:  30  cost:  0.340756869612617\n",
      "iteration:  40  cost:  0.30441453030407467\n",
      "iteration:  50  cost:  0.19943491513982045\n",
      "iteration:  60  cost:  0.22864073839813842\n",
      "iteration:  70  cost:  0.2609874543641418\n",
      "iteration:  80  cost:  0.2881410889552713\n",
      "iteration:  90  cost:  0.25575449040636405\n",
      "iteration:  100  cost:  0.21664602090206359\n",
      "iteration:  110  cost:  0.24723683430377455\n",
      "iteration:  120  cost:  0.3150496641140586\n",
      "iteration:  130  cost:  0.1287185794370628\n",
      "iteration:  140  cost:  0.2864062021395822\n",
      "Accuracy for U_15 autoencoder8 :0.9773049645390071\n",
      "\n",
      "\n",
      "Loss History for Hierarchical circuits, U_SO4 resize256\n",
      "iteration:  0  cost:  0.986332340264686\n",
      "iteration:  10  cost:  0.8004809988489627\n",
      "iteration:  20  cost:  0.3284911796098636\n",
      "iteration:  30  cost:  0.31324073384518386\n",
      "iteration:  40  cost:  0.17254475868794528\n",
      "iteration:  50  cost:  0.300470112929711\n",
      "iteration:  60  cost:  0.1235210644226126\n",
      "iteration:  70  cost:  0.274584315079888\n",
      "iteration:  80  cost:  0.24299155066607006\n",
      "iteration:  90  cost:  0.25104743626714393\n",
      "iteration:  100  cost:  0.17849909670894276\n",
      "iteration:  110  cost:  0.14437242626872224\n",
      "iteration:  120  cost:  0.1550572752748282\n",
      "iteration:  130  cost:  0.1942608635766877\n",
      "iteration:  140  cost:  0.22369755255134607\n",
      "Accuracy for U_SO4 resize256 :0.9881796690307328\n",
      "\n",
      "\n",
      "Loss History for Hierarchical circuits, U_SO4 pca8\n",
      "iteration:  0  cost:  1.166902712878496\n",
      "iteration:  10  cost:  0.9766511057570125\n",
      "iteration:  20  cost:  1.0183393607520383\n",
      "iteration:  30  cost:  0.8546433093727629\n",
      "iteration:  40  cost:  1.0677961942380265\n",
      "iteration:  50  cost:  0.3920762615451525\n",
      "iteration:  60  cost:  0.3330913685163919\n",
      "iteration:  70  cost:  0.18309727942681073\n",
      "iteration:  80  cost:  0.2682799624870419\n",
      "iteration:  90  cost:  0.1921381152583254\n",
      "iteration:  100  cost:  0.0964736243418498\n",
      "iteration:  110  cost:  0.10881770896857162\n",
      "iteration:  120  cost:  0.15370947568854615\n",
      "iteration:  130  cost:  0.044236856135649025\n",
      "iteration:  140  cost:  0.11041315589431135\n",
      "Accuracy for U_SO4 pca8 :0.9867612293144208\n",
      "Epoch 1/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.1071 - val_loss: 0.0336\n",
      "Epoch 2/10\n",
      "396/396 [==============================] - 1s 1ms/step - loss: 0.0312 - val_loss: 0.0272\n",
      "Epoch 3/10\n",
      "396/396 [==============================] - 1s 1ms/step - loss: 0.0269 - val_loss: 0.0245\n",
      "Epoch 4/10\n",
      "396/396 [==============================] - 1s 1ms/step - loss: 0.0241 - val_loss: 0.0220\n",
      "Epoch 5/10\n",
      "396/396 [==============================] - 1s 1ms/step - loss: 0.0218 - val_loss: 0.0203\n",
      "Epoch 6/10\n",
      "396/396 [==============================] - 1s 1ms/step - loss: 0.0203 - val_loss: 0.0193\n",
      "Epoch 7/10\n",
      "396/396 [==============================] - 1s 1ms/step - loss: 0.0192 - val_loss: 0.0185\n",
      "Epoch 8/10\n",
      "396/396 [==============================] - 1s 1ms/step - loss: 0.0184 - val_loss: 0.0180\n",
      "Epoch 9/10\n",
      "396/396 [==============================] - 1s 1ms/step - loss: 0.0185 - val_loss: 0.0177\n",
      "Epoch 10/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.0176 - val_loss: 0.0175\n",
      "\n",
      "\n",
      "Loss History for Hierarchical circuits, U_SO4 autoencoder8\n",
      "iteration:  0  cost:  0.8489369721587932\n",
      "iteration:  10  cost:  0.39688493852156315\n",
      "iteration:  20  cost:  0.2750839350816972\n",
      "iteration:  30  cost:  0.42197149332614925\n",
      "iteration:  40  cost:  0.442020442227582\n",
      "iteration:  50  cost:  0.3529243279542562\n",
      "iteration:  60  cost:  0.3551918615448173\n",
      "iteration:  70  cost:  0.21856171998167326\n",
      "iteration:  80  cost:  0.18275430055240335\n",
      "iteration:  90  cost:  0.30079850555012033\n",
      "iteration:  100  cost:  0.18122843250542575\n",
      "iteration:  110  cost:  0.19283730928533846\n",
      "iteration:  120  cost:  0.1598569119029882\n",
      "iteration:  130  cost:  0.19845883400936226\n",
      "iteration:  140  cost:  0.20678763231449832\n",
      "Accuracy for U_SO4 autoencoder8 :0.9739952718676123\n",
      "[0.9725768321513002, 0.9626477541371158, 0.7881796690307329, 0.9730496453900709, 0.9531914893617022, 0.8373522458628841, 0.9858156028368794, 0.9777777777777777, 0.9498817966903074, 0.9801418439716312, 0.6647754137115839, 0.9640661938534278, 0.9853427895981087, 0.6382978723404256, 0.9919621749408983, 0.9872340425531915, 0.9858156028368794, 0.9867612293144208, 0.9380614657210402, 0.983451536643026, 0.9839243498817967, 0.9706855791962175, 0.9692671394799054, 0.9749408983451536, 0.5947990543735224, 0.6392434988179669, 0.9631205673758865, 0.9796690307328605, 0.9541371158392435, 0.9952718676122931, 0.9791962174940898, 0.9569739952718677, 0.9229314420803783, 0.9475177304964539, 0.7423167848699763, 0.9498817966903074, 0.9895981087470449, 0.9843971631205674, 0.9654846335697399, 0.9886524822695035, 0.983451536643026, 0.9801418439716312, 0.975886524822695, 0.9801418439716312, 0.9167848699763593, 0.968321513002364, 0.6392434988179669, 0.8936170212765957, 0.9891252955082742, 0.9806146572104019, 0.9550827423167849, 0.9716312056737588, 0.6151300236406619, 0.9011820330969267, 0.9654846335697399, 0.9744680851063829, 0.9380614657210402, 0.9877068557919622, 0.9853427895981087, 0.991016548463357, 0.9385342789598109, 0.9872340425531915, 0.9872340425531915, 0.9739952718676123, 0.9456264775413712, 0.9546099290780142, 0.9735224586288416, 0.6042553191489362, 0.950354609929078, 0.9881796690307328, 0.9810874704491725, 0.9862884160756501, 0.957919621749409, 0.9810874704491725, 0.9617021276595744, 0.9858156028368794, 0.9588652482269504, 0.9749408983451536, 0.9886524822695035, 0.9862884160756501, 0.9678486997635933, 0.9891252955082742, 0.9810874704491725, 0.9697399527186761, 0.9777777777777777, 0.9527186761229315, 0.9602836879432625, 0.5366430260047281, 0.5583924349881797, 0.9947990543735225, 0.9886524822695035, 0.6548463356973995, 0.9900709219858156, 0.9796690307328605, 0.6033096926713948, 0.9513002364066194, 0.9881796690307328, 0.9815602836879432, 0.9513002364066194, 0.9891252955082742, 0.9839243498817967, 0.9773049645390071, 0.9881796690307328, 0.9867612293144208, 0.9739952718676123]\n"
     ]
    }
   ],
   "source": [
    "Benchmarking(Unitaries, U_num_params, Encodings, circuit, binary = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = [0.9725768321513002, 0.9626477541371158, 0.7881796690307329, 0.9730496453900709, 0.9531914893617022, 0.8373522458628841, 0.9858156028368794, 0.9777777777777777, 0.9498817966903074, 0.9801418439716312, 0.6647754137115839, 0.9640661938534278, 0.9853427895981087, 0.6382978723404256, 0.9919621749408983, 0.9872340425531915, 0.9858156028368794, 0.9867612293144208, 0.9380614657210402, 0.983451536643026, 0.9839243498817967, 0.9706855791962175, 0.9692671394799054, 0.9749408983451536, 0.5947990543735224, 0.6392434988179669, 0.9631205673758865, 0.9796690307328605, 0.9541371158392435, 0.9952718676122931, 0.9791962174940898, 0.9569739952718677, 0.9229314420803783, 0.9475177304964539, 0.7423167848699763, 0.9498817966903074, 0.9895981087470449, 0.9843971631205674, 0.9654846335697399, 0.9886524822695035, 0.983451536643026, 0.9801418439716312, 0.975886524822695, 0.9801418439716312, 0.9167848699763593, 0.968321513002364, 0.6392434988179669, 0.8936170212765957, 0.9891252955082742, 0.9806146572104019, 0.9550827423167849, 0.9716312056737588, 0.6151300236406619, 0.9011820330969267, 0.9654846335697399, 0.9744680851063829, 0.9380614657210402, 0.9877068557919622, 0.9853427895981087, 0.991016548463357, 0.9385342789598109, 0.9872340425531915, 0.9872340425531915, 0.9739952718676123, 0.9456264775413712, 0.9546099290780142, 0.9735224586288416, 0.6042553191489362, 0.950354609929078, 0.9881796690307328, 0.9810874704491725, 0.9862884160756501, 0.957919621749409, 0.9810874704491725, 0.9617021276595744, 0.9858156028368794, 0.9588652482269504, 0.9749408983451536, 0.9886524822695035, 0.9862884160756501, 0.9678486997635933, 0.9891252955082742, 0.9810874704491725, 0.9697399527186761, 0.9777777777777777, 0.9527186761229315, 0.9602836879432625, 0.5366430260047281, 0.5583924349881797, 0.9947990543735225, 0.9886524822695035, 0.6548463356973995, 0.9900709219858156, 0.9796690307328605, 0.6033096926713948, 0.9513002364066194, 0.9881796690307328, 0.9815602836879432, 0.9513002364066194, 0.9891252955082742, 0.9839243498817967, 0.9773049645390071, 0.9881796690307328, 0.9867612293144208, 0.9739952718676123]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "results_list = []\n",
    "for i in range(21):\n",
    "    #print(results[i], results[i+21], results[i+2*21], results[i+3*21], results[i+4*21])\n",
    "    results_list.append([results[i], results[i+21], results[i+2*21], results[i+3*21], results[i+4*21]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statistics as st"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.9725768321513002,\n",
       " 0.9706855791962175,\n",
       " 0.975886524822695,\n",
       " 0.9739952718676123,\n",
       " 0.9777777777777777]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_list[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for a quantum hierarchical classifier with 5 random initializations\n",
      "\n",
      "U_TTN Resize Mean : 0.9741843971631206 U_TTN Resize Variance : 7.66784590535913e-06\n",
      "U_TTN PCA Mean : 0.962080378250591 U_TTN PCA Variance : 0.00018414007790799612\n",
      "U_TTN Autoencoding Mean : 0.9189598108747045 U_TTN Autoencoding Variance : 0.0058051629417254875\n",
      "U_5 Resize Mean : 0.8092671394799054 U_5 Resize Variance : 0.049855819906219775\n",
      "U_5 PCA Mean : 0.6788652482269504 U_5 PCA Variance : 0.024618748218567143\n",
      "U_5 Autoencoding Mean : 0.9278486997635934 U_5 Autoencoding Variance : 0.0038985966500679047\n",
      "U_6 Resize Mean : 0.9862884160756501 U_6 Resize Variance : 1.531333657484258e-05\n",
      "U_6 PCA Mean : 0.909692671394799 U_6 PCA Variance : 0.020421172643897863\n",
      "U_6 Autoencoding Mean : 0.9753191489361702 U_6 Autoencoding Variance : 0.0004481554135998065\n",
      "U_13 Resize Mean : 0.9737115839243499 U_13 Resize Variance : 9.015866628662704e-05\n",
      "U_13 PCA Mean : 0.7642553191489362 U_13 PCA Variance : 0.03554869249814173\n",
      "U_13 Autoencoding Mean : 0.9402364066193853 U_13 Autoencoding Variance : 0.000743937539470963\n",
      "U_14 Resize Mean : 0.9744680851063829 U_14 Resize Variance : 0.0003105142263132298\n",
      "U_14 PCA Mean : 0.8591016548463357 U_14 PCA Variance : 0.0251628299493095\n",
      "U_14 Autoencoding Mean : 0.9612293144208038 U_14 Autoencoding Variance : 0.0004741545529232254\n",
      "U_15 Resize Mean : 0.9884633569739952 U_15 Resize Variance : 9.612751426543516e-07\n",
      "U_15 PCA Mean : 0.9851536643026004 U_15 PCA Variance : 9.612751426543516e-07\n",
      "U_15 Autoencoding Mean : 0.9776832151300237 U_15 Autoencoding Variance : 0.00012646356934873645\n",
      "SO(4) Resize Mean : 0.9685106382978723 SO(4) Resize Variance : 0.0007608157425571025\n",
      "SO(4) PCA Mean : 0.9843971631205674 SO(4) PCA Variance : 6.594794583326366e-06\n",
      "SO(4) Autoencoding Mean : 0.9790070921985815 SO(4) Autoencoding Variance : 5.103700350418337e-05\n"
     ]
    }
   ],
   "source": [
    "print(\"Results for a quantum hierarchical classifier with 5 random initializations\")\n",
    "print(\"\")\n",
    "for i in range(21):\n",
    "    if i < 3:\n",
    "        it = \"U_TTN\"\n",
    "    elif 2<i<6:\n",
    "        it = 'U_5'\n",
    "    elif 5<i<9:\n",
    "        it = 'U_6'\n",
    "    elif 8<i<12:\n",
    "        it = 'U_13'\n",
    "    elif 11<i<15:\n",
    "        it = 'U_14'\n",
    "    elif 14<i<18:\n",
    "        it = 'U_15'\n",
    "    else:\n",
    "        it = 'SO(4)'\n",
    "    \n",
    "    if i % 3 == 0:\n",
    "        emb = \"Resize\"\n",
    "    elif i % 3 == 1:\n",
    "        emb = \"PCA\"\n",
    "    else:\n",
    "        emb = \"Autoencoding\"\n",
    "        \n",
    "    print(it + \" \" + emb + \" Mean : \" + str(st.mean(results_list[i])),  it + \" \" + emb + \" Variance : \" + str(st.variance(results_list[i])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2 One Class Classification with 0, 1 labeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "Unitaries = ['U_TTN', 'U_5', 'U_6', 'U_13', 'U_14', 'U_15', 'U_SO4'] \n",
    "U_num_params = [2, 10, 10, 6, 6, 4, 6]\n",
    "Encodings = ['resize256', 'pca8', 'autoencoder8']\n",
    "classes = [0,1]\n",
    "circuit = 'Hierarchical'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Loss History for Hierarchical circuits, U_TTN resize256\n",
      "iteration:  0  cost:  0.35525773742240896\n",
      "iteration:  10  cost:  0.3328691558220538\n",
      "iteration:  20  cost:  0.2140754008832847\n",
      "iteration:  30  cost:  0.1015911831206335\n",
      "iteration:  40  cost:  0.08523465681568673\n",
      "iteration:  50  cost:  0.13504519589169214\n",
      "iteration:  60  cost:  0.16959733491187542\n",
      "iteration:  70  cost:  0.2056834277536673\n",
      "iteration:  80  cost:  0.10870341952284272\n",
      "iteration:  90  cost:  0.11761417128397657\n",
      "iteration:  100  cost:  0.11893951068590494\n",
      "iteration:  110  cost:  0.09069035817993487\n",
      "iteration:  120  cost:  0.13341179349553453\n",
      "iteration:  130  cost:  0.08403569285131886\n",
      "iteration:  140  cost:  0.10402214866940401\n",
      "Accuracy for U_TTN resize256 :0.9234042553191489\n",
      "\n",
      "\n",
      "Loss History for Hierarchical circuits, U_TTN pca8\n",
      "iteration:  0  cost:  0.4030474611440642\n",
      "iteration:  10  cost:  0.2398302903707779\n",
      "iteration:  20  cost:  0.19140073583434347\n",
      "iteration:  30  cost:  0.2604377151220624\n",
      "iteration:  40  cost:  0.17877926972908018\n",
      "iteration:  50  cost:  0.1238124106518014\n",
      "iteration:  60  cost:  0.18034799500328547\n",
      "iteration:  70  cost:  0.15470900330100978\n",
      "iteration:  80  cost:  0.1786454403290714\n",
      "iteration:  90  cost:  0.15552341338609912\n",
      "iteration:  100  cost:  0.1080365312462175\n",
      "iteration:  110  cost:  0.13626972451180194\n",
      "iteration:  120  cost:  0.07387872615792274\n",
      "iteration:  130  cost:  0.0590703888519139\n",
      "iteration:  140  cost:  0.1647587794761228\n",
      "Accuracy for U_TTN pca8 :0.9408983451536643\n",
      "Train on 12665 samples, validate on 2115 samples\n",
      "Epoch 1/10\n",
      "12665/12665 [==============================] - 1s 59us/sample - loss: 0.0638 - val_loss: 0.0336\n",
      "Epoch 2/10\n",
      "12665/12665 [==============================] - 1s 44us/sample - loss: 0.0290 - val_loss: 0.0264\n",
      "Epoch 3/10\n",
      "12665/12665 [==============================] - 1s 44us/sample - loss: 0.0250 - val_loss: 0.0233\n",
      "Epoch 4/10\n",
      "12665/12665 [==============================] - 1s 40us/sample - loss: 0.0223 - val_loss: 0.0212\n",
      "Epoch 5/10\n",
      "12665/12665 [==============================] - 1s 41us/sample - loss: 0.0206 - val_loss: 0.0198\n",
      "Epoch 6/10\n",
      "12665/12665 [==============================] - 1s 41us/sample - loss: 0.0197 - val_loss: 0.0191\n",
      "Epoch 7/10\n",
      "12665/12665 [==============================] - 1s 42us/sample - loss: 0.0191 - val_loss: 0.0187\n",
      "Epoch 8/10\n",
      "12665/12665 [==============================] - 1s 42us/sample - loss: 0.0187 - val_loss: 0.0183\n",
      "Epoch 9/10\n",
      "12665/12665 [==============================] - 1s 41us/sample - loss: 0.0184 - val_loss: 0.0180\n",
      "Epoch 10/10\n",
      "12665/12665 [==============================] - 1s 41us/sample - loss: 0.0181 - val_loss: 0.0178\n",
      "WARNING:tensorflow:Layer flatten_7 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer flatten_7 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Loss History for Hierarchical circuits, U_TTN autoencoder8\n",
      "iteration:  0  cost:  0.45104668114502133\n",
      "iteration:  10  cost:  0.13006874763709894\n",
      "iteration:  20  cost:  0.16286208703665153\n",
      "iteration:  30  cost:  0.06777652117910357\n",
      "iteration:  40  cost:  0.0459391601608008\n",
      "iteration:  50  cost:  0.06394366327047958\n",
      "iteration:  60  cost:  0.03721093113572069\n",
      "iteration:  70  cost:  0.034127685274360886\n",
      "iteration:  80  cost:  0.08091913406808816\n",
      "iteration:  90  cost:  0.05133387049661154\n",
      "iteration:  100  cost:  0.039230947766204144\n",
      "iteration:  110  cost:  0.07935346013945002\n",
      "iteration:  120  cost:  0.05189745380239168\n",
      "iteration:  130  cost:  0.05803668770364166\n",
      "iteration:  140  cost:  0.03936430964616579\n",
      "Accuracy for U_TTN autoencoder8 :0.9687943262411347\n",
      "\n",
      "\n",
      "Loss History for Hierarchical circuits, U_5 resize256\n",
      "iteration:  0  cost:  0.997476893650433\n",
      "iteration:  10  cost:  0.4954167402847351\n",
      "iteration:  20  cost:  0.24272056847158224\n",
      "iteration:  30  cost:  0.20005502694858276\n",
      "iteration:  40  cost:  0.13455155990291945\n",
      "iteration:  50  cost:  0.062391772882405515\n",
      "iteration:  60  cost:  0.06782984679061964\n",
      "iteration:  70  cost:  0.051669669560627914\n",
      "iteration:  80  cost:  0.08555047077084968\n",
      "iteration:  90  cost:  0.07754165842500776\n",
      "iteration:  100  cost:  0.08747648131396935\n",
      "iteration:  110  cost:  0.08216842735858754\n",
      "iteration:  120  cost:  0.06763290308263083\n",
      "iteration:  130  cost:  0.057370274365762225\n",
      "iteration:  140  cost:  0.04137957185042605\n",
      "Accuracy for U_5 resize256 :0.9730496453900709\n",
      "\n",
      "\n",
      "Loss History for Hierarchical circuits, U_5 pca8\n",
      "iteration:  0  cost:  0.4467016707658158\n",
      "iteration:  10  cost:  0.24165864807435697\n",
      "iteration:  20  cost:  0.39272876596729467\n",
      "iteration:  30  cost:  0.23641842619271533\n",
      "iteration:  40  cost:  0.2620000985371808\n",
      "iteration:  50  cost:  0.2583071047066748\n",
      "iteration:  60  cost:  0.2529738061437965\n",
      "iteration:  70  cost:  0.2663020601518469\n",
      "iteration:  80  cost:  0.23204714303962157\n",
      "iteration:  90  cost:  0.197878813750475\n",
      "iteration:  100  cost:  0.10714220263455583\n",
      "iteration:  110  cost:  0.08582382208494688\n",
      "iteration:  120  cost:  0.05874817954019195\n",
      "iteration:  130  cost:  0.030301907481934953\n",
      "iteration:  140  cost:  0.06545392653193942\n",
      "Accuracy for U_5 pca8 :0.9527186761229315\n",
      "Train on 12665 samples, validate on 2115 samples\n",
      "Epoch 1/10\n",
      "12665/12665 [==============================] - 1s 55us/sample - loss: 0.0660 - val_loss: 0.0370\n",
      "Epoch 2/10\n",
      "12665/12665 [==============================] - 0s 37us/sample - loss: 0.0316 - val_loss: 0.0282\n",
      "Epoch 3/10\n",
      "12665/12665 [==============================] - 0s 38us/sample - loss: 0.0271 - val_loss: 0.0257\n",
      "Epoch 4/10\n",
      "12665/12665 [==============================] - 0s 37us/sample - loss: 0.0247 - val_loss: 0.0235\n",
      "Epoch 5/10\n",
      "12665/12665 [==============================] - 0s 37us/sample - loss: 0.0230 - val_loss: 0.0223\n",
      "Epoch 6/10\n",
      "12665/12665 [==============================] - 0s 37us/sample - loss: 0.0221 - val_loss: 0.0215\n",
      "Epoch 7/10\n",
      "12665/12665 [==============================] - 0s 38us/sample - loss: 0.0215 - val_loss: 0.0210\n",
      "Epoch 8/10\n",
      "12665/12665 [==============================] - 0s 37us/sample - loss: 0.0211 - val_loss: 0.0206\n",
      "Epoch 9/10\n",
      "12665/12665 [==============================] - 0s 38us/sample - loss: 0.0207 - val_loss: 0.0203\n",
      "Epoch 10/10\n",
      "12665/12665 [==============================] - 0s 37us/sample - loss: 0.0204 - val_loss: 0.0201\n",
      "WARNING:tensorflow:Layer flatten_8 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer flatten_8 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Loss History for Hierarchical circuits, U_5 autoencoder8\n",
      "iteration:  0  cost:  0.792473784379411\n",
      "iteration:  10  cost:  0.14829486428336727\n",
      "iteration:  20  cost:  0.09960659126649281\n",
      "iteration:  30  cost:  0.07587366534578206\n",
      "iteration:  40  cost:  0.13129787976785048\n",
      "iteration:  50  cost:  0.170075390009835\n",
      "iteration:  60  cost:  0.25372058195333985\n",
      "iteration:  70  cost:  0.08029172844577716\n",
      "iteration:  80  cost:  0.133766905830799\n",
      "iteration:  90  cost:  0.11004888054169273\n",
      "iteration:  100  cost:  0.1343455148924195\n",
      "iteration:  110  cost:  0.08182072952662356\n",
      "iteration:  120  cost:  0.0937487055403106\n",
      "iteration:  130  cost:  0.1531691639080851\n",
      "iteration:  140  cost:  0.15391712490631615\n",
      "Accuracy for U_5 autoencoder8 :0.8770685579196218\n",
      "\n",
      "\n",
      "Loss History for Hierarchical circuits, U_6 resize256\n",
      "iteration:  0  cost:  0.28987397936802606\n",
      "iteration:  10  cost:  0.24476557047361036\n",
      "iteration:  20  cost:  0.221873622868841\n",
      "iteration:  30  cost:  0.20406692830207832\n",
      "iteration:  40  cost:  0.18201165271213554\n",
      "iteration:  50  cost:  0.13390876141313418\n",
      "iteration:  60  cost:  0.11024532470327837\n",
      "iteration:  70  cost:  0.11863987837480665\n",
      "iteration:  80  cost:  0.08713503682474431\n",
      "iteration:  90  cost:  0.057092328364426674\n",
      "iteration:  100  cost:  0.06691115167054655\n",
      "iteration:  110  cost:  0.09612967182826626\n",
      "iteration:  120  cost:  0.07165359975980291\n",
      "iteration:  130  cost:  0.05380625170591584\n",
      "iteration:  140  cost:  0.028909672664901673\n",
      "Accuracy for U_6 resize256 :0.9640661938534278\n",
      "\n",
      "\n",
      "Loss History for Hierarchical circuits, U_6 pca8\n",
      "iteration:  0  cost:  0.179825476662808\n",
      "iteration:  10  cost:  0.24529366735078859\n",
      "iteration:  20  cost:  0.24638989114405582\n",
      "iteration:  30  cost:  0.2314893040082261\n",
      "iteration:  40  cost:  0.3281841540374615\n",
      "iteration:  50  cost:  0.25846907919762097\n",
      "iteration:  60  cost:  0.272708029434377\n",
      "iteration:  70  cost:  0.24049131956690017\n",
      "iteration:  80  cost:  0.20766768869240693\n",
      "iteration:  90  cost:  0.24200552260888084\n",
      "iteration:  100  cost:  0.2340803531583707\n",
      "iteration:  110  cost:  0.23381665791930017\n",
      "iteration:  120  cost:  0.2765202299678139\n",
      "iteration:  130  cost:  0.22252396161097468\n",
      "iteration:  140  cost:  0.2155700355224469\n",
      "Accuracy for U_6 pca8 :0.6260047281323877\n",
      "Train on 12665 samples, validate on 2115 samples\n",
      "Epoch 1/10\n",
      "12665/12665 [==============================] - 1s 55us/sample - loss: 0.0637 - val_loss: 0.0357\n",
      "Epoch 2/10\n",
      "12665/12665 [==============================] - 0s 37us/sample - loss: 0.0302 - val_loss: 0.0269\n",
      "Epoch 3/10\n",
      "12665/12665 [==============================] - 0s 38us/sample - loss: 0.0255 - val_loss: 0.0236\n",
      "Epoch 4/10\n",
      "12665/12665 [==============================] - 0s 38us/sample - loss: 0.0227 - val_loss: 0.0213\n",
      "Epoch 5/10\n",
      "12665/12665 [==============================] - 0s 38us/sample - loss: 0.0208 - val_loss: 0.0197\n",
      "Epoch 6/10\n",
      "12665/12665 [==============================] - 0s 38us/sample - loss: 0.0196 - val_loss: 0.0188\n",
      "Epoch 7/10\n",
      "12665/12665 [==============================] - 0s 38us/sample - loss: 0.0190 - val_loss: 0.0183\n",
      "Epoch 8/10\n",
      "12665/12665 [==============================] - 0s 38us/sample - loss: 0.0185 - val_loss: 0.0179\n",
      "Epoch 9/10\n",
      "12665/12665 [==============================] - 0s 38us/sample - loss: 0.0182 - val_loss: 0.0177\n",
      "Epoch 10/10\n",
      "12665/12665 [==============================] - 0s 37us/sample - loss: 0.0180 - val_loss: 0.0174\n",
      "WARNING:tensorflow:Layer flatten_9 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer flatten_9 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Loss History for Hierarchical circuits, U_6 autoencoder8\n",
      "iteration:  0  cost:  0.884746280387618\n",
      "iteration:  10  cost:  0.18848997964692127\n",
      "iteration:  20  cost:  0.11011102315239783\n",
      "iteration:  30  cost:  0.12921555386963385\n",
      "iteration:  40  cost:  0.07676507491372274\n",
      "iteration:  50  cost:  0.036805043310308844\n",
      "iteration:  60  cost:  0.0342886036101641\n",
      "iteration:  70  cost:  0.025840610665159535\n",
      "iteration:  80  cost:  0.030302511917205947\n",
      "iteration:  90  cost:  0.0294368864741148\n",
      "iteration:  100  cost:  0.022364020828409742\n",
      "iteration:  110  cost:  0.03520522884299213\n",
      "iteration:  120  cost:  0.02540795844764764\n",
      "iteration:  130  cost:  0.009567073911783198\n",
      "iteration:  140  cost:  0.02170171892454082\n",
      "Accuracy for U_6 autoencoder8 :0.9895981087470449\n",
      "\n",
      "\n",
      "Loss History for Hierarchical circuits, U_13 resize256\n",
      "iteration:  0  cost:  1.0423310682545885\n",
      "iteration:  10  cost:  0.2036813482775628\n",
      "iteration:  20  cost:  0.14925755665068968\n",
      "iteration:  30  cost:  0.09303801288887564\n",
      "iteration:  40  cost:  0.09605731116415478\n",
      "iteration:  50  cost:  0.10351786512725802\n",
      "iteration:  60  cost:  0.12245715285192763\n",
      "iteration:  70  cost:  0.10106700074236845\n",
      "iteration:  80  cost:  0.12204232281301886\n",
      "iteration:  90  cost:  0.07702222687175238\n",
      "iteration:  100  cost:  0.06224875462532641\n",
      "iteration:  110  cost:  0.09364121016156156\n",
      "iteration:  120  cost:  0.09424924464472799\n",
      "iteration:  130  cost:  0.07298270730124014\n",
      "iteration:  140  cost:  0.06909019698559442\n",
      "Accuracy for U_13 resize256 :0.9569739952718677\n",
      "\n",
      "\n",
      "Loss History for Hierarchical circuits, U_13 pca8\n",
      "iteration:  0  cost:  0.43173955057230373\n",
      "iteration:  10  cost:  0.272961987794069\n",
      "iteration:  20  cost:  0.23052119190545922\n",
      "iteration:  30  cost:  0.25442088269563656\n",
      "iteration:  40  cost:  0.2732107854157789\n",
      "iteration:  50  cost:  0.2616558750291943\n",
      "iteration:  60  cost:  0.2522650496231968\n",
      "iteration:  70  cost:  0.2733007920675225\n",
      "iteration:  80  cost:  0.2662582099380435\n",
      "iteration:  90  cost:  0.2638462356152719\n",
      "iteration:  100  cost:  0.24825066046426592\n",
      "iteration:  110  cost:  0.24733779824232321\n",
      "iteration:  120  cost:  0.2861215374859574\n",
      "iteration:  130  cost:  0.23848791920717619\n",
      "iteration:  140  cost:  0.22278492578654205\n",
      "Accuracy for U_13 pca8 :0.5858156028368794\n",
      "Train on 12665 samples, validate on 2115 samples\n",
      "Epoch 1/10\n",
      "12665/12665 [==============================] - 1s 55us/sample - loss: 0.0645 - val_loss: 0.0354\n",
      "Epoch 2/10\n",
      "12665/12665 [==============================] - 0s 38us/sample - loss: 0.0309 - val_loss: 0.0275\n",
      "Epoch 3/10\n",
      "12665/12665 [==============================] - 0s 38us/sample - loss: 0.0263 - val_loss: 0.0243\n",
      "Epoch 4/10\n",
      "12665/12665 [==============================] - 0s 37us/sample - loss: 0.0233 - val_loss: 0.0216\n",
      "Epoch 5/10\n",
      "12665/12665 [==============================] - 0s 38us/sample - loss: 0.0211 - val_loss: 0.0200\n",
      "Epoch 6/10\n",
      "12665/12665 [==============================] - 0s 38us/sample - loss: 0.0199 - val_loss: 0.0192\n",
      "Epoch 7/10\n",
      "12665/12665 [==============================] - 0s 38us/sample - loss: 0.0193 - val_loss: 0.0186\n",
      "Epoch 8/10\n",
      "12665/12665 [==============================] - 0s 38us/sample - loss: 0.0188 - val_loss: 0.0183\n",
      "Epoch 9/10\n",
      "12665/12665 [==============================] - 0s 38us/sample - loss: 0.0185 - val_loss: 0.0180\n",
      "Epoch 10/10\n",
      "12665/12665 [==============================] - 0s 38us/sample - loss: 0.0183 - val_loss: 0.0177\n",
      "WARNING:tensorflow:Layer flatten_10 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer flatten_10 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Loss History for Hierarchical circuits, U_13 autoencoder8\n",
      "iteration:  0  cost:  0.23734756706186622\n",
      "iteration:  10  cost:  0.23610652127373524\n",
      "iteration:  20  cost:  0.24084124366331927\n",
      "iteration:  30  cost:  0.17347289183362954\n",
      "iteration:  40  cost:  0.15365096011179236\n",
      "iteration:  50  cost:  0.11987188929010711\n",
      "iteration:  60  cost:  0.14831156030235199\n",
      "iteration:  70  cost:  0.13736283249631942\n",
      "iteration:  80  cost:  0.12923184966949913\n",
      "iteration:  90  cost:  0.10580906657195614\n",
      "iteration:  100  cost:  0.11944241277138326\n",
      "iteration:  110  cost:  0.09911839661842714\n",
      "iteration:  120  cost:  0.14159287274109245\n",
      "iteration:  130  cost:  0.06880974627480627\n",
      "iteration:  140  cost:  0.12777236721733445\n",
      "Accuracy for U_13 autoencoder8 :0.893144208037825\n",
      "\n",
      "\n",
      "Loss History for Hierarchical circuits, U_14 resize256\n",
      "iteration:  0  cost:  1.7194838363704903\n",
      "iteration:  10  cost:  0.2628228495833312\n",
      "iteration:  20  cost:  0.2628164758677851\n",
      "iteration:  30  cost:  0.23258569953932234\n",
      "iteration:  40  cost:  0.2560687476009314\n",
      "iteration:  50  cost:  0.25187713990138\n",
      "iteration:  60  cost:  0.2322332966877765\n",
      "iteration:  70  cost:  0.2288006626769609\n",
      "iteration:  80  cost:  0.19166566407852803\n",
      "iteration:  90  cost:  0.17342371838088788\n",
      "iteration:  100  cost:  0.14985685741619306\n",
      "iteration:  110  cost:  0.10084736438631937\n",
      "iteration:  120  cost:  0.07206221661324176\n",
      "iteration:  130  cost:  0.0444698034671169\n",
      "iteration:  140  cost:  0.06096957504932561\n",
      "Accuracy for U_14 resize256 :0.950354609929078\n",
      "\n",
      "\n",
      "Loss History for Hierarchical circuits, U_14 pca8\n",
      "iteration:  0  cost:  0.3713248396848535\n",
      "iteration:  10  cost:  0.3014093230569053\n",
      "iteration:  20  cost:  0.24735052101282895\n",
      "iteration:  30  cost:  0.24911719884334263\n",
      "iteration:  40  cost:  0.2599090729518148\n",
      "iteration:  50  cost:  0.24193862439651903\n",
      "iteration:  60  cost:  0.21153276536061608\n",
      "iteration:  70  cost:  0.23669365346708285\n",
      "iteration:  80  cost:  0.2374058514271298\n",
      "iteration:  90  cost:  0.1939281876582476\n",
      "iteration:  100  cost:  0.13752384151718114\n",
      "iteration:  110  cost:  0.09667717082752501\n",
      "iteration:  120  cost:  0.0840301148830599\n",
      "iteration:  130  cost:  0.0342483832437462\n",
      "iteration:  140  cost:  0.038693163594429134\n",
      "Accuracy for U_14 pca8 :0.9754137115839243\n",
      "Train on 12665 samples, validate on 2115 samples\n",
      "Epoch 1/10\n",
      "12665/12665 [==============================] - 1s 55us/sample - loss: 0.0677 - val_loss: 0.0347\n",
      "Epoch 2/10\n",
      "12665/12665 [==============================] - 0s 38us/sample - loss: 0.0312 - val_loss: 0.0284\n",
      "Epoch 3/10\n",
      "12665/12665 [==============================] - 0s 37us/sample - loss: 0.0274 - val_loss: 0.0260\n",
      "Epoch 4/10\n",
      "12665/12665 [==============================] - 0s 38us/sample - loss: 0.0243 - val_loss: 0.0222\n",
      "Epoch 5/10\n",
      "12665/12665 [==============================] - 0s 38us/sample - loss: 0.0217 - val_loss: 0.0207\n",
      "Epoch 6/10\n",
      "12665/12665 [==============================] - 0s 37us/sample - loss: 0.0205 - val_loss: 0.0197\n",
      "Epoch 7/10\n",
      "12665/12665 [==============================] - 0s 38us/sample - loss: 0.0197 - val_loss: 0.0189\n",
      "Epoch 8/10\n",
      "12665/12665 [==============================] - 0s 38us/sample - loss: 0.0190 - val_loss: 0.0184\n",
      "Epoch 9/10\n",
      "12665/12665 [==============================] - 0s 38us/sample - loss: 0.0186 - val_loss: 0.0179\n",
      "Epoch 10/10\n",
      "12665/12665 [==============================] - 0s 38us/sample - loss: 0.0182 - val_loss: 0.0176\n",
      "WARNING:tensorflow:Layer flatten_11 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer flatten_11 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Loss History for Hierarchical circuits, U_14 autoencoder8\n",
      "iteration:  0  cost:  0.3572586296063401\n",
      "iteration:  10  cost:  0.19502081378433278\n",
      "iteration:  20  cost:  0.20977013776562026\n",
      "iteration:  30  cost:  0.21195527335313763\n",
      "iteration:  40  cost:  0.11075903707560085\n",
      "iteration:  50  cost:  0.13008799116386732\n",
      "iteration:  60  cost:  0.11451330637085343\n",
      "iteration:  70  cost:  0.10083753816851596\n",
      "iteration:  80  cost:  0.1093915683024726\n",
      "iteration:  90  cost:  0.10989801530048707\n",
      "iteration:  100  cost:  0.09837303827764397\n",
      "iteration:  110  cost:  0.1121862820059631\n",
      "iteration:  120  cost:  0.0801396764777206\n",
      "iteration:  130  cost:  0.08387410004447958\n",
      "iteration:  140  cost:  0.07184851728393073\n",
      "Accuracy for U_14 autoencoder8 :0.9706855791962175\n",
      "\n",
      "\n",
      "Loss History for Hierarchical circuits, U_15 resize256\n",
      "iteration:  0  cost:  0.5960445067441198\n",
      "iteration:  10  cost:  0.1463659383104196\n",
      "iteration:  20  cost:  0.13632372659031866\n",
      "iteration:  30  cost:  0.10195681024820946\n",
      "iteration:  40  cost:  0.025806482025001607\n",
      "iteration:  50  cost:  0.07086046522610201\n",
      "iteration:  60  cost:  0.03329860419756964\n",
      "iteration:  70  cost:  0.03661063521697161\n",
      "iteration:  80  cost:  0.06719061082971294\n",
      "iteration:  90  cost:  0.0662030678780513\n",
      "iteration:  100  cost:  0.02852886811375269\n",
      "iteration:  110  cost:  0.03869056001366259\n",
      "iteration:  120  cost:  0.03322155371917846\n",
      "iteration:  130  cost:  0.04266469469572694\n",
      "iteration:  140  cost:  0.042815154804603586\n",
      "Accuracy for U_15 resize256 :0.9867612293144208\n",
      "\n",
      "\n",
      "Loss History for Hierarchical circuits, U_15 pca8\n",
      "iteration:  0  cost:  0.345142036927165\n",
      "iteration:  10  cost:  0.30860552832461313\n",
      "iteration:  20  cost:  0.2056414882801136\n",
      "iteration:  30  cost:  0.18443275686927116\n",
      "iteration:  40  cost:  0.22520527169481463\n",
      "iteration:  50  cost:  0.16745254664474277\n",
      "iteration:  60  cost:  0.07994637814889907\n",
      "iteration:  70  cost:  0.06133240841399048\n",
      "iteration:  80  cost:  0.02790395197901531\n",
      "iteration:  90  cost:  0.052827421328343734\n",
      "iteration:  100  cost:  0.027615598550350676\n",
      "iteration:  110  cost:  0.04470942925369878\n",
      "iteration:  120  cost:  0.013090673449343226\n",
      "iteration:  130  cost:  0.03262411790088247\n",
      "iteration:  140  cost:  0.020719252848874894\n",
      "Accuracy for U_15 pca8 :0.9787234042553191\n",
      "Train on 12665 samples, validate on 2115 samples\n",
      "Epoch 1/10\n",
      "12665/12665 [==============================] - 1s 54us/sample - loss: 0.0652 - val_loss: 0.0360\n",
      "Epoch 2/10\n",
      "12665/12665 [==============================] - 0s 37us/sample - loss: 0.0303 - val_loss: 0.0274\n",
      "Epoch 3/10\n",
      "12665/12665 [==============================] - 0s 38us/sample - loss: 0.0262 - val_loss: 0.0248\n",
      "Epoch 4/10\n",
      "12665/12665 [==============================] - 0s 38us/sample - loss: 0.0238 - val_loss: 0.0225\n",
      "Epoch 5/10\n",
      "12665/12665 [==============================] - 0s 37us/sample - loss: 0.0220 - val_loss: 0.0211\n",
      "Epoch 6/10\n",
      "12665/12665 [==============================] - 0s 37us/sample - loss: 0.0209 - val_loss: 0.0201\n",
      "Epoch 7/10\n",
      "12665/12665 [==============================] - 0s 38us/sample - loss: 0.0200 - val_loss: 0.0194\n",
      "Epoch 8/10\n",
      "12665/12665 [==============================] - 0s 38us/sample - loss: 0.0194 - val_loss: 0.0188\n",
      "Epoch 9/10\n",
      "12665/12665 [==============================] - 0s 38us/sample - loss: 0.0190 - val_loss: 0.0184\n",
      "Epoch 10/10\n",
      "12665/12665 [==============================] - 0s 37us/sample - loss: 0.0186 - val_loss: 0.0182\n",
      "WARNING:tensorflow:Layer flatten_12 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer flatten_12 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Loss History for Hierarchical circuits, U_15 autoencoder8\n",
      "iteration:  0  cost:  0.1607200299821103\n",
      "iteration:  10  cost:  0.10707737984189969\n",
      "iteration:  20  cost:  0.04105760161061437\n",
      "iteration:  30  cost:  0.04436563552708688\n",
      "iteration:  40  cost:  0.029634263644470325\n",
      "iteration:  50  cost:  0.030843134844376664\n",
      "iteration:  60  cost:  0.030263129330024053\n",
      "iteration:  70  cost:  0.02616273426498309\n",
      "iteration:  80  cost:  0.014233070226215158\n",
      "iteration:  90  cost:  0.025472571026347094\n",
      "iteration:  100  cost:  0.05569407544679674\n",
      "iteration:  110  cost:  0.019367488019393107\n",
      "iteration:  120  cost:  0.02061968137896745\n",
      "iteration:  130  cost:  0.010410629662882436\n",
      "iteration:  140  cost:  0.03161753524011306\n",
      "Accuracy for U_15 autoencoder8 :0.992434988179669\n",
      "\n",
      "\n",
      "Loss History for Hierarchical circuits, U_SO4 resize256\n",
      "iteration:  0  cost:  0.3553435337738612\n",
      "iteration:  10  cost:  0.3320599358207073\n",
      "iteration:  20  cost:  0.2607467730973488\n",
      "iteration:  30  cost:  0.2345352265007858\n",
      "iteration:  40  cost:  0.1760638249874835\n",
      "iteration:  50  cost:  0.17529976419094853\n",
      "iteration:  60  cost:  0.1376289589976074\n",
      "iteration:  70  cost:  0.11783670379777396\n",
      "iteration:  80  cost:  0.05188027692247545\n",
      "iteration:  90  cost:  0.06261785013552527\n",
      "iteration:  100  cost:  0.08637153358941217\n",
      "iteration:  110  cost:  0.05399929140311745\n",
      "iteration:  120  cost:  0.12585591703101087\n",
      "iteration:  130  cost:  0.07089801226979094\n",
      "iteration:  140  cost:  0.07961803292353989\n",
      "Accuracy for U_SO4 resize256 :0.9588652482269504\n",
      "\n",
      "\n",
      "Loss History for Hierarchical circuits, U_SO4 pca8\n",
      "iteration:  0  cost:  0.45507778856748565\n",
      "iteration:  10  cost:  0.2569792331391362\n",
      "iteration:  20  cost:  0.2122899725570405\n",
      "iteration:  30  cost:  0.13300722057913617\n",
      "iteration:  40  cost:  0.03204412125693314\n",
      "iteration:  50  cost:  0.07171122393357927\n",
      "iteration:  60  cost:  0.036781085781811364\n",
      "iteration:  70  cost:  0.04777072545794585\n",
      "iteration:  80  cost:  0.04293420139581972\n",
      "iteration:  90  cost:  0.01075423622674549\n",
      "iteration:  100  cost:  0.032612798879064944\n",
      "iteration:  110  cost:  0.02042109239567642\n",
      "iteration:  120  cost:  0.04761207219510358\n",
      "iteration:  130  cost:  0.018146379408688094\n",
      "iteration:  140  cost:  0.015643950048255556\n",
      "Accuracy for U_SO4 pca8 :0.9815602836879432\n",
      "Train on 12665 samples, validate on 2115 samples\n",
      "Epoch 1/10\n",
      "12665/12665 [==============================] - 1s 55us/sample - loss: 0.0647 - val_loss: 0.0378\n",
      "Epoch 2/10\n",
      "12665/12665 [==============================] - 0s 38us/sample - loss: 0.0311 - val_loss: 0.0270\n",
      "Epoch 3/10\n",
      "12665/12665 [==============================] - 0s 37us/sample - loss: 0.0257 - val_loss: 0.0241\n",
      "Epoch 4/10\n",
      "12665/12665 [==============================] - 0s 37us/sample - loss: 0.0232 - val_loss: 0.0220\n",
      "Epoch 5/10\n",
      "12665/12665 [==============================] - 0s 38us/sample - loss: 0.0215 - val_loss: 0.0205\n",
      "Epoch 6/10\n",
      "12665/12665 [==============================] - 0s 37us/sample - loss: 0.0203 - val_loss: 0.0195\n",
      "Epoch 7/10\n",
      "12665/12665 [==============================] - 0s 38us/sample - loss: 0.0195 - val_loss: 0.0189\n",
      "Epoch 8/10\n",
      "12665/12665 [==============================] - 0s 38us/sample - loss: 0.0190 - val_loss: 0.0185\n",
      "Epoch 9/10\n",
      "12665/12665 [==============================] - 0s 38us/sample - loss: 0.0186 - val_loss: 0.0181\n",
      "Epoch 10/10\n",
      "12665/12665 [==============================] - 1s 48us/sample - loss: 0.0183 - val_loss: 0.0179\n",
      "WARNING:tensorflow:Layer flatten_13 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer flatten_13 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Loss History for Hierarchical circuits, U_SO4 autoencoder8\n",
      "iteration:  0  cost:  0.3510546701533224\n",
      "iteration:  10  cost:  0.09761463420025823\n",
      "iteration:  20  cost:  0.02397880549625883\n",
      "iteration:  30  cost:  0.013904913720665116\n",
      "iteration:  40  cost:  0.019979492217430412\n",
      "iteration:  50  cost:  0.05444298196984325\n",
      "iteration:  60  cost:  0.02591592070788897\n",
      "iteration:  70  cost:  0.03392110830378884\n",
      "iteration:  80  cost:  0.018468827989503687\n",
      "iteration:  90  cost:  0.03045450012979467\n",
      "iteration:  100  cost:  0.01612231112560783\n",
      "iteration:  110  cost:  0.01679955287509967\n",
      "iteration:  120  cost:  0.034568265798485064\n",
      "iteration:  130  cost:  0.011824425365508871\n",
      "iteration:  140  cost:  0.02467169435996436\n",
      "Accuracy for U_SO4 autoencoder8 :0.9877068557919622\n"
     ]
    }
   ],
   "source": [
    "Benchmarking(Unitaries, U_num_params, Encodings, circuit, binary = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "Unitaries = ['U_TTN', 'U_5', 'U_6', 'U_9', 'U_13', 'U_14', 'U_15', 'U_SO4']\n",
    "U_num_params = [2, 10, 10, 4, 6, 6, 4, 6]\n",
    "Encodings = ['pca24', 'autoencoder24']\n",
    "classes = [0,1]\n",
    "circuit = 'Hierarchical'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0th step : \n",
      "\n",
      "\n",
      "Loss History for Hierarchical circuits, U_TTN pca24\n",
      "iteration:  0  cost:  0.9997996153381501\n",
      "iteration:  10  cost:  0.9998064128078369\n",
      "iteration:  20  cost:  0.9989525046880982\n",
      "iteration:  30  cost:  0.9997559368239729\n",
      "iteration:  40  cost:  0.9998278502347802\n",
      "iteration:  50  cost:  1.0000842951290212\n",
      "iteration:  60  cost:  0.9997679269654296\n",
      "iteration:  70  cost:  0.9993545427635425\n",
      "iteration:  80  cost:  0.998816429538643\n",
      "iteration:  90  cost:  1.0002795163935976\n",
      "iteration:  100  cost:  0.9991333403118513\n",
      "iteration:  110  cost:  1.0006037428202683\n",
      "iteration:  120  cost:  1.0000612875633228\n",
      "iteration:  130  cost:  0.9992653894169533\n",
      "iteration:  140  cost:  0.9994949833363068\n",
      "Accuracy for U_TTN pca24 :0.574468085106383\n",
      "Epoch 1/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.0884 - val_loss: 0.0247\n",
      "Epoch 2/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.0235 - val_loss: 0.0189\n",
      "Epoch 3/10\n",
      "396/396 [==============================] - 1s 1ms/step - loss: 0.0181 - val_loss: 0.0148\n",
      "Epoch 4/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.0141 - val_loss: 0.0123\n",
      "Epoch 5/10\n",
      "396/396 [==============================] - 1s 1ms/step - loss: 0.0121 - val_loss: 0.0108\n",
      "Epoch 6/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.0107 - val_loss: 0.0097\n",
      "Epoch 7/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.0096 - val_loss: 0.0089\n",
      "Epoch 8/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.0089 - val_loss: 0.0083\n",
      "Epoch 9/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.0082 - val_loss: 0.0077\n",
      "Epoch 10/10\n",
      "396/396 [==============================] - 0s 1ms/step - loss: 0.0077 - val_loss: 0.0075\n",
      "\n",
      "\n",
      "Loss History for Hierarchical circuits, U_TTN autoencoder24\n",
      "iteration:  0  cost:  0.996187941072818\n",
      "iteration:  10  cost:  0.9665923839206663\n",
      "iteration:  20  cost:  0.5756271403533458\n",
      "iteration:  30  cost:  0.6958301087265367\n",
      "iteration:  40  cost:  0.6980093025898363\n",
      "iteration:  50  cost:  0.6965883878339286\n",
      "iteration:  60  cost:  0.7333733446678795\n",
      "iteration:  70  cost:  0.5861647916867755\n",
      "iteration:  80  cost:  0.581440227260134\n",
      "iteration:  90  cost:  0.5998541166885065\n",
      "iteration:  100  cost:  0.47439109785012173\n",
      "iteration:  110  cost:  0.6389057919900041\n",
      "iteration:  120  cost:  0.5736875635851224\n",
      "iteration:  130  cost:  0.6951916172650582\n",
      "iteration:  140  cost:  0.7949721232183694\n",
      "Accuracy for U_TTN autoencoder24 :0.8250591016548463\n",
      "\n",
      "\n",
      "Loss History for Hierarchical circuits, U_5 pca24\n",
      "iteration:  0  cost:  1.2657474769547223\n",
      "iteration:  10  cost:  0.9806325480279845\n",
      "iteration:  20  cost:  1.0378355298761197\n",
      "iteration:  30  cost:  0.9688902435912243\n",
      "iteration:  40  cost:  1.0179679609876942\n",
      "iteration:  50  cost:  1.0914478589825125\n",
      "iteration:  60  cost:  0.9976368201311012\n",
      "iteration:  70  cost:  0.9954059212320722\n",
      "iteration:  80  cost:  1.0285663362330266\n",
      "iteration:  90  cost:  0.9631058475404296\n",
      "iteration:  100  cost:  1.0032373548826263\n",
      "iteration:  110  cost:  1.0073520407255527\n",
      "iteration:  120  cost:  0.9437351404983205\n",
      "iteration:  130  cost:  1.0369623023852257\n",
      "iteration:  140  cost:  1.0005593148531986\n",
      "Accuracy for U_5 pca24 :0.5366430260047281\n",
      "Epoch 1/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.0880 - val_loss: 0.0261\n",
      "Epoch 2/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.0239 - val_loss: 0.0192\n",
      "Epoch 3/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.0183 - val_loss: 0.0149\n",
      "Epoch 4/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.0143 - val_loss: 0.0124\n",
      "Epoch 5/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.0122 - val_loss: 0.0109\n",
      "Epoch 6/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.0107 - val_loss: 0.0098\n",
      "Epoch 7/10\n",
      "396/396 [==============================] - 1s 1ms/step - loss: 0.0098 - val_loss: 0.0090\n",
      "Epoch 8/10\n",
      "396/396 [==============================] - 1s 1ms/step - loss: 0.0091 - val_loss: 0.0083\n",
      "Epoch 9/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.0083 - val_loss: 0.0079\n",
      "Epoch 10/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.0078 - val_loss: 0.0075\n",
      "\n",
      "\n",
      "Loss History for Hierarchical circuits, U_5 autoencoder24\n",
      "iteration:  0  cost:  1.3092686080854352\n",
      "iteration:  10  cost:  0.8373935018848371\n",
      "iteration:  20  cost:  0.6398365241790323\n",
      "iteration:  30  cost:  0.8365887854518332\n",
      "iteration:  40  cost:  0.6968749635425775\n",
      "iteration:  50  cost:  0.7957888937536822\n",
      "iteration:  60  cost:  0.6808027448866356\n",
      "iteration:  70  cost:  0.7010044121279785\n",
      "iteration:  80  cost:  0.5889957099620762\n",
      "iteration:  90  cost:  0.621209420175005\n",
      "iteration:  100  cost:  0.6895637905895867\n",
      "iteration:  110  cost:  0.7485478474401781\n",
      "iteration:  120  cost:  0.5592595941877355\n",
      "iteration:  130  cost:  0.6377697925455033\n",
      "iteration:  140  cost:  0.5593282988594843\n",
      "Accuracy for U_5 autoencoder24 :0.8539007092198582\n",
      "\n",
      "\n",
      "Loss History for Hierarchical circuits, U_6 pca24\n",
      "iteration:  0  cost:  1.0188270860356987\n",
      "iteration:  10  cost:  0.939875828059428\n",
      "iteration:  20  cost:  1.004045561216189\n",
      "iteration:  30  cost:  1.0387697143051668\n",
      "iteration:  40  cost:  1.0143671877876694\n",
      "iteration:  50  cost:  0.9990249700013698\n",
      "iteration:  60  cost:  0.9101076141163188\n",
      "iteration:  70  cost:  0.9979987824726537\n",
      "iteration:  80  cost:  1.002994363719089\n",
      "iteration:  90  cost:  1.0051115498708973\n",
      "iteration:  100  cost:  1.056191460550698\n",
      "iteration:  110  cost:  1.0525726120007295\n",
      "iteration:  120  cost:  1.0246871804149882\n",
      "iteration:  130  cost:  1.1742596106755976\n",
      "iteration:  140  cost:  1.004044329361615\n",
      "Accuracy for U_6 pca24 :0.5451536643026005\n",
      "Epoch 1/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.0860 - val_loss: 0.0267\n",
      "Epoch 2/10\n",
      "396/396 [==============================] - 0s 1ms/step - loss: 0.0250 - val_loss: 0.0199\n",
      "Epoch 3/10\n",
      "396/396 [==============================] - 0s 1ms/step - loss: 0.0188 - val_loss: 0.0148\n",
      "Epoch 4/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.0144 - val_loss: 0.0125\n",
      "Epoch 5/10\n",
      "396/396 [==============================] - 0s 818us/step - loss: 0.0123 - val_loss: 0.0110\n",
      "Epoch 6/10\n",
      "396/396 [==============================] - 0s 807us/step - loss: 0.0109 - val_loss: 0.0097\n",
      "Epoch 7/10\n",
      "396/396 [==============================] - 0s 809us/step - loss: 0.0096 - val_loss: 0.0088\n",
      "Epoch 8/10\n",
      "396/396 [==============================] - 0s 806us/step - loss: 0.0088 - val_loss: 0.0082\n",
      "Epoch 9/10\n",
      "396/396 [==============================] - 0s 820us/step - loss: 0.0081 - val_loss: 0.0077\n",
      "Epoch 10/10\n",
      "396/396 [==============================] - 1s 1ms/step - loss: 0.0077 - val_loss: 0.0073\n",
      "\n",
      "\n",
      "Loss History for Hierarchical circuits, U_6 autoencoder24\n",
      "iteration:  0  cost:  1.0826002846570442\n",
      "iteration:  10  cost:  1.0056607137057598\n",
      "iteration:  20  cost:  0.7414225201346896\n",
      "iteration:  30  cost:  0.5748740237557008\n",
      "iteration:  40  cost:  0.572669592895073\n",
      "iteration:  50  cost:  0.4564903133613967\n",
      "iteration:  60  cost:  0.6415244780239239\n",
      "iteration:  70  cost:  0.51331668955155\n",
      "iteration:  80  cost:  0.5038677094156379\n",
      "iteration:  90  cost:  0.5741109216351495\n",
      "iteration:  100  cost:  0.5814623457420748\n",
      "iteration:  110  cost:  0.5446752166215153\n",
      "iteration:  120  cost:  0.53227677546572\n",
      "iteration:  130  cost:  0.4754941452269164\n",
      "iteration:  140  cost:  0.5146307162694866\n",
      "Accuracy for U_6 autoencoder24 :0.9163120567375886\n",
      "\n",
      "\n",
      "Loss History for Hierarchical circuits, U_9 pca24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leeseok/.local/lib/python3.7/site-packages/autograd/tracer.py:14: UserWarning: Output seems independent of input.\n",
      "  warnings.warn(\"Output seems independent of input.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration:  0  cost:  1.004155630425517\n",
      "iteration:  10  cost:  0.9801186313093001\n",
      "iteration:  20  cost:  0.9884125088058524\n",
      "iteration:  30  cost:  1.0212804057196612\n",
      "iteration:  40  cost:  1.0185179702753564\n",
      "iteration:  50  cost:  1.017015709009763\n",
      "iteration:  60  cost:  1.0213386606990287\n",
      "iteration:  70  cost:  0.9812997264625917\n",
      "iteration:  80  cost:  0.9985003180322145\n",
      "iteration:  90  cost:  0.9750897709318568\n",
      "iteration:  100  cost:  1.0036768792964255\n",
      "iteration:  110  cost:  1.0217111892627084\n",
      "iteration:  120  cost:  1.0166359125604827\n",
      "iteration:  130  cost:  1.015118002550057\n",
      "iteration:  140  cost:  1.0105589937868844\n",
      "Accuracy for U_9 pca24 :0.4988179669030733\n",
      "Epoch 1/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.0885 - val_loss: 0.0258\n",
      "Epoch 2/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.0244 - val_loss: 0.0188\n",
      "Epoch 3/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.0177 - val_loss: 0.0146\n",
      "Epoch 4/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.0144 - val_loss: 0.0125\n",
      "Epoch 5/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.0120 - val_loss: 0.0109\n",
      "Epoch 6/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.0108 - val_loss: 0.0098\n",
      "Epoch 7/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.0096 - val_loss: 0.0090\n",
      "Epoch 8/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.0089 - val_loss: 0.0084\n",
      "Epoch 9/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.0082 - val_loss: 0.0078\n",
      "Epoch 10/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.0078 - val_loss: 0.0075\n",
      "\n",
      "\n",
      "Loss History for Hierarchical circuits, U_9 autoencoder24\n",
      "iteration:  0  cost:  1.5801248232333038\n",
      "iteration:  10  cost:  1.4908649217003196\n",
      "iteration:  20  cost:  1.8866067866289788\n",
      "iteration:  30  cost:  1.8774697265156743\n",
      "iteration:  40  cost:  1.7468137788491762\n",
      "iteration:  50  cost:  2.231722998143754\n",
      "iteration:  60  cost:  2.1546875526291616\n",
      "iteration:  70  cost:  2.2767071607089204\n",
      "iteration:  80  cost:  1.793676896859181\n",
      "iteration:  90  cost:  0.943476996475672\n",
      "iteration:  100  cost:  1.8715617510311382\n",
      "iteration:  110  cost:  1.3129774182360145\n",
      "iteration:  120  cost:  1.9378474327611317\n",
      "iteration:  130  cost:  1.825972550410362\n",
      "iteration:  140  cost:  2.0653768513677795\n",
      "Accuracy for U_9 autoencoder24 :0.46335697399527187\n",
      "\n",
      "\n",
      "Loss History for Hierarchical circuits, U_13 pca24\n",
      "iteration:  0  cost:  1.0186156188664803\n",
      "iteration:  10  cost:  1.0357753901509503\n",
      "iteration:  20  cost:  1.0174103887938033\n",
      "iteration:  30  cost:  0.9627684054099194\n",
      "iteration:  40  cost:  1.0454169009134875\n",
      "iteration:  50  cost:  1.0112528249774453\n",
      "iteration:  60  cost:  0.9785003759693364\n",
      "iteration:  70  cost:  1.0049217492251967\n",
      "iteration:  80  cost:  1.0014512559745488\n",
      "iteration:  90  cost:  0.9811816674188638\n",
      "iteration:  100  cost:  1.00884061814985\n",
      "iteration:  110  cost:  0.9664921749947948\n",
      "iteration:  120  cost:  0.9866127646871441\n",
      "iteration:  130  cost:  0.9632154462688686\n",
      "iteration:  140  cost:  1.005365745984174\n",
      "Accuracy for U_13 pca24 :0.5470449172576832\n",
      "Epoch 1/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.0868 - val_loss: 0.0261\n",
      "Epoch 2/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.0242 - val_loss: 0.0187\n",
      "Epoch 3/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.0178 - val_loss: 0.0147\n",
      "Epoch 4/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.0143 - val_loss: 0.0123\n",
      "Epoch 5/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.0119 - val_loss: 0.0108\n",
      "Epoch 6/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.0106 - val_loss: 0.0097\n",
      "Epoch 7/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.0096 - val_loss: 0.0088\n",
      "Epoch 8/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.0087 - val_loss: 0.0082\n",
      "Epoch 9/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.0082 - val_loss: 0.0078\n",
      "Epoch 10/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.0077 - val_loss: 0.0075\n",
      "\n",
      "\n",
      "Loss History for Hierarchical circuits, U_13 autoencoder24\n",
      "iteration:  0  cost:  1.4630300672548038\n",
      "iteration:  10  cost:  0.905662984002644\n",
      "iteration:  20  cost:  0.9711513176691742\n",
      "iteration:  30  cost:  0.7932097915763398\n",
      "iteration:  40  cost:  0.7879331950622307\n",
      "iteration:  50  cost:  0.7344226815244329\n",
      "iteration:  60  cost:  0.668263732895083\n",
      "iteration:  70  cost:  0.6212230121546236\n",
      "iteration:  80  cost:  0.7316935459267093\n",
      "iteration:  90  cost:  0.642153504874926\n",
      "iteration:  100  cost:  0.5433878688768418\n",
      "iteration:  110  cost:  0.5193647580438717\n",
      "iteration:  120  cost:  0.46211967561466877\n",
      "iteration:  130  cost:  0.47516804917119254\n",
      "iteration:  140  cost:  0.7026328535793814\n",
      "Accuracy for U_13 autoencoder24 :0.8832151300236407\n",
      "\n",
      "\n",
      "Loss History for Hierarchical circuits, U_14 pca24\n",
      "iteration:  0  cost:  1.0607788065013342\n",
      "iteration:  10  cost:  1.004641623256776\n",
      "iteration:  20  cost:  1.0248304529003112\n",
      "iteration:  30  cost:  1.0349864995267757\n",
      "iteration:  40  cost:  0.9889683253770718\n",
      "iteration:  50  cost:  1.0891792282642119\n",
      "iteration:  60  cost:  0.9980302811499222\n",
      "iteration:  70  cost:  1.0012352995596197\n",
      "iteration:  80  cost:  1.0506258926363028\n",
      "iteration:  90  cost:  0.9899067589195996\n",
      "iteration:  100  cost:  1.0497464852431921\n",
      "iteration:  110  cost:  0.9899844671630875\n",
      "iteration:  120  cost:  1.0056871767517375\n",
      "iteration:  130  cost:  0.9886225007165325\n",
      "iteration:  140  cost:  0.9777592045604796\n",
      "Accuracy for U_14 pca24 :0.4912529550827423\n",
      "Epoch 1/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.0890 - val_loss: 0.0254\n",
      "Epoch 2/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.0239 - val_loss: 0.0191\n",
      "Epoch 3/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.0181 - val_loss: 0.0149\n",
      "Epoch 4/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.0143 - val_loss: 0.0125\n",
      "Epoch 5/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.0122 - val_loss: 0.0109\n",
      "Epoch 6/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.0107 - val_loss: 0.0096\n",
      "Epoch 7/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.0095 - val_loss: 0.0088\n",
      "Epoch 8/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.0087 - val_loss: 0.0082\n",
      "Epoch 9/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.0083 - val_loss: 0.0078\n",
      "Epoch 10/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.0079 - val_loss: 0.0075\n",
      "\n",
      "\n",
      "Loss History for Hierarchical circuits, U_14 autoencoder24\n",
      "iteration:  0  cost:  1.3122313953819895\n",
      "iteration:  10  cost:  1.1370213549138932\n",
      "iteration:  20  cost:  1.1488486867314485\n",
      "iteration:  30  cost:  0.9460140977969695\n",
      "iteration:  40  cost:  0.9204302467898668\n",
      "iteration:  50  cost:  0.8059456807186903\n",
      "iteration:  60  cost:  0.8442086827942036\n",
      "iteration:  70  cost:  0.7667976915093111\n",
      "iteration:  80  cost:  0.7467776056369669\n",
      "iteration:  90  cost:  0.7475903281389051\n",
      "iteration:  100  cost:  0.7621336324560787\n",
      "iteration:  110  cost:  0.6681426893734432\n",
      "iteration:  120  cost:  0.7573483965784866\n",
      "iteration:  130  cost:  0.8352847197733004\n",
      "iteration:  140  cost:  0.8070127845133465\n",
      "Accuracy for U_14 autoencoder24 :0.742789598108747\n",
      "\n",
      "\n",
      "Loss History for Hierarchical circuits, U_15 pca24\n",
      "iteration:  0  cost:  0.9743078764479388\n",
      "iteration:  10  cost:  0.9801847074611091\n",
      "iteration:  20  cost:  0.9912248343903163\n",
      "iteration:  30  cost:  1.0018070981691845\n",
      "iteration:  40  cost:  1.0157372856069744\n",
      "iteration:  50  cost:  1.1107737786522867\n",
      "iteration:  60  cost:  0.9903106224981145\n",
      "iteration:  70  cost:  0.9421244319778045\n",
      "iteration:  80  cost:  0.9708503794006846\n",
      "iteration:  90  cost:  0.9826359196551475\n",
      "iteration:  100  cost:  0.992358348855499\n",
      "iteration:  110  cost:  1.0648567144675205\n",
      "iteration:  120  cost:  0.9714133914371452\n",
      "iteration:  130  cost:  0.8884656164372885\n",
      "iteration:  140  cost:  1.0663596004051505\n",
      "Accuracy for U_15 pca24 :0.4293144208037825\n",
      "Epoch 1/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.0878 - val_loss: 0.0256\n",
      "Epoch 2/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.0232 - val_loss: 0.0179\n",
      "Epoch 3/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.0171 - val_loss: 0.0144\n",
      "Epoch 4/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.0138 - val_loss: 0.0122\n",
      "Epoch 5/10\n",
      "396/396 [==============================] - 1s 1ms/step - loss: 0.0119 - val_loss: 0.0108\n",
      "Epoch 6/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.0104 - val_loss: 0.0097\n",
      "Epoch 7/10\n",
      "396/396 [==============================] - 1s 1ms/step - loss: 0.0095 - val_loss: 0.0088\n",
      "Epoch 8/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.0088 - val_loss: 0.0083\n",
      "Epoch 9/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.0081 - val_loss: 0.0078\n",
      "Epoch 10/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.0076 - val_loss: 0.0074\n",
      "\n",
      "\n",
      "Loss History for Hierarchical circuits, U_15 autoencoder24\n",
      "iteration:  0  cost:  1.1623834004567384\n",
      "iteration:  10  cost:  0.9833251940625003\n",
      "iteration:  20  cost:  0.8709682264466901\n",
      "iteration:  30  cost:  0.6454634898252078\n",
      "iteration:  40  cost:  0.9476636087036345\n",
      "iteration:  50  cost:  0.8061546628571931\n",
      "iteration:  60  cost:  0.704489352716151\n",
      "iteration:  70  cost:  0.707130229870158\n",
      "iteration:  80  cost:  0.5244125826255385\n",
      "iteration:  90  cost:  0.6749898969307351\n",
      "iteration:  100  cost:  0.6032687508738946\n",
      "iteration:  110  cost:  0.49374833939307405\n",
      "iteration:  120  cost:  0.5091968472646511\n",
      "iteration:  130  cost:  0.6718992510432166\n",
      "iteration:  140  cost:  0.6224771364188291\n",
      "Accuracy for U_15 autoencoder24 :0.902127659574468\n",
      "\n",
      "\n",
      "Loss History for Hierarchical circuits, U_SO4 pca24\n",
      "iteration:  0  cost:  0.977651606456582\n",
      "iteration:  10  cost:  0.9728411721486708\n",
      "iteration:  20  cost:  0.9909896080203257\n",
      "iteration:  30  cost:  0.9648390965331265\n",
      "iteration:  40  cost:  1.0312930063614747\n",
      "iteration:  50  cost:  0.9985530434982567\n",
      "iteration:  60  cost:  1.0054031894266493\n",
      "iteration:  70  cost:  0.9814089866568756\n",
      "iteration:  80  cost:  0.9855187351034977\n",
      "iteration:  90  cost:  0.9983030457724954\n",
      "iteration:  100  cost:  1.0493186364977638\n",
      "iteration:  110  cost:  1.0398646919955548\n",
      "iteration:  120  cost:  0.9938394628795832\n",
      "iteration:  130  cost:  0.9926277549077934\n",
      "iteration:  140  cost:  0.9911676333649458\n",
      "Accuracy for U_SO4 pca24 :0.5366430260047281\n",
      "Epoch 1/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.0856 - val_loss: 0.0263\n",
      "Epoch 2/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.0247 - val_loss: 0.0198\n",
      "Epoch 3/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.0184 - val_loss: 0.0149\n",
      "Epoch 4/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.0144 - val_loss: 0.0122\n",
      "Epoch 5/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.0121 - val_loss: 0.0106\n",
      "Epoch 6/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.0105 - val_loss: 0.0098\n",
      "Epoch 7/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.0096 - val_loss: 0.0089\n",
      "Epoch 8/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.0089 - val_loss: 0.0084\n",
      "Epoch 9/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.0083 - val_loss: 0.0079\n",
      "Epoch 10/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.0079 - val_loss: 0.0075\n",
      "\n",
      "\n",
      "Loss History for Hierarchical circuits, U_SO4 autoencoder24\n",
      "iteration:  0  cost:  0.9809544130893246\n",
      "iteration:  10  cost:  0.6951463302508216\n",
      "iteration:  20  cost:  0.7390990751952523\n",
      "iteration:  30  cost:  0.4397342700943906\n",
      "iteration:  40  cost:  0.5646235940324094\n",
      "iteration:  50  cost:  0.5266948111385586\n",
      "iteration:  60  cost:  0.6125614243173187\n",
      "iteration:  70  cost:  0.5253623023985544\n",
      "iteration:  80  cost:  0.6137937517617622\n",
      "iteration:  90  cost:  0.5413621292167831\n",
      "iteration:  100  cost:  0.5796509403332802\n",
      "iteration:  110  cost:  0.581465828716371\n",
      "iteration:  120  cost:  0.5627618108787685\n",
      "iteration:  130  cost:  0.4201754487640962\n",
      "iteration:  140  cost:  0.3937653478337612\n",
      "Accuracy for U_SO4 autoencoder24 :0.8893617021276595\n",
      "1th step : \n",
      "\n",
      "\n",
      "Loss History for Hierarchical circuits, U_TTN pca24\n",
      "iteration:  0  cost:  0.9996631540895352\n",
      "iteration:  10  cost:  1.0000189004189772\n",
      "iteration:  20  cost:  1.000358614848047\n",
      "iteration:  30  cost:  0.9999116402100526\n",
      "iteration:  40  cost:  0.9998929350717016\n",
      "iteration:  50  cost:  0.9997908394771653\n",
      "iteration:  60  cost:  0.999702969088413\n",
      "iteration:  70  cost:  0.9998459051601156\n",
      "iteration:  80  cost:  1.0000902949724868\n",
      "iteration:  90  cost:  0.9999895213269765\n",
      "iteration:  100  cost:  1.0000429640868163\n",
      "iteration:  110  cost:  1.0010963442421215\n",
      "iteration:  120  cost:  0.9999618892613032\n",
      "iteration:  130  cost:  0.9997522296630496\n",
      "iteration:  140  cost:  0.9996659098097873\n",
      "Accuracy for U_TTN pca24 :0.5328605200945626\n",
      "Epoch 1/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.0899 - val_loss: 0.0236\n",
      "Epoch 2/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.0225 - val_loss: 0.0186\n",
      "Epoch 3/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.0179 - val_loss: 0.0150\n",
      "Epoch 4/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.0144 - val_loss: 0.0125\n",
      "Epoch 5/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.0123 - val_loss: 0.0107\n",
      "Epoch 6/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.0105 - val_loss: 0.0096\n",
      "Epoch 7/10\n",
      "396/396 [==============================] - 1s 1ms/step - loss: 0.0093 - val_loss: 0.0086\n",
      "Epoch 8/10\n",
      "396/396 [==============================] - 1s 1ms/step - loss: 0.0085 - val_loss: 0.0080\n",
      "Epoch 9/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.0079 - val_loss: 0.0075\n",
      "Epoch 10/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.0076 - val_loss: 0.0072\n",
      "\n",
      "\n",
      "Loss History for Hierarchical circuits, U_TTN autoencoder24\n",
      "iteration:  0  cost:  0.8838472605019302\n",
      "iteration:  10  cost:  0.7292978181462143\n",
      "iteration:  20  cost:  0.5682323235681259\n",
      "iteration:  30  cost:  0.7102997718150309\n",
      "iteration:  40  cost:  0.6878505711225915\n",
      "iteration:  50  cost:  0.6285624907304631\n",
      "iteration:  60  cost:  0.6956137573201824\n",
      "iteration:  70  cost:  0.6679476864047157\n",
      "iteration:  80  cost:  0.7226183352167106\n",
      "iteration:  90  cost:  0.6805446011401146\n",
      "iteration:  100  cost:  0.694744625549057\n",
      "iteration:  110  cost:  0.8113014462231982\n",
      "iteration:  120  cost:  0.6575483104001727\n",
      "iteration:  130  cost:  0.652409869072483\n",
      "iteration:  140  cost:  0.79183176655858\n",
      "Accuracy for U_TTN autoencoder24 :0.742789598108747\n",
      "\n",
      "\n",
      "Loss History for Hierarchical circuits, U_5 pca24\n",
      "iteration:  0  cost:  1.1138425341734932\n",
      "iteration:  10  cost:  1.1616228045085546\n",
      "iteration:  20  cost:  1.101618238277673\n",
      "iteration:  30  cost:  0.9787286743947093\n",
      "iteration:  40  cost:  1.0790300754629498\n",
      "iteration:  50  cost:  1.0020195637511629\n",
      "iteration:  60  cost:  1.0138119836724973\n",
      "iteration:  70  cost:  0.9812945894160869\n",
      "iteration:  80  cost:  0.8319818642522242\n",
      "iteration:  90  cost:  0.9998216886631073\n",
      "iteration:  100  cost:  0.9896610736096116\n",
      "iteration:  110  cost:  1.0163645079551478\n",
      "iteration:  120  cost:  1.0049004549427034\n",
      "iteration:  130  cost:  1.1788893135018\n",
      "iteration:  140  cost:  0.9844333449195968\n",
      "Accuracy for U_5 pca24 :0.5371158392434988\n",
      "Epoch 1/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.0870 - val_loss: 0.0262\n",
      "Epoch 2/10\n",
      "396/396 [==============================] - 1s 1ms/step - loss: 0.0244 - val_loss: 0.0191\n",
      "Epoch 3/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.0181 - val_loss: 0.0146\n",
      "Epoch 4/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.0141 - val_loss: 0.0121\n",
      "Epoch 5/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.0120 - val_loss: 0.0106\n",
      "Epoch 6/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.0105 - val_loss: 0.0094\n",
      "Epoch 7/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.0094 - val_loss: 0.0086\n",
      "Epoch 8/10\n",
      "396/396 [==============================] - 1s 1ms/step - loss: 0.0086 - val_loss: 0.0080\n",
      "Epoch 9/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.0081 - val_loss: 0.0076\n",
      "Epoch 10/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.0076 - val_loss: 0.0073\n",
      "\n",
      "\n",
      "Loss History for Hierarchical circuits, U_5 autoencoder24\n",
      "iteration:  0  cost:  1.5323652364843765\n",
      "iteration:  10  cost:  0.8551019078157859\n",
      "iteration:  20  cost:  0.6433982667372555\n",
      "iteration:  30  cost:  0.6130949252640397\n",
      "iteration:  40  cost:  0.6802254269205544\n",
      "iteration:  50  cost:  0.7148235393957312\n",
      "iteration:  60  cost:  0.696555883384502\n",
      "iteration:  70  cost:  0.4701759444832338\n",
      "iteration:  80  cost:  0.5011289451794522\n",
      "iteration:  90  cost:  0.6263504879382981\n",
      "iteration:  100  cost:  0.5877932486285948\n",
      "iteration:  110  cost:  0.4302012068112458\n",
      "iteration:  120  cost:  0.5743949783239688\n",
      "iteration:  130  cost:  0.5719390281472091\n",
      "iteration:  140  cost:  0.7669117363624135\n",
      "Accuracy for U_5 autoencoder24 :0.8936170212765957\n",
      "\n",
      "\n",
      "Loss History for Hierarchical circuits, U_6 pca24\n",
      "iteration:  0  cost:  1.912595172788853\n",
      "iteration:  10  cost:  0.9848219712968378\n",
      "iteration:  20  cost:  0.9591226644889379\n",
      "iteration:  30  cost:  1.1121626086717196\n",
      "iteration:  40  cost:  1.0878689800427082\n",
      "iteration:  50  cost:  1.1399749720125112\n",
      "iteration:  60  cost:  1.081261591635296\n",
      "iteration:  70  cost:  1.0415578657490705\n",
      "iteration:  80  cost:  1.1226637802752877\n",
      "iteration:  90  cost:  1.0049645013574753\n",
      "iteration:  100  cost:  1.0050714969709527\n",
      "iteration:  110  cost:  1.0006945265697522\n",
      "iteration:  120  cost:  0.9833359158980686\n",
      "iteration:  130  cost:  1.1233194388393968\n",
      "iteration:  140  cost:  1.0004007085748616\n",
      "Accuracy for U_6 pca24 :0.5371158392434988\n",
      "Epoch 1/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.0872 - val_loss: 0.0255\n",
      "Epoch 2/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.0239 - val_loss: 0.0187\n",
      "Epoch 3/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.0178 - val_loss: 0.0144\n",
      "Epoch 4/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.0140 - val_loss: 0.0121\n",
      "Epoch 5/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.0118 - val_loss: 0.0107\n",
      "Epoch 6/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.0105 - val_loss: 0.0096\n",
      "Epoch 7/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.0096 - val_loss: 0.0088\n",
      "Epoch 8/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.0088 - val_loss: 0.0084\n",
      "Epoch 9/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.0082 - val_loss: 0.0078\n",
      "Epoch 10/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.0079 - val_loss: 0.0075\n",
      "\n",
      "\n",
      "Loss History for Hierarchical circuits, U_6 autoencoder24\n",
      "iteration:  0  cost:  1.3338301012472598\n",
      "iteration:  10  cost:  0.9034598642371456\n",
      "iteration:  20  cost:  0.6821939746529757\n",
      "iteration:  30  cost:  0.7396366480310896\n",
      "iteration:  40  cost:  0.5312969876192406\n",
      "iteration:  50  cost:  0.5812194842555446\n",
      "iteration:  60  cost:  0.5586348822242756\n",
      "iteration:  70  cost:  0.5141711334305686\n",
      "iteration:  80  cost:  0.44826697945830773\n",
      "iteration:  90  cost:  0.4404742870913169\n",
      "iteration:  100  cost:  0.4101774971205792\n",
      "iteration:  110  cost:  0.3766095078031245\n",
      "iteration:  120  cost:  0.4461314859171507\n",
      "iteration:  130  cost:  0.4109134141634484\n",
      "iteration:  140  cost:  0.44648858758198295\n",
      "Accuracy for U_6 autoencoder24 :0.957919621749409\n",
      "\n",
      "\n",
      "Loss History for Hierarchical circuits, U_9 pca24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leeseok/.local/lib/python3.7/site-packages/autograd/tracer.py:14: UserWarning: Output seems independent of input.\n",
      "  warnings.warn(\"Output seems independent of input.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration:  0  cost:  0.9973452681031474\n",
      "iteration:  10  cost:  0.9731298761397481\n",
      "iteration:  20  cost:  0.9696156124220093\n",
      "iteration:  30  cost:  1.0025119370986753\n",
      "iteration:  40  cost:  1.0173612455305416\n",
      "iteration:  50  cost:  0.9868668567709828\n",
      "iteration:  60  cost:  1.0068777164661527\n",
      "iteration:  70  cost:  0.9934352750143159\n",
      "iteration:  80  cost:  0.999264636898722\n",
      "iteration:  90  cost:  1.0338102838160916\n",
      "iteration:  100  cost:  0.9847054756924272\n",
      "iteration:  110  cost:  0.9815042534389662\n",
      "iteration:  120  cost:  1.0208361265833408\n",
      "iteration:  130  cost:  1.0197417114191678\n",
      "iteration:  140  cost:  0.9981657018377432\n",
      "Accuracy for U_9 pca24 :0.4988179669030733\n",
      "Epoch 1/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.0855 - val_loss: 0.0260\n",
      "Epoch 2/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.0246 - val_loss: 0.0195\n",
      "Epoch 3/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.0184 - val_loss: 0.0148\n",
      "Epoch 4/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.0144 - val_loss: 0.0124\n",
      "Epoch 5/10\n",
      "396/396 [==============================] - 1s 1ms/step - loss: 0.0123 - val_loss: 0.0109\n",
      "Epoch 6/10\n",
      "396/396 [==============================] - 0s 867us/step - loss: 0.0108 - val_loss: 0.0097\n",
      "Epoch 7/10\n",
      "396/396 [==============================] - 0s 937us/step - loss: 0.0097 - val_loss: 0.0089\n",
      "Epoch 8/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.0088 - val_loss: 0.0083\n",
      "Epoch 9/10\n",
      "396/396 [==============================] - 1s 1ms/step - loss: 0.0083 - val_loss: 0.0078\n",
      "Epoch 10/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.0078 - val_loss: 0.0075\n",
      "\n",
      "\n",
      "Loss History for Hierarchical circuits, U_9 autoencoder24\n",
      "iteration:  0  cost:  2.4285081886352384\n",
      "iteration:  10  cost:  1.9910103936050971\n",
      "iteration:  20  cost:  2.3058750543159534\n",
      "iteration:  30  cost:  2.369914499059423\n",
      "iteration:  40  cost:  1.8307703809900406\n",
      "iteration:  50  cost:  2.174881330216227\n",
      "iteration:  60  cost:  2.3873766802211747\n",
      "iteration:  70  cost:  2.3430565894133433\n",
      "iteration:  80  cost:  2.176477164623186\n",
      "iteration:  90  cost:  1.7608926726310365\n",
      "iteration:  100  cost:  1.4851735722353414\n",
      "iteration:  110  cost:  1.8499003381417582\n",
      "iteration:  120  cost:  2.2554141965649066\n",
      "iteration:  130  cost:  2.0294165120103473\n",
      "iteration:  140  cost:  1.7348805568600227\n",
      "Accuracy for U_9 autoencoder24 :0.4628841607565012\n",
      "\n",
      "\n",
      "Loss History for Hierarchical circuits, U_13 pca24\n",
      "iteration:  0  cost:  1.020512560176644\n",
      "iteration:  10  cost:  1.031924549541258\n",
      "iteration:  20  cost:  0.9939657340078359\n",
      "iteration:  30  cost:  0.9812828330616357\n",
      "iteration:  40  cost:  0.9558858266886289\n",
      "iteration:  50  cost:  0.9566118920849466\n",
      "iteration:  60  cost:  1.0011485134155846\n",
      "iteration:  70  cost:  0.9371722677356928\n",
      "iteration:  80  cost:  0.9827746759923864\n",
      "iteration:  90  cost:  0.9476488614805898\n",
      "iteration:  100  cost:  0.9840746821801335\n",
      "iteration:  110  cost:  1.0088555711561897\n",
      "iteration:  120  cost:  0.952864312586677\n",
      "iteration:  130  cost:  0.9697148439318249\n",
      "iteration:  140  cost:  0.9890672182944021\n",
      "Accuracy for U_13 pca24 :0.4302600472813239\n",
      "Epoch 1/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.0881 - val_loss: 0.0261\n",
      "Epoch 2/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.0241 - val_loss: 0.0187\n",
      "Epoch 3/10\n",
      "396/396 [==============================] - 0s 1ms/step - loss: 0.0176 - val_loss: 0.0145\n",
      "Epoch 4/10\n",
      "396/396 [==============================] - 0s 1ms/step - loss: 0.0142 - val_loss: 0.0122\n",
      "Epoch 5/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.0121 - val_loss: 0.0107\n",
      "Epoch 6/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.0106 - val_loss: 0.0097\n",
      "Epoch 7/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.0096 - val_loss: 0.0089\n",
      "Epoch 8/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.0088 - val_loss: 0.0083\n",
      "Epoch 9/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.0083 - val_loss: 0.0079\n",
      "Epoch 10/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.0079 - val_loss: 0.0075\n",
      "\n",
      "\n",
      "Loss History for Hierarchical circuits, U_13 autoencoder24\n",
      "iteration:  0  cost:  0.877496266458908\n",
      "iteration:  10  cost:  0.8444891313280631\n",
      "iteration:  20  cost:  0.8885934946998357\n",
      "iteration:  30  cost:  0.8947554423690278\n",
      "iteration:  40  cost:  0.8878503761733438\n",
      "iteration:  50  cost:  0.8356627178385007\n",
      "iteration:  60  cost:  0.8999093791372677\n",
      "iteration:  70  cost:  0.8635503308546432\n",
      "iteration:  80  cost:  0.8281118570459455\n",
      "iteration:  90  cost:  0.6960699428556333\n",
      "iteration:  100  cost:  0.656604528164252\n",
      "iteration:  110  cost:  0.6507619978478807\n",
      "iteration:  120  cost:  0.4479462879726877\n",
      "iteration:  130  cost:  0.38441866244525386\n",
      "iteration:  140  cost:  0.287628911874273\n",
      "Accuracy for U_13 autoencoder24 :0.9432624113475178\n",
      "\n",
      "\n",
      "Loss History for Hierarchical circuits, U_14 pca24\n",
      "iteration:  0  cost:  1.1056257130303357\n",
      "iteration:  10  cost:  0.9683516313527208\n",
      "iteration:  20  cost:  0.9613162695617923\n",
      "iteration:  30  cost:  1.0463509560738569\n",
      "iteration:  40  cost:  1.0359232415900028\n",
      "iteration:  50  cost:  0.9696967348634373\n",
      "iteration:  60  cost:  1.0005600941515491\n",
      "iteration:  70  cost:  0.9689218172404166\n",
      "iteration:  80  cost:  1.034685029633813\n",
      "iteration:  90  cost:  0.9845256574352064\n",
      "iteration:  100  cost:  0.9549607645621966\n",
      "iteration:  110  cost:  1.0371368357264465\n",
      "iteration:  120  cost:  0.9363375095596514\n",
      "iteration:  130  cost:  1.0280433795236272\n",
      "iteration:  140  cost:  1.0106813696207646\n",
      "Accuracy for U_14 pca24 :0.5721040189125296\n",
      "Epoch 1/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.0862 - val_loss: 0.0257\n",
      "Epoch 2/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.0241 - val_loss: 0.0191\n",
      "Epoch 3/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.0181 - val_loss: 0.0145\n",
      "Epoch 4/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.0142 - val_loss: 0.0120\n",
      "Epoch 5/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.0117 - val_loss: 0.0104\n",
      "Epoch 6/10\n",
      "396/396 [==============================] - 1s 1ms/step - loss: 0.0104 - val_loss: 0.0094\n",
      "Epoch 7/10\n",
      "396/396 [==============================] - 1s 1ms/step - loss: 0.0094 - val_loss: 0.0086\n",
      "Epoch 8/10\n",
      "396/396 [==============================] - 1s 1ms/step - loss: 0.0085 - val_loss: 0.0081\n",
      "Epoch 9/10\n",
      "396/396 [==============================] - 1s 1ms/step - loss: 0.0079 - val_loss: 0.0077\n",
      "Epoch 10/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.0076 - val_loss: 0.0073\n",
      "\n",
      "\n",
      "Loss History for Hierarchical circuits, U_14 autoencoder24\n",
      "iteration:  0  cost:  1.0100755835099022\n",
      "iteration:  10  cost:  0.8180015045397289\n",
      "iteration:  20  cost:  0.6926699938861661\n",
      "iteration:  30  cost:  0.7169411542014221\n",
      "iteration:  40  cost:  0.7127248403232247\n",
      "iteration:  50  cost:  0.7661587869164902\n",
      "iteration:  60  cost:  0.7832478103237355\n",
      "iteration:  70  cost:  0.8244724376339384\n",
      "iteration:  80  cost:  0.6760280325346985\n",
      "iteration:  90  cost:  0.7457820670040064\n",
      "iteration:  100  cost:  0.6594231319772555\n",
      "iteration:  110  cost:  0.7742357956128373\n",
      "iteration:  120  cost:  0.7958989618403918\n",
      "iteration:  130  cost:  0.672317302321399\n",
      "iteration:  140  cost:  0.6637948963798607\n",
      "Accuracy for U_14 autoencoder24 :0.8723404255319149\n",
      "\n",
      "\n",
      "Loss History for Hierarchical circuits, U_15 pca24\n",
      "iteration:  0  cost:  1.0100204474033443\n",
      "iteration:  10  cost:  1.0570232315780745\n",
      "iteration:  20  cost:  1.1177302554824857\n",
      "iteration:  30  cost:  1.0040137217180198\n",
      "iteration:  40  cost:  0.9674199523401057\n",
      "iteration:  50  cost:  0.9666790405791014\n",
      "iteration:  60  cost:  0.9904059426786533\n",
      "iteration:  70  cost:  1.0541186145411714\n",
      "iteration:  80  cost:  0.9991918746062752\n",
      "iteration:  90  cost:  1.007781482525611\n",
      "iteration:  100  cost:  1.0089625345823303\n",
      "iteration:  110  cost:  0.9901670289563163\n",
      "iteration:  120  cost:  0.9992428553390151\n",
      "iteration:  130  cost:  0.9912657348359741\n",
      "iteration:  140  cost:  1.0022405424876215\n",
      "Accuracy for U_15 pca24 :0.5394799054373522\n",
      "Epoch 1/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.0852 - val_loss: 0.0261\n",
      "Epoch 2/10\n",
      "396/396 [==============================] - 1s 1ms/step - loss: 0.0243 - val_loss: 0.0192\n",
      "Epoch 3/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.0182 - val_loss: 0.0149\n",
      "Epoch 4/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.0145 - val_loss: 0.0125\n",
      "Epoch 5/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.0123 - val_loss: 0.0109\n",
      "Epoch 6/10\n",
      "396/396 [==============================] - 1s 1ms/step - loss: 0.0108 - val_loss: 0.0099\n",
      "Epoch 7/10\n",
      "396/396 [==============================] - 1s 1ms/step - loss: 0.0096 - val_loss: 0.0091\n",
      "Epoch 8/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.0091 - val_loss: 0.0084\n",
      "Epoch 9/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.0084 - val_loss: 0.0080\n",
      "Epoch 10/10\n",
      "396/396 [==============================] - 1s 1ms/step - loss: 0.0079 - val_loss: 0.0075\n",
      "\n",
      "\n",
      "Loss History for Hierarchical circuits, U_15 autoencoder24\n",
      "iteration:  0  cost:  0.9838789178906946\n",
      "iteration:  10  cost:  0.45627601174026106\n",
      "iteration:  20  cost:  0.6029044325094307\n",
      "iteration:  30  cost:  0.5761411217328215\n",
      "iteration:  40  cost:  0.5415040704977065\n",
      "iteration:  50  cost:  0.5029232734548646\n",
      "iteration:  60  cost:  0.3783034058579711\n",
      "iteration:  70  cost:  0.5071991351674794\n",
      "iteration:  80  cost:  0.5179618570759383\n",
      "iteration:  90  cost:  0.649628690960831\n",
      "iteration:  100  cost:  0.5752567833917428\n",
      "iteration:  110  cost:  0.550576792160635\n",
      "iteration:  120  cost:  0.4175307307983753\n",
      "iteration:  130  cost:  0.3836852951249877\n",
      "iteration:  140  cost:  0.5855750673020035\n",
      "Accuracy for U_15 autoencoder24 :0.873758865248227\n",
      "\n",
      "\n",
      "Loss History for Hierarchical circuits, U_SO4 pca24\n",
      "iteration:  0  cost:  1.0311371068155915\n",
      "iteration:  10  cost:  0.995185595550467\n",
      "iteration:  20  cost:  0.9616067343340855\n",
      "iteration:  30  cost:  1.0055652983644512\n",
      "iteration:  40  cost:  0.9561176769076107\n",
      "iteration:  50  cost:  1.002328851338276\n",
      "iteration:  60  cost:  1.041637778323724\n",
      "iteration:  70  cost:  1.0007359697829614\n",
      "iteration:  80  cost:  0.9814498296058397\n",
      "iteration:  90  cost:  1.048520478480989\n",
      "iteration:  100  cost:  1.002180025606016\n",
      "iteration:  110  cost:  0.9445514298394966\n",
      "iteration:  120  cost:  0.9852856499956982\n",
      "iteration:  130  cost:  0.9872324644131308\n",
      "iteration:  140  cost:  0.9541074975044248\n",
      "Accuracy for U_SO4 pca24 :0.5366430260047281\n",
      "Epoch 1/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.0878 - val_loss: 0.0248\n",
      "Epoch 2/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.0236 - val_loss: 0.0185\n",
      "Epoch 3/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.0175 - val_loss: 0.0142\n",
      "Epoch 4/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.0138 - val_loss: 0.0119\n",
      "Epoch 5/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.0117 - val_loss: 0.0105\n",
      "Epoch 6/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.0104 - val_loss: 0.0095\n",
      "Epoch 7/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.0094 - val_loss: 0.0088\n",
      "Epoch 8/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.0087 - val_loss: 0.0082\n",
      "Epoch 9/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.0082 - val_loss: 0.0077\n",
      "Epoch 10/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.0078 - val_loss: 0.0073\n",
      "\n",
      "\n",
      "Loss History for Hierarchical circuits, U_SO4 autoencoder24\n",
      "iteration:  0  cost:  1.0785179796877626\n",
      "iteration:  10  cost:  0.6706912144544726\n",
      "iteration:  20  cost:  0.5444337727470357\n",
      "iteration:  30  cost:  0.5786342286323751\n",
      "iteration:  40  cost:  0.5868761182049167\n",
      "iteration:  50  cost:  0.608576964320529\n",
      "iteration:  60  cost:  0.6732595913166893\n",
      "iteration:  70  cost:  0.48094384645554017\n",
      "iteration:  80  cost:  0.4971538233392252\n",
      "iteration:  90  cost:  0.6172755119307007\n",
      "iteration:  100  cost:  0.5554240978363749\n",
      "iteration:  110  cost:  0.5990911707326512\n",
      "iteration:  120  cost:  0.5858703521911193\n",
      "iteration:  130  cost:  0.5703889852309502\n",
      "iteration:  140  cost:  0.6519756747571774\n",
      "Accuracy for U_SO4 autoencoder24 :0.8283687943262411\n",
      "2th step : \n",
      "\n",
      "\n",
      "Loss History for Hierarchical circuits, U_TTN pca24\n",
      "iteration:  0  cost:  1.0000490239319655\n",
      "iteration:  10  cost:  0.9999055927091192\n",
      "iteration:  20  cost:  0.999850446368929\n",
      "iteration:  30  cost:  0.9999126305191071\n",
      "iteration:  40  cost:  1.0000032197358752\n",
      "iteration:  50  cost:  0.9997951528340007\n",
      "iteration:  60  cost:  0.9998712431660002\n",
      "iteration:  70  cost:  1.0000057175123258\n",
      "iteration:  80  cost:  0.9999010575796234\n",
      "iteration:  90  cost:  1.0000102907670636\n",
      "iteration:  100  cost:  0.999928382808564\n",
      "iteration:  110  cost:  0.9998728392033389\n",
      "iteration:  120  cost:  0.9999018975148272\n",
      "iteration:  130  cost:  0.9998805916735485\n",
      "iteration:  140  cost:  0.9999271623126559\n",
      "Accuracy for U_TTN pca24 :0.5498817966903073\n",
      "Epoch 1/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.0856 - val_loss: 0.0265\n",
      "Epoch 2/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.0248 - val_loss: 0.0194\n",
      "Epoch 3/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.0183 - val_loss: 0.0147\n",
      "Epoch 4/10\n",
      "396/396 [==============================] - 1s 1ms/step - loss: 0.0145 - val_loss: 0.0124\n",
      "Epoch 5/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.0121 - val_loss: 0.0110\n",
      "Epoch 6/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.0109 - val_loss: 0.0099\n",
      "Epoch 7/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.0097 - val_loss: 0.0091\n",
      "Epoch 8/10\n",
      "396/396 [==============================] - 1s 1ms/step - loss: 0.0090 - val_loss: 0.0085\n",
      "Epoch 9/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.0084 - val_loss: 0.0080\n",
      "Epoch 10/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.0079 - val_loss: 0.0076\n",
      "\n",
      "\n",
      "Loss History for Hierarchical circuits, U_TTN autoencoder24\n",
      "iteration:  0  cost:  0.9544933754554509\n",
      "iteration:  10  cost:  0.7282076361385709\n",
      "iteration:  20  cost:  0.46939679095628106\n",
      "iteration:  30  cost:  0.5093991074833764\n",
      "iteration:  40  cost:  0.6092249238111862\n",
      "iteration:  50  cost:  0.5623433805165612\n",
      "iteration:  60  cost:  0.5802609952182913\n",
      "iteration:  70  cost:  0.4810304461752377\n",
      "iteration:  80  cost:  0.6163533580641399\n",
      "iteration:  90  cost:  0.6922815072196304\n",
      "iteration:  100  cost:  0.4730656184458185\n",
      "iteration:  110  cost:  0.6252947322004649\n",
      "iteration:  120  cost:  0.6800778034530981\n",
      "iteration:  130  cost:  0.6703707343773242\n",
      "iteration:  140  cost:  0.7423589192597423\n",
      "Accuracy for U_TTN autoencoder24 :0.8699763593380615\n",
      "\n",
      "\n",
      "Loss History for Hierarchical circuits, U_5 pca24\n",
      "iteration:  0  cost:  1.2346488514336749\n",
      "iteration:  10  cost:  1.1871282066508706\n",
      "iteration:  20  cost:  1.1198838567632485\n",
      "iteration:  30  cost:  0.9255903191276644\n",
      "iteration:  40  cost:  0.9752778607750295\n",
      "iteration:  50  cost:  0.9902182386235415\n",
      "iteration:  60  cost:  1.0614693894378853\n",
      "iteration:  70  cost:  0.9934404898878583\n",
      "iteration:  80  cost:  0.9928451193561131\n",
      "iteration:  90  cost:  1.0025820822840235\n",
      "iteration:  100  cost:  1.0180945453991932\n",
      "iteration:  110  cost:  0.9268443801637362\n",
      "iteration:  120  cost:  1.0011582237163321\n",
      "iteration:  130  cost:  0.975912591743014\n",
      "iteration:  140  cost:  0.969917880144029\n",
      "Accuracy for U_5 pca24 :0.5423167848699764\n",
      "Epoch 1/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.0884 - val_loss: 0.0268\n",
      "Epoch 2/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.0251 - val_loss: 0.0200\n",
      "Epoch 3/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.0192 - val_loss: 0.0158\n",
      "Epoch 4/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.0153 - val_loss: 0.0134\n",
      "Epoch 5/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.0129 - val_loss: 0.0115\n",
      "Epoch 6/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.0114 - val_loss: 0.0103\n",
      "Epoch 7/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.0103 - val_loss: 0.0095\n",
      "Epoch 8/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.0094 - val_loss: 0.0088\n",
      "Epoch 9/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.0089 - val_loss: 0.0084\n",
      "Epoch 10/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.0083 - val_loss: 0.0080\n",
      "\n",
      "\n",
      "Loss History for Hierarchical circuits, U_5 autoencoder24\n",
      "iteration:  0  cost:  2.300018730003944\n",
      "iteration:  10  cost:  1.0785289598232428\n",
      "iteration:  20  cost:  0.9175974112460072\n",
      "iteration:  30  cost:  0.7835668011621232\n",
      "iteration:  40  cost:  0.5917160460000158\n",
      "iteration:  50  cost:  0.5851376252449974\n",
      "iteration:  60  cost:  0.8676208024656604\n",
      "iteration:  70  cost:  0.7186566569747344\n",
      "iteration:  80  cost:  0.6119388645528503\n",
      "iteration:  90  cost:  0.6697017215493197\n",
      "iteration:  100  cost:  0.7738969470618019\n",
      "iteration:  110  cost:  0.7607970025664575\n",
      "iteration:  120  cost:  0.7179593445737297\n",
      "iteration:  130  cost:  0.7784416909054466\n",
      "iteration:  140  cost:  0.6701025278750886\n",
      "Accuracy for U_5 autoencoder24 :0.908274231678487\n",
      "\n",
      "\n",
      "Loss History for Hierarchical circuits, U_6 pca24\n",
      "iteration:  0  cost:  1.3931396902046358\n",
      "iteration:  10  cost:  0.9993019706806155\n",
      "iteration:  20  cost:  1.0471827922326218\n",
      "iteration:  30  cost:  0.9989424798903834\n",
      "iteration:  40  cost:  1.0833896640271363\n",
      "iteration:  50  cost:  0.9842874900288555\n",
      "iteration:  60  cost:  0.9811004121348071\n",
      "iteration:  70  cost:  1.0285309211015952\n",
      "iteration:  80  cost:  1.0837234829857438\n",
      "iteration:  90  cost:  0.9949384059791312\n",
      "iteration:  100  cost:  1.2984903287942884\n",
      "iteration:  110  cost:  1.0208615217534622\n",
      "iteration:  120  cost:  0.9442783506885926\n",
      "iteration:  130  cost:  0.9946261708186214\n",
      "iteration:  140  cost:  1.0092706481949696\n",
      "Accuracy for U_6 pca24 :0.5366430260047281\n",
      "Epoch 1/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.0869 - val_loss: 0.0263\n",
      "Epoch 2/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.0247 - val_loss: 0.0192\n",
      "Epoch 3/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.0179 - val_loss: 0.0145\n",
      "Epoch 4/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.0139 - val_loss: 0.0121\n",
      "Epoch 5/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.0119 - val_loss: 0.0106\n",
      "Epoch 6/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.0105 - val_loss: 0.0096\n",
      "Epoch 7/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.0094 - val_loss: 0.0089\n",
      "Epoch 8/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.0089 - val_loss: 0.0083\n",
      "Epoch 9/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.0082 - val_loss: 0.0078\n",
      "Epoch 10/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.0078 - val_loss: 0.0074\n",
      "\n",
      "\n",
      "Loss History for Hierarchical circuits, U_6 autoencoder24\n",
      "iteration:  0  cost:  1.5283330645448399\n",
      "iteration:  10  cost:  0.8996544016465882\n",
      "iteration:  20  cost:  0.708585583357896\n",
      "iteration:  30  cost:  1.006211636744271\n",
      "iteration:  40  cost:  0.5890146899393892\n",
      "iteration:  50  cost:  0.649280174366865\n",
      "iteration:  60  cost:  0.6684691209226341\n",
      "iteration:  70  cost:  0.7506178379907894\n",
      "iteration:  80  cost:  0.6871979925512823\n",
      "iteration:  90  cost:  0.7192370437212675\n",
      "iteration:  100  cost:  0.6948008641426372\n",
      "iteration:  110  cost:  0.5790931504591719\n",
      "iteration:  120  cost:  0.687314543319272\n",
      "iteration:  130  cost:  0.6195464727204874\n",
      "iteration:  140  cost:  0.5895465589648163\n",
      "Accuracy for U_6 autoencoder24 :0.9087470449172577\n",
      "\n",
      "\n",
      "Loss History for Hierarchical circuits, U_9 pca24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leeseok/.local/lib/python3.7/site-packages/autograd/tracer.py:14: UserWarning: Output seems independent of input.\n",
      "  warnings.warn(\"Output seems independent of input.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration:  0  cost:  1.002967728972443\n",
      "iteration:  10  cost:  1.0240474365667336\n",
      "iteration:  20  cost:  0.9730328195750312\n",
      "iteration:  30  cost:  0.9969858190687658\n",
      "iteration:  40  cost:  1.0404855211821427\n",
      "iteration:  50  cost:  1.0122706042522407\n",
      "iteration:  60  cost:  1.004024611326056\n",
      "iteration:  70  cost:  0.9942764401548103\n",
      "iteration:  80  cost:  0.9983072910243636\n",
      "iteration:  90  cost:  1.021248734511385\n",
      "iteration:  100  cost:  1.0113942470219823\n",
      "iteration:  110  cost:  1.028316364002478\n",
      "iteration:  120  cost:  1.041763496522084\n",
      "iteration:  130  cost:  1.000962120334127\n",
      "iteration:  140  cost:  0.9938664971369717\n",
      "Accuracy for U_9 pca24 :0.4988179669030733\n",
      "Epoch 1/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.0891 - val_loss: 0.0267\n",
      "Epoch 2/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.0247 - val_loss: 0.0191\n",
      "Epoch 3/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.0183 - val_loss: 0.0150\n",
      "Epoch 4/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.0147 - val_loss: 0.0124\n",
      "Epoch 5/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.0123 - val_loss: 0.0108\n",
      "Epoch 6/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.0106 - val_loss: 0.0098\n",
      "Epoch 7/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.0098 - val_loss: 0.0089\n",
      "Epoch 8/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.0089 - val_loss: 0.0083\n",
      "Epoch 9/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.0083 - val_loss: 0.0078\n",
      "Epoch 10/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.0079 - val_loss: 0.0074\n",
      "\n",
      "\n",
      "Loss History for Hierarchical circuits, U_9 autoencoder24\n",
      "iteration:  0  cost:  2.174230808924903\n",
      "iteration:  10  cost:  1.7431863015676765\n",
      "iteration:  20  cost:  1.7067020194821787\n",
      "iteration:  30  cost:  2.0523871740279067\n",
      "iteration:  40  cost:  2.3705207340413965\n",
      "iteration:  50  cost:  2.0537393258357532\n",
      "iteration:  60  cost:  2.795353401025574\n",
      "iteration:  70  cost:  2.203396958407844\n",
      "iteration:  80  cost:  2.189246619671665\n",
      "iteration:  90  cost:  2.33957909257647\n",
      "iteration:  100  cost:  2.5045791257533185\n",
      "iteration:  110  cost:  1.7422014945108881\n",
      "iteration:  120  cost:  2.040508226286134\n",
      "iteration:  130  cost:  1.8717346053141657\n",
      "iteration:  140  cost:  1.7143441941471693\n",
      "Accuracy for U_9 autoencoder24 :0.46335697399527187\n",
      "\n",
      "\n",
      "Loss History for Hierarchical circuits, U_13 pca24\n",
      "iteration:  0  cost:  1.021002980559279\n",
      "iteration:  10  cost:  1.0190857624000542\n",
      "iteration:  20  cost:  0.9479673871908751\n",
      "iteration:  30  cost:  1.0644865315853935\n",
      "iteration:  40  cost:  0.9867862959997963\n",
      "iteration:  50  cost:  1.0399220509881983\n",
      "iteration:  60  cost:  1.0520731970118697\n",
      "iteration:  70  cost:  1.0071778032760816\n",
      "iteration:  80  cost:  0.916400636894219\n",
      "iteration:  90  cost:  1.074482501564928\n",
      "iteration:  100  cost:  1.0041515041676203\n",
      "iteration:  110  cost:  0.9174499494017406\n",
      "iteration:  120  cost:  1.001925898729475\n",
      "iteration:  130  cost:  0.9700432992816056\n",
      "iteration:  140  cost:  0.9930779664393738\n",
      "Accuracy for U_13 pca24 :0.5380614657210402\n",
      "Epoch 1/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.0869 - val_loss: 0.0254\n",
      "Epoch 2/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.0240 - val_loss: 0.0194\n",
      "Epoch 3/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.0183 - val_loss: 0.0150\n",
      "Epoch 4/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.0145 - val_loss: 0.0125\n",
      "Epoch 5/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.0121 - val_loss: 0.0109\n",
      "Epoch 6/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.0107 - val_loss: 0.0098\n",
      "Epoch 7/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.0097 - val_loss: 0.0089\n",
      "Epoch 8/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.0087 - val_loss: 0.0083\n",
      "Epoch 9/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.0083 - val_loss: 0.0079\n",
      "Epoch 10/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.0078 - val_loss: 0.0075\n",
      "\n",
      "\n",
      "Loss History for Hierarchical circuits, U_13 autoencoder24\n",
      "iteration:  0  cost:  1.256885970443192\n",
      "iteration:  10  cost:  0.6633483625258658\n",
      "iteration:  20  cost:  0.5838682444491038\n",
      "iteration:  30  cost:  0.6052531535924747\n",
      "iteration:  40  cost:  0.5678977129997211\n",
      "iteration:  50  cost:  0.47849290956541474\n",
      "iteration:  60  cost:  0.6223896297700388\n",
      "iteration:  70  cost:  0.5306906216845024\n",
      "iteration:  80  cost:  0.5680687898451259\n",
      "iteration:  90  cost:  0.6009879363501703\n",
      "iteration:  100  cost:  0.5694065980552517\n",
      "iteration:  110  cost:  0.5532872953183057\n",
      "iteration:  120  cost:  0.5536705804920413\n",
      "iteration:  130  cost:  0.619952221883432\n",
      "iteration:  140  cost:  0.5001021193267182\n",
      "Accuracy for U_13 autoencoder24 :0.9054373522458629\n",
      "\n",
      "\n",
      "Loss History for Hierarchical circuits, U_14 pca24\n",
      "iteration:  0  cost:  1.0211337580534723\n",
      "iteration:  10  cost:  1.0262598207604245\n",
      "iteration:  20  cost:  1.0013657003621221\n",
      "iteration:  30  cost:  0.991806556230724\n",
      "iteration:  40  cost:  0.9994283502888744\n",
      "iteration:  50  cost:  0.9977002448423449\n",
      "iteration:  60  cost:  0.9686528721624086\n",
      "iteration:  70  cost:  1.0098920071275592\n",
      "iteration:  80  cost:  1.0047396425621056\n",
      "iteration:  90  cost:  0.9767739506746687\n",
      "iteration:  100  cost:  0.9456950037157877\n",
      "iteration:  110  cost:  0.9952714224761613\n",
      "iteration:  120  cost:  0.9786549642635636\n",
      "iteration:  130  cost:  0.9830656376419112\n",
      "iteration:  140  cost:  0.9707566410002687\n",
      "Accuracy for U_14 pca24 :0.548936170212766\n",
      "Epoch 1/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.0863 - val_loss: 0.0261\n",
      "Epoch 2/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.0248 - val_loss: 0.0193\n",
      "Epoch 3/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.0183 - val_loss: 0.0148\n",
      "Epoch 4/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.0143 - val_loss: 0.0122\n",
      "Epoch 5/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.0120 - val_loss: 0.0107\n",
      "Epoch 6/10\n",
      "396/396 [==============================] - 1s 1ms/step - loss: 0.0104 - val_loss: 0.0095\n",
      "Epoch 7/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.0095 - val_loss: 0.0088\n",
      "Epoch 8/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.0087 - val_loss: 0.0082\n",
      "Epoch 9/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.0081 - val_loss: 0.0078\n",
      "Epoch 10/10\n",
      "396/396 [==============================] - 1s 1ms/step - loss: 0.0077 - val_loss: 0.0074\n",
      "\n",
      "\n",
      "Loss History for Hierarchical circuits, U_14 autoencoder24\n",
      "iteration:  0  cost:  1.2836255871331184\n",
      "iteration:  10  cost:  0.8779672927710749\n",
      "iteration:  20  cost:  0.862763120027862\n",
      "iteration:  30  cost:  0.6957818514374692\n",
      "iteration:  40  cost:  0.6897213470571327\n",
      "iteration:  50  cost:  0.6909101810709762\n",
      "iteration:  60  cost:  0.6497214855443002\n",
      "iteration:  70  cost:  0.7061335351219112\n",
      "iteration:  80  cost:  0.6746561266590332\n",
      "iteration:  90  cost:  0.5773286255175331\n",
      "iteration:  100  cost:  0.6467012172243761\n",
      "iteration:  110  cost:  0.6224757240930456\n",
      "iteration:  120  cost:  0.5996243730836504\n",
      "iteration:  130  cost:  0.531692352725253\n",
      "iteration:  140  cost:  0.5412693326805605\n",
      "Accuracy for U_14 autoencoder24 :0.8761229314420804\n",
      "\n",
      "\n",
      "Loss History for Hierarchical circuits, U_15 pca24\n",
      "iteration:  0  cost:  1.2595969040107127\n",
      "iteration:  10  cost:  1.060541559748838\n",
      "iteration:  20  cost:  0.9731287936545826\n",
      "iteration:  30  cost:  1.002901475716911\n",
      "iteration:  40  cost:  1.0043476592585288\n",
      "iteration:  50  cost:  0.9901091123708164\n",
      "iteration:  60  cost:  0.9285673604503151\n",
      "iteration:  70  cost:  1.0439355126645546\n",
      "iteration:  80  cost:  0.9991133124311373\n",
      "iteration:  90  cost:  1.0071438893768725\n",
      "iteration:  100  cost:  1.015266396377131\n",
      "iteration:  110  cost:  1.1821136041158078\n",
      "iteration:  120  cost:  1.0189676116905255\n",
      "iteration:  130  cost:  1.0062867238042763\n",
      "iteration:  140  cost:  1.001319879642313\n",
      "Accuracy for U_15 pca24 :0.5408983451536643\n",
      "Epoch 1/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.0869 - val_loss: 0.0257\n",
      "Epoch 2/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.0240 - val_loss: 0.0188\n",
      "Epoch 3/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.0179 - val_loss: 0.0146\n",
      "Epoch 4/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.0141 - val_loss: 0.0122\n",
      "Epoch 5/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.0119 - val_loss: 0.0108\n",
      "Epoch 6/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.0105 - val_loss: 0.0098\n",
      "Epoch 7/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.0096 - val_loss: 0.0090\n",
      "Epoch 8/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.0087 - val_loss: 0.0084\n",
      "Epoch 9/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.0083 - val_loss: 0.0079\n",
      "Epoch 10/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.0078 - val_loss: 0.0075\n",
      "\n",
      "\n",
      "Loss History for Hierarchical circuits, U_15 autoencoder24\n",
      "iteration:  0  cost:  1.0408205038368283\n",
      "iteration:  10  cost:  0.640815877435087\n",
      "iteration:  20  cost:  0.6633489948683255\n",
      "iteration:  30  cost:  0.5739752547699815\n",
      "iteration:  40  cost:  0.6242641364963099\n",
      "iteration:  50  cost:  0.3492914266597302\n",
      "iteration:  60  cost:  0.4736316909000137\n",
      "iteration:  70  cost:  0.4548301839408209\n",
      "iteration:  80  cost:  0.44344242956165725\n",
      "iteration:  90  cost:  0.44149207350513875\n",
      "iteration:  100  cost:  0.4665594881312971\n",
      "iteration:  110  cost:  0.6185459386660276\n",
      "iteration:  120  cost:  0.48634896913853054\n",
      "iteration:  130  cost:  0.4055451205597801\n",
      "iteration:  140  cost:  0.5238635628158987\n",
      "Accuracy for U_15 autoencoder24 :0.9106382978723404\n",
      "\n",
      "\n",
      "Loss History for Hierarchical circuits, U_SO4 pca24\n",
      "iteration:  0  cost:  0.9764199591357453\n",
      "iteration:  10  cost:  1.0054902554209617\n",
      "iteration:  20  cost:  0.958245610216466\n",
      "iteration:  30  cost:  1.0021691219608149\n",
      "iteration:  40  cost:  0.999938808186039\n",
      "iteration:  50  cost:  1.0041203808906192\n",
      "iteration:  60  cost:  1.0006904895322932\n",
      "iteration:  70  cost:  1.0005613492945526\n",
      "iteration:  80  cost:  1.0002011744516848\n",
      "iteration:  90  cost:  0.9956302016808213\n",
      "iteration:  100  cost:  0.9980237169957152\n",
      "iteration:  110  cost:  1.002254463683381\n",
      "iteration:  120  cost:  1.0273718225075663\n",
      "iteration:  130  cost:  0.9153921486655936\n",
      "iteration:  140  cost:  0.9644491704941978\n",
      "Accuracy for U_SO4 pca24 :0.5366430260047281\n",
      "Epoch 1/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.0898 - val_loss: 0.0259\n",
      "Epoch 2/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.0243 - val_loss: 0.0190\n",
      "Epoch 3/10\n",
      "396/396 [==============================] - 1s 1ms/step - loss: 0.0180 - val_loss: 0.0146\n",
      "Epoch 4/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.0141 - val_loss: 0.0121\n",
      "Epoch 5/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.0118 - val_loss: 0.0106\n",
      "Epoch 6/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.0104 - val_loss: 0.0095\n",
      "Epoch 7/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.0095 - val_loss: 0.0088\n",
      "Epoch 8/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.0087 - val_loss: 0.0081\n",
      "Epoch 9/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.0081 - val_loss: 0.0077\n",
      "Epoch 10/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.0076 - val_loss: 0.0073\n",
      "\n",
      "\n",
      "Loss History for Hierarchical circuits, U_SO4 autoencoder24\n",
      "iteration:  0  cost:  1.356985573172025\n",
      "iteration:  10  cost:  0.9304923231792518\n",
      "iteration:  20  cost:  0.720896493141709\n",
      "iteration:  30  cost:  0.6288548250138306\n",
      "iteration:  40  cost:  0.4777655551406931\n",
      "iteration:  50  cost:  0.5835057377122737\n",
      "iteration:  60  cost:  0.6073992659746033\n",
      "iteration:  70  cost:  0.5662644610116048\n",
      "iteration:  80  cost:  0.4578490548312358\n",
      "iteration:  90  cost:  0.42122008554804063\n",
      "iteration:  100  cost:  0.5011949150644872\n",
      "iteration:  110  cost:  0.5218025257987867\n",
      "iteration:  120  cost:  0.46281851455188766\n",
      "iteration:  130  cost:  0.39672429523423935\n",
      "iteration:  140  cost:  0.7231979682170773\n",
      "Accuracy for U_SO4 autoencoder24 :0.8293144208037825\n",
      "3th step : \n",
      "\n",
      "\n",
      "Loss History for Hierarchical circuits, U_TTN pca24\n",
      "iteration:  0  cost:  1.0000182868068483\n",
      "iteration:  10  cost:  1.0000033669199302\n",
      "iteration:  20  cost:  1.000007954977637\n",
      "iteration:  30  cost:  0.9999951395501552\n",
      "iteration:  40  cost:  0.999999823983817\n",
      "iteration:  50  cost:  1.000000594080011\n",
      "iteration:  60  cost:  1.0000005836618928\n",
      "iteration:  70  cost:  0.9999399633924629\n",
      "iteration:  80  cost:  0.9999915920652808\n",
      "iteration:  90  cost:  0.9999992730201709\n",
      "iteration:  100  cost:  1.0000095697369364\n",
      "iteration:  110  cost:  0.9999674527882899\n",
      "iteration:  120  cost:  0.9999966007855059\n",
      "iteration:  130  cost:  0.9999746959271318\n",
      "iteration:  140  cost:  1.0000056217905533\n",
      "Accuracy for U_TTN pca24 :0.49976359338061466\n",
      "Epoch 1/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.0860 - val_loss: 0.0261\n",
      "Epoch 2/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.0242 - val_loss: 0.0189\n",
      "Epoch 3/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.0181 - val_loss: 0.0149\n",
      "Epoch 4/10\n",
      "396/396 [==============================] - 1s 1ms/step - loss: 0.0144 - val_loss: 0.0125\n",
      "Epoch 5/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.0122 - val_loss: 0.0109\n",
      "Epoch 6/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.0107 - val_loss: 0.0098\n",
      "Epoch 7/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.0097 - val_loss: 0.0090\n",
      "Epoch 8/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.0090 - val_loss: 0.0084\n",
      "Epoch 9/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.0083 - val_loss: 0.0080\n",
      "Epoch 10/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.0081 - val_loss: 0.0076\n",
      "\n",
      "\n",
      "Loss History for Hierarchical circuits, U_TTN autoencoder24\n",
      "iteration:  0  cost:  1.04297094330545\n",
      "iteration:  10  cost:  0.9166280207475249\n",
      "iteration:  20  cost:  0.7386358006693642\n",
      "iteration:  30  cost:  0.7734917057594042\n",
      "iteration:  40  cost:  0.655599893304863\n",
      "iteration:  50  cost:  0.805029835740682\n",
      "iteration:  60  cost:  0.8023974151165639\n",
      "iteration:  70  cost:  0.6859198946481135\n",
      "iteration:  80  cost:  0.688800196240592\n",
      "iteration:  90  cost:  0.7201231641666485\n",
      "iteration:  100  cost:  0.6001397438206941\n",
      "iteration:  110  cost:  0.7102344350267106\n",
      "iteration:  120  cost:  0.7159098155104309\n",
      "iteration:  130  cost:  0.7821570904939192\n",
      "iteration:  140  cost:  0.6749189399632634\n",
      "Accuracy for U_TTN autoencoder24 :0.7120567375886525\n",
      "\n",
      "\n",
      "Loss History for Hierarchical circuits, U_5 pca24\n",
      "iteration:  0  cost:  1.0729832187318238\n",
      "iteration:  10  cost:  1.0165016136444607\n",
      "iteration:  20  cost:  1.2732980793049193\n",
      "iteration:  30  cost:  0.9706656906507197\n",
      "iteration:  40  cost:  1.0454494298110346\n",
      "iteration:  50  cost:  1.246531702842407\n",
      "iteration:  60  cost:  0.9590352275296763\n",
      "iteration:  70  cost:  1.0161966745202458\n",
      "iteration:  80  cost:  0.9919477588325409\n",
      "iteration:  90  cost:  1.0054719030324124\n",
      "iteration:  100  cost:  1.0173628376613795\n",
      "iteration:  110  cost:  1.000924711704216\n",
      "iteration:  120  cost:  1.0260409860948363\n",
      "iteration:  130  cost:  0.9298424060824456\n",
      "iteration:  140  cost:  0.939692698469389\n",
      "Accuracy for U_5 pca24 :0.5366430260047281\n",
      "Epoch 1/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.0881 - val_loss: 0.0260\n",
      "Epoch 2/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.0240 - val_loss: 0.0189\n",
      "Epoch 3/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.0180 - val_loss: 0.0145\n",
      "Epoch 4/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.0139 - val_loss: 0.0122\n",
      "Epoch 5/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.0121 - val_loss: 0.0107\n",
      "Epoch 6/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.0107 - val_loss: 0.0097\n",
      "Epoch 7/10\n",
      "396/396 [==============================] - 1s 1ms/step - loss: 0.0095 - val_loss: 0.0089\n",
      "Epoch 8/10\n",
      "396/396 [==============================] - 1s 1ms/step - loss: 0.0088 - val_loss: 0.0083\n",
      "Epoch 9/10\n",
      "396/396 [==============================] - 1s 1ms/step - loss: 0.0083 - val_loss: 0.0078\n",
      "Epoch 10/10\n",
      "396/396 [==============================] - 1s 1ms/step - loss: 0.0078 - val_loss: 0.0074\n",
      "\n",
      "\n",
      "Loss History for Hierarchical circuits, U_5 autoencoder24\n",
      "iteration:  0  cost:  1.2249979842655205\n",
      "iteration:  10  cost:  1.0834069527643102\n",
      "iteration:  20  cost:  0.792238945200608\n",
      "iteration:  30  cost:  0.8175147659585197\n",
      "iteration:  40  cost:  0.7101748836226617\n",
      "iteration:  50  cost:  0.7660165364799192\n",
      "iteration:  60  cost:  0.6505767087664683\n",
      "iteration:  70  cost:  0.6328633103309711\n",
      "iteration:  80  cost:  0.8704718038044552\n",
      "iteration:  90  cost:  0.6980036463485523\n",
      "iteration:  100  cost:  0.6723585141418614\n",
      "iteration:  110  cost:  0.6621527523556469\n",
      "iteration:  120  cost:  0.7478351426946105\n",
      "iteration:  130  cost:  0.641895767956671\n",
      "iteration:  140  cost:  0.7041055782140911\n",
      "Accuracy for U_5 autoencoder24 :0.8973995271867612\n",
      "\n",
      "\n",
      "Loss History for Hierarchical circuits, U_6 pca24\n",
      "iteration:  0  cost:  1.2545825439776381\n",
      "iteration:  10  cost:  1.083257051310338\n",
      "iteration:  20  cost:  1.0493217039416598\n",
      "iteration:  30  cost:  1.0216210685987999\n",
      "iteration:  40  cost:  0.9996896240863735\n",
      "iteration:  50  cost:  0.9990784746099416\n",
      "iteration:  60  cost:  0.979439853384196\n",
      "iteration:  70  cost:  1.0268011686027807\n",
      "iteration:  80  cost:  0.9704402650583671\n",
      "iteration:  90  cost:  1.0027288409820765\n",
      "iteration:  100  cost:  0.997972592211744\n",
      "iteration:  110  cost:  1.0392943957164489\n",
      "iteration:  120  cost:  1.0027177088720318\n",
      "iteration:  130  cost:  1.0273185591188172\n",
      "iteration:  140  cost:  1.0271002455576062\n",
      "Accuracy for U_6 pca24 :0.5366430260047281\n",
      "Epoch 1/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.0876 - val_loss: 0.0254\n",
      "Epoch 2/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.0236 - val_loss: 0.0189\n",
      "Epoch 3/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.0180 - val_loss: 0.0147\n",
      "Epoch 4/10\n",
      "396/396 [==============================] - 1s 1ms/step - loss: 0.0141 - val_loss: 0.0122\n",
      "Epoch 5/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.0119 - val_loss: 0.0106\n",
      "Epoch 6/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.0104 - val_loss: 0.0094\n",
      "Epoch 7/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.0092 - val_loss: 0.0086\n",
      "Epoch 8/10\n",
      "396/396 [==============================] - 1s 1ms/step - loss: 0.0085 - val_loss: 0.0080\n",
      "Epoch 9/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.0080 - val_loss: 0.0077\n",
      "Epoch 10/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.0075 - val_loss: 0.0073\n",
      "\n",
      "\n",
      "Loss History for Hierarchical circuits, U_6 autoencoder24\n",
      "iteration:  0  cost:  1.4779204291733565\n",
      "iteration:  10  cost:  0.6285006890880526\n",
      "iteration:  20  cost:  0.6452757172479504\n",
      "iteration:  30  cost:  0.624721968068271\n",
      "iteration:  40  cost:  0.5463632377542283\n",
      "iteration:  50  cost:  0.48881946255163755\n",
      "iteration:  60  cost:  0.5823573465641873\n",
      "iteration:  70  cost:  0.38936835146542137\n",
      "iteration:  80  cost:  0.3899339831487466\n",
      "iteration:  90  cost:  0.4741875630574232\n",
      "iteration:  100  cost:  0.592227115708968\n",
      "iteration:  110  cost:  0.47893711170639397\n",
      "iteration:  120  cost:  0.38542416724439943\n",
      "iteration:  130  cost:  0.3610115559369166\n",
      "iteration:  140  cost:  0.3519414684254041\n",
      "Accuracy for U_6 autoencoder24 :0.8704491725768322\n",
      "\n",
      "\n",
      "Loss History for Hierarchical circuits, U_9 pca24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leeseok/.local/lib/python3.7/site-packages/autograd/tracer.py:14: UserWarning: Output seems independent of input.\n",
      "  warnings.warn(\"Output seems independent of input.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration:  0  cost:  1.0393626908627434\n",
      "iteration:  10  cost:  1.0043454064270723\n",
      "iteration:  20  cost:  0.9810154970928531\n",
      "iteration:  30  cost:  1.0353666099942405\n",
      "iteration:  40  cost:  1.022503651574295\n",
      "iteration:  50  cost:  0.9714064596107633\n",
      "iteration:  60  cost:  0.9884497977527457\n",
      "iteration:  70  cost:  0.9898100098059968\n",
      "iteration:  80  cost:  1.003980299243432\n",
      "iteration:  90  cost:  0.9859406385189189\n",
      "iteration:  100  cost:  0.9818148995278273\n",
      "iteration:  110  cost:  1.013954670415737\n",
      "iteration:  120  cost:  0.9883723436448122\n",
      "iteration:  130  cost:  1.0305266384072977\n",
      "iteration:  140  cost:  1.0325623232500727\n",
      "Accuracy for U_9 pca24 :0.4988179669030733\n",
      "Epoch 1/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.0879 - val_loss: 0.0261\n",
      "Epoch 2/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.0246 - val_loss: 0.0197\n",
      "Epoch 3/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.0184 - val_loss: 0.0150\n",
      "Epoch 4/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.0143 - val_loss: 0.0124\n",
      "Epoch 5/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.0120 - val_loss: 0.0108\n",
      "Epoch 6/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.0106 - val_loss: 0.0097\n",
      "Epoch 7/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.0095 - val_loss: 0.0089\n",
      "Epoch 8/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.0087 - val_loss: 0.0082\n",
      "Epoch 9/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.0082 - val_loss: 0.0078\n",
      "Epoch 10/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.0078 - val_loss: 0.0075\n",
      "\n",
      "\n",
      "Loss History for Hierarchical circuits, U_9 autoencoder24\n",
      "iteration:  0  cost:  2.0447365355644513\n",
      "iteration:  10  cost:  2.0541365750707805\n",
      "iteration:  20  cost:  2.039783840977441\n",
      "iteration:  30  cost:  1.7462756306888574\n",
      "iteration:  40  cost:  2.6961065568040725\n",
      "iteration:  50  cost:  1.5983879028754504\n",
      "iteration:  60  cost:  2.5158967022303225\n",
      "iteration:  70  cost:  2.3503093453853863\n",
      "iteration:  80  cost:  2.6121800531104116\n",
      "iteration:  90  cost:  2.2137459969000743\n",
      "iteration:  100  cost:  2.370508598947791\n",
      "iteration:  110  cost:  1.6061434886593011\n",
      "iteration:  120  cost:  2.208538127086783\n",
      "iteration:  130  cost:  1.9007493433381037\n",
      "iteration:  140  cost:  2.186189131882521\n",
      "Accuracy for U_9 autoencoder24 :0.46335697399527187\n",
      "\n",
      "\n",
      "Loss History for Hierarchical circuits, U_13 pca24\n",
      "iteration:  0  cost:  1.4306238801846536\n",
      "iteration:  10  cost:  0.9845527134725306\n",
      "iteration:  20  cost:  0.9821297463517173\n",
      "iteration:  30  cost:  0.9918741662803748\n",
      "iteration:  40  cost:  0.9983535384663398\n",
      "iteration:  50  cost:  1.0086589300938804\n",
      "iteration:  60  cost:  0.9850663600932286\n",
      "iteration:  70  cost:  1.016566893144898\n",
      "iteration:  80  cost:  1.0336382060922142\n",
      "iteration:  90  cost:  0.9957094550319863\n",
      "iteration:  100  cost:  0.9687586830241806\n",
      "iteration:  110  cost:  1.0286881405502157\n",
      "iteration:  120  cost:  1.0484711739236168\n",
      "iteration:  130  cost:  1.0326999083308896\n",
      "iteration:  140  cost:  1.0458679278018206\n",
      "Accuracy for U_13 pca24 :0.5470449172576832\n",
      "Epoch 1/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.0873 - val_loss: 0.0264\n",
      "Epoch 2/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.0250 - val_loss: 0.0195\n",
      "Epoch 3/10\n",
      "396/396 [==============================] - 1s 1ms/step - loss: 0.0185 - val_loss: 0.0152\n",
      "Epoch 4/10\n",
      "396/396 [==============================] - 1s 1ms/step - loss: 0.0145 - val_loss: 0.0126\n",
      "Epoch 5/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.0124 - val_loss: 0.0110\n",
      "Epoch 6/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.0109 - val_loss: 0.0099\n",
      "Epoch 7/10\n",
      "396/396 [==============================] - 1s 1ms/step - loss: 0.0101 - val_loss: 0.0090\n",
      "Epoch 8/10\n",
      "396/396 [==============================] - 1s 1ms/step - loss: 0.0091 - val_loss: 0.0085\n",
      "Epoch 9/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.0085 - val_loss: 0.0080\n",
      "Epoch 10/10\n",
      "396/396 [==============================] - 1s 1ms/step - loss: 0.0080 - val_loss: 0.0077\n",
      "\n",
      "\n",
      "Loss History for Hierarchical circuits, U_13 autoencoder24\n",
      "iteration:  0  cost:  1.0959514601379268\n",
      "iteration:  10  cost:  0.8775691048371906\n",
      "iteration:  20  cost:  0.7408692330625246\n",
      "iteration:  30  cost:  0.6862046479140851\n",
      "iteration:  40  cost:  0.5395749565951313\n",
      "iteration:  50  cost:  0.45047469284786573\n",
      "iteration:  60  cost:  0.6235964686266107\n",
      "iteration:  70  cost:  0.47121126934854396\n",
      "iteration:  80  cost:  0.6409511050251667\n",
      "iteration:  90  cost:  0.625440876065121\n",
      "iteration:  100  cost:  0.5194216931037119\n",
      "iteration:  110  cost:  0.5497408376944137\n",
      "iteration:  120  cost:  0.5341382818223638\n",
      "iteration:  130  cost:  0.45323389739383463\n",
      "iteration:  140  cost:  0.47240661281513396\n",
      "Accuracy for U_13 autoencoder24 :0.8912529550827423\n",
      "\n",
      "\n",
      "Loss History for Hierarchical circuits, U_14 pca24\n",
      "iteration:  0  cost:  1.341934915269764\n",
      "iteration:  10  cost:  1.103341352564546\n",
      "iteration:  20  cost:  1.0018493156266586\n",
      "iteration:  30  cost:  0.9705427936555605\n",
      "iteration:  40  cost:  1.0225242536374208\n",
      "iteration:  50  cost:  1.0185236928369639\n",
      "iteration:  60  cost:  0.9447358916960873\n",
      "iteration:  70  cost:  0.9912280531175577\n",
      "iteration:  80  cost:  0.9515674738357112\n",
      "iteration:  90  cost:  0.989504667446251\n",
      "iteration:  100  cost:  1.0190574638887404\n",
      "iteration:  110  cost:  0.9513219172098938\n",
      "iteration:  120  cost:  0.9568789675151216\n",
      "iteration:  130  cost:  0.991454273222805\n",
      "iteration:  140  cost:  0.957354326068969\n",
      "Accuracy for U_14 pca24 :0.5820330969267139\n",
      "Epoch 1/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.0889 - val_loss: 0.0261\n",
      "Epoch 2/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.0245 - val_loss: 0.0193\n",
      "Epoch 3/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.0181 - val_loss: 0.0150\n",
      "Epoch 4/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.0146 - val_loss: 0.0127\n",
      "Epoch 5/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.0125 - val_loss: 0.0111\n",
      "Epoch 6/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.0108 - val_loss: 0.0100\n",
      "Epoch 7/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.0099 - val_loss: 0.0092\n",
      "Epoch 8/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.0092 - val_loss: 0.0086\n",
      "Epoch 9/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.0086 - val_loss: 0.0081\n",
      "Epoch 10/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.0081 - val_loss: 0.0077\n",
      "\n",
      "\n",
      "Loss History for Hierarchical circuits, U_14 autoencoder24\n",
      "iteration:  0  cost:  2.16782263293487\n",
      "iteration:  10  cost:  1.0626122882129319\n",
      "iteration:  20  cost:  0.528721117601316\n",
      "iteration:  30  cost:  0.669634227193782\n",
      "iteration:  40  cost:  0.5852933006418942\n",
      "iteration:  50  cost:  0.6685472990706284\n",
      "iteration:  60  cost:  0.5894641414475863\n",
      "iteration:  70  cost:  0.46994123985564346\n",
      "iteration:  80  cost:  0.554604396789895\n",
      "iteration:  90  cost:  0.49343526831358325\n",
      "iteration:  100  cost:  0.604768341023207\n",
      "iteration:  110  cost:  0.4078651803623693\n",
      "iteration:  120  cost:  0.40654225936423194\n",
      "iteration:  130  cost:  0.5530246896152398\n",
      "iteration:  140  cost:  0.39732456512742387\n",
      "Accuracy for U_14 autoencoder24 :0.9139479905437352\n",
      "\n",
      "\n",
      "Loss History for Hierarchical circuits, U_15 pca24\n",
      "iteration:  0  cost:  0.9955627993568196\n",
      "iteration:  10  cost:  0.9849024317357795\n",
      "iteration:  20  cost:  0.9903075461240028\n",
      "iteration:  30  cost:  0.9129460389790797\n",
      "iteration:  40  cost:  0.9628133490617324\n",
      "iteration:  50  cost:  1.0051774106269762\n",
      "iteration:  60  cost:  1.0067335472245535\n",
      "iteration:  70  cost:  0.98479564588337\n",
      "iteration:  80  cost:  0.9962081251413002\n",
      "iteration:  90  cost:  0.995984048492033\n",
      "iteration:  100  cost:  0.9993409579095229\n",
      "iteration:  110  cost:  1.0060690322729782\n",
      "iteration:  120  cost:  1.0119236638946034\n",
      "iteration:  130  cost:  0.9963730063438\n",
      "iteration:  140  cost:  0.9999429199548411\n",
      "Accuracy for U_15 pca24 :0.5394799054373522\n",
      "Epoch 1/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.0872 - val_loss: 0.0245\n",
      "Epoch 2/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.0230 - val_loss: 0.0185\n",
      "Epoch 3/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.0175 - val_loss: 0.0146\n",
      "Epoch 4/10\n",
      "396/396 [==============================] - 1s 1ms/step - loss: 0.0140 - val_loss: 0.0124\n",
      "Epoch 5/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.0124 - val_loss: 0.0110\n",
      "Epoch 6/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.0108 - val_loss: 0.0099\n",
      "Epoch 7/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.0097 - val_loss: 0.0090\n",
      "Epoch 8/10\n",
      "396/396 [==============================] - 1s 1ms/step - loss: 0.0089 - val_loss: 0.0084\n",
      "Epoch 9/10\n",
      "396/396 [==============================] - 1s 1ms/step - loss: 0.0082 - val_loss: 0.0079\n",
      "Epoch 10/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.0078 - val_loss: 0.0075\n",
      "\n",
      "\n",
      "Loss History for Hierarchical circuits, U_15 autoencoder24\n",
      "iteration:  0  cost:  1.188335752336459\n",
      "iteration:  10  cost:  0.9000834839795248\n",
      "iteration:  20  cost:  0.6834261973658031\n",
      "iteration:  30  cost:  0.6781085044690329\n",
      "iteration:  40  cost:  0.6113473094652622\n",
      "iteration:  50  cost:  0.5821231292307736\n",
      "iteration:  60  cost:  0.6009682932859911\n",
      "iteration:  70  cost:  0.4637783423193415\n",
      "iteration:  80  cost:  0.5045489521187195\n",
      "iteration:  90  cost:  0.646143441084535\n",
      "iteration:  100  cost:  0.4017571388503707\n",
      "iteration:  110  cost:  0.5816855122415192\n",
      "iteration:  120  cost:  0.42520803742131813\n",
      "iteration:  130  cost:  0.44563678931431283\n",
      "iteration:  140  cost:  0.5167515014139734\n",
      "Accuracy for U_15 autoencoder24 :0.915839243498818\n",
      "\n",
      "\n",
      "Loss History for Hierarchical circuits, U_SO4 pca24\n",
      "iteration:  0  cost:  0.9602531249484646\n",
      "iteration:  10  cost:  1.0353369920909052\n",
      "iteration:  20  cost:  0.9988978080982694\n",
      "iteration:  30  cost:  0.9596595918466666\n",
      "iteration:  40  cost:  0.994481071639839\n",
      "iteration:  50  cost:  1.0015448996872063\n",
      "iteration:  60  cost:  1.001063696680856\n",
      "iteration:  70  cost:  0.9784302053612796\n",
      "iteration:  80  cost:  0.9207203164895121\n",
      "iteration:  90  cost:  0.9890718004841712\n",
      "iteration:  100  cost:  1.0365261055592645\n",
      "iteration:  110  cost:  0.9936792243523789\n",
      "iteration:  120  cost:  1.015859473427177\n",
      "iteration:  130  cost:  0.9925122833465087\n",
      "iteration:  140  cost:  0.9934575461841675\n",
      "Accuracy for U_SO4 pca24 :0.5366430260047281\n",
      "Epoch 1/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.0885 - val_loss: 0.0260\n",
      "Epoch 2/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.0244 - val_loss: 0.0184\n",
      "Epoch 3/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.0176 - val_loss: 0.0147\n",
      "Epoch 4/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.0144 - val_loss: 0.0125\n",
      "Epoch 5/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.0122 - val_loss: 0.0109\n",
      "Epoch 6/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.0107 - val_loss: 0.0097\n",
      "Epoch 7/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.0096 - val_loss: 0.0089\n",
      "Epoch 8/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.0088 - val_loss: 0.0084\n",
      "Epoch 9/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.0082 - val_loss: 0.0079\n",
      "Epoch 10/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.0079 - val_loss: 0.0076\n",
      "\n",
      "\n",
      "Loss History for Hierarchical circuits, U_SO4 autoencoder24\n",
      "iteration:  0  cost:  1.0956344517306822\n",
      "iteration:  10  cost:  0.7552335217364566\n",
      "iteration:  20  cost:  0.6591682278770336\n",
      "iteration:  30  cost:  0.5904910042269887\n",
      "iteration:  40  cost:  0.5837765938846857\n",
      "iteration:  50  cost:  0.6093824642040176\n",
      "iteration:  60  cost:  0.5990322393150589\n",
      "iteration:  70  cost:  0.6515388064641272\n",
      "iteration:  80  cost:  0.6027081555464602\n",
      "iteration:  90  cost:  0.6320093573785543\n",
      "iteration:  100  cost:  0.5622187671008665\n",
      "iteration:  110  cost:  0.6942639359765278\n",
      "iteration:  120  cost:  0.5820229224247008\n",
      "iteration:  130  cost:  0.5712808861884074\n",
      "iteration:  140  cost:  0.5411259175594784\n",
      "Accuracy for U_SO4 autoencoder24 :0.9706855791962175\n",
      "4th step : \n",
      "\n",
      "\n",
      "Loss History for Hierarchical circuits, U_TTN pca24\n",
      "iteration:  0  cost:  1.0000975292897178\n",
      "iteration:  10  cost:  1.0000131294447114\n",
      "iteration:  20  cost:  0.9999754945566626\n",
      "iteration:  30  cost:  0.9999907989458287\n",
      "iteration:  40  cost:  1.0000435063801174\n",
      "iteration:  50  cost:  0.9996690187983536\n",
      "iteration:  60  cost:  1.000103606066052\n",
      "iteration:  70  cost:  1.0000008699416127\n",
      "iteration:  80  cost:  1.0000005206999445\n",
      "iteration:  90  cost:  1.0000224016092363\n",
      "iteration:  100  cost:  0.9999986554970863\n",
      "iteration:  110  cost:  1.0000566322469333\n",
      "iteration:  120  cost:  1.0001434885438072\n",
      "iteration:  130  cost:  1.0001895311780042\n",
      "iteration:  140  cost:  1.0000278520725434\n",
      "Accuracy for U_TTN pca24 :0.42080378250591016\n",
      "Epoch 1/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.0881 - val_loss: 0.0265\n",
      "Epoch 2/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.0248 - val_loss: 0.0197\n",
      "Epoch 3/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.0186 - val_loss: 0.0151\n",
      "Epoch 4/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.0146 - val_loss: 0.0124\n",
      "Epoch 5/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.0122 - val_loss: 0.0107\n",
      "Epoch 6/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.0107 - val_loss: 0.0095\n",
      "Epoch 7/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.0095 - val_loss: 0.0087\n",
      "Epoch 8/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.0087 - val_loss: 0.0082\n",
      "Epoch 9/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.0082 - val_loss: 0.0077\n",
      "Epoch 10/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.0077 - val_loss: 0.0074\n",
      "\n",
      "\n",
      "Loss History for Hierarchical circuits, U_TTN autoencoder24\n",
      "iteration:  0  cost:  1.2299111855442146\n",
      "iteration:  10  cost:  0.632201654191207\n",
      "iteration:  20  cost:  0.4934966202143252\n",
      "iteration:  30  cost:  0.4493889651053597\n",
      "iteration:  40  cost:  0.4123521553424731\n",
      "iteration:  50  cost:  0.5400018180836317\n",
      "iteration:  60  cost:  0.3458636076414365\n",
      "iteration:  70  cost:  0.3741799126174257\n",
      "iteration:  80  cost:  0.4105152098474176\n",
      "iteration:  90  cost:  0.4010154190480735\n",
      "iteration:  100  cost:  0.3627705840334081\n",
      "iteration:  110  cost:  0.4367462531007572\n",
      "iteration:  120  cost:  0.3457164183195821\n",
      "iteration:  130  cost:  0.42430319725090415\n",
      "iteration:  140  cost:  0.43516132934643176\n",
      "Accuracy for U_TTN autoencoder24 :0.9130023640661938\n",
      "\n",
      "\n",
      "Loss History for Hierarchical circuits, U_5 pca24\n",
      "iteration:  0  cost:  1.1837396647936482\n",
      "iteration:  10  cost:  0.9158751777470193\n",
      "iteration:  20  cost:  0.9813671621641172\n",
      "iteration:  30  cost:  0.9813146748507893\n",
      "iteration:  40  cost:  1.0252410146184863\n",
      "iteration:  50  cost:  1.0019435868988436\n",
      "iteration:  60  cost:  1.0230390871150694\n",
      "iteration:  70  cost:  0.9336846487609552\n",
      "iteration:  80  cost:  0.9982522717158\n",
      "iteration:  90  cost:  0.9789810706578753\n",
      "iteration:  100  cost:  0.9277697835182112\n",
      "iteration:  110  cost:  1.0283964691807963\n",
      "iteration:  120  cost:  0.9950890647184287\n",
      "iteration:  130  cost:  1.0019214181402394\n",
      "iteration:  140  cost:  1.0525839469996667\n",
      "Accuracy for U_5 pca24 :0.5366430260047281\n",
      "Epoch 1/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.0893 - val_loss: 0.0255\n",
      "Epoch 2/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.0237 - val_loss: 0.0189\n",
      "Epoch 3/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.0180 - val_loss: 0.0144\n",
      "Epoch 4/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.0140 - val_loss: 0.0121\n",
      "Epoch 5/10\n",
      "396/396 [==============================] - 1s 1ms/step - loss: 0.0120 - val_loss: 0.0106\n",
      "Epoch 6/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.0106 - val_loss: 0.0095\n",
      "Epoch 7/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.0094 - val_loss: 0.0088\n",
      "Epoch 8/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.0088 - val_loss: 0.0083\n",
      "Epoch 9/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.0082 - val_loss: 0.0078\n",
      "Epoch 10/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.0078 - val_loss: 0.0075\n",
      "\n",
      "\n",
      "Loss History for Hierarchical circuits, U_5 autoencoder24\n",
      "iteration:  0  cost:  1.1275962860374302\n",
      "iteration:  10  cost:  0.7466613426983345\n",
      "iteration:  20  cost:  0.529633738848859\n",
      "iteration:  30  cost:  0.4227796712432088\n",
      "iteration:  40  cost:  0.6777389676688901\n",
      "iteration:  50  cost:  0.45572681706377355\n",
      "iteration:  60  cost:  0.5788746938007379\n",
      "iteration:  70  cost:  0.6235379133287963\n",
      "iteration:  80  cost:  0.5823307389911223\n",
      "iteration:  90  cost:  0.6202527898638122\n",
      "iteration:  100  cost:  0.6131436131311068\n",
      "iteration:  110  cost:  0.6823911445715614\n",
      "iteration:  120  cost:  0.6112444465673877\n",
      "iteration:  130  cost:  0.5299834816567273\n",
      "iteration:  140  cost:  0.6353014819877453\n",
      "Accuracy for U_5 autoencoder24 :0.7692671394799054\n",
      "\n",
      "\n",
      "Loss History for Hierarchical circuits, U_6 pca24\n",
      "iteration:  0  cost:  0.9449945682520746\n",
      "iteration:  10  cost:  1.0074785825493329\n",
      "iteration:  20  cost:  1.0315543059093313\n",
      "iteration:  30  cost:  1.0381617033460895\n",
      "iteration:  40  cost:  0.9672432924966631\n",
      "iteration:  50  cost:  0.9987803777112246\n",
      "iteration:  60  cost:  1.0091639683256872\n",
      "iteration:  70  cost:  0.970384231211476\n",
      "iteration:  80  cost:  1.028802977843654\n",
      "iteration:  90  cost:  1.0144064955210108\n",
      "iteration:  100  cost:  0.9986535934988696\n",
      "iteration:  110  cost:  0.9993577224851309\n",
      "iteration:  120  cost:  0.9992126020174896\n",
      "iteration:  130  cost:  0.9634621677831433\n",
      "iteration:  140  cost:  1.0014929698703654\n",
      "Accuracy for U_6 pca24 :0.5366430260047281\n",
      "Epoch 1/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.0875 - val_loss: 0.0251\n",
      "Epoch 2/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.0235 - val_loss: 0.0185\n",
      "Epoch 3/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.0177 - val_loss: 0.0143\n",
      "Epoch 4/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.0140 - val_loss: 0.0120\n",
      "Epoch 5/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.0118 - val_loss: 0.0105\n",
      "Epoch 6/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.0105 - val_loss: 0.0094\n",
      "Epoch 7/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.0094 - val_loss: 0.0086\n",
      "Epoch 8/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.0085 - val_loss: 0.0081\n",
      "Epoch 9/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.0080 - val_loss: 0.0076\n",
      "Epoch 10/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.0076 - val_loss: 0.0073\n",
      "\n",
      "\n",
      "Loss History for Hierarchical circuits, U_6 autoencoder24\n",
      "iteration:  0  cost:  0.7001476272571518\n",
      "iteration:  10  cost:  0.7827915599511411\n",
      "iteration:  20  cost:  0.5467955681862261\n",
      "iteration:  30  cost:  0.46315510769491586\n",
      "iteration:  40  cost:  0.6902305857970685\n",
      "iteration:  50  cost:  0.5744939230418228\n",
      "iteration:  60  cost:  0.5423397707202569\n",
      "iteration:  70  cost:  0.5905282302265481\n",
      "iteration:  80  cost:  0.6506027605743522\n",
      "iteration:  90  cost:  0.6035922362328124\n",
      "iteration:  100  cost:  0.48388182978234917\n",
      "iteration:  110  cost:  0.5467386302808679\n",
      "iteration:  120  cost:  0.492136997107695\n",
      "iteration:  130  cost:  0.7403117866709404\n",
      "iteration:  140  cost:  0.7789802260548698\n",
      "Accuracy for U_6 autoencoder24 :0.8666666666666667\n",
      "\n",
      "\n",
      "Loss History for Hierarchical circuits, U_9 pca24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leeseok/.local/lib/python3.7/site-packages/autograd/tracer.py:14: UserWarning: Output seems independent of input.\n",
      "  warnings.warn(\"Output seems independent of input.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration:  0  cost:  0.9804565338749075\n",
      "iteration:  10  cost:  1.0121983173126123\n",
      "iteration:  20  cost:  1.0212743275325167\n",
      "iteration:  30  cost:  1.0413833096048994\n",
      "iteration:  40  cost:  0.9823333564977923\n",
      "iteration:  50  cost:  0.999428430878267\n",
      "iteration:  60  cost:  0.9982094462270041\n",
      "iteration:  70  cost:  1.0039761445716504\n",
      "iteration:  80  cost:  1.0018317663314458\n",
      "iteration:  90  cost:  1.0002301374350488\n",
      "iteration:  100  cost:  0.9954367316815387\n",
      "iteration:  110  cost:  0.9863874432654923\n",
      "iteration:  120  cost:  1.0212201885544274\n",
      "iteration:  130  cost:  1.0099469162289945\n",
      "iteration:  140  cost:  0.9929014578071024\n",
      "Accuracy for U_9 pca24 :0.4988179669030733\n",
      "Epoch 1/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.0877 - val_loss: 0.0263\n",
      "Epoch 2/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.0249 - val_loss: 0.0198\n",
      "Epoch 3/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.0184 - val_loss: 0.0148\n",
      "Epoch 4/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.0142 - val_loss: 0.0122\n",
      "Epoch 5/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.0120 - val_loss: 0.0106\n",
      "Epoch 6/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.0105 - val_loss: 0.0096\n",
      "Epoch 7/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.0097 - val_loss: 0.0088\n",
      "Epoch 8/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.0087 - val_loss: 0.0082\n",
      "Epoch 9/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.0083 - val_loss: 0.0078\n",
      "Epoch 10/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.0077 - val_loss: 0.0074\n",
      "\n",
      "\n",
      "Loss History for Hierarchical circuits, U_9 autoencoder24\n",
      "iteration:  0  cost:  1.0715977853169654\n",
      "iteration:  10  cost:  2.4607672209062437\n",
      "iteration:  20  cost:  2.175708426344702\n",
      "iteration:  30  cost:  2.4693898747024154\n",
      "iteration:  40  cost:  2.546021583444943\n",
      "iteration:  50  cost:  1.8646685806360546\n",
      "iteration:  60  cost:  2.2823424823508374\n",
      "iteration:  70  cost:  2.0308180138312797\n",
      "iteration:  80  cost:  2.104836785221467\n",
      "iteration:  90  cost:  1.9427371990546016\n",
      "iteration:  100  cost:  1.5769507929264963\n",
      "iteration:  110  cost:  1.885467590744957\n",
      "iteration:  120  cost:  2.2355604883582543\n",
      "iteration:  130  cost:  1.893070892332031\n",
      "iteration:  140  cost:  2.1827149834504267\n",
      "Accuracy for U_9 autoencoder24 :0.4595744680851064\n",
      "\n",
      "\n",
      "Loss History for Hierarchical circuits, U_13 pca24\n",
      "iteration:  0  cost:  1.0805736611688157\n",
      "iteration:  10  cost:  1.0280123559047174\n",
      "iteration:  20  cost:  1.0142569649310027\n",
      "iteration:  30  cost:  0.9980274321687729\n",
      "iteration:  40  cost:  0.9846961114161086\n",
      "iteration:  50  cost:  0.9999257506067153\n",
      "iteration:  60  cost:  0.9514557441288976\n",
      "iteration:  70  cost:  0.9616181755815413\n",
      "iteration:  80  cost:  0.9644371621579338\n",
      "iteration:  90  cost:  0.9485085110728059\n",
      "iteration:  100  cost:  0.9950665128623963\n",
      "iteration:  110  cost:  1.045285357596925\n",
      "iteration:  120  cost:  0.9795108735025067\n",
      "iteration:  130  cost:  0.9628570831570445\n",
      "iteration:  140  cost:  1.0282343161973586\n",
      "Accuracy for U_13 pca24 :0.5394799054373522\n",
      "Epoch 1/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.0858 - val_loss: 0.0267\n",
      "Epoch 2/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.0251 - val_loss: 0.0198\n",
      "Epoch 3/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.0186 - val_loss: 0.0151\n",
      "Epoch 4/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.0146 - val_loss: 0.0127\n",
      "Epoch 5/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.0124 - val_loss: 0.0111\n",
      "Epoch 6/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.0111 - val_loss: 0.0100\n",
      "Epoch 7/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.0099 - val_loss: 0.0092\n",
      "Epoch 8/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.0092 - val_loss: 0.0086\n",
      "Epoch 9/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.0087 - val_loss: 0.0081\n",
      "Epoch 10/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.0081 - val_loss: 0.0078\n",
      "\n",
      "\n",
      "Loss History for Hierarchical circuits, U_13 autoencoder24\n",
      "iteration:  0  cost:  1.1486573374674698\n",
      "iteration:  10  cost:  0.83203427668702\n",
      "iteration:  20  cost:  0.3976630572510668\n",
      "iteration:  30  cost:  0.4841077931186925\n",
      "iteration:  40  cost:  0.44093488011808896\n",
      "iteration:  50  cost:  0.3694345652881326\n",
      "iteration:  60  cost:  0.34767009432113033\n",
      "iteration:  70  cost:  0.43947976138270467\n",
      "iteration:  80  cost:  0.41153200684431085\n",
      "iteration:  90  cost:  0.38616963791306225\n",
      "iteration:  100  cost:  0.40800687752246634\n",
      "iteration:  110  cost:  0.4012183731288487\n",
      "iteration:  120  cost:  0.6514753512462157\n",
      "iteration:  130  cost:  0.38452038392159593\n",
      "iteration:  140  cost:  0.39111029963466387\n",
      "Accuracy for U_13 autoencoder24 :0.9361702127659575\n",
      "\n",
      "\n",
      "Loss History for Hierarchical circuits, U_14 pca24\n",
      "iteration:  0  cost:  0.9991993865065198\n",
      "iteration:  10  cost:  0.9892211637601044\n",
      "iteration:  20  cost:  1.0232219254666557\n",
      "iteration:  30  cost:  1.1800140871220426\n",
      "iteration:  40  cost:  1.0189432721000573\n",
      "iteration:  50  cost:  0.9963403051877563\n",
      "iteration:  60  cost:  0.965260775642496\n",
      "iteration:  70  cost:  0.9787176684052633\n",
      "iteration:  80  cost:  0.9836172776864852\n",
      "iteration:  90  cost:  0.9594189129463984\n",
      "iteration:  100  cost:  0.9970882728082529\n",
      "iteration:  110  cost:  0.9401202435377788\n",
      "iteration:  120  cost:  0.9712911873695222\n",
      "iteration:  130  cost:  1.0241920885278244\n",
      "iteration:  140  cost:  0.988627637953416\n",
      "Accuracy for U_14 pca24 :0.5375886524822695\n",
      "Epoch 1/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.0851 - val_loss: 0.0265\n",
      "Epoch 2/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.0249 - val_loss: 0.0196\n",
      "Epoch 3/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.0186 - val_loss: 0.0150\n",
      "Epoch 4/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.0143 - val_loss: 0.0124\n",
      "Epoch 5/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.0123 - val_loss: 0.0108\n",
      "Epoch 6/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.0107 - val_loss: 0.0097\n",
      "Epoch 7/10\n",
      "396/396 [==============================] - 1s 1ms/step - loss: 0.0097 - val_loss: 0.0089\n",
      "Epoch 8/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.0089 - val_loss: 0.0083\n",
      "Epoch 9/10\n",
      "396/396 [==============================] - 1s 1ms/step - loss: 0.0082 - val_loss: 0.0078\n",
      "Epoch 10/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.0079 - val_loss: 0.0075\n",
      "\n",
      "\n",
      "Loss History for Hierarchical circuits, U_14 autoencoder24\n",
      "iteration:  0  cost:  2.448246998808374\n",
      "iteration:  10  cost:  0.7885822501811474\n",
      "iteration:  20  cost:  0.8211083512811753\n",
      "iteration:  30  cost:  0.8034193241099414\n",
      "iteration:  40  cost:  0.6571340631086312\n",
      "iteration:  50  cost:  0.8002055641257507\n",
      "iteration:  60  cost:  0.5598372775386192\n",
      "iteration:  70  cost:  0.5934910116162336\n",
      "iteration:  80  cost:  0.6155099083968573\n",
      "iteration:  90  cost:  0.5668742551000812\n",
      "iteration:  100  cost:  0.49076530956337805\n",
      "iteration:  110  cost:  0.4911713687535075\n",
      "iteration:  120  cost:  0.6002507258808574\n",
      "iteration:  130  cost:  0.8269758951343087\n",
      "iteration:  140  cost:  0.4767652688913466\n",
      "Accuracy for U_14 autoencoder24 :0.9186761229314421\n",
      "\n",
      "\n",
      "Loss History for Hierarchical circuits, U_15 pca24\n",
      "iteration:  0  cost:  1.1350117625557552\n",
      "iteration:  10  cost:  1.0104313180136744\n",
      "iteration:  20  cost:  1.1088509124178811\n",
      "iteration:  30  cost:  1.0000108420014684\n",
      "iteration:  40  cost:  0.998582561949283\n",
      "iteration:  50  cost:  0.9916250985458965\n",
      "iteration:  60  cost:  0.9954903902560481\n",
      "iteration:  70  cost:  0.9876974566124046\n",
      "iteration:  80  cost:  0.9954185235969429\n",
      "iteration:  90  cost:  1.0466201518282894\n",
      "iteration:  100  cost:  1.0243073039804873\n",
      "iteration:  110  cost:  0.9989286369439127\n",
      "iteration:  120  cost:  0.9995492757830007\n",
      "iteration:  130  cost:  1.0253683928700053\n",
      "iteration:  140  cost:  0.9931287272457959\n",
      "Accuracy for U_15 pca24 :0.5408983451536643\n",
      "Epoch 1/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.0868 - val_loss: 0.0262\n",
      "Epoch 2/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.0247 - val_loss: 0.0190\n",
      "Epoch 3/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.0179 - val_loss: 0.0146\n",
      "Epoch 4/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.0142 - val_loss: 0.0122\n",
      "Epoch 5/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.0120 - val_loss: 0.0106\n",
      "Epoch 6/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.0106 - val_loss: 0.0096\n",
      "Epoch 7/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.0094 - val_loss: 0.0088\n",
      "Epoch 8/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.0088 - val_loss: 0.0082\n",
      "Epoch 9/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.0083 - val_loss: 0.0078\n",
      "Epoch 10/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.0079 - val_loss: 0.0075\n",
      "\n",
      "\n",
      "Loss History for Hierarchical circuits, U_15 autoencoder24\n",
      "iteration:  0  cost:  0.9431204684385633\n",
      "iteration:  10  cost:  0.47747444741708606\n",
      "iteration:  20  cost:  0.42031411962714244\n",
      "iteration:  30  cost:  0.4201882532445475\n",
      "iteration:  40  cost:  0.4417199617273741\n",
      "iteration:  50  cost:  0.5450793837131023\n",
      "iteration:  60  cost:  0.4112782700406868\n",
      "iteration:  70  cost:  0.43356437008675164\n",
      "iteration:  80  cost:  0.3175649967195842\n",
      "iteration:  90  cost:  0.476186407649015\n",
      "iteration:  100  cost:  0.4461425525777378\n",
      "iteration:  110  cost:  0.40163759800535337\n",
      "iteration:  120  cost:  0.35370050400868996\n",
      "iteration:  130  cost:  0.41373333137157325\n",
      "iteration:  140  cost:  0.32322103100787347\n",
      "Accuracy for U_15 autoencoder24 :0.9513002364066194\n",
      "\n",
      "\n",
      "Loss History for Hierarchical circuits, U_SO4 pca24\n",
      "iteration:  0  cost:  1.0051872333634058\n",
      "iteration:  10  cost:  1.0049514019652654\n",
      "iteration:  20  cost:  0.9187800532654289\n",
      "iteration:  30  cost:  1.0951606826985119\n",
      "iteration:  40  cost:  0.99345227775165\n",
      "iteration:  50  cost:  1.0026058367277009\n",
      "iteration:  60  cost:  1.000892721300386\n",
      "iteration:  70  cost:  1.0083366000398502\n",
      "iteration:  80  cost:  0.9908322778809459\n",
      "iteration:  90  cost:  0.9791266522245355\n",
      "iteration:  100  cost:  1.0187012676982057\n",
      "iteration:  110  cost:  1.0014322192185794\n",
      "iteration:  120  cost:  1.0019697587379943\n",
      "iteration:  130  cost:  0.986205513104775\n",
      "iteration:  140  cost:  0.9964161665681511\n",
      "Accuracy for U_SO4 pca24 :0.5366430260047281\n",
      "Epoch 1/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.0867 - val_loss: 0.0255\n",
      "Epoch 2/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.0236 - val_loss: 0.0186\n",
      "Epoch 3/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.0175 - val_loss: 0.0145\n",
      "Epoch 4/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.0139 - val_loss: 0.0122\n",
      "Epoch 5/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.0122 - val_loss: 0.0108\n",
      "Epoch 6/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.0106 - val_loss: 0.0098\n",
      "Epoch 7/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.0096 - val_loss: 0.0090\n",
      "Epoch 8/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.0089 - val_loss: 0.0084\n",
      "Epoch 9/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.0084 - val_loss: 0.0080\n",
      "Epoch 10/10\n",
      "396/396 [==============================] - 1s 2ms/step - loss: 0.0078 - val_loss: 0.0076\n",
      "\n",
      "\n",
      "Loss History for Hierarchical circuits, U_SO4 autoencoder24\n",
      "iteration:  0  cost:  1.2292515551506222\n",
      "iteration:  10  cost:  0.817713763263572\n",
      "iteration:  20  cost:  0.7019433501187325\n",
      "iteration:  30  cost:  0.7690041553356114\n",
      "iteration:  40  cost:  0.7204371134153393\n",
      "iteration:  50  cost:  0.6131029501819352\n",
      "iteration:  60  cost:  0.6313884846221962\n",
      "iteration:  70  cost:  0.529155988168542\n",
      "iteration:  80  cost:  0.5658845004016633\n",
      "iteration:  90  cost:  0.808632621619502\n",
      "iteration:  100  cost:  0.5760483614839111\n",
      "iteration:  110  cost:  0.6692552826640218\n",
      "iteration:  120  cost:  0.664477939478284\n",
      "iteration:  130  cost:  0.6101965198164813\n",
      "iteration:  140  cost:  0.6433225947952548\n",
      "Accuracy for U_SO4 autoencoder24 :0.766903073286052\n",
      "[0.574468085106383, 0.8250591016548463, 0.5366430260047281, 0.8539007092198582, 0.5451536643026005, 0.9163120567375886, 0.4988179669030733, 0.46335697399527187, 0.5470449172576832, 0.8832151300236407, 0.4912529550827423, 0.742789598108747, 0.4293144208037825, 0.902127659574468, 0.5366430260047281, 0.8893617021276595, 0.5328605200945626, 0.742789598108747, 0.5371158392434988, 0.8936170212765957, 0.5371158392434988, 0.957919621749409, 0.4988179669030733, 0.4628841607565012, 0.4302600472813239, 0.9432624113475178, 0.5721040189125296, 0.8723404255319149, 0.5394799054373522, 0.873758865248227, 0.5366430260047281, 0.8283687943262411, 0.5498817966903073, 0.8699763593380615, 0.5423167848699764, 0.908274231678487, 0.5366430260047281, 0.9087470449172577, 0.4988179669030733, 0.46335697399527187, 0.5380614657210402, 0.9054373522458629, 0.548936170212766, 0.8761229314420804, 0.5408983451536643, 0.9106382978723404, 0.5366430260047281, 0.8293144208037825, 0.49976359338061466, 0.7120567375886525, 0.5366430260047281, 0.8973995271867612, 0.5366430260047281, 0.8704491725768322, 0.4988179669030733, 0.46335697399527187, 0.5470449172576832, 0.8912529550827423, 0.5820330969267139, 0.9139479905437352, 0.5394799054373522, 0.915839243498818, 0.5366430260047281, 0.9706855791962175, 0.42080378250591016, 0.9130023640661938, 0.5366430260047281, 0.7692671394799054, 0.5366430260047281, 0.8666666666666667, 0.4988179669030733, 0.4595744680851064, 0.5394799054373522, 0.9361702127659575, 0.5375886524822695, 0.9186761229314421, 0.5408983451536643, 0.9513002364066194, 0.5366430260047281, 0.766903073286052]\n"
     ]
    }
   ],
   "source": [
    "Benchmarking(Unitaries, U_num_params, Encodings, circuit, binary = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = [0.574468085106383, 0.8250591016548463, 0.5366430260047281, 0.8539007092198582, 0.5451536643026005, 0.9163120567375886, 0.4988179669030733, 0.46335697399527187, 0.5470449172576832, 0.8832151300236407, 0.4912529550827423, 0.742789598108747, 0.4293144208037825, 0.902127659574468, 0.5366430260047281, 0.8893617021276595, 0.5328605200945626, 0.742789598108747, 0.5371158392434988, 0.8936170212765957, 0.5371158392434988, 0.957919621749409, 0.4988179669030733, 0.4628841607565012, 0.4302600472813239, 0.9432624113475178, 0.5721040189125296, 0.8723404255319149, 0.5394799054373522, 0.873758865248227, 0.5366430260047281, 0.8283687943262411, 0.5498817966903073, 0.8699763593380615, 0.5423167848699764, 0.908274231678487, 0.5366430260047281, 0.9087470449172577, 0.4988179669030733, 0.46335697399527187, 0.5380614657210402, 0.9054373522458629, 0.548936170212766, 0.8761229314420804, 0.5408983451536643, 0.9106382978723404, 0.5366430260047281, 0.8293144208037825, 0.49976359338061466, 0.7120567375886525, 0.5366430260047281, 0.8973995271867612, 0.5366430260047281, 0.8704491725768322, 0.4988179669030733, 0.46335697399527187, 0.5470449172576832, 0.8912529550827423, 0.5820330969267139, 0.9139479905437352, 0.5394799054373522, 0.915839243498818, 0.5366430260047281, 0.9706855791962175, 0.42080378250591016, 0.9130023640661938, 0.5366430260047281, 0.7692671394799054, 0.5366430260047281, 0.8666666666666667, 0.4988179669030733, 0.4595744680851064, 0.5394799054373522, 0.9361702127659575, 0.5375886524822695, 0.9186761229314421, 0.5408983451536643, 0.9513002364066194, 0.5366430260047281, 0.766903073286052]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_list = []\n",
    "for i in range(16):\n",
    "    #print(results[i], results[i+21], results[i+2*21], results[i+3*21], results[i+4*21])\n",
    "    results_list.append([results[i], results[i+16], results[i+2*16], results[i+3*16], results[i+4*16]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for Hierarchical with Compact-Compact Embedding (Ry-Rz-Ry) with 5 random initializations\n",
      "\n",
      "U_TTN pca24 Mean : 0.5155555555555555 U_TTN pca24 Variance : 0.0035439308329002026\n",
      "U_TTN Autoencoding24 Mean : 0.8125768321513003 U_TTN Autoencoding24 Variance : 0.007127586919951489\n",
      "U_5 pca24 Mean : 0.5378723404255319 U_5 pca24 Variance : 6.2147555734397624e-06\n",
      "U_5 Autoencoding24 Mean : 0.8644917257683215 U_5 Autoencoding24 Variance : 0.0032570013804358133\n",
      "U_6 pca24 Mean : 0.5384397163120568 U_6 pca24 Variance : 1.4128509073431402e-05\n",
      "U_6 Autoencoding24 Mean : 0.9040189125295508 U_6 Autoencoding24 Variance : 0.0014002201990733756\n",
      "U_9 pca24 Mean : 0.4988179669030733 U_9 pca24 Variance : 0.0\n",
      "U_9 Autoencoding24 Mean : 0.46250591016548465 U_9 Autoencoding24 Variance : 2.727338776833277e-06\n",
      "U_13 pca24 Mean : 0.5203782505910166 U_13 pca24 Variance : 0.0025552705262981406\n",
      "U_13 Autoencoding24 Mean : 0.9118676122931442 U_13 Autoencoding24 Variance : 0.0007158817184469823\n",
      "U_14 pca24 Mean : 0.5463829787234042 U_14 pca24 Variance : 0.001263920325939339\n",
      "U_14 Autoencoding24 Mean : 0.864775413711584 U_14 Autoencoding24 Variance : 0.005097440884373134\n",
      "U_15 pca24 Mean : 0.5180141843971631 U_15 pca24 Variance : 0.0024591430120327056\n",
      "U_15 Autoencoding24 Mean : 0.9107328605200946 U_15 Autoencoding24 Variance : 0.0007782304713042606\n",
      "SO(4) pca24 Mean : 0.5366430260047281 SO(4) pca24 Variance : 0.0\n",
      "SO(4) Autoencoding24 Mean : 0.8569267139479905 SO(4) Autoencoding24 Variance : 0.005918839316153332\n"
     ]
    }
   ],
   "source": [
    "print(\"Results for Hierarchical with Compact-Compact Embedding (Rz-Rz-Ry) with 5 random initializations\")\n",
    "print(\"\")\n",
    "for i in range(16):\n",
    "    if i < 2:\n",
    "        it = \"U_TTN\"\n",
    "    elif 1<i<4:\n",
    "        it = 'U_5'\n",
    "    elif 3<i<6:\n",
    "        it = 'U_6'\n",
    "    elif 5<i<8:\n",
    "        it = 'U_9'\n",
    "    elif 7<i<10:\n",
    "        it = 'U_13'\n",
    "    elif 9<i<12:\n",
    "        it = 'U_14'\n",
    "    elif 11<i<14:\n",
    "        it = 'U_15'\n",
    "    else:\n",
    "        it = 'SO(4)'\n",
    "    \n",
    "    if i % 2 == 0:\n",
    "        emb = \"pca24\"\n",
    "    else:\n",
    "        emb = \"Autoencoding24\"\n",
    "        \n",
    "    print(it + \" \" + emb + \" Mean : \" + str(st.mean(results_list[i])),  it + \" \" + emb + \" Variance : \" + str(st.variance(results_list[i])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
